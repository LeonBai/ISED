{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31209e87-3070-4aa6-8001-0d3ef2e40301",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import MARBLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b51e9c04-17db-4d84-8fe7-8820133cfd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb4c8cf-7980-4db7-87a6-afaaec477c03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a622c9-fda6-4c62-a0e9-65335ae02165",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../'\n",
    "\n",
    "np.save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70bfc6e-60be-4dfc-b247-d6867007cf4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a1ec1b-faac-4615-841e-0f5863cae875",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05473f4e-7e0d-4012-a9e7-2d0dc12d6139",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5223e22-21bd-4ad5-b1de-3c2b9559065f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../SeED/dataset/Xs.pkl','rb') as file:\n",
    "    \n",
    "    raw_data = pickle.load(file)\n",
    "    \n",
    "from sklearn import preprocessing\n",
    "\n",
    "X_trains = []\n",
    "X_tests = []\n",
    "\n",
    "for i in range(3):\n",
    "    X_normalized = preprocessing.MinMaxScaler().fit_transform(raw_data[i])\n",
    "\n",
    "    train_data = X_normalized[:500]\n",
    "    test_data = X_normalized[500:500+320]\n",
    "    X_trains.append(train_data)\n",
    "    X_tests.append(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e20dc4c7-13c7-474f-aeae-a00d3b15c317",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(320, 100)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tests[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f047a23d-40bf-499f-9d61-89c1ce8f0bf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---- Embedding dimension: 100\n",
      "---- Signal dimension: 100\n",
      "---- Computing kernels ... \n",
      "---- Computing full spectrum ...\n",
      "              (if this takes too long, then run construct_dataset()\n",
      "              with number_of_eigenvectors specified) \n",
      "---- Embedding dimension: 100\n",
      "---- Signal dimension: 100\n",
      "---- Computing kernels ... \n",
      "---- Computing full spectrum ...\n",
      "              (if this takes too long, then run construct_dataset()\n",
      "              with number_of_eigenvectors specified) "
     ]
    }
   ],
   "source": [
    "Train_data_marble = MARBLE.construct_dataset(anchor=[train_data], vector=[train_data], k =100)\n",
    "Test_data_marble = MARBLE.construct_dataset(anchor=[test_data], vector=[test_data], k =100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7bd7b54c-9a08-4726-9f6b-7f0fcc803bf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---- Settings: \n",
      "\n",
      "epochs : 1000\n",
      "hidden_channels : [32]\n",
      "out_channels : 2\n",
      "inner_product_features : False\n",
      "batch_size : 64\n",
      "lr : 0.01\n",
      "momentum : 0.9\n",
      "dropout : 0.0\n",
      "batch_norm : batch_norm\n",
      "bias : True\n",
      "order : 2\n",
      "diffusion : True\n",
      "frac_sampled_nb : -1\n",
      "include_positions : False\n",
      "include_self : True\n",
      "vec_norm : False\n",
      "emb_norm : False\n",
      "seed : 0\n",
      "dim_signal : 100\n",
      "dim_emb : 100\n",
      "n_sampled_nb : -1\n",
      "\n",
      "---- Number of features to pass to the MLP:  1010100\n",
      "---- Total number of parameters:  32323363\n",
      "\n",
      "Using device cuda:0\n"
     ]
    }
   ],
   "source": [
    "params = {'epochs': 1000, #optimisation epochs\n",
    "          'hidden_channels': 10, #number of internal dimensions in MLP\n",
    "          'out_channels': 2,\n",
    "          'inner_product_features': False, ## Control over the embedding-aware or agnostic \n",
    "         }\n",
    "model = MARBLE.net(Train_data_marble, params= params, )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d692f1aa-3234-45ba-9e3c-4cdbd5b6a9fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---- Training network ...\n",
      "\n",
      "---- Timestamp: 20250612-192642\n",
      "\n",
      " *och: 0, Training loss: 1.480389, Validation loss: 1.4487, lr: 0.0100\n",
      " *och: 1, Training loss: 1.401148, Validation loss: 1.3921, lr: 0.0100\n",
      " *och: 2, Training loss: 1.407600, Validation loss: 1.3888, lr: 0.0100\n",
      " *och: 3, Training loss: 1.390185, Validation loss: 1.3819, lr: 0.0100\n",
      "Epoch: 4, Training loss: 1.401833, Validation loss: 1.3859, lr: 0.0100\n",
      "Epoch: 5, Training loss: 1.388259, Validation loss: 1.3827, lr: 0.0100\n",
      "Epoch: 6, Training loss: 1.385875, Validation loss: 1.3863, lr: 0.0100\n",
      "Epoch: 7, Training loss: 1.389462, Validation loss: 1.3861, lr: 0.0100\n",
      "Epoch: 8, Training loss: 1.384147, Validation loss: 1.3857, lr: 0.0100\n",
      "Epoch: 9, Training loss: 1.389648, Validation loss: 1.3866, lr: 0.0100\n",
      "Epoch: 10, Training loss: 1.387929, Validation loss: 1.3913, lr: 0.0100\n",
      " *och: 11, Training loss: 1.386161, Validation loss: 1.3714, lr: 0.0100\n",
      " *och: 12, Training loss: 1.378184, Validation loss: 1.3710, lr: 0.0100\n",
      "Epoch: 13, Training loss: 1.378648, Validation loss: 1.3846, lr: 0.0100\n",
      "Epoch: 14, Training loss: 1.399626, Validation loss: 1.4206, lr: 0.0100\n",
      "Epoch: 15, Training loss: 1.394215, Validation loss: 1.3850, lr: 0.0100\n",
      "Epoch: 16, Training loss: 1.390341, Validation loss: 1.3843, lr: 0.0100\n",
      "Epoch: 17, Training loss: 1.379322, Validation loss: 1.3864, lr: 0.0100\n",
      "Epoch: 18, Training loss: 1.378106, Validation loss: 1.3814, lr: 0.0100\n",
      "Epoch: 19, Training loss: 1.386068, Validation loss: 1.3776, lr: 0.0100\n",
      "Epoch: 20, Training loss: 1.392836, Validation loss: 1.3862, lr: 0.0100\n",
      "Epoch: 21, Training loss: 1.386642, Validation loss: 1.3860, lr: 0.0100\n",
      "Epoch: 22, Training loss: 1.387044, Validation loss: 1.3870, lr: 0.0100\n",
      "Epoch: 23, Training loss: 1.399913, Validation loss: 1.3852, lr: 0.0010\n",
      "Epoch: 24, Training loss: 1.401242, Validation loss: 1.3825, lr: 0.0010\n",
      "Epoch: 25, Training loss: 1.401367, Validation loss: 1.3869, lr: 0.0010\n",
      "Epoch: 26, Training loss: 1.386070, Validation loss: 1.3870, lr: 0.0010\n",
      "Epoch: 27, Training loss: 1.383713, Validation loss: 1.3831, lr: 0.0010\n",
      "Epoch: 28, Training loss: 1.384114, Validation loss: 1.3862, lr: 0.0010\n",
      "Epoch: 29, Training loss: 1.384594, Validation loss: 1.3855, lr: 0.0010\n",
      "Epoch: 30, Training loss: 1.382128, Validation loss: 1.3767, lr: 0.0010\n",
      "Epoch: 31, Training loss: 1.389202, Validation loss: 1.3861, lr: 0.0010\n",
      "Epoch: 32, Training loss: 1.389131, Validation loss: 1.3855, lr: 0.0010\n",
      "Epoch: 33, Training loss: 1.380257, Validation loss: 1.3726, lr: 0.0010\n",
      "Epoch: 34, Training loss: 1.382572, Validation loss: 1.3865, lr: 0.0001\n",
      "Epoch: 35, Training loss: 1.380914, Validation loss: 1.3861, lr: 0.0001\n",
      "Epoch: 36, Training loss: 1.381247, Validation loss: 1.3838, lr: 0.0001\n",
      "Epoch: 37, Training loss: 1.382889, Validation loss: 1.3885, lr: 0.0001\n",
      "Epoch: 38, Training loss: 1.386802, Validation loss: 1.3801, lr: 0.0001\n",
      "Epoch: 39, Training loss: 1.383778, Validation loss: 1.3847, lr: 0.0001\n",
      "Epoch: 40, Training loss: 1.381602, Validation loss: 1.3859, lr: 0.0001\n",
      "Epoch: 41, Training loss: 1.380300, Validation loss: 1.3870, lr: 0.0001\n",
      "Epoch: 42, Training loss: 1.379227, Validation loss: 1.3757, lr: 0.0001\n",
      "Epoch: 43, Training loss: 1.386695, Validation loss: 1.3852, lr: 0.0001\n",
      "Epoch: 44, Training loss: 1.388356, Validation loss: 1.3853, lr: 0.0001\n",
      "Epoch: 45, Training loss: 1.385154, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 46, Training loss: 1.381109, Validation loss: 1.3886, lr: 0.0000\n",
      "Epoch: 47, Training loss: 1.380835, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 48, Training loss: 1.384205, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 49, Training loss: 1.378619, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 50, Training loss: 1.380905, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 51, Training loss: 1.385494, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 52, Training loss: 1.384538, Validation loss: 1.3881, lr: 0.0000\n",
      "Epoch: 53, Training loss: 1.383274, Validation loss: 1.3871, lr: 0.0000\n",
      "Epoch: 54, Training loss: 1.388216, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 55, Training loss: 1.379777, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 56, Training loss: 1.375215, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 57, Training loss: 1.390273, Validation loss: 1.3881, lr: 0.0000\n",
      "Epoch: 58, Training loss: 1.379886, Validation loss: 1.3797, lr: 0.0000\n",
      "Epoch: 59, Training loss: 1.381410, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 60, Training loss: 1.377865, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 61, Training loss: 1.383177, Validation loss: 1.3875, lr: 0.0000\n",
      "Epoch: 62, Training loss: 1.386738, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 63, Training loss: 1.382166, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 64, Training loss: 1.384633, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 65, Training loss: 1.385600, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 66, Training loss: 1.383514, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 67, Training loss: 1.381753, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 68, Training loss: 1.381827, Validation loss: 1.3881, lr: 0.0000\n",
      "Epoch: 69, Training loss: 1.381598, Validation loss: 1.3871, lr: 0.0000\n",
      "Epoch: 70, Training loss: 1.377725, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 71, Training loss: 1.386600, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 72, Training loss: 1.377228, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 73, Training loss: 1.381151, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 74, Training loss: 1.381386, Validation loss: 1.3874, lr: 0.0000\n",
      "Epoch: 75, Training loss: 1.379699, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 76, Training loss: 1.380854, Validation loss: 1.3729, lr: 0.0000\n",
      "Epoch: 77, Training loss: 1.388366, Validation loss: 1.3791, lr: 0.0000\n",
      "Epoch: 78, Training loss: 1.384682, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 79, Training loss: 1.388173, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 80, Training loss: 1.382557, Validation loss: 1.3861, lr: 0.0000\n",
      " *och: 81, Training loss: 1.384026, Validation loss: 1.3660, lr: 0.0000\n",
      "Epoch: 82, Training loss: 1.381708, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 83, Training loss: 1.386213, Validation loss: 1.3865, lr: 0.0000\n",
      " *och: 84, Training loss: 1.389997, Validation loss: 1.3608, lr: 0.0000\n",
      "Epoch: 85, Training loss: 1.382592, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 86, Training loss: 1.384012, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 87, Training loss: 1.382619, Validation loss: 1.3909, lr: 0.0000\n",
      "Epoch: 88, Training loss: 1.385588, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 89, Training loss: 1.385803, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 90, Training loss: 1.379989, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 91, Training loss: 1.386295, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 92, Training loss: 1.378029, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 93, Training loss: 1.384855, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 94, Training loss: 1.383625, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 95, Training loss: 1.386003, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 96, Training loss: 1.382294, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 97, Training loss: 1.382676, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 98, Training loss: 1.391347, Validation loss: 1.3646, lr: 0.0000\n",
      "Epoch: 99, Training loss: 1.382419, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 100, Training loss: 1.391295, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 101, Training loss: 1.382962, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 102, Training loss: 1.385628, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 103, Training loss: 1.377601, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 104, Training loss: 1.381289, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 105, Training loss: 1.386730, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 106, Training loss: 1.381613, Validation loss: 1.3881, lr: 0.0000\n",
      "Epoch: 107, Training loss: 1.383363, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 108, Training loss: 1.383189, Validation loss: 1.3722, lr: 0.0000\n",
      "Epoch: 109, Training loss: 1.381283, Validation loss: 1.3900, lr: 0.0000\n",
      "Epoch: 110, Training loss: 1.382739, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 111, Training loss: 1.384572, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 112, Training loss: 1.377550, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 113, Training loss: 1.376608, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 114, Training loss: 1.386742, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 115, Training loss: 1.384221, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 116, Training loss: 1.381220, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 117, Training loss: 1.382825, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 118, Training loss: 1.384661, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 119, Training loss: 1.379186, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 120, Training loss: 1.382647, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 121, Training loss: 1.385020, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 122, Training loss: 1.381430, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 123, Training loss: 1.382923, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 124, Training loss: 1.384203, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 125, Training loss: 1.386129, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 126, Training loss: 1.376900, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 127, Training loss: 1.374343, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 128, Training loss: 1.380003, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 129, Training loss: 1.380822, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 130, Training loss: 1.385983, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 131, Training loss: 1.384028, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 132, Training loss: 1.382532, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 133, Training loss: 1.381884, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 134, Training loss: 1.378854, Validation loss: 1.4000, lr: 0.0000\n",
      "Epoch: 135, Training loss: 1.387598, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 136, Training loss: 1.381870, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 137, Training loss: 1.389029, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 138, Training loss: 1.390842, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 139, Training loss: 1.384964, Validation loss: 1.3880, lr: 0.0000\n",
      "Epoch: 140, Training loss: 1.386877, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 141, Training loss: 1.385045, Validation loss: 1.3667, lr: 0.0000\n",
      "Epoch: 142, Training loss: 1.386141, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 143, Training loss: 1.385874, Validation loss: 1.3891, lr: 0.0000\n",
      "Epoch: 144, Training loss: 1.382217, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 145, Training loss: 1.375721, Validation loss: 1.3889, lr: 0.0000\n",
      "Epoch: 146, Training loss: 1.381871, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 147, Training loss: 1.382739, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 148, Training loss: 1.382960, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 149, Training loss: 1.385157, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 150, Training loss: 1.388948, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 151, Training loss: 1.380689, Validation loss: 1.3874, lr: 0.0000\n",
      "Epoch: 152, Training loss: 1.376899, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 153, Training loss: 1.383098, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 154, Training loss: 1.384026, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 155, Training loss: 1.385101, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 156, Training loss: 1.382105, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 157, Training loss: 1.382594, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 158, Training loss: 1.382905, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 159, Training loss: 1.381729, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 160, Training loss: 1.381769, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 161, Training loss: 1.385669, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 162, Training loss: 1.386405, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 163, Training loss: 1.381665, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 164, Training loss: 1.382597, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 165, Training loss: 1.385078, Validation loss: 1.3889, lr: 0.0000\n",
      "Epoch: 166, Training loss: 1.385044, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 167, Training loss: 1.381032, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 168, Training loss: 1.386092, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 169, Training loss: 1.380541, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 170, Training loss: 1.384713, Validation loss: 1.3877, lr: 0.0000\n",
      "Epoch: 171, Training loss: 1.387439, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 172, Training loss: 1.383537, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 173, Training loss: 1.378659, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 174, Training loss: 1.380971, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 175, Training loss: 1.382888, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 176, Training loss: 1.380946, Validation loss: 1.3750, lr: 0.0000\n",
      "Epoch: 177, Training loss: 1.381652, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 178, Training loss: 1.384076, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 179, Training loss: 1.382563, Validation loss: 1.3782, lr: 0.0000\n",
      "Epoch: 180, Training loss: 1.381044, Validation loss: 1.3873, lr: 0.0000\n",
      "Epoch: 181, Training loss: 1.382002, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 182, Training loss: 1.384059, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 183, Training loss: 1.380324, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 184, Training loss: 1.381335, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 185, Training loss: 1.385916, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 186, Training loss: 1.378192, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 187, Training loss: 1.380827, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 188, Training loss: 1.380967, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 189, Training loss: 1.383109, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 190, Training loss: 1.385332, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 191, Training loss: 1.379947, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 192, Training loss: 1.376502, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 193, Training loss: 1.387646, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 194, Training loss: 1.386986, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 195, Training loss: 1.383162, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 196, Training loss: 1.393377, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 197, Training loss: 1.382549, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 198, Training loss: 1.375927, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 199, Training loss: 1.387094, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 200, Training loss: 1.381038, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 201, Training loss: 1.384633, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 202, Training loss: 1.386061, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 203, Training loss: 1.378685, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 204, Training loss: 1.381358, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 205, Training loss: 1.381855, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 206, Training loss: 1.385432, Validation loss: 1.3879, lr: 0.0000\n",
      "Epoch: 207, Training loss: 1.378442, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 208, Training loss: 1.380479, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 209, Training loss: 1.381515, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 210, Training loss: 1.384015, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 211, Training loss: 1.382336, Validation loss: 1.3924, lr: 0.0000\n",
      "Epoch: 212, Training loss: 1.378377, Validation loss: 1.3793, lr: 0.0000\n",
      "Epoch: 213, Training loss: 1.382959, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 214, Training loss: 1.384694, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 215, Training loss: 1.384476, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 216, Training loss: 1.378819, Validation loss: 1.3873, lr: 0.0000\n",
      "Epoch: 217, Training loss: 1.383450, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 218, Training loss: 1.382176, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 219, Training loss: 1.389236, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 220, Training loss: 1.388022, Validation loss: 1.3872, lr: 0.0000\n",
      "Epoch: 221, Training loss: 1.382350, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 222, Training loss: 1.384110, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 223, Training loss: 1.383081, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 224, Training loss: 1.382508, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 225, Training loss: 1.377027, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 226, Training loss: 1.386265, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 227, Training loss: 1.382205, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 228, Training loss: 1.379871, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 229, Training loss: 1.387380, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 230, Training loss: 1.380977, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 231, Training loss: 1.381888, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 232, Training loss: 1.383855, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 233, Training loss: 1.381600, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 234, Training loss: 1.383069, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 235, Training loss: 1.378515, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 236, Training loss: 1.383804, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 237, Training loss: 1.379923, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 238, Training loss: 1.383140, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 239, Training loss: 1.380829, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 240, Training loss: 1.378317, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 241, Training loss: 1.383669, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 242, Training loss: 1.385846, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 243, Training loss: 1.377565, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 244, Training loss: 1.380119, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 245, Training loss: 1.384117, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 246, Training loss: 1.380832, Validation loss: 1.3879, lr: 0.0000\n",
      "Epoch: 247, Training loss: 1.384357, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 248, Training loss: 1.382883, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 249, Training loss: 1.383260, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 250, Training loss: 1.381685, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 251, Training loss: 1.379644, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 252, Training loss: 1.385755, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 253, Training loss: 1.382595, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 254, Training loss: 1.379177, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 255, Training loss: 1.384963, Validation loss: 1.3797, lr: 0.0000\n",
      "Epoch: 256, Training loss: 1.378018, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 257, Training loss: 1.379218, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 258, Training loss: 1.383472, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 259, Training loss: 1.381350, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 260, Training loss: 1.377982, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 261, Training loss: 1.383384, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 262, Training loss: 1.380931, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 263, Training loss: 1.389690, Validation loss: 1.3933, lr: 0.0000\n",
      "Epoch: 264, Training loss: 1.382036, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 265, Training loss: 1.379983, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 266, Training loss: 1.381292, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 267, Training loss: 1.378397, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 268, Training loss: 1.389756, Validation loss: 1.4130, lr: 0.0000\n",
      "Epoch: 269, Training loss: 1.383715, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 270, Training loss: 1.381321, Validation loss: 1.3875, lr: 0.0000\n",
      "Epoch: 271, Training loss: 1.387278, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 272, Training loss: 1.380536, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 273, Training loss: 1.376620, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 274, Training loss: 1.383520, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 275, Training loss: 1.383944, Validation loss: 1.3900, lr: 0.0000\n",
      "Epoch: 276, Training loss: 1.380822, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 277, Training loss: 1.385037, Validation loss: 1.3877, lr: 0.0000\n",
      "Epoch: 278, Training loss: 1.378604, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 279, Training loss: 1.385053, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 280, Training loss: 1.384255, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 281, Training loss: 1.381001, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 282, Training loss: 1.385405, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 283, Training loss: 1.383533, Validation loss: 1.3871, lr: 0.0000\n",
      "Epoch: 284, Training loss: 1.379620, Validation loss: 1.3885, lr: 0.0000\n",
      "Epoch: 285, Training loss: 1.380217, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 286, Training loss: 1.386855, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 287, Training loss: 1.385332, Validation loss: 1.4254, lr: 0.0000\n",
      "Epoch: 288, Training loss: 1.385037, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 289, Training loss: 1.378414, Validation loss: 1.3949, lr: 0.0000\n",
      "Epoch: 290, Training loss: 1.387178, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 291, Training loss: 1.383474, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 292, Training loss: 1.384402, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 293, Training loss: 1.387721, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 294, Training loss: 1.379307, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 295, Training loss: 1.372123, Validation loss: 1.3877, lr: 0.0000\n",
      "Epoch: 296, Training loss: 1.381519, Validation loss: 1.3880, lr: 0.0000\n",
      "Epoch: 297, Training loss: 1.385011, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 298, Training loss: 1.389266, Validation loss: 1.3875, lr: 0.0000\n",
      "Epoch: 299, Training loss: 1.382029, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 300, Training loss: 1.386311, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 301, Training loss: 1.380609, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 302, Training loss: 1.382480, Validation loss: 1.3873, lr: 0.0000\n",
      "Epoch: 303, Training loss: 1.388902, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 304, Training loss: 1.386377, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 305, Training loss: 1.382922, Validation loss: 1.3901, lr: 0.0000\n",
      "Epoch: 306, Training loss: 1.380575, Validation loss: 1.3871, lr: 0.0000\n",
      "Epoch: 307, Training loss: 1.385693, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 308, Training loss: 1.390364, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 309, Training loss: 1.383794, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 310, Training loss: 1.384016, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 311, Training loss: 1.382904, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 312, Training loss: 1.382037, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 313, Training loss: 1.389726, Validation loss: 1.3872, lr: 0.0000\n",
      "Epoch: 314, Training loss: 1.380341, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 315, Training loss: 1.384212, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 316, Training loss: 1.379786, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 317, Training loss: 1.383108, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 318, Training loss: 1.377333, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 319, Training loss: 1.384992, Validation loss: 1.3878, lr: 0.0000\n",
      "Epoch: 320, Training loss: 1.382174, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 321, Training loss: 1.384708, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 322, Training loss: 1.388952, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 323, Training loss: 1.385562, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 324, Training loss: 1.391933, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 325, Training loss: 1.378590, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 326, Training loss: 1.380050, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 327, Training loss: 1.380085, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 328, Training loss: 1.385734, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 329, Training loss: 1.380191, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 330, Training loss: 1.378415, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 331, Training loss: 1.379686, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 332, Training loss: 1.379772, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 333, Training loss: 1.385163, Validation loss: 1.3871, lr: 0.0000\n",
      "Epoch: 334, Training loss: 1.382443, Validation loss: 1.3893, lr: 0.0000\n",
      "Epoch: 335, Training loss: 1.380875, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 336, Training loss: 1.383417, Validation loss: 1.3770, lr: 0.0000\n",
      "Epoch: 337, Training loss: 1.382210, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 338, Training loss: 1.383772, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 339, Training loss: 1.378766, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 340, Training loss: 1.385720, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 341, Training loss: 1.384223, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 342, Training loss: 1.382863, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 343, Training loss: 1.385179, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 344, Training loss: 1.382972, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 345, Training loss: 1.387683, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 346, Training loss: 1.383395, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 347, Training loss: 1.386719, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 348, Training loss: 1.379885, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 349, Training loss: 1.385922, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 350, Training loss: 1.383993, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 351, Training loss: 1.381233, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 352, Training loss: 1.387561, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 353, Training loss: 1.383278, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 354, Training loss: 1.380425, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 355, Training loss: 1.383237, Validation loss: 1.3879, lr: 0.0000\n",
      "Epoch: 356, Training loss: 1.385372, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 357, Training loss: 1.382841, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 358, Training loss: 1.382604, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 359, Training loss: 1.388937, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 360, Training loss: 1.393089, Validation loss: 1.3871, lr: 0.0000\n",
      "Epoch: 361, Training loss: 1.385005, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 362, Training loss: 1.386424, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 363, Training loss: 1.385112, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 364, Training loss: 1.381689, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 365, Training loss: 1.383305, Validation loss: 1.3873, lr: 0.0000\n",
      "Epoch: 366, Training loss: 1.384748, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 367, Training loss: 1.377136, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 368, Training loss: 1.384108, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 369, Training loss: 1.381288, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 370, Training loss: 1.381552, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 371, Training loss: 1.383781, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 372, Training loss: 1.395889, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 373, Training loss: 1.382307, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 374, Training loss: 1.385882, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 375, Training loss: 1.380811, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 376, Training loss: 1.387525, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 377, Training loss: 1.373780, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 378, Training loss: 1.387207, Validation loss: 1.3913, lr: 0.0000\n",
      "Epoch: 379, Training loss: 1.380572, Validation loss: 1.3872, lr: 0.0000\n",
      "Epoch: 380, Training loss: 1.382032, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 381, Training loss: 1.373483, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 382, Training loss: 1.390620, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 383, Training loss: 1.378599, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 384, Training loss: 1.385399, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 385, Training loss: 1.380901, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 386, Training loss: 1.382019, Validation loss: 1.4191, lr: 0.0000\n",
      "Epoch: 387, Training loss: 1.383377, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 388, Training loss: 1.387193, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 389, Training loss: 1.379536, Validation loss: 1.3878, lr: 0.0000\n",
      "Epoch: 390, Training loss: 1.381461, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 391, Training loss: 1.380235, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 392, Training loss: 1.384462, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 393, Training loss: 1.386804, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 394, Training loss: 1.382697, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 395, Training loss: 1.383902, Validation loss: 1.3874, lr: 0.0000\n",
      "Epoch: 396, Training loss: 1.385514, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 397, Training loss: 1.388773, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 398, Training loss: 1.384075, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 399, Training loss: 1.385457, Validation loss: 1.3781, lr: 0.0000\n",
      "Epoch: 400, Training loss: 1.394249, Validation loss: 1.3881, lr: 0.0000\n",
      "Epoch: 401, Training loss: 1.385450, Validation loss: 1.4050, lr: 0.0000\n",
      "Epoch: 402, Training loss: 1.385680, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 403, Training loss: 1.382315, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 404, Training loss: 1.383722, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 405, Training loss: 1.379505, Validation loss: 1.3779, lr: 0.0000\n",
      "Epoch: 406, Training loss: 1.389212, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 407, Training loss: 1.380309, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 408, Training loss: 1.381037, Validation loss: 1.3780, lr: 0.0000\n",
      "Epoch: 409, Training loss: 1.385498, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 410, Training loss: 1.383538, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 411, Training loss: 1.386074, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 412, Training loss: 1.397269, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 413, Training loss: 1.386052, Validation loss: 1.3880, lr: 0.0000\n",
      "Epoch: 414, Training loss: 1.383319, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 415, Training loss: 1.383186, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 416, Training loss: 1.385542, Validation loss: 1.3919, lr: 0.0000\n",
      "Epoch: 417, Training loss: 1.387915, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 418, Training loss: 1.379850, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 419, Training loss: 1.381122, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 420, Training loss: 1.380567, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 421, Training loss: 1.384837, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 422, Training loss: 1.386139, Validation loss: 1.3890, lr: 0.0000\n",
      "Epoch: 423, Training loss: 1.380061, Validation loss: 1.3882, lr: 0.0000\n",
      "Epoch: 424, Training loss: 1.381268, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 425, Training loss: 1.376217, Validation loss: 1.3902, lr: 0.0000\n",
      "Epoch: 426, Training loss: 1.380771, Validation loss: 1.3890, lr: 0.0000\n",
      "Epoch: 427, Training loss: 1.385931, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 428, Training loss: 1.381870, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 429, Training loss: 1.380511, Validation loss: 1.3875, lr: 0.0000\n",
      "Epoch: 430, Training loss: 1.385522, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 431, Training loss: 1.380634, Validation loss: 1.3731, lr: 0.0000\n",
      "Epoch: 432, Training loss: 1.383517, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 433, Training loss: 1.384986, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 434, Training loss: 1.386305, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 435, Training loss: 1.379313, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 436, Training loss: 1.389189, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 437, Training loss: 1.390918, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 438, Training loss: 1.389973, Validation loss: 1.3725, lr: 0.0000\n",
      "Epoch: 439, Training loss: 1.381708, Validation loss: 1.3894, lr: 0.0000\n",
      "Epoch: 440, Training loss: 1.381452, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 441, Training loss: 1.379818, Validation loss: 1.3882, lr: 0.0000\n",
      "Epoch: 442, Training loss: 1.379600, Validation loss: 1.3877, lr: 0.0000\n",
      "Epoch: 443, Training loss: 1.375994, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 444, Training loss: 1.381067, Validation loss: 1.3776, lr: 0.0000\n",
      "Epoch: 445, Training loss: 1.384833, Validation loss: 1.3896, lr: 0.0000\n",
      "Epoch: 446, Training loss: 1.381505, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 447, Training loss: 1.383299, Validation loss: 1.3743, lr: 0.0000\n",
      "Epoch: 448, Training loss: 1.383299, Validation loss: 1.3872, lr: 0.0000\n",
      "Epoch: 449, Training loss: 1.383103, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 450, Training loss: 1.383143, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 451, Training loss: 1.383923, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 452, Training loss: 1.391683, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 453, Training loss: 1.383568, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 454, Training loss: 1.393437, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 455, Training loss: 1.383120, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 456, Training loss: 1.384872, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 457, Training loss: 1.383263, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 458, Training loss: 1.387431, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 459, Training loss: 1.385794, Validation loss: 1.3876, lr: 0.0000\n",
      "Epoch: 460, Training loss: 1.380730, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 461, Training loss: 1.385796, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 462, Training loss: 1.390011, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 463, Training loss: 1.384885, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 464, Training loss: 1.385484, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 465, Training loss: 1.382376, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 466, Training loss: 1.383392, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 467, Training loss: 1.382912, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 468, Training loss: 1.382110, Validation loss: 1.3889, lr: 0.0000\n",
      "Epoch: 469, Training loss: 1.383032, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 470, Training loss: 1.377090, Validation loss: 1.3959, lr: 0.0000\n",
      "Epoch: 471, Training loss: 1.385190, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 472, Training loss: 1.386364, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 473, Training loss: 1.381145, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 474, Training loss: 1.381407, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 475, Training loss: 1.389742, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 476, Training loss: 1.382774, Validation loss: 1.3889, lr: 0.0000\n",
      "Epoch: 477, Training loss: 1.390577, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 478, Training loss: 1.389397, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 479, Training loss: 1.374916, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 480, Training loss: 1.382685, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 481, Training loss: 1.381932, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 482, Training loss: 1.379673, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 483, Training loss: 1.387474, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 484, Training loss: 1.391463, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 485, Training loss: 1.380113, Validation loss: 1.3676, lr: 0.0000\n",
      "Epoch: 486, Training loss: 1.387168, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 487, Training loss: 1.384895, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 488, Training loss: 1.381025, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 489, Training loss: 1.382293, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 490, Training loss: 1.391521, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 491, Training loss: 1.374716, Validation loss: 1.3885, lr: 0.0000\n",
      "Epoch: 492, Training loss: 1.383311, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 493, Training loss: 1.390456, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 494, Training loss: 1.378665, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 495, Training loss: 1.378299, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 496, Training loss: 1.383230, Validation loss: 1.3873, lr: 0.0000\n",
      "Epoch: 497, Training loss: 1.380368, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 498, Training loss: 1.386251, Validation loss: 1.3871, lr: 0.0000\n",
      "Epoch: 499, Training loss: 1.383565, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 500, Training loss: 1.377643, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 501, Training loss: 1.385033, Validation loss: 1.3871, lr: 0.0000\n",
      "Epoch: 502, Training loss: 1.381438, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 503, Training loss: 1.382519, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 504, Training loss: 1.381276, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 505, Training loss: 1.388132, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 506, Training loss: 1.379364, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 507, Training loss: 1.382657, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 508, Training loss: 1.384127, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 509, Training loss: 1.377587, Validation loss: 1.3876, lr: 0.0000\n",
      "Epoch: 510, Training loss: 1.381179, Validation loss: 1.3873, lr: 0.0000\n",
      "Epoch: 511, Training loss: 1.385095, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 512, Training loss: 1.379151, Validation loss: 1.3917, lr: 0.0000\n",
      "Epoch: 513, Training loss: 1.381310, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 514, Training loss: 1.380183, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 515, Training loss: 1.377859, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 516, Training loss: 1.384904, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 517, Training loss: 1.384266, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 518, Training loss: 1.367132, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 519, Training loss: 1.381514, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 520, Training loss: 1.377509, Validation loss: 1.3873, lr: 0.0000\n",
      "Epoch: 521, Training loss: 1.378268, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 522, Training loss: 1.386117, Validation loss: 1.3874, lr: 0.0000\n",
      "Epoch: 523, Training loss: 1.376180, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 524, Training loss: 1.383930, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 525, Training loss: 1.389332, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 526, Training loss: 1.374497, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 527, Training loss: 1.382291, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 528, Training loss: 1.374553, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 529, Training loss: 1.391994, Validation loss: 1.3899, lr: 0.0000\n",
      "Epoch: 530, Training loss: 1.385238, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 531, Training loss: 1.380883, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 532, Training loss: 1.386741, Validation loss: 1.3879, lr: 0.0000\n",
      "Epoch: 533, Training loss: 1.379762, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 534, Training loss: 1.383588, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 535, Training loss: 1.392722, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 536, Training loss: 1.383921, Validation loss: 1.3797, lr: 0.0000\n",
      "Epoch: 537, Training loss: 1.378936, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 538, Training loss: 1.385488, Validation loss: 1.3912, lr: 0.0000\n",
      "Epoch: 539, Training loss: 1.381207, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 540, Training loss: 1.386957, Validation loss: 1.3794, lr: 0.0000\n",
      "Epoch: 541, Training loss: 1.379058, Validation loss: 1.3893, lr: 0.0000\n",
      "Epoch: 542, Training loss: 1.384886, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 543, Training loss: 1.381644, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 544, Training loss: 1.378657, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 545, Training loss: 1.389771, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 546, Training loss: 1.382447, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 547, Training loss: 1.377226, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 548, Training loss: 1.382201, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 549, Training loss: 1.386615, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 550, Training loss: 1.382937, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 551, Training loss: 1.379893, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 552, Training loss: 1.381823, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 553, Training loss: 1.382620, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 554, Training loss: 1.386515, Validation loss: 1.3911, lr: 0.0000\n",
      "Epoch: 555, Training loss: 1.381456, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 556, Training loss: 1.383343, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 557, Training loss: 1.380640, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 558, Training loss: 1.388395, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 559, Training loss: 1.380605, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 560, Training loss: 1.387094, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 561, Training loss: 1.386477, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 562, Training loss: 1.388374, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 563, Training loss: 1.387364, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 564, Training loss: 1.386073, Validation loss: 1.3872, lr: 0.0000\n",
      "Epoch: 565, Training loss: 1.396082, Validation loss: 1.3875, lr: 0.0000\n",
      "Epoch: 566, Training loss: 1.383218, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 567, Training loss: 1.382837, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 568, Training loss: 1.387419, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 569, Training loss: 1.381200, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 570, Training loss: 1.384057, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 571, Training loss: 1.393887, Validation loss: 1.4020, lr: 0.0000\n",
      "Epoch: 572, Training loss: 1.386591, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 573, Training loss: 1.388346, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 574, Training loss: 1.379965, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 575, Training loss: 1.383172, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 576, Training loss: 1.384295, Validation loss: 1.3896, lr: 0.0000\n",
      "Epoch: 577, Training loss: 1.377921, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 578, Training loss: 1.385776, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 579, Training loss: 1.388087, Validation loss: 1.3873, lr: 0.0000\n",
      "Epoch: 580, Training loss: 1.384061, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 581, Training loss: 1.381236, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 582, Training loss: 1.379031, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 583, Training loss: 1.381321, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 584, Training loss: 1.380002, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 585, Training loss: 1.379923, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 586, Training loss: 1.376787, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 587, Training loss: 1.389471, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 588, Training loss: 1.385791, Validation loss: 1.3788, lr: 0.0000\n",
      "Epoch: 589, Training loss: 1.385732, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 590, Training loss: 1.378760, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 591, Training loss: 1.384060, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 592, Training loss: 1.395425, Validation loss: 1.3873, lr: 0.0000\n",
      "Epoch: 593, Training loss: 1.383995, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 594, Training loss: 1.379003, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 595, Training loss: 1.386940, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 596, Training loss: 1.382026, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 597, Training loss: 1.385761, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 598, Training loss: 1.385831, Validation loss: 1.5948, lr: 0.0000\n",
      "Epoch: 599, Training loss: 1.383452, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 600, Training loss: 1.390217, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 601, Training loss: 1.385382, Validation loss: 1.3871, lr: 0.0000\n",
      "Epoch: 602, Training loss: 1.385028, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 603, Training loss: 1.382862, Validation loss: 1.3872, lr: 0.0000\n",
      "Epoch: 604, Training loss: 1.382072, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 605, Training loss: 1.377722, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 606, Training loss: 1.382059, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 607, Training loss: 1.383120, Validation loss: 1.3752, lr: 0.0000\n",
      "Epoch: 608, Training loss: 1.376830, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 609, Training loss: 1.385150, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 610, Training loss: 1.383764, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 611, Training loss: 1.382674, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 612, Training loss: 1.382882, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 613, Training loss: 1.380860, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 614, Training loss: 1.391148, Validation loss: 1.3871, lr: 0.0000\n",
      "Epoch: 615, Training loss: 1.378416, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 616, Training loss: 1.383042, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 617, Training loss: 1.385648, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 618, Training loss: 1.385342, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 619, Training loss: 1.379894, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 620, Training loss: 1.381221, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 621, Training loss: 1.376740, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 622, Training loss: 1.380163, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 623, Training loss: 1.385717, Validation loss: 1.3903, lr: 0.0000\n",
      "Epoch: 624, Training loss: 1.385169, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 625, Training loss: 1.387107, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 626, Training loss: 1.383068, Validation loss: 1.3950, lr: 0.0000\n",
      "Epoch: 627, Training loss: 1.379103, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 628, Training loss: 1.390960, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 629, Training loss: 1.386907, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 630, Training loss: 1.380742, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 631, Training loss: 1.380065, Validation loss: 1.3883, lr: 0.0000\n",
      "Epoch: 632, Training loss: 1.386315, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 633, Training loss: 1.379529, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 634, Training loss: 1.381328, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 635, Training loss: 1.385617, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 636, Training loss: 1.379627, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 637, Training loss: 1.381140, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 638, Training loss: 1.381996, Validation loss: 1.3895, lr: 0.0000\n",
      "Epoch: 639, Training loss: 1.381014, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 640, Training loss: 1.380484, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 641, Training loss: 1.377053, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 642, Training loss: 1.385150, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 643, Training loss: 1.382203, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 644, Training loss: 1.385584, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 645, Training loss: 1.383219, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 646, Training loss: 1.381747, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 647, Training loss: 1.385759, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 648, Training loss: 1.383746, Validation loss: 1.3957, lr: 0.0000\n",
      "Epoch: 649, Training loss: 1.384837, Validation loss: 1.3878, lr: 0.0000\n",
      "Epoch: 650, Training loss: 1.383670, Validation loss: 1.3796, lr: 0.0000\n",
      "Epoch: 651, Training loss: 1.379737, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 652, Training loss: 1.385835, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 653, Training loss: 1.384958, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 654, Training loss: 1.383842, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 655, Training loss: 1.382028, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 656, Training loss: 1.379868, Validation loss: 1.3875, lr: 0.0000\n",
      "Epoch: 657, Training loss: 1.379088, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 658, Training loss: 1.383470, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 659, Training loss: 1.383081, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 660, Training loss: 1.373677, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 661, Training loss: 1.382706, Validation loss: 1.3724, lr: 0.0000\n",
      "Epoch: 662, Training loss: 1.381402, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 663, Training loss: 1.381402, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 664, Training loss: 1.397448, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 665, Training loss: 1.381947, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 666, Training loss: 1.378704, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 667, Training loss: 1.381514, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 668, Training loss: 1.374183, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 669, Training loss: 1.378939, Validation loss: 1.3742, lr: 0.0000\n",
      "Epoch: 670, Training loss: 1.384386, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 671, Training loss: 1.383521, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 672, Training loss: 1.379210, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 673, Training loss: 1.383613, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 674, Training loss: 1.378914, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 675, Training loss: 1.383437, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 676, Training loss: 1.381023, Validation loss: 1.4660, lr: 0.0000\n",
      "Epoch: 677, Training loss: 1.387647, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 678, Training loss: 1.375707, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 679, Training loss: 1.383004, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 680, Training loss: 1.383021, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 681, Training loss: 1.383653, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 682, Training loss: 1.379648, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 683, Training loss: 1.382317, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 684, Training loss: 1.377858, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 685, Training loss: 1.386700, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 686, Training loss: 1.380208, Validation loss: 1.3775, lr: 0.0000\n",
      "Epoch: 687, Training loss: 1.379357, Validation loss: 1.3758, lr: 0.0000\n",
      "Epoch: 688, Training loss: 1.379238, Validation loss: 1.3876, lr: 0.0000\n",
      "Epoch: 689, Training loss: 1.380543, Validation loss: 1.3874, lr: 0.0000\n",
      "Epoch: 690, Training loss: 1.379304, Validation loss: 1.3874, lr: 0.0000\n",
      "Epoch: 691, Training loss: 1.385493, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 692, Training loss: 1.384390, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 693, Training loss: 1.385731, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 694, Training loss: 1.384957, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 695, Training loss: 1.382770, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 696, Training loss: 1.376058, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 697, Training loss: 1.376212, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 698, Training loss: 1.384053, Validation loss: 1.3961, lr: 0.0000\n",
      "Epoch: 699, Training loss: 1.381139, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 700, Training loss: 1.386445, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 701, Training loss: 1.374110, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 702, Training loss: 1.383230, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 703, Training loss: 1.385006, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 704, Training loss: 1.383022, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 705, Training loss: 1.384426, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 706, Training loss: 1.384689, Validation loss: 1.3786, lr: 0.0000\n",
      "Epoch: 707, Training loss: 1.381412, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 708, Training loss: 1.381973, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 709, Training loss: 1.384524, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 710, Training loss: 1.384251, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 711, Training loss: 1.384793, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 712, Training loss: 1.383280, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 713, Training loss: 1.378320, Validation loss: 1.3886, lr: 0.0000\n",
      "Epoch: 714, Training loss: 1.384437, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 715, Training loss: 1.381676, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 716, Training loss: 1.384388, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 717, Training loss: 1.381214, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 718, Training loss: 1.379758, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 719, Training loss: 1.383563, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 720, Training loss: 1.386395, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 721, Training loss: 1.384076, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 722, Training loss: 1.386293, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 723, Training loss: 1.385802, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 724, Training loss: 1.379722, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 725, Training loss: 1.383112, Validation loss: 1.3792, lr: 0.0000\n",
      "Epoch: 726, Training loss: 1.388017, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 727, Training loss: 1.379226, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 728, Training loss: 1.380594, Validation loss: 1.3809, lr: 0.0000\n",
      "Epoch: 729, Training loss: 1.383532, Validation loss: 1.3878, lr: 0.0000\n",
      "Epoch: 730, Training loss: 1.384417, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 731, Training loss: 1.383177, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 732, Training loss: 1.382899, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 733, Training loss: 1.389373, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 734, Training loss: 1.383086, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 735, Training loss: 1.381487, Validation loss: 1.3895, lr: 0.0000\n",
      "Epoch: 736, Training loss: 1.382551, Validation loss: 1.3731, lr: 0.0000\n",
      "Epoch: 737, Training loss: 1.379658, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 738, Training loss: 1.382832, Validation loss: 1.3898, lr: 0.0000\n",
      "Epoch: 739, Training loss: 1.379479, Validation loss: 1.3900, lr: 0.0000\n",
      "Epoch: 740, Training loss: 1.392937, Validation loss: 1.3876, lr: 0.0000\n",
      "Epoch: 741, Training loss: 1.381874, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 742, Training loss: 1.382732, Validation loss: 1.3875, lr: 0.0000\n",
      "Epoch: 743, Training loss: 1.383335, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 744, Training loss: 1.384054, Validation loss: 1.3898, lr: 0.0000\n",
      "Epoch: 745, Training loss: 1.386538, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 746, Training loss: 1.379211, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 747, Training loss: 1.385230, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 748, Training loss: 1.386936, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 749, Training loss: 1.381468, Validation loss: 1.3891, lr: 0.0000\n",
      "Epoch: 750, Training loss: 1.378623, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 751, Training loss: 1.379752, Validation loss: 1.3872, lr: 0.0000\n",
      "Epoch: 752, Training loss: 1.386677, Validation loss: 1.3871, lr: 0.0000\n",
      "Epoch: 753, Training loss: 1.380240, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 754, Training loss: 1.375958, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 755, Training loss: 1.382213, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 756, Training loss: 1.405275, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 757, Training loss: 1.387587, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 758, Training loss: 1.384810, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 759, Training loss: 1.382213, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 760, Training loss: 1.385676, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 761, Training loss: 1.384558, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 762, Training loss: 1.387193, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 763, Training loss: 1.383057, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 764, Training loss: 1.384341, Validation loss: 1.3781, lr: 0.0000\n",
      "Epoch: 765, Training loss: 1.384199, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 766, Training loss: 1.381282, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 767, Training loss: 1.378756, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 768, Training loss: 1.382536, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 769, Training loss: 1.387300, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 770, Training loss: 1.383170, Validation loss: 1.3803, lr: 0.0000\n",
      "Epoch: 771, Training loss: 1.385118, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 772, Training loss: 1.378079, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 773, Training loss: 1.382167, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 774, Training loss: 1.379899, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 775, Training loss: 1.386455, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 776, Training loss: 1.389612, Validation loss: 1.3784, lr: 0.0000\n",
      "Epoch: 777, Training loss: 1.386987, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 778, Training loss: 1.380089, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 779, Training loss: 1.385068, Validation loss: 1.3775, lr: 0.0000\n",
      "Epoch: 780, Training loss: 1.382960, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 781, Training loss: 1.385042, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 782, Training loss: 1.378929, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 783, Training loss: 1.385625, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 784, Training loss: 1.387924, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 785, Training loss: 1.383632, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 786, Training loss: 1.383051, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 787, Training loss: 1.387982, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 788, Training loss: 1.380647, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 789, Training loss: 1.382580, Validation loss: 1.3872, lr: 0.0000\n",
      "Epoch: 790, Training loss: 1.386166, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 791, Training loss: 1.388724, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 792, Training loss: 1.380574, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 793, Training loss: 1.385634, Validation loss: 1.3916, lr: 0.0000\n",
      "Epoch: 794, Training loss: 1.382734, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 795, Training loss: 1.386877, Validation loss: 1.3871, lr: 0.0000\n",
      "Epoch: 796, Training loss: 1.382680, Validation loss: 1.3884, lr: 0.0000\n",
      "Epoch: 797, Training loss: 1.380207, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 798, Training loss: 1.382787, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 799, Training loss: 1.385917, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 800, Training loss: 1.385961, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 801, Training loss: 1.383964, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 802, Training loss: 1.381217, Validation loss: 1.3894, lr: 0.0000\n",
      "Epoch: 803, Training loss: 1.381536, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 804, Training loss: 1.389129, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 805, Training loss: 1.398074, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 806, Training loss: 1.383627, Validation loss: 1.3873, lr: 0.0000\n",
      "Epoch: 807, Training loss: 1.375249, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 808, Training loss: 1.376630, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 809, Training loss: 1.383489, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 810, Training loss: 1.387922, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 811, Training loss: 1.381536, Validation loss: 1.3877, lr: 0.0000\n",
      "Epoch: 812, Training loss: 1.380532, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 813, Training loss: 1.395754, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 814, Training loss: 1.382738, Validation loss: 1.3892, lr: 0.0000\n",
      "Epoch: 815, Training loss: 1.382233, Validation loss: 1.3723, lr: 0.0000\n",
      "Epoch: 816, Training loss: 1.384824, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 817, Training loss: 1.378015, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 818, Training loss: 1.382403, Validation loss: 1.3877, lr: 0.0000\n",
      "Epoch: 819, Training loss: 1.382572, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 820, Training loss: 1.381873, Validation loss: 1.3877, lr: 0.0000\n",
      "Epoch: 821, Training loss: 1.388186, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 822, Training loss: 1.378851, Validation loss: 1.3882, lr: 0.0000\n",
      "Epoch: 823, Training loss: 1.381833, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 824, Training loss: 1.385704, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 825, Training loss: 1.382403, Validation loss: 1.3873, lr: 0.0000\n",
      "Epoch: 826, Training loss: 1.378460, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 827, Training loss: 1.381639, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 828, Training loss: 1.381194, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 829, Training loss: 1.380988, Validation loss: 1.3789, lr: 0.0000\n",
      "Epoch: 830, Training loss: 1.381892, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 831, Training loss: 1.389026, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 832, Training loss: 1.384714, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 833, Training loss: 1.379966, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 834, Training loss: 1.380402, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 835, Training loss: 1.383517, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 836, Training loss: 1.381198, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 837, Training loss: 1.380717, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 838, Training loss: 1.382591, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 839, Training loss: 1.380369, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 840, Training loss: 1.384119, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 841, Training loss: 1.387382, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 842, Training loss: 1.381029, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 843, Training loss: 1.383369, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 844, Training loss: 1.384625, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 845, Training loss: 1.373165, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 846, Training loss: 1.385205, Validation loss: 1.3872, lr: 0.0000\n",
      "Epoch: 847, Training loss: 1.382940, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 848, Training loss: 1.383181, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 849, Training loss: 1.384448, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 850, Training loss: 1.387413, Validation loss: 1.3789, lr: 0.0000\n",
      "Epoch: 851, Training loss: 1.383708, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 852, Training loss: 1.383450, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 853, Training loss: 1.385277, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 854, Training loss: 1.380302, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 855, Training loss: 1.378153, Validation loss: 1.3891, lr: 0.0000\n",
      "Epoch: 856, Training loss: 1.384971, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 857, Training loss: 1.388254, Validation loss: 1.3876, lr: 0.0000\n",
      "Epoch: 858, Training loss: 1.389168, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 859, Training loss: 1.380494, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 860, Training loss: 1.386557, Validation loss: 1.4126, lr: 0.0000\n",
      "Epoch: 861, Training loss: 1.384778, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 862, Training loss: 1.381362, Validation loss: 1.3887, lr: 0.0000\n",
      "Epoch: 863, Training loss: 1.382092, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 864, Training loss: 1.383537, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 865, Training loss: 1.384983, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 866, Training loss: 1.380420, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 867, Training loss: 1.385305, Validation loss: 1.3871, lr: 0.0000\n",
      "Epoch: 868, Training loss: 1.384113, Validation loss: 1.3655, lr: 0.0000\n",
      "Epoch: 869, Training loss: 1.383073, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 870, Training loss: 1.382300, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 871, Training loss: 1.386388, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 872, Training loss: 1.380216, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 873, Training loss: 1.383336, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 874, Training loss: 1.382700, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 875, Training loss: 1.386118, Validation loss: 1.3872, lr: 0.0000\n",
      "Epoch: 876, Training loss: 1.381358, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 877, Training loss: 1.385579, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 878, Training loss: 1.383614, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 879, Training loss: 1.387279, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 880, Training loss: 1.383483, Validation loss: 1.3875, lr: 0.0000\n",
      "Epoch: 881, Training loss: 1.386955, Validation loss: 1.3871, lr: 0.0000\n",
      "Epoch: 882, Training loss: 1.387159, Validation loss: 1.3724, lr: 0.0000\n",
      "Epoch: 883, Training loss: 1.378995, Validation loss: 1.3883, lr: 0.0000\n",
      "Epoch: 884, Training loss: 1.386418, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 885, Training loss: 1.382875, Validation loss: 1.3877, lr: 0.0000\n",
      "Epoch: 886, Training loss: 1.386219, Validation loss: 1.3884, lr: 0.0000\n",
      "Epoch: 887, Training loss: 1.382484, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 888, Training loss: 1.380867, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 889, Training loss: 1.378066, Validation loss: 1.3873, lr: 0.0000\n",
      "Epoch: 890, Training loss: 1.387117, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 891, Training loss: 1.385167, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 892, Training loss: 1.386958, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 893, Training loss: 1.384425, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 894, Training loss: 1.385727, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 895, Training loss: 1.386825, Validation loss: 1.3879, lr: 0.0000\n",
      "Epoch: 896, Training loss: 1.382907, Validation loss: 1.3778, lr: 0.0000\n",
      "Epoch: 897, Training loss: 1.384386, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 898, Training loss: 1.382951, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 899, Training loss: 1.386552, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 900, Training loss: 1.389899, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 901, Training loss: 1.378953, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 902, Training loss: 1.379705, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 903, Training loss: 1.381956, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 904, Training loss: 1.388054, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 905, Training loss: 1.385231, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 906, Training loss: 1.386793, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 907, Training loss: 1.385992, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 908, Training loss: 1.383790, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 909, Training loss: 1.382379, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 910, Training loss: 1.380621, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 911, Training loss: 1.384913, Validation loss: 1.3792, lr: 0.0000\n",
      "Epoch: 912, Training loss: 1.392248, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 913, Training loss: 1.381058, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 914, Training loss: 1.383539, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 915, Training loss: 1.389861, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 916, Training loss: 1.380244, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 917, Training loss: 1.381287, Validation loss: 1.3873, lr: 0.0000\n",
      "Epoch: 918, Training loss: 1.383908, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 919, Training loss: 1.381571, Validation loss: 1.3795, lr: 0.0000\n",
      "Epoch: 920, Training loss: 1.384588, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 921, Training loss: 1.377917, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 922, Training loss: 1.384031, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 923, Training loss: 1.386002, Validation loss: 1.3798, lr: 0.0000\n",
      "Epoch: 924, Training loss: 1.383472, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 925, Training loss: 1.385198, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 926, Training loss: 1.386892, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 927, Training loss: 1.378633, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 928, Training loss: 1.381997, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 929, Training loss: 1.384261, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 930, Training loss: 1.385644, Validation loss: 1.3872, lr: 0.0000\n",
      "Epoch: 931, Training loss: 1.380859, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 932, Training loss: 1.371118, Validation loss: 1.3890, lr: 0.0000\n",
      "Epoch: 933, Training loss: 1.389834, Validation loss: 1.3872, lr: 0.0000\n",
      "Epoch: 934, Training loss: 1.386070, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 935, Training loss: 1.382661, Validation loss: 1.3790, lr: 0.0000\n",
      "Epoch: 936, Training loss: 1.377120, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 937, Training loss: 1.381553, Validation loss: 1.3881, lr: 0.0000\n",
      "Epoch: 938, Training loss: 1.380664, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 939, Training loss: 1.385839, Validation loss: 1.3878, lr: 0.0000\n",
      "Epoch: 940, Training loss: 1.378883, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 941, Training loss: 1.387961, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 942, Training loss: 1.377005, Validation loss: 1.3783, lr: 0.0000\n",
      "Epoch: 943, Training loss: 1.386494, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 944, Training loss: 1.394035, Validation loss: 1.3795, lr: 0.0000\n",
      "Epoch: 945, Training loss: 1.379862, Validation loss: 1.3728, lr: 0.0000\n",
      "Epoch: 946, Training loss: 1.382598, Validation loss: 1.3871, lr: 0.0000\n",
      "Epoch: 947, Training loss: 1.384150, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 948, Training loss: 1.378471, Validation loss: 1.3785, lr: 0.0000\n",
      "Epoch: 949, Training loss: 1.386390, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 950, Training loss: 1.382409, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 951, Training loss: 1.381451, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 952, Training loss: 1.384651, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 953, Training loss: 1.377474, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 954, Training loss: 1.385497, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 955, Training loss: 1.382466, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 956, Training loss: 1.387466, Validation loss: 1.3894, lr: 0.0000\n",
      "Epoch: 957, Training loss: 1.383072, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 958, Training loss: 1.383833, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 959, Training loss: 1.381383, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 960, Training loss: 1.377004, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 961, Training loss: 1.386964, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 962, Training loss: 1.390231, Validation loss: 1.3878, lr: 0.0000\n",
      "Epoch: 963, Training loss: 1.384703, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 964, Training loss: 1.381179, Validation loss: 1.3797, lr: 0.0000\n",
      "Epoch: 965, Training loss: 1.384040, Validation loss: 1.3756, lr: 0.0000\n",
      "Epoch: 966, Training loss: 1.384882, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 967, Training loss: 1.385898, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 968, Training loss: 1.382304, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 969, Training loss: 1.383950, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 970, Training loss: 1.378182, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 971, Training loss: 1.380583, Validation loss: 1.3914, lr: 0.0000\n",
      "Epoch: 972, Training loss: 1.386406, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 973, Training loss: 1.382929, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 974, Training loss: 1.381881, Validation loss: 1.3884, lr: 0.0000\n",
      "Epoch: 975, Training loss: 1.386355, Validation loss: 1.3771, lr: 0.0000\n",
      "Epoch: 976, Training loss: 1.385050, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 977, Training loss: 1.387958, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 978, Training loss: 1.377335, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 979, Training loss: 1.387550, Validation loss: 1.3789, lr: 0.0000\n",
      "Epoch: 980, Training loss: 1.378766, Validation loss: 1.3978, lr: 0.0000\n",
      "Epoch: 981, Training loss: 1.385374, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 982, Training loss: 1.386682, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 983, Training loss: 1.384342, Validation loss: 1.3872, lr: 0.0000\n",
      "Epoch: 984, Training loss: 1.380823, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 985, Training loss: 1.383391, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 986, Training loss: 1.383775, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 987, Training loss: 1.381532, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 988, Training loss: 1.383664, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 989, Training loss: 1.379048, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 990, Training loss: 1.379209, Validation loss: 1.3875, lr: 0.0000\n",
      "Epoch: 991, Training loss: 1.381320, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 992, Training loss: 1.382571, Validation loss: 1.3872, lr: 0.0000\n",
      "Epoch: 993, Training loss: 1.391351, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 994, Training loss: 1.385635, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 995, Training loss: 1.385579, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 996, Training loss: 1.386615, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 997, Training loss: 1.386298, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 998, Training loss: 1.378935, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 999, Training loss: 1.381805, Validation loss: 1.3866, lr: 0.0000\n",
      "Final test loss: 1.3846\n"
     ]
    }
   ],
   "source": [
    "model.fit(Train_data_marble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "28f68fa1-a46f-4d2d-812c-8402a87ad2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "marble_results = model.transform(Test_data_marble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c5acacb1-eca5-4987-b1ce-c58823cc3a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "marble_embedding = preprocessing.MinMaxScaler().fit_transform(\n",
    "                marble_results.emb.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "102be614-537c-401e-9897-445cf99855e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "fig = plt.figure(figsize=(3,3), dpi = 100)\n",
    "ax = fig.add_subplot(111)\n",
    "time_points = np.arange(marble_embedding.shape[0])\n",
    "sc = ax.scatter(marble_embedding[:,0],\n",
    "                marble_embedding[:,1],\n",
    "           c=time_points,\n",
    "           cmap='coolwarm', s=40)\n",
    "\n",
    "ax.grid(False)\n",
    "ax.set_axis_off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ce87258b-d00b-4159-8f54-710c5470f07c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05853319141249417"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_smoothness(data):\n",
    "    diff = np.diff(data, axis=0)\n",
    "    bending_energy = np.sum(np.linalg.norm(diff, axis=1)**2)  ## conventional 1-degree time difference\n",
    "    return 1/bending_energy   ### to ensure it is monotonic increasing properity \n",
    "\n",
    "compute_smoothness(marble_embedding[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "787755d7-dab0-4a48-98e9-2dde709373d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.zeros(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cb6e5406-1843-4150-9d09-402ba765b6a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20aefdc6-fdd9-44c8-b128-79debdb41735",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8d050c72-4f33-4ed5-a078-de4c8a873fbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---- Embedding dimension: 100\n",
      "---- Signal dimension: 100\n",
      "---- Computing kernels ... \n",
      "---- Computing full spectrum ...\n",
      "              (if this takes too long, then run construct_dataset()\n",
      "              with number_of_eigenvectors specified) \n",
      "---- Embedding dimension: 100\n",
      "---- Signal dimension: 100\n",
      "---- Computing kernels ... \n",
      "---- Computing full spectrum ...\n",
      "              (if this takes too long, then run construct_dataset()\n",
      "=== Run 01/10 ===h number_of_eigenvectors specified) \n",
      "\n",
      "---- Settings: \n",
      "\n",
      "epochs : 1000\n",
      "hidden_channels : [32]\n",
      "out_channels : 10\n",
      "inner_product_features : False\n",
      "batch_size : 64\n",
      "lr : 0.01\n",
      "momentum : 0.9\n",
      "dropout : 0.0\n",
      "batch_norm : batch_norm\n",
      "bias : True\n",
      "order : 2\n",
      "diffusion : True\n",
      "frac_sampled_nb : -1\n",
      "include_positions : False\n",
      "include_self : True\n",
      "vec_norm : False\n",
      "emb_norm : False\n",
      "seed : 0\n",
      "dim_signal : 100\n",
      "dim_emb : 100\n",
      "n_sampled_nb : -1\n",
      "\n",
      "---- Number of features to pass to the MLP:  1010100\n",
      "---- Total number of parameters:  32323627\n",
      "\n",
      "Using device cuda:0\n",
      "\n",
      "---- Training network ...\n",
      "\n",
      "---- Timestamp: 20250613-193942\n",
      "\n",
      " *och: 0, Training loss: 1.461026, Validation loss: 1.7316, lr: 0.0100\n",
      " *och: 1, Training loss: 1.456864, Validation loss: 1.3891, lr: 0.0100\n",
      "Epoch: 2, Training loss: 1.393614, Validation loss: 1.4465, lr: 0.0100\n",
      " *och: 3, Training loss: 1.373095, Validation loss: 1.3751, lr: 0.0100\n",
      "Epoch: 4, Training loss: 1.395660, Validation loss: 1.3865, lr: 0.0100\n",
      " *och: 5, Training loss: 1.412000, Validation loss: 1.3681, lr: 0.0100\n",
      " *och: 6, Training loss: 1.396416, Validation loss: 1.3602, lr: 0.0100\n",
      "Epoch: 7, Training loss: 1.399033, Validation loss: 1.3800, lr: 0.0100\n",
      "Epoch: 8, Training loss: 1.367505, Validation loss: 1.3727, lr: 0.0100\n",
      "Epoch: 9, Training loss: 1.375071, Validation loss: 1.3775, lr: 0.0100\n",
      "Epoch: 10, Training loss: 1.434612, Validation loss: 1.3779, lr: 0.0100\n",
      "Epoch: 11, Training loss: 1.373756, Validation loss: 1.4487, lr: 0.0100\n",
      "Epoch: 12, Training loss: 1.390343, Validation loss: 1.5099, lr: 0.0100\n",
      "Epoch: 13, Training loss: 1.489144, Validation loss: 1.3793, lr: 0.0100\n",
      "Epoch: 14, Training loss: 1.392702, Validation loss: 1.3869, lr: 0.0100\n",
      "Epoch: 15, Training loss: 1.396203, Validation loss: 1.3633, lr: 0.0100\n",
      "Epoch: 16, Training loss: 1.392902, Validation loss: 1.3820, lr: 0.0100\n",
      "Epoch: 17, Training loss: 1.391798, Validation loss: 1.3727, lr: 0.0100\n",
      " *och: 18, Training loss: 1.433411, Validation loss: 1.3535, lr: 0.0100\n",
      "Epoch: 19, Training loss: 1.388446, Validation loss: 1.3837, lr: 0.0010\n",
      "Epoch: 20, Training loss: 1.372053, Validation loss: 1.3831, lr: 0.0010\n",
      "Epoch: 21, Training loss: 1.359434, Validation loss: 1.3739, lr: 0.0010\n",
      "Epoch: 22, Training loss: 1.378588, Validation loss: 1.3758, lr: 0.0010\n",
      "Epoch: 23, Training loss: 1.398795, Validation loss: 1.3826, lr: 0.0010\n",
      "Epoch: 24, Training loss: 1.378195, Validation loss: 1.3835, lr: 0.0010\n",
      "Epoch: 25, Training loss: 1.365224, Validation loss: 1.3670, lr: 0.0010\n",
      "Epoch: 26, Training loss: 1.393633, Validation loss: 1.3867, lr: 0.0010\n",
      "Epoch: 27, Training loss: 1.385348, Validation loss: 1.3856, lr: 0.0010\n",
      "Epoch: 28, Training loss: 1.387099, Validation loss: 1.3832, lr: 0.0010\n",
      "Epoch: 29, Training loss: 1.399460, Validation loss: 1.3828, lr: 0.0010\n",
      "Epoch: 30, Training loss: 1.392025, Validation loss: 1.3879, lr: 0.0010\n",
      "Epoch: 31, Training loss: 1.375825, Validation loss: 1.3716, lr: 0.0010\n",
      "Epoch: 32, Training loss: 1.376394, Validation loss: 1.3936, lr: 0.0001\n",
      "Epoch: 33, Training loss: 1.385576, Validation loss: 1.3577, lr: 0.0001\n",
      "Epoch: 34, Training loss: 1.374675, Validation loss: 1.3795, lr: 0.0001\n",
      "Epoch: 35, Training loss: 1.376945, Validation loss: 1.3864, lr: 0.0001\n",
      "Epoch: 36, Training loss: 1.377562, Validation loss: 1.3907, lr: 0.0001\n",
      "Epoch: 37, Training loss: 1.397425, Validation loss: 1.3884, lr: 0.0001\n",
      "Epoch: 38, Training loss: 1.397620, Validation loss: 1.3826, lr: 0.0001\n",
      "Epoch: 39, Training loss: 1.379693, Validation loss: 1.3546, lr: 0.0001\n",
      "Epoch: 40, Training loss: 1.384872, Validation loss: 1.3819, lr: 0.0001\n",
      "Epoch: 41, Training loss: 1.487639, Validation loss: 1.3886, lr: 0.0001\n",
      "Epoch: 42, Training loss: 1.393416, Validation loss: 1.3809, lr: 0.0001\n",
      "Epoch: 43, Training loss: 1.384716, Validation loss: 1.3648, lr: 0.0000\n",
      "Epoch: 44, Training loss: 1.377481, Validation loss: 1.3879, lr: 0.0000\n",
      "Epoch: 45, Training loss: 1.381220, Validation loss: 1.3781, lr: 0.0000\n",
      "Epoch: 46, Training loss: 1.389893, Validation loss: 1.3793, lr: 0.0000\n",
      "Epoch: 47, Training loss: 1.376314, Validation loss: 1.4374, lr: 0.0000\n",
      "Epoch: 48, Training loss: 1.377072, Validation loss: 1.3625, lr: 0.0000\n",
      "Epoch: 49, Training loss: 1.374144, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 50, Training loss: 1.388982, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 51, Training loss: 1.399039, Validation loss: 1.3671, lr: 0.0000\n",
      "Epoch: 52, Training loss: 1.376477, Validation loss: 1.3750, lr: 0.0000\n",
      "Epoch: 53, Training loss: 1.430232, Validation loss: 1.3765, lr: 0.0000\n",
      " *och: 54, Training loss: 1.393486, Validation loss: 1.3345, lr: 0.0000\n",
      "Epoch: 55, Training loss: 1.377411, Validation loss: 1.4109, lr: 0.0000\n",
      "Epoch: 56, Training loss: 1.365507, Validation loss: 1.4049, lr: 0.0000\n",
      "Epoch: 57, Training loss: 1.385729, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 58, Training loss: 1.401594, Validation loss: 1.3781, lr: 0.0000\n",
      "Epoch: 59, Training loss: 1.388919, Validation loss: 1.3995, lr: 0.0000\n",
      "Epoch: 60, Training loss: 1.378023, Validation loss: 1.3601, lr: 0.0000\n",
      "Epoch: 61, Training loss: 1.363986, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 62, Training loss: 1.384553, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 63, Training loss: 1.373162, Validation loss: 1.3702, lr: 0.0000\n",
      "Epoch: 64, Training loss: 1.383774, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 65, Training loss: 1.386411, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 66, Training loss: 1.369834, Validation loss: 1.3758, lr: 0.0000\n",
      "Epoch: 67, Training loss: 1.373323, Validation loss: 1.3733, lr: 0.0000\n",
      "Epoch: 68, Training loss: 1.391196, Validation loss: 1.3797, lr: 0.0000\n",
      " *och: 69, Training loss: 1.374437, Validation loss: 1.3339, lr: 0.0000\n",
      "Epoch: 70, Training loss: 1.389571, Validation loss: 1.3921, lr: 0.0000\n",
      "Epoch: 71, Training loss: 1.373549, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 72, Training loss: 1.383577, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 73, Training loss: 1.408102, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 74, Training loss: 1.388217, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 75, Training loss: 1.356391, Validation loss: 1.3905, lr: 0.0000\n",
      "Epoch: 76, Training loss: 1.382048, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 77, Training loss: 1.380311, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 78, Training loss: 1.379865, Validation loss: 1.3591, lr: 0.0000\n",
      "Epoch: 79, Training loss: 1.374020, Validation loss: 1.3777, lr: 0.0000\n",
      "Epoch: 80, Training loss: 1.455844, Validation loss: 1.3718, lr: 0.0000\n",
      "Epoch: 81, Training loss: 1.387155, Validation loss: 1.3800, lr: 0.0000\n",
      "Epoch: 82, Training loss: 1.367134, Validation loss: 1.3681, lr: 0.0000\n",
      "Epoch: 83, Training loss: 1.388325, Validation loss: 1.3755, lr: 0.0000\n",
      "Epoch: 84, Training loss: 1.380260, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 85, Training loss: 1.365580, Validation loss: 1.3637, lr: 0.0000\n",
      "Epoch: 86, Training loss: 1.380808, Validation loss: 1.8898, lr: 0.0000\n",
      "Epoch: 87, Training loss: 1.379195, Validation loss: 1.3754, lr: 0.0000\n",
      "Epoch: 88, Training loss: 1.377850, Validation loss: 1.3796, lr: 0.0000\n",
      "Epoch: 89, Training loss: 1.390247, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 90, Training loss: 1.389325, Validation loss: 1.3742, lr: 0.0000\n",
      "Epoch: 91, Training loss: 1.400529, Validation loss: 1.3874, lr: 0.0000\n",
      "Epoch: 92, Training loss: 1.369451, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 93, Training loss: 1.414930, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 94, Training loss: 1.381011, Validation loss: 1.3722, lr: 0.0000\n",
      "Epoch: 95, Training loss: 1.404730, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 96, Training loss: 1.379028, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 97, Training loss: 1.371076, Validation loss: 1.3666, lr: 0.0000\n",
      "Epoch: 98, Training loss: 1.374397, Validation loss: 1.3776, lr: 0.0000\n",
      "Epoch: 99, Training loss: 1.379817, Validation loss: 1.3802, lr: 0.0000\n",
      "Epoch: 100, Training loss: 1.388058, Validation loss: 1.3976, lr: 0.0000\n",
      "Epoch: 101, Training loss: 1.391911, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 102, Training loss: 1.378267, Validation loss: 1.3923, lr: 0.0000\n",
      "Epoch: 103, Training loss: 1.382053, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 104, Training loss: 1.385382, Validation loss: 1.3803, lr: 0.0000\n",
      "Epoch: 105, Training loss: 1.446037, Validation loss: 1.3931, lr: 0.0000\n",
      "Epoch: 106, Training loss: 1.382794, Validation loss: 3.6457, lr: 0.0000\n",
      "Epoch: 107, Training loss: 1.376931, Validation loss: 1.3999, lr: 0.0000\n",
      "Epoch: 108, Training loss: 1.397541, Validation loss: 1.3785, lr: 0.0000\n",
      "Epoch: 109, Training loss: 1.383623, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 110, Training loss: 1.427615, Validation loss: 1.3665, lr: 0.0000\n",
      "Epoch: 111, Training loss: 1.380218, Validation loss: 1.3634, lr: 0.0000\n",
      "Epoch: 112, Training loss: 1.375740, Validation loss: 1.3788, lr: 0.0000\n",
      "Epoch: 113, Training loss: 1.397328, Validation loss: 1.3697, lr: 0.0000\n",
      "Epoch: 114, Training loss: 1.462867, Validation loss: 1.3778, lr: 0.0000\n",
      "Epoch: 115, Training loss: 1.377906, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 116, Training loss: 1.468194, Validation loss: 1.3874, lr: 0.0000\n",
      "Epoch: 117, Training loss: 1.372590, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 118, Training loss: 1.371037, Validation loss: 1.3765, lr: 0.0000\n",
      "Epoch: 119, Training loss: 1.375585, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 120, Training loss: 1.376499, Validation loss: 1.3873, lr: 0.0000\n",
      "Epoch: 121, Training loss: 1.370517, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 122, Training loss: 1.406779, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 123, Training loss: 1.389680, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 124, Training loss: 1.393952, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 125, Training loss: 1.373229, Validation loss: 1.3941, lr: 0.0000\n",
      "Epoch: 126, Training loss: 1.391017, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 127, Training loss: 1.379544, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 128, Training loss: 1.374022, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 129, Training loss: 1.392360, Validation loss: 1.3799, lr: 0.0000\n",
      "Epoch: 130, Training loss: 1.371468, Validation loss: 1.3878, lr: 0.0000\n",
      "Epoch: 131, Training loss: 1.381329, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 132, Training loss: 1.406053, Validation loss: 1.4119, lr: 0.0000\n",
      "Epoch: 133, Training loss: 1.398887, Validation loss: 1.3951, lr: 0.0000\n",
      "Epoch: 134, Training loss: 1.366753, Validation loss: 1.3809, lr: 0.0000\n",
      "Epoch: 135, Training loss: 1.392772, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 136, Training loss: 1.386511, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 137, Training loss: 1.373064, Validation loss: 1.4068, lr: 0.0000\n",
      "Epoch: 138, Training loss: 1.372685, Validation loss: 1.3873, lr: 0.0000\n",
      "Epoch: 139, Training loss: 1.390119, Validation loss: 1.3902, lr: 0.0000\n",
      "Epoch: 140, Training loss: 1.376867, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 141, Training loss: 1.405044, Validation loss: 1.3708, lr: 0.0000\n",
      "Epoch: 142, Training loss: 1.398307, Validation loss: 1.3958, lr: 0.0000\n",
      "Epoch: 143, Training loss: 1.385723, Validation loss: 1.3726, lr: 0.0000\n",
      "Epoch: 144, Training loss: 1.371931, Validation loss: 1.3792, lr: 0.0000\n",
      "Epoch: 145, Training loss: 1.385849, Validation loss: 1.3871, lr: 0.0000\n",
      "Epoch: 146, Training loss: 1.393386, Validation loss: 1.7869, lr: 0.0000\n",
      "Epoch: 147, Training loss: 1.376051, Validation loss: 1.3737, lr: 0.0000\n",
      "Epoch: 148, Training loss: 1.386493, Validation loss: 1.3718, lr: 0.0000\n",
      "Epoch: 149, Training loss: 1.373326, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 150, Training loss: 1.406533, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 151, Training loss: 1.387182, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 152, Training loss: 1.373709, Validation loss: 1.3728, lr: 0.0000\n",
      "Epoch: 153, Training loss: 1.386264, Validation loss: 1.3774, lr: 0.0000\n",
      "Epoch: 154, Training loss: 1.366163, Validation loss: 1.3885, lr: 0.0000\n",
      "Epoch: 155, Training loss: 1.402781, Validation loss: 1.3767, lr: 0.0000\n",
      "Epoch: 156, Training loss: 1.372300, Validation loss: 1.3783, lr: 0.0000\n",
      "Epoch: 157, Training loss: 1.395964, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 158, Training loss: 1.387961, Validation loss: 1.3736, lr: 0.0000\n",
      "Epoch: 159, Training loss: 1.369487, Validation loss: 1.3636, lr: 0.0000\n",
      "Epoch: 160, Training loss: 1.378230, Validation loss: 1.3944, lr: 0.0000\n",
      "Epoch: 161, Training loss: 1.391663, Validation loss: 1.3540, lr: 0.0000\n",
      "Epoch: 162, Training loss: 1.380732, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 163, Training loss: 1.370503, Validation loss: 1.3397, lr: 0.0000\n",
      "Epoch: 164, Training loss: 1.380732, Validation loss: 1.3777, lr: 0.0000\n",
      "Epoch: 165, Training loss: 1.385558, Validation loss: 1.3890, lr: 0.0000\n",
      "Epoch: 166, Training loss: 1.369486, Validation loss: 1.3749, lr: 0.0000\n",
      "Epoch: 167, Training loss: 1.396069, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 168, Training loss: 1.394791, Validation loss: 1.3750, lr: 0.0000\n",
      "Epoch: 169, Training loss: 1.372291, Validation loss: 1.3714, lr: 0.0000\n",
      "Epoch: 170, Training loss: 1.380075, Validation loss: 1.3893, lr: 0.0000\n",
      "Epoch: 171, Training loss: 1.373472, Validation loss: 1.3543, lr: 0.0000\n",
      "Epoch: 172, Training loss: 1.390788, Validation loss: 1.3780, lr: 0.0000\n",
      "Epoch: 173, Training loss: 1.392029, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 174, Training loss: 1.395376, Validation loss: 1.3929, lr: 0.0000\n",
      "Epoch: 175, Training loss: 1.370409, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 176, Training loss: 1.369934, Validation loss: 1.3914, lr: 0.0000\n",
      "Epoch: 177, Training loss: 1.383140, Validation loss: 1.3535, lr: 0.0000\n",
      "Epoch: 178, Training loss: 1.367225, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 179, Training loss: 1.404915, Validation loss: 1.3742, lr: 0.0000\n",
      "Epoch: 180, Training loss: 1.366951, Validation loss: 1.3786, lr: 0.0000\n",
      "Epoch: 181, Training loss: 1.391995, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 182, Training loss: 1.381241, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 183, Training loss: 1.429018, Validation loss: 1.3754, lr: 0.0000\n",
      "Epoch: 184, Training loss: 1.388894, Validation loss: 1.4329, lr: 0.0000\n",
      "Epoch: 185, Training loss: 1.377999, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 186, Training loss: 1.376327, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 187, Training loss: 1.374754, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 188, Training loss: 1.380392, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 189, Training loss: 1.378989, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 190, Training loss: 1.396825, Validation loss: 1.3764, lr: 0.0000\n",
      "Epoch: 191, Training loss: 1.374623, Validation loss: 1.3900, lr: 0.0000\n",
      "Epoch: 192, Training loss: 1.372980, Validation loss: 1.3744, lr: 0.0000\n",
      "Epoch: 193, Training loss: 1.385284, Validation loss: 1.3901, lr: 0.0000\n",
      "Epoch: 194, Training loss: 1.383485, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 195, Training loss: 1.372060, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 196, Training loss: 1.385711, Validation loss: 1.4984, lr: 0.0000\n",
      "Epoch: 197, Training loss: 1.372662, Validation loss: 1.3662, lr: 0.0000\n",
      "Epoch: 198, Training loss: 1.378202, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 199, Training loss: 1.392720, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 200, Training loss: 1.372953, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 201, Training loss: 1.376231, Validation loss: 1.3908, lr: 0.0000\n",
      "Epoch: 202, Training loss: 1.392263, Validation loss: 1.4073, lr: 0.0000\n",
      "Epoch: 203, Training loss: 1.396993, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 204, Training loss: 1.376683, Validation loss: 1.3895, lr: 0.0000\n",
      "Epoch: 205, Training loss: 1.371936, Validation loss: 1.3764, lr: 0.0000\n",
      "Epoch: 206, Training loss: 1.393420, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 207, Training loss: 1.389955, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 208, Training loss: 1.376616, Validation loss: 1.3606, lr: 0.0000\n",
      "Epoch: 209, Training loss: 1.372802, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 210, Training loss: 1.361525, Validation loss: 1.3777, lr: 0.0000\n",
      "Epoch: 211, Training loss: 1.382852, Validation loss: 1.3727, lr: 0.0000\n",
      "Epoch: 212, Training loss: 1.361584, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 213, Training loss: 1.383421, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 214, Training loss: 1.376791, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 215, Training loss: 1.389212, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 216, Training loss: 1.377405, Validation loss: 1.3762, lr: 0.0000\n",
      "Epoch: 217, Training loss: 1.375690, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 218, Training loss: 1.416192, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 219, Training loss: 1.375368, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 220, Training loss: 1.389084, Validation loss: 1.3542, lr: 0.0000\n",
      "Epoch: 221, Training loss: 1.372532, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 222, Training loss: 1.398048, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 223, Training loss: 1.377623, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 224, Training loss: 1.399636, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 225, Training loss: 1.384309, Validation loss: 1.3727, lr: 0.0000\n",
      "Epoch: 226, Training loss: 1.374732, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 227, Training loss: 1.384970, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 228, Training loss: 1.379978, Validation loss: 1.3883, lr: 0.0000\n",
      "Epoch: 229, Training loss: 1.404276, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 230, Training loss: 1.376725, Validation loss: 1.3739, lr: 0.0000\n",
      "Epoch: 231, Training loss: 1.374299, Validation loss: 1.3777, lr: 0.0000\n",
      "Epoch: 232, Training loss: 1.375169, Validation loss: 1.4121, lr: 0.0000\n",
      "Epoch: 233, Training loss: 1.397019, Validation loss: 1.3873, lr: 0.0000\n",
      "Epoch: 234, Training loss: 1.366257, Validation loss: 1.3791, lr: 0.0000\n",
      "Epoch: 235, Training loss: 1.365670, Validation loss: 1.3877, lr: 0.0000\n",
      "Epoch: 236, Training loss: 1.368316, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 237, Training loss: 1.377472, Validation loss: 1.3765, lr: 0.0000\n",
      "Epoch: 238, Training loss: 1.368710, Validation loss: 1.3740, lr: 0.0000\n",
      "Epoch: 239, Training loss: 1.390120, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 240, Training loss: 1.389128, Validation loss: 1.3874, lr: 0.0000\n",
      "Epoch: 241, Training loss: 1.395296, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 242, Training loss: 1.368004, Validation loss: 1.4230, lr: 0.0000\n",
      "Epoch: 243, Training loss: 1.376656, Validation loss: 1.3910, lr: 0.0000\n",
      "Epoch: 244, Training loss: 1.374807, Validation loss: 1.3776, lr: 0.0000\n",
      "Epoch: 245, Training loss: 1.387911, Validation loss: 1.3891, lr: 0.0000\n",
      "Epoch: 246, Training loss: 1.386923, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 247, Training loss: 1.383294, Validation loss: 1.3793, lr: 0.0000\n",
      "Epoch: 248, Training loss: 1.385594, Validation loss: 1.3904, lr: 0.0000\n",
      "Epoch: 249, Training loss: 1.376339, Validation loss: 1.3995, lr: 0.0000\n",
      "Epoch: 250, Training loss: 1.397601, Validation loss: 1.3942, lr: 0.0000\n",
      "Epoch: 251, Training loss: 1.368992, Validation loss: 1.3758, lr: 0.0000\n",
      "Epoch: 252, Training loss: 1.396091, Validation loss: 1.3875, lr: 0.0000\n",
      "Epoch: 253, Training loss: 1.404234, Validation loss: 1.3932, lr: 0.0000\n",
      "Epoch: 254, Training loss: 1.391800, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 255, Training loss: 1.389654, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 256, Training loss: 1.387277, Validation loss: 1.3756, lr: 0.0000\n",
      "Epoch: 257, Training loss: 1.385310, Validation loss: 1.3767, lr: 0.0000\n",
      "Epoch: 258, Training loss: 1.390352, Validation loss: 1.3892, lr: 0.0000\n",
      "Epoch: 259, Training loss: 1.379873, Validation loss: 1.3444, lr: 0.0000\n",
      "Epoch: 260, Training loss: 1.362758, Validation loss: 1.3779, lr: 0.0000\n",
      "Epoch: 261, Training loss: 1.383748, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 262, Training loss: 1.386294, Validation loss: 1.3883, lr: 0.0000\n",
      "Epoch: 263, Training loss: 1.379139, Validation loss: 1.3674, lr: 0.0000\n",
      "Epoch: 264, Training loss: 1.371406, Validation loss: 1.3989, lr: 0.0000\n",
      "Epoch: 265, Training loss: 1.374948, Validation loss: 1.3691, lr: 0.0000\n",
      "Epoch: 266, Training loss: 1.376120, Validation loss: 1.4142, lr: 0.0000\n",
      "Epoch: 267, Training loss: 1.387779, Validation loss: 1.3743, lr: 0.0000\n",
      "Epoch: 268, Training loss: 1.362336, Validation loss: 1.4036, lr: 0.0000\n",
      "Epoch: 269, Training loss: 1.379236, Validation loss: 1.3703, lr: 0.0000\n",
      "Epoch: 270, Training loss: 1.374923, Validation loss: 1.3910, lr: 0.0000\n",
      "Epoch: 271, Training loss: 1.364506, Validation loss: 1.3796, lr: 0.0000\n",
      "Epoch: 272, Training loss: 1.381675, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 273, Training loss: 1.383299, Validation loss: 1.3794, lr: 0.0000\n",
      "Epoch: 274, Training loss: 1.386292, Validation loss: 1.4165, lr: 0.0000\n",
      "Epoch: 275, Training loss: 1.391821, Validation loss: 1.4044, lr: 0.0000\n",
      "Epoch: 276, Training loss: 1.418471, Validation loss: 1.4038, lr: 0.0000\n",
      "Epoch: 277, Training loss: 1.382822, Validation loss: 1.3748, lr: 0.0000\n",
      "Epoch: 278, Training loss: 1.378527, Validation loss: 1.3660, lr: 0.0000\n",
      "Epoch: 279, Training loss: 1.383124, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 280, Training loss: 1.393220, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 281, Training loss: 1.410840, Validation loss: 1.3614, lr: 0.0000\n",
      "Epoch: 282, Training loss: 1.383129, Validation loss: 1.3938, lr: 0.0000\n",
      "Epoch: 283, Training loss: 1.397094, Validation loss: 1.3781, lr: 0.0000\n",
      "Epoch: 284, Training loss: 1.383613, Validation loss: 1.3715, lr: 0.0000\n",
      "Epoch: 285, Training loss: 1.384400, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 286, Training loss: 1.390800, Validation loss: 1.3749, lr: 0.0000\n",
      "Epoch: 287, Training loss: 1.365650, Validation loss: 1.3979, lr: 0.0000\n",
      "Epoch: 288, Training loss: 1.388975, Validation loss: 1.3871, lr: 0.0000\n",
      "Epoch: 289, Training loss: 1.398261, Validation loss: 1.3774, lr: 0.0000\n",
      "Epoch: 290, Training loss: 1.386303, Validation loss: 1.3771, lr: 0.0000\n",
      "Epoch: 291, Training loss: 1.373553, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 292, Training loss: 1.391175, Validation loss: 1.3794, lr: 0.0000\n",
      "Epoch: 293, Training loss: 1.416472, Validation loss: 1.3634, lr: 0.0000\n",
      "Epoch: 294, Training loss: 1.385732, Validation loss: 1.3936, lr: 0.0000\n",
      "Epoch: 295, Training loss: 1.383499, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 296, Training loss: 1.378057, Validation loss: 1.3755, lr: 0.0000\n",
      "Epoch: 297, Training loss: 1.384976, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 298, Training loss: 1.410077, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 299, Training loss: 1.393806, Validation loss: 1.3838, lr: 0.0000\n",
      " *och: 300, Training loss: 1.472265, Validation loss: 1.3335, lr: 0.0000\n",
      "Epoch: 301, Training loss: 1.389418, Validation loss: 1.3897, lr: 0.0000\n",
      "Epoch: 302, Training loss: 1.377209, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 303, Training loss: 1.369186, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 304, Training loss: 1.384382, Validation loss: 1.3663, lr: 0.0000\n",
      "Epoch: 305, Training loss: 1.363115, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 306, Training loss: 1.401880, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 307, Training loss: 1.395788, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 308, Training loss: 1.382438, Validation loss: 1.3983, lr: 0.0000\n",
      "Epoch: 309, Training loss: 1.389453, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 310, Training loss: 1.385140, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 311, Training loss: 1.435223, Validation loss: 1.3712, lr: 0.0000\n",
      "Epoch: 312, Training loss: 1.386818, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 313, Training loss: 1.377174, Validation loss: 1.3753, lr: 0.0000\n",
      "Epoch: 314, Training loss: 1.459499, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 315, Training loss: 1.370373, Validation loss: 1.3696, lr: 0.0000\n",
      "Epoch: 316, Training loss: 1.377842, Validation loss: 1.3773, lr: 0.0000\n",
      "Epoch: 317, Training loss: 1.382114, Validation loss: 1.3664, lr: 0.0000\n",
      "Epoch: 318, Training loss: 1.407441, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 319, Training loss: 1.374176, Validation loss: 1.4030, lr: 0.0000\n",
      "Epoch: 320, Training loss: 1.385237, Validation loss: 1.8548, lr: 0.0000\n",
      "Epoch: 321, Training loss: 1.378695, Validation loss: 1.3928, lr: 0.0000\n",
      "Epoch: 322, Training loss: 1.396475, Validation loss: 1.3719, lr: 0.0000\n",
      "Epoch: 323, Training loss: 1.383215, Validation loss: 1.3718, lr: 0.0000\n",
      "Epoch: 324, Training loss: 1.379664, Validation loss: 1.3919, lr: 0.0000\n",
      "Epoch: 325, Training loss: 1.456348, Validation loss: 1.3759, lr: 0.0000\n",
      "Epoch: 326, Training loss: 1.411319, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 327, Training loss: 1.376791, Validation loss: 1.3911, lr: 0.0000\n",
      "Epoch: 328, Training loss: 1.369225, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 329, Training loss: 1.407660, Validation loss: 1.3733, lr: 0.0000\n",
      "Epoch: 330, Training loss: 1.405557, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 331, Training loss: 1.393033, Validation loss: 1.3734, lr: 0.0000\n",
      "Epoch: 332, Training loss: 1.378293, Validation loss: 1.3879, lr: 0.0000\n",
      "Epoch: 333, Training loss: 1.382707, Validation loss: 1.3798, lr: 0.0000\n",
      "Epoch: 334, Training loss: 1.384112, Validation loss: 1.5541, lr: 0.0000\n",
      "Epoch: 335, Training loss: 1.381666, Validation loss: 1.3468, lr: 0.0000\n",
      "Epoch: 336, Training loss: 1.375945, Validation loss: 1.3802, lr: 0.0000\n",
      "Epoch: 337, Training loss: 1.384114, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 338, Training loss: 1.376220, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 339, Training loss: 1.381927, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 340, Training loss: 1.417738, Validation loss: 1.3667, lr: 0.0000\n",
      "Epoch: 341, Training loss: 1.383345, Validation loss: 1.3880, lr: 0.0000\n",
      "Epoch: 342, Training loss: 1.394937, Validation loss: 1.3798, lr: 0.0000\n",
      "Epoch: 343, Training loss: 1.391016, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 344, Training loss: 1.384666, Validation loss: 1.3433, lr: 0.0000\n",
      "Epoch: 345, Training loss: 1.364305, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 346, Training loss: 1.378788, Validation loss: 1.3879, lr: 0.0000\n",
      "Epoch: 347, Training loss: 1.386912, Validation loss: 1.3741, lr: 0.0000\n",
      "Epoch: 348, Training loss: 1.385005, Validation loss: 1.3777, lr: 0.0000\n",
      "Epoch: 349, Training loss: 1.415058, Validation loss: 1.4742, lr: 0.0000\n",
      "Epoch: 350, Training loss: 1.370989, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 351, Training loss: 1.372716, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 352, Training loss: 1.396315, Validation loss: 1.3926, lr: 0.0000\n",
      "Epoch: 353, Training loss: 1.394811, Validation loss: 1.3959, lr: 0.0000\n",
      "Epoch: 354, Training loss: 1.354639, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 355, Training loss: 1.376747, Validation loss: 1.3977, lr: 0.0000\n",
      "Epoch: 356, Training loss: 1.395500, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 357, Training loss: 1.372057, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 358, Training loss: 1.372874, Validation loss: 1.3873, lr: 0.0000\n",
      "Epoch: 359, Training loss: 1.377085, Validation loss: 1.3876, lr: 0.0000\n",
      "Epoch: 360, Training loss: 1.365427, Validation loss: 1.4027, lr: 0.0000\n",
      "Epoch: 361, Training loss: 1.370944, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 362, Training loss: 1.383172, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 363, Training loss: 1.389813, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 364, Training loss: 1.387916, Validation loss: 1.3574, lr: 0.0000\n",
      "Epoch: 365, Training loss: 1.377022, Validation loss: 1.3647, lr: 0.0000\n",
      "Epoch: 366, Training loss: 1.385385, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 367, Training loss: 1.391232, Validation loss: 1.3780, lr: 0.0000\n",
      "Epoch: 368, Training loss: 1.383245, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 369, Training loss: 1.385333, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 370, Training loss: 1.389197, Validation loss: 1.3788, lr: 0.0000\n",
      "Epoch: 371, Training loss: 1.404157, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 372, Training loss: 1.376842, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 373, Training loss: 1.379907, Validation loss: 1.3909, lr: 0.0000\n",
      "Epoch: 374, Training loss: 1.375359, Validation loss: 1.3713, lr: 0.0000\n",
      "Epoch: 375, Training loss: 1.375704, Validation loss: 1.3795, lr: 0.0000\n",
      "Epoch: 376, Training loss: 1.390082, Validation loss: 2.1242, lr: 0.0000\n",
      "Epoch: 377, Training loss: 1.372864, Validation loss: 1.3710, lr: 0.0000\n",
      "Epoch: 378, Training loss: 1.366390, Validation loss: 1.3766, lr: 0.0000\n",
      "Epoch: 379, Training loss: 1.383162, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 380, Training loss: 1.377065, Validation loss: 1.3891, lr: 0.0000\n",
      "Epoch: 381, Training loss: 1.379277, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 382, Training loss: 1.374874, Validation loss: 1.3871, lr: 0.0000\n",
      "Epoch: 383, Training loss: 1.372934, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 384, Training loss: 1.371526, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 385, Training loss: 1.384576, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 386, Training loss: 1.381499, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 387, Training loss: 1.381669, Validation loss: 1.3771, lr: 0.0000\n",
      "Epoch: 388, Training loss: 1.383271, Validation loss: 1.3924, lr: 0.0000\n",
      "Epoch: 389, Training loss: 1.396916, Validation loss: 1.3958, lr: 0.0000\n",
      "Epoch: 390, Training loss: 1.382753, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 391, Training loss: 1.406854, Validation loss: 1.3905, lr: 0.0000\n",
      "Epoch: 392, Training loss: 1.379967, Validation loss: 1.3798, lr: 0.0000\n",
      "Epoch: 393, Training loss: 1.378568, Validation loss: 1.4230, lr: 0.0000\n",
      "Epoch: 394, Training loss: 1.404740, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 395, Training loss: 1.403657, Validation loss: 1.3952, lr: 0.0000\n",
      "Epoch: 396, Training loss: 1.378572, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 397, Training loss: 1.379220, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 398, Training loss: 1.370164, Validation loss: 1.3647, lr: 0.0000\n",
      "Epoch: 399, Training loss: 1.390289, Validation loss: 1.3654, lr: 0.0000\n",
      "Epoch: 400, Training loss: 1.375131, Validation loss: 1.3726, lr: 0.0000\n",
      "Epoch: 401, Training loss: 1.381886, Validation loss: 1.3783, lr: 0.0000\n",
      "Epoch: 402, Training loss: 1.381875, Validation loss: 1.3649, lr: 0.0000\n",
      "Epoch: 403, Training loss: 1.387656, Validation loss: 1.3767, lr: 0.0000\n",
      "Epoch: 404, Training loss: 1.387521, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 405, Training loss: 1.406533, Validation loss: 1.3787, lr: 0.0000\n",
      "Epoch: 406, Training loss: 1.382477, Validation loss: 1.4195, lr: 0.0000\n",
      "Epoch: 407, Training loss: 1.384107, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 408, Training loss: 1.413041, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 409, Training loss: 1.384458, Validation loss: 1.3883, lr: 0.0000\n",
      "Epoch: 410, Training loss: 1.369616, Validation loss: 1.3927, lr: 0.0000\n",
      "Epoch: 411, Training loss: 1.377475, Validation loss: 1.3880, lr: 0.0000\n",
      "Epoch: 412, Training loss: 1.424360, Validation loss: 1.3727, lr: 0.0000\n",
      "Epoch: 413, Training loss: 1.377443, Validation loss: 1.3778, lr: 0.0000\n",
      "Epoch: 414, Training loss: 1.389777, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 415, Training loss: 1.366620, Validation loss: 1.4043, lr: 0.0000\n",
      "Epoch: 416, Training loss: 1.375604, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 417, Training loss: 1.386699, Validation loss: 1.4205, lr: 0.0000\n",
      "Epoch: 418, Training loss: 1.373060, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 419, Training loss: 1.369940, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 420, Training loss: 1.380913, Validation loss: 1.3873, lr: 0.0000\n",
      "Epoch: 421, Training loss: 1.396037, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 422, Training loss: 1.388453, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 423, Training loss: 1.386967, Validation loss: 1.3698, lr: 0.0000\n",
      "Epoch: 424, Training loss: 1.379098, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 425, Training loss: 1.390832, Validation loss: 1.4155, lr: 0.0000\n",
      "Epoch: 426, Training loss: 1.379189, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 427, Training loss: 1.381674, Validation loss: 1.3722, lr: 0.0000\n",
      "Epoch: 428, Training loss: 1.383714, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 429, Training loss: 1.377311, Validation loss: 1.3991, lr: 0.0000\n",
      "Epoch: 430, Training loss: 1.373295, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 431, Training loss: 1.368342, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 432, Training loss: 1.393865, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 433, Training loss: 1.390381, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 434, Training loss: 1.372297, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 435, Training loss: 1.394021, Validation loss: 1.3727, lr: 0.0000\n",
      "Epoch: 436, Training loss: 1.386874, Validation loss: 1.4009, lr: 0.0000\n",
      "Epoch: 437, Training loss: 1.389352, Validation loss: 1.3452, lr: 0.0000\n",
      "Epoch: 438, Training loss: 1.369683, Validation loss: 1.3728, lr: 0.0000\n",
      "Epoch: 439, Training loss: 1.396241, Validation loss: 1.3883, lr: 0.0000\n",
      "Epoch: 440, Training loss: 1.409503, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 441, Training loss: 1.377975, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 442, Training loss: 1.375954, Validation loss: 1.3775, lr: 0.0000\n",
      "Epoch: 443, Training loss: 1.371824, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 444, Training loss: 1.363015, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 445, Training loss: 1.387509, Validation loss: 1.3791, lr: 0.0000\n",
      "Epoch: 446, Training loss: 1.395678, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 447, Training loss: 1.393306, Validation loss: 1.3798, lr: 0.0000\n",
      "Epoch: 448, Training loss: 1.374832, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 449, Training loss: 1.370983, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 450, Training loss: 1.405916, Validation loss: 1.3836, lr: 0.0000\n",
      " *och: 451, Training loss: 1.415319, Validation loss: 1.3316, lr: 0.0000\n",
      "Epoch: 452, Training loss: 1.381403, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 453, Training loss: 1.406859, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 454, Training loss: 1.373893, Validation loss: 1.3789, lr: 0.0000\n",
      "Epoch: 455, Training loss: 1.393761, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 456, Training loss: 1.368890, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 457, Training loss: 1.374235, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 458, Training loss: 1.387629, Validation loss: 1.3692, lr: 0.0000\n",
      "Epoch: 459, Training loss: 1.383398, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 460, Training loss: 1.370575, Validation loss: 1.3690, lr: 0.0000\n",
      "Epoch: 461, Training loss: 1.431473, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 462, Training loss: 1.383753, Validation loss: 1.3926, lr: 0.0000\n",
      "Epoch: 463, Training loss: 1.374345, Validation loss: 1.3894, lr: 0.0000\n",
      "Epoch: 464, Training loss: 1.367746, Validation loss: 1.3738, lr: 0.0000\n",
      "Epoch: 465, Training loss: 1.366942, Validation loss: 1.3977, lr: 0.0000\n",
      "Epoch: 466, Training loss: 1.380867, Validation loss: 1.3621, lr: 0.0000\n",
      "Epoch: 467, Training loss: 1.378090, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 468, Training loss: 1.381525, Validation loss: 1.3722, lr: 0.0000\n",
      "Epoch: 469, Training loss: 1.404984, Validation loss: 1.3544, lr: 0.0000\n",
      "Epoch: 470, Training loss: 1.369455, Validation loss: 1.3651, lr: 0.0000\n",
      "Epoch: 471, Training loss: 1.387903, Validation loss: 1.3685, lr: 0.0000\n",
      "Epoch: 472, Training loss: 1.390485, Validation loss: 1.3944, lr: 0.0000\n",
      "Epoch: 473, Training loss: 1.397470, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 474, Training loss: 1.376163, Validation loss: 1.3615, lr: 0.0000\n",
      "Epoch: 475, Training loss: 1.374629, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 476, Training loss: 1.409355, Validation loss: 1.3728, lr: 0.0000\n",
      "Epoch: 477, Training loss: 1.372201, Validation loss: 1.3595, lr: 0.0000\n",
      "Epoch: 478, Training loss: 1.376156, Validation loss: 1.3874, lr: 0.0000\n",
      "Epoch: 479, Training loss: 1.397957, Validation loss: 1.3762, lr: 0.0000\n",
      "Epoch: 480, Training loss: 1.406872, Validation loss: 1.3882, lr: 0.0000\n",
      "Epoch: 481, Training loss: 1.369544, Validation loss: 1.3878, lr: 0.0000\n",
      "Epoch: 482, Training loss: 1.384425, Validation loss: 1.3738, lr: 0.0000\n",
      "Epoch: 483, Training loss: 1.390207, Validation loss: 1.3914, lr: 0.0000\n",
      "Epoch: 484, Training loss: 1.380487, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 485, Training loss: 1.390643, Validation loss: 1.3515, lr: 0.0000\n",
      "Epoch: 486, Training loss: 1.369030, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 487, Training loss: 1.423711, Validation loss: 1.3800, lr: 0.0000\n",
      "Epoch: 488, Training loss: 1.388986, Validation loss: 1.3766, lr: 0.0000\n",
      "Epoch: 489, Training loss: 1.392304, Validation loss: 1.3594, lr: 0.0000\n",
      "Epoch: 490, Training loss: 1.371233, Validation loss: 1.3908, lr: 0.0000\n",
      "Epoch: 491, Training loss: 1.363340, Validation loss: 1.3616, lr: 0.0000\n",
      "Epoch: 492, Training loss: 1.381048, Validation loss: 1.3784, lr: 0.0000\n",
      "Epoch: 493, Training loss: 1.361660, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 494, Training loss: 1.395450, Validation loss: 1.3880, lr: 0.0000\n",
      "Epoch: 495, Training loss: 1.386050, Validation loss: 1.4029, lr: 0.0000\n",
      "Epoch: 496, Training loss: 1.365358, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 497, Training loss: 1.373036, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 498, Training loss: 1.358767, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 499, Training loss: 1.389458, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 500, Training loss: 1.371930, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 501, Training loss: 1.375145, Validation loss: 1.3769, lr: 0.0000\n",
      "Epoch: 502, Training loss: 1.396503, Validation loss: 1.3694, lr: 0.0000\n",
      "Epoch: 503, Training loss: 1.385805, Validation loss: 1.3898, lr: 0.0000\n",
      "Epoch: 504, Training loss: 1.384580, Validation loss: 1.3557, lr: 0.0000\n",
      "Epoch: 505, Training loss: 1.363265, Validation loss: 1.3875, lr: 0.0000\n",
      "Epoch: 506, Training loss: 1.378022, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 507, Training loss: 1.381426, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 508, Training loss: 1.370385, Validation loss: 1.3576, lr: 0.0000\n",
      "Epoch: 509, Training loss: 1.388671, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 510, Training loss: 1.379190, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 511, Training loss: 1.383509, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 512, Training loss: 1.367820, Validation loss: 1.3890, lr: 0.0000\n",
      "Epoch: 513, Training loss: 1.372498, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 514, Training loss: 1.379774, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 515, Training loss: 1.376104, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 516, Training loss: 1.365634, Validation loss: 1.3750, lr: 0.0000\n",
      "Epoch: 517, Training loss: 1.383113, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 518, Training loss: 1.389738, Validation loss: 1.3799, lr: 0.0000\n",
      "Epoch: 519, Training loss: 1.388444, Validation loss: 1.3885, lr: 0.0000\n",
      "Epoch: 520, Training loss: 1.402171, Validation loss: 1.4058, lr: 0.0000\n",
      "Epoch: 521, Training loss: 1.404923, Validation loss: 1.3766, lr: 0.0000\n",
      "Epoch: 522, Training loss: 1.367671, Validation loss: 1.3877, lr: 0.0000\n",
      "Epoch: 523, Training loss: 1.380479, Validation loss: 1.3914, lr: 0.0000\n",
      "Epoch: 524, Training loss: 1.376447, Validation loss: 1.3975, lr: 0.0000\n",
      "Epoch: 525, Training loss: 1.393923, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 526, Training loss: 1.377820, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 527, Training loss: 1.364656, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 528, Training loss: 1.384916, Validation loss: 1.3778, lr: 0.0000\n",
      "Epoch: 529, Training loss: 1.392624, Validation loss: 1.3874, lr: 0.0000\n",
      "Epoch: 530, Training loss: 1.400922, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 531, Training loss: 1.379052, Validation loss: 1.3750, lr: 0.0000\n",
      "Epoch: 532, Training loss: 1.370812, Validation loss: 1.3883, lr: 0.0000\n",
      "Epoch: 533, Training loss: 1.382936, Validation loss: 1.3786, lr: 0.0000\n",
      "Epoch: 534, Training loss: 1.386450, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 535, Training loss: 1.391642, Validation loss: 1.4181, lr: 0.0000\n",
      "Epoch: 536, Training loss: 1.427958, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 537, Training loss: 1.385471, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 538, Training loss: 1.378341, Validation loss: 1.3636, lr: 0.0000\n",
      "Epoch: 539, Training loss: 1.387380, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 540, Training loss: 1.370810, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 541, Training loss: 1.375725, Validation loss: 1.3914, lr: 0.0000\n",
      "Epoch: 542, Training loss: 1.379602, Validation loss: 1.3703, lr: 0.0000\n",
      "Epoch: 543, Training loss: 1.370742, Validation loss: 1.3739, lr: 0.0000\n",
      "Epoch: 544, Training loss: 1.387541, Validation loss: 1.4042, lr: 0.0000\n",
      "Epoch: 545, Training loss: 1.391098, Validation loss: 1.3950, lr: 0.0000\n",
      "Epoch: 546, Training loss: 1.371530, Validation loss: 1.3745, lr: 0.0000\n",
      "Epoch: 547, Training loss: 1.366291, Validation loss: 3.8467, lr: 0.0000\n",
      "Epoch: 548, Training loss: 1.373935, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 549, Training loss: 1.375739, Validation loss: 1.3802, lr: 0.0000\n",
      "Epoch: 550, Training loss: 1.378327, Validation loss: 1.3787, lr: 0.0000\n",
      "Epoch: 551, Training loss: 1.375023, Validation loss: 1.3767, lr: 0.0000\n",
      "Epoch: 552, Training loss: 1.376818, Validation loss: 1.3944, lr: 0.0000\n",
      "Epoch: 553, Training loss: 1.374898, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 554, Training loss: 1.404270, Validation loss: 1.3887, lr: 0.0000\n",
      "Epoch: 555, Training loss: 1.390256, Validation loss: 1.3881, lr: 0.0000\n",
      "Epoch: 556, Training loss: 1.391227, Validation loss: 1.3934, lr: 0.0000\n",
      "Epoch: 557, Training loss: 1.390311, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 558, Training loss: 1.383371, Validation loss: 1.3624, lr: 0.0000\n",
      "Epoch: 559, Training loss: 1.368858, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 560, Training loss: 1.370199, Validation loss: 1.3748, lr: 0.0000\n",
      "Epoch: 561, Training loss: 1.401493, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 562, Training loss: 1.404926, Validation loss: 1.3894, lr: 0.0000\n",
      "Epoch: 563, Training loss: 1.386892, Validation loss: 1.3561, lr: 0.0000\n",
      "Epoch: 564, Training loss: 1.383434, Validation loss: 1.4197, lr: 0.0000\n",
      "Epoch: 565, Training loss: 1.380325, Validation loss: 1.3649, lr: 0.0000\n",
      "Epoch: 566, Training loss: 1.380406, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 567, Training loss: 1.384106, Validation loss: 1.3620, lr: 0.0000\n",
      "Epoch: 568, Training loss: 1.383627, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 569, Training loss: 1.398881, Validation loss: 1.3728, lr: 0.0000\n",
      "Epoch: 570, Training loss: 1.381405, Validation loss: 1.3888, lr: 0.0000\n",
      "Epoch: 571, Training loss: 1.381167, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 572, Training loss: 1.378428, Validation loss: 1.3749, lr: 0.0000\n",
      "Epoch: 573, Training loss: 1.388644, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 574, Training loss: 1.389221, Validation loss: 1.3979, lr: 0.0000\n",
      "Epoch: 575, Training loss: 1.373466, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 576, Training loss: 1.386322, Validation loss: 1.3918, lr: 0.0000\n",
      "Epoch: 577, Training loss: 1.400036, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 578, Training loss: 1.372889, Validation loss: 1.4118, lr: 0.0000\n",
      "Epoch: 579, Training loss: 1.389060, Validation loss: 1.3885, lr: 0.0000\n",
      "Epoch: 580, Training loss: 1.370271, Validation loss: 1.3880, lr: 0.0000\n",
      "Epoch: 581, Training loss: 1.404728, Validation loss: 1.4025, lr: 0.0000\n",
      "Epoch: 582, Training loss: 1.376445, Validation loss: 1.3871, lr: 0.0000\n",
      "Epoch: 583, Training loss: 1.372891, Validation loss: 1.3678, lr: 0.0000\n",
      "Epoch: 584, Training loss: 1.385639, Validation loss: 1.3749, lr: 0.0000\n",
      "Epoch: 585, Training loss: 1.386834, Validation loss: 1.3881, lr: 0.0000\n",
      "Epoch: 586, Training loss: 1.374446, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 587, Training loss: 1.390712, Validation loss: 1.3803, lr: 0.0000\n",
      "Epoch: 588, Training loss: 1.390309, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 589, Training loss: 1.386771, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 590, Training loss: 1.390496, Validation loss: 1.3730, lr: 0.0000\n",
      "Epoch: 591, Training loss: 1.386378, Validation loss: 1.3905, lr: 0.0000\n",
      "Epoch: 592, Training loss: 1.381326, Validation loss: 1.3782, lr: 0.0000\n",
      "Epoch: 593, Training loss: 1.367568, Validation loss: 1.3750, lr: 0.0000\n",
      "Epoch: 594, Training loss: 1.375186, Validation loss: 1.3871, lr: 0.0000\n",
      "Epoch: 595, Training loss: 1.370955, Validation loss: 1.3729, lr: 0.0000\n",
      "Epoch: 596, Training loss: 1.388531, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 597, Training loss: 1.372105, Validation loss: 1.3926, lr: 0.0000\n",
      "Epoch: 598, Training loss: 1.374262, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 599, Training loss: 1.382149, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 600, Training loss: 1.400397, Validation loss: 1.3705, lr: 0.0000\n",
      "Epoch: 601, Training loss: 1.372187, Validation loss: 1.3926, lr: 0.0000\n",
      "Epoch: 602, Training loss: 1.389522, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 603, Training loss: 1.374513, Validation loss: 1.3740, lr: 0.0000\n",
      "Epoch: 604, Training loss: 1.400901, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 605, Training loss: 1.374287, Validation loss: 1.3908, lr: 0.0000\n",
      "Epoch: 606, Training loss: 1.362268, Validation loss: 1.3881, lr: 0.0000\n",
      "Epoch: 607, Training loss: 1.386787, Validation loss: 1.3735, lr: 0.0000\n",
      "Epoch: 608, Training loss: 1.441347, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 609, Training loss: 1.390694, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 610, Training loss: 1.388510, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 611, Training loss: 1.370461, Validation loss: 1.3701, lr: 0.0000\n",
      "Epoch: 612, Training loss: 1.370859, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 613, Training loss: 1.382174, Validation loss: 1.3953, lr: 0.0000\n",
      "Epoch: 614, Training loss: 1.375320, Validation loss: 1.3784, lr: 0.0000\n",
      "Epoch: 615, Training loss: 1.378993, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 616, Training loss: 1.407414, Validation loss: 1.3717, lr: 0.0000\n",
      "Epoch: 617, Training loss: 1.389574, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 618, Training loss: 1.382832, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 619, Training loss: 1.391349, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 620, Training loss: 1.403203, Validation loss: 1.3800, lr: 0.0000\n",
      "Epoch: 621, Training loss: 1.376783, Validation loss: 1.3760, lr: 0.0000\n",
      "Epoch: 622, Training loss: 1.376456, Validation loss: 1.3568, lr: 0.0000\n",
      "Epoch: 623, Training loss: 1.371207, Validation loss: 1.3788, lr: 0.0000\n",
      "Epoch: 624, Training loss: 1.413172, Validation loss: 1.3873, lr: 0.0000\n",
      "Epoch: 625, Training loss: 1.413939, Validation loss: 1.3659, lr: 0.0000\n",
      "Epoch: 626, Training loss: 1.378689, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 627, Training loss: 1.369143, Validation loss: 1.3670, lr: 0.0000\n",
      "Epoch: 628, Training loss: 1.396071, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 629, Training loss: 1.369978, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 630, Training loss: 1.363198, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 631, Training loss: 1.377099, Validation loss: 1.3737, lr: 0.0000\n",
      "Epoch: 632, Training loss: 1.376054, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 633, Training loss: 1.375426, Validation loss: 1.3921, lr: 0.0000\n",
      "Epoch: 634, Training loss: 1.421935, Validation loss: 1.3894, lr: 0.0000\n",
      "Epoch: 635, Training loss: 1.397234, Validation loss: 1.3901, lr: 0.0000\n",
      "Epoch: 636, Training loss: 1.389942, Validation loss: 1.3875, lr: 0.0000\n",
      "Epoch: 637, Training loss: 1.369328, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 638, Training loss: 1.356497, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 639, Training loss: 1.359151, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 640, Training loss: 1.402176, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 641, Training loss: 1.374551, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 642, Training loss: 1.395500, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 643, Training loss: 1.386004, Validation loss: 1.3738, lr: 0.0000\n",
      "Epoch: 644, Training loss: 1.387717, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 645, Training loss: 1.380360, Validation loss: 1.3698, lr: 0.0000\n",
      "Epoch: 646, Training loss: 1.365968, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 647, Training loss: 1.388583, Validation loss: 1.3775, lr: 0.0000\n",
      "Epoch: 648, Training loss: 1.391518, Validation loss: 1.4231, lr: 0.0000\n",
      "Epoch: 649, Training loss: 1.398151, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 650, Training loss: 1.395875, Validation loss: 1.3586, lr: 0.0000\n",
      "Epoch: 651, Training loss: 1.394375, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 652, Training loss: 1.375242, Validation loss: 1.3718, lr: 0.0000\n",
      "Epoch: 653, Training loss: 1.373415, Validation loss: 1.3782, lr: 0.0000\n",
      "Epoch: 654, Training loss: 1.400792, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 655, Training loss: 1.373780, Validation loss: 1.3759, lr: 0.0000\n",
      "Epoch: 656, Training loss: 1.377693, Validation loss: 1.4108, lr: 0.0000\n",
      "Epoch: 657, Training loss: 1.388525, Validation loss: 1.3892, lr: 0.0000\n",
      "Epoch: 658, Training loss: 1.380383, Validation loss: 1.3871, lr: 0.0000\n",
      "Epoch: 659, Training loss: 1.380883, Validation loss: 1.3666, lr: 0.0000\n",
      "Epoch: 660, Training loss: 1.384265, Validation loss: 1.3918, lr: 0.0000\n",
      "Epoch: 661, Training loss: 1.391474, Validation loss: 1.3774, lr: 0.0000\n",
      "Epoch: 662, Training loss: 1.425683, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 663, Training loss: 1.434562, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 664, Training loss: 1.377675, Validation loss: 1.4709, lr: 0.0000\n",
      "Epoch: 665, Training loss: 1.398329, Validation loss: 1.3690, lr: 0.0000\n",
      "Epoch: 666, Training loss: 1.370713, Validation loss: 1.3679, lr: 0.0000\n",
      "Epoch: 667, Training loss: 1.373463, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 668, Training loss: 1.410939, Validation loss: 1.3799, lr: 0.0000\n",
      "Epoch: 669, Training loss: 1.379788, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 670, Training loss: 1.385001, Validation loss: 1.3733, lr: 0.0000\n",
      "Epoch: 671, Training loss: 1.391193, Validation loss: 1.3893, lr: 0.0000\n",
      "Epoch: 672, Training loss: 1.411101, Validation loss: 1.3794, lr: 0.0000\n",
      "Epoch: 673, Training loss: 1.399627, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 674, Training loss: 1.389945, Validation loss: 1.3875, lr: 0.0000\n",
      "Epoch: 675, Training loss: 1.382591, Validation loss: 1.3877, lr: 0.0000\n",
      "Epoch: 676, Training loss: 1.377048, Validation loss: 1.3760, lr: 0.0000\n",
      "Epoch: 677, Training loss: 1.390016, Validation loss: 1.3779, lr: 0.0000\n",
      "Epoch: 678, Training loss: 1.397753, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 679, Training loss: 1.392659, Validation loss: 1.3710, lr: 0.0000\n",
      "Epoch: 680, Training loss: 1.377761, Validation loss: 1.4079, lr: 0.0000\n",
      "Epoch: 681, Training loss: 1.400466, Validation loss: 1.3782, lr: 0.0000\n",
      "Epoch: 682, Training loss: 1.374828, Validation loss: 1.3878, lr: 0.0000\n",
      "Epoch: 683, Training loss: 1.395855, Validation loss: 1.3584, lr: 0.0000\n",
      "Epoch: 684, Training loss: 1.396897, Validation loss: 1.3766, lr: 0.0000\n",
      "Epoch: 685, Training loss: 1.388121, Validation loss: 1.3927, lr: 0.0000\n",
      "Epoch: 686, Training loss: 1.372270, Validation loss: 1.3713, lr: 0.0000\n",
      "Epoch: 687, Training loss: 1.377362, Validation loss: 1.3687, lr: 0.0000\n",
      "Epoch: 688, Training loss: 1.386167, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 689, Training loss: 1.384216, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 690, Training loss: 1.383130, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 691, Training loss: 1.396988, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 692, Training loss: 1.375314, Validation loss: 1.3650, lr: 0.0000\n",
      "Epoch: 693, Training loss: 1.392628, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 694, Training loss: 1.386318, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 695, Training loss: 1.383321, Validation loss: 1.3872, lr: 0.0000\n",
      "Epoch: 696, Training loss: 1.391055, Validation loss: 1.3704, lr: 0.0000\n",
      "Epoch: 697, Training loss: 1.387007, Validation loss: 1.3914, lr: 0.0000\n",
      "Epoch: 698, Training loss: 1.383457, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 699, Training loss: 1.381712, Validation loss: 1.3914, lr: 0.0000\n",
      "Epoch: 700, Training loss: 1.419057, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 701, Training loss: 1.377039, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 702, Training loss: 1.377432, Validation loss: 1.3641, lr: 0.0000\n",
      "Epoch: 703, Training loss: 1.401699, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 704, Training loss: 1.372614, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 705, Training loss: 1.384747, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 706, Training loss: 1.370628, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 707, Training loss: 1.381080, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 708, Training loss: 1.374907, Validation loss: 1.3885, lr: 0.0000\n",
      "Epoch: 709, Training loss: 1.382255, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 710, Training loss: 1.370969, Validation loss: 1.3890, lr: 0.0000\n",
      "Epoch: 711, Training loss: 1.378109, Validation loss: 1.4243, lr: 0.0000\n",
      "Epoch: 712, Training loss: 1.406556, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 713, Training loss: 1.376863, Validation loss: 1.3924, lr: 0.0000\n",
      "Epoch: 714, Training loss: 1.384221, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 715, Training loss: 1.381967, Validation loss: 1.3882, lr: 0.0000\n",
      "Epoch: 716, Training loss: 1.373170, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 717, Training loss: 1.393963, Validation loss: 1.3747, lr: 0.0000\n",
      "Epoch: 718, Training loss: 1.365917, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 719, Training loss: 1.393764, Validation loss: 1.3871, lr: 0.0000\n",
      "Epoch: 720, Training loss: 1.371824, Validation loss: 1.3708, lr: 0.0000\n",
      "Epoch: 721, Training loss: 1.397557, Validation loss: 1.3901, lr: 0.0000\n",
      "Epoch: 722, Training loss: 1.378303, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 723, Training loss: 1.372898, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 724, Training loss: 1.386901, Validation loss: 1.4370, lr: 0.0000\n",
      "Epoch: 725, Training loss: 1.395793, Validation loss: 1.3741, lr: 0.0000\n",
      "Epoch: 726, Training loss: 1.371706, Validation loss: 1.3907, lr: 0.0000\n",
      "Epoch: 727, Training loss: 1.361471, Validation loss: 1.3754, lr: 0.0000\n",
      "Epoch: 728, Training loss: 1.368611, Validation loss: 1.3733, lr: 0.0000\n",
      " *och: 729, Training loss: 1.419990, Validation loss: 1.3286, lr: 0.0000\n",
      "Epoch: 730, Training loss: 1.360113, Validation loss: 1.3772, lr: 0.0000\n",
      "Epoch: 731, Training loss: 1.468812, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 732, Training loss: 1.397768, Validation loss: 1.3915, lr: 0.0000\n",
      "Epoch: 733, Training loss: 1.363122, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 734, Training loss: 1.436600, Validation loss: 1.3591, lr: 0.0000\n",
      "Epoch: 735, Training loss: 1.409172, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 736, Training loss: 1.384557, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 737, Training loss: 1.386426, Validation loss: 1.3985, lr: 0.0000\n",
      "Epoch: 738, Training loss: 1.381178, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 739, Training loss: 1.453196, Validation loss: 1.3742, lr: 0.0000\n",
      "Epoch: 740, Training loss: 1.400399, Validation loss: 1.3794, lr: 0.0000\n",
      "Epoch: 741, Training loss: 1.385507, Validation loss: 1.3793, lr: 0.0000\n",
      "Epoch: 742, Training loss: 1.411892, Validation loss: 1.3718, lr: 0.0000\n",
      "Epoch: 743, Training loss: 1.400762, Validation loss: 1.4228, lr: 0.0000\n",
      "Epoch: 744, Training loss: 1.369596, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 745, Training loss: 1.381474, Validation loss: 1.3873, lr: 0.0000\n",
      "Epoch: 746, Training loss: 1.379798, Validation loss: 1.4535, lr: 0.0000\n",
      "Epoch: 747, Training loss: 1.375916, Validation loss: 1.3873, lr: 0.0000\n",
      "Epoch: 748, Training loss: 1.378454, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 749, Training loss: 1.378733, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 750, Training loss: 1.383209, Validation loss: 1.3433, lr: 0.0000\n",
      "Epoch: 751, Training loss: 1.384358, Validation loss: 1.3745, lr: 0.0000\n",
      "Epoch: 752, Training loss: 1.385549, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 753, Training loss: 1.395189, Validation loss: 1.3933, lr: 0.0000\n",
      "Epoch: 754, Training loss: 1.375023, Validation loss: 1.3676, lr: 0.0000\n",
      "Epoch: 755, Training loss: 1.507001, Validation loss: 1.3803, lr: 0.0000\n",
      "Epoch: 756, Training loss: 1.380583, Validation loss: 1.3803, lr: 0.0000\n",
      "Epoch: 757, Training loss: 1.368818, Validation loss: 1.5237, lr: 0.0000\n",
      "Epoch: 758, Training loss: 1.378846, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 759, Training loss: 1.375758, Validation loss: 1.3935, lr: 0.0000\n",
      "Epoch: 760, Training loss: 1.420124, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 761, Training loss: 1.380054, Validation loss: 1.3877, lr: 0.0000\n",
      "Epoch: 762, Training loss: 1.381480, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 763, Training loss: 1.375004, Validation loss: 1.3879, lr: 0.0000\n",
      "Epoch: 764, Training loss: 1.404112, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 765, Training loss: 1.424932, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 766, Training loss: 1.395802, Validation loss: 1.3919, lr: 0.0000\n",
      "Epoch: 767, Training loss: 1.386392, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 768, Training loss: 1.393731, Validation loss: 1.3769, lr: 0.0000\n",
      "Epoch: 769, Training loss: 1.427474, Validation loss: 1.3776, lr: 0.0000\n",
      "Epoch: 770, Training loss: 1.365440, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 771, Training loss: 1.377253, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 772, Training loss: 1.383204, Validation loss: 1.3897, lr: 0.0000\n",
      "Epoch: 773, Training loss: 1.383082, Validation loss: 1.3769, lr: 0.0000\n",
      "Epoch: 774, Training loss: 1.389567, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 775, Training loss: 1.359303, Validation loss: 1.3696, lr: 0.0000\n",
      "Epoch: 776, Training loss: 1.386597, Validation loss: 1.3699, lr: 0.0000\n",
      "Epoch: 777, Training loss: 1.437824, Validation loss: 1.3797, lr: 0.0000\n",
      "Epoch: 778, Training loss: 1.405124, Validation loss: 1.3706, lr: 0.0000\n",
      "Epoch: 779, Training loss: 1.377604, Validation loss: 1.3607, lr: 0.0000\n",
      "Epoch: 780, Training loss: 1.396432, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 781, Training loss: 1.402299, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 782, Training loss: 1.385400, Validation loss: 1.3882, lr: 0.0000\n",
      "Epoch: 783, Training loss: 1.393878, Validation loss: 1.3481, lr: 0.0000\n",
      "Epoch: 784, Training loss: 1.388694, Validation loss: 1.4293, lr: 0.0000\n",
      "Epoch: 785, Training loss: 1.451764, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 786, Training loss: 1.395408, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 787, Training loss: 1.391773, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 788, Training loss: 1.367630, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 789, Training loss: 1.427981, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 790, Training loss: 1.379435, Validation loss: 1.3932, lr: 0.0000\n",
      "Epoch: 791, Training loss: 1.372048, Validation loss: 1.3909, lr: 0.0000\n",
      "Epoch: 792, Training loss: 1.426305, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 793, Training loss: 1.380115, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 794, Training loss: 1.366856, Validation loss: 1.3891, lr: 0.0000\n",
      "Epoch: 795, Training loss: 1.400545, Validation loss: 1.3710, lr: 0.0000\n",
      "Epoch: 796, Training loss: 1.394660, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 797, Training loss: 1.378269, Validation loss: 1.3741, lr: 0.0000\n",
      "Epoch: 798, Training loss: 1.368298, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 799, Training loss: 1.368653, Validation loss: 1.3790, lr: 0.0000\n",
      "Epoch: 800, Training loss: 1.388556, Validation loss: 1.3780, lr: 0.0000\n",
      "Epoch: 801, Training loss: 1.384517, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 802, Training loss: 1.395715, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 803, Training loss: 1.391083, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 804, Training loss: 1.389397, Validation loss: 1.4024, lr: 0.0000\n",
      "Epoch: 805, Training loss: 1.379534, Validation loss: 1.3663, lr: 0.0000\n",
      "Epoch: 806, Training loss: 1.387843, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 807, Training loss: 1.390568, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 808, Training loss: 1.393939, Validation loss: 1.3977, lr: 0.0000\n",
      "Epoch: 809, Training loss: 1.389924, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 810, Training loss: 1.390500, Validation loss: 1.3740, lr: 0.0000\n",
      "Epoch: 811, Training loss: 1.377865, Validation loss: 1.4865, lr: 0.0000\n",
      "Epoch: 812, Training loss: 1.378833, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 813, Training loss: 1.359781, Validation loss: 1.3800, lr: 0.0000\n",
      "Epoch: 814, Training loss: 1.383455, Validation loss: 1.3912, lr: 0.0000\n",
      "Epoch: 815, Training loss: 1.373737, Validation loss: 1.3706, lr: 0.0000\n",
      "Epoch: 816, Training loss: 1.386662, Validation loss: 1.3889, lr: 0.0000\n",
      "Epoch: 817, Training loss: 1.363670, Validation loss: 1.3731, lr: 0.0000\n",
      "Epoch: 818, Training loss: 1.368662, Validation loss: 1.3701, lr: 0.0000\n",
      "Epoch: 819, Training loss: 1.385887, Validation loss: 1.3767, lr: 0.0000\n",
      "Epoch: 820, Training loss: 1.376007, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 821, Training loss: 1.384963, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 822, Training loss: 1.365301, Validation loss: 1.4039, lr: 0.0000\n",
      "Epoch: 823, Training loss: 1.389954, Validation loss: 1.3891, lr: 0.0000\n",
      "Epoch: 824, Training loss: 1.388622, Validation loss: 1.3795, lr: 0.0000\n",
      "Epoch: 825, Training loss: 1.384796, Validation loss: 1.4737, lr: 0.0000\n",
      "Epoch: 826, Training loss: 1.370427, Validation loss: 1.3889, lr: 0.0000\n",
      "Epoch: 827, Training loss: 1.373445, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 828, Training loss: 1.369898, Validation loss: 1.3935, lr: 0.0000\n",
      "Epoch: 829, Training loss: 1.370123, Validation loss: 1.3798, lr: 0.0000\n",
      "Epoch: 830, Training loss: 1.365838, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 831, Training loss: 1.385163, Validation loss: 1.3802, lr: 0.0000\n",
      "Epoch: 832, Training loss: 1.415053, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 833, Training loss: 1.378893, Validation loss: 1.3595, lr: 0.0000\n",
      "Epoch: 834, Training loss: 1.418534, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 835, Training loss: 1.390155, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 836, Training loss: 1.372220, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 837, Training loss: 1.387832, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 838, Training loss: 1.382982, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 839, Training loss: 1.424831, Validation loss: 1.3878, lr: 0.0000\n",
      "Epoch: 840, Training loss: 1.405595, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 841, Training loss: 1.364947, Validation loss: 1.3544, lr: 0.0000\n",
      "Epoch: 842, Training loss: 1.393458, Validation loss: 1.3733, lr: 0.0000\n",
      "Epoch: 843, Training loss: 1.379254, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 844, Training loss: 1.378722, Validation loss: 1.3787, lr: 0.0000\n",
      "Epoch: 845, Training loss: 1.372216, Validation loss: 1.3737, lr: 0.0000\n",
      "Epoch: 846, Training loss: 1.383055, Validation loss: 1.3953, lr: 0.0000\n",
      "Epoch: 847, Training loss: 1.381540, Validation loss: 1.3987, lr: 0.0000\n",
      "Epoch: 848, Training loss: 1.403182, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 849, Training loss: 1.396767, Validation loss: 1.3985, lr: 0.0000\n",
      "Epoch: 850, Training loss: 1.382700, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 851, Training loss: 1.396057, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 852, Training loss: 1.380321, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 853, Training loss: 1.362845, Validation loss: 1.3784, lr: 0.0000\n",
      "Epoch: 854, Training loss: 1.400923, Validation loss: 1.3745, lr: 0.0000\n",
      "Epoch: 855, Training loss: 1.367548, Validation loss: 1.3705, lr: 0.0000\n",
      "Epoch: 856, Training loss: 1.395078, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 857, Training loss: 1.374680, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 858, Training loss: 1.373268, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 859, Training loss: 1.383994, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 860, Training loss: 1.385158, Validation loss: 1.3953, lr: 0.0000\n",
      "Epoch: 861, Training loss: 1.393785, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 862, Training loss: 1.392850, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 863, Training loss: 1.381192, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 864, Training loss: 1.378554, Validation loss: 1.3759, lr: 0.0000\n",
      "Epoch: 865, Training loss: 1.381942, Validation loss: 1.3721, lr: 0.0000\n",
      "Epoch: 866, Training loss: 1.377232, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 867, Training loss: 1.381089, Validation loss: 1.3931, lr: 0.0000\n",
      "Epoch: 868, Training loss: 1.382472, Validation loss: 1.3890, lr: 0.0000\n",
      "Epoch: 869, Training loss: 1.371380, Validation loss: 1.3876, lr: 0.0000\n",
      "Epoch: 870, Training loss: 1.383331, Validation loss: 1.3894, lr: 0.0000\n",
      "Epoch: 871, Training loss: 1.355815, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 872, Training loss: 1.378972, Validation loss: 1.3542, lr: 0.0000\n",
      "Epoch: 873, Training loss: 1.411246, Validation loss: 1.3892, lr: 0.0000\n",
      "Epoch: 874, Training loss: 1.390433, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 875, Training loss: 1.386346, Validation loss: 1.3888, lr: 0.0000\n",
      "Epoch: 876, Training loss: 1.384938, Validation loss: 1.3987, lr: 0.0000\n",
      "Epoch: 877, Training loss: 1.382449, Validation loss: 1.3641, lr: 0.0000\n",
      "Epoch: 878, Training loss: 1.391308, Validation loss: 1.3757, lr: 0.0000\n",
      "Epoch: 879, Training loss: 1.417438, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 880, Training loss: 1.376806, Validation loss: 1.3877, lr: 0.0000\n",
      "Epoch: 881, Training loss: 1.386000, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 882, Training loss: 1.384754, Validation loss: 1.3803, lr: 0.0000\n",
      "Epoch: 883, Training loss: 1.381845, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 884, Training loss: 1.380781, Validation loss: 1.4205, lr: 0.0000\n",
      "Epoch: 885, Training loss: 1.365923, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 886, Training loss: 1.376981, Validation loss: 1.4115, lr: 0.0000\n",
      "Epoch: 887, Training loss: 1.370366, Validation loss: 1.3735, lr: 0.0000\n",
      "Epoch: 888, Training loss: 1.411219, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 889, Training loss: 1.397276, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 890, Training loss: 1.382394, Validation loss: 1.3946, lr: 0.0000\n",
      "Epoch: 891, Training loss: 1.372247, Validation loss: 1.3799, lr: 0.0000\n",
      "Epoch: 892, Training loss: 1.375564, Validation loss: 1.3717, lr: 0.0000\n",
      "Epoch: 893, Training loss: 1.375180, Validation loss: 1.3556, lr: 0.0000\n",
      "Epoch: 894, Training loss: 1.378750, Validation loss: 1.3671, lr: 0.0000\n",
      "Epoch: 895, Training loss: 1.385358, Validation loss: 1.3894, lr: 0.0000\n",
      "Epoch: 896, Training loss: 1.391304, Validation loss: 1.3998, lr: 0.0000\n",
      "Epoch: 897, Training loss: 1.380043, Validation loss: 1.3793, lr: 0.0000\n",
      "Epoch: 898, Training loss: 1.386411, Validation loss: 1.4018, lr: 0.0000\n",
      "Epoch: 899, Training loss: 1.369698, Validation loss: 1.3781, lr: 0.0000\n",
      "Epoch: 900, Training loss: 1.377373, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 901, Training loss: 1.450745, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 902, Training loss: 1.441293, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 903, Training loss: 1.396523, Validation loss: 1.3908, lr: 0.0000\n",
      "Epoch: 904, Training loss: 1.390133, Validation loss: 1.3755, lr: 0.0000\n",
      "Epoch: 905, Training loss: 1.402349, Validation loss: 1.4339, lr: 0.0000\n",
      "Epoch: 906, Training loss: 1.407477, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 907, Training loss: 1.380803, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 908, Training loss: 1.387371, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 909, Training loss: 1.392250, Validation loss: 1.3937, lr: 0.0000\n",
      "Epoch: 910, Training loss: 1.374216, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 911, Training loss: 1.375470, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 912, Training loss: 1.426817, Validation loss: 1.3656, lr: 0.0000\n",
      "Epoch: 913, Training loss: 1.375215, Validation loss: 1.3934, lr: 0.0000\n",
      "Epoch: 914, Training loss: 1.401468, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 915, Training loss: 1.384020, Validation loss: 1.3880, lr: 0.0000\n",
      "Epoch: 916, Training loss: 1.360467, Validation loss: 1.4308, lr: 0.0000\n",
      "Epoch: 917, Training loss: 1.364865, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 918, Training loss: 1.374840, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 919, Training loss: 1.377057, Validation loss: 1.3893, lr: 0.0000\n",
      "Epoch: 920, Training loss: 1.381230, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 921, Training loss: 1.375579, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 922, Training loss: 1.387346, Validation loss: 1.3795, lr: 0.0000\n",
      "Epoch: 923, Training loss: 1.410498, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 924, Training loss: 1.380422, Validation loss: 1.3747, lr: 0.0000\n",
      "Epoch: 925, Training loss: 1.381198, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 926, Training loss: 1.386392, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 927, Training loss: 1.373971, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 928, Training loss: 1.384435, Validation loss: 1.3710, lr: 0.0000\n",
      "Epoch: 929, Training loss: 1.375786, Validation loss: 1.3732, lr: 0.0000\n",
      "Epoch: 930, Training loss: 1.387427, Validation loss: 1.3883, lr: 0.0000\n",
      "Epoch: 931, Training loss: 1.376561, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 932, Training loss: 1.385846, Validation loss: 1.3882, lr: 0.0000\n",
      "Epoch: 933, Training loss: 1.380343, Validation loss: 1.5975, lr: 0.0000\n",
      "Epoch: 934, Training loss: 1.383279, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 935, Training loss: 1.376963, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 936, Training loss: 1.379508, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 937, Training loss: 1.361320, Validation loss: 1.3703, lr: 0.0000\n",
      "Epoch: 938, Training loss: 1.380375, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 939, Training loss: 1.398199, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 940, Training loss: 1.370765, Validation loss: 1.3785, lr: 0.0000\n",
      "Epoch: 941, Training loss: 1.387645, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 942, Training loss: 1.365354, Validation loss: 1.3877, lr: 0.0000\n",
      "Epoch: 943, Training loss: 1.389235, Validation loss: 1.3709, lr: 0.0000\n",
      "Epoch: 944, Training loss: 1.383319, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 945, Training loss: 1.416181, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 946, Training loss: 1.377937, Validation loss: 1.3791, lr: 0.0000\n",
      "Epoch: 947, Training loss: 1.398978, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 948, Training loss: 1.374863, Validation loss: 1.3749, lr: 0.0000\n",
      "Epoch: 949, Training loss: 1.373045, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 950, Training loss: 1.376668, Validation loss: 1.3872, lr: 0.0000\n",
      "Epoch: 951, Training loss: 1.383623, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 952, Training loss: 1.412801, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 953, Training loss: 1.364386, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 954, Training loss: 1.386257, Validation loss: 1.4113, lr: 0.0000\n",
      "Epoch: 955, Training loss: 1.366625, Validation loss: 1.3779, lr: 0.0000\n",
      "Epoch: 956, Training loss: 1.367812, Validation loss: 1.3739, lr: 0.0000\n",
      "Epoch: 957, Training loss: 1.381291, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 958, Training loss: 1.376662, Validation loss: 1.3719, lr: 0.0000\n",
      "Epoch: 959, Training loss: 1.384984, Validation loss: 1.3697, lr: 0.0000\n",
      "Epoch: 960, Training loss: 1.391972, Validation loss: 1.3748, lr: 0.0000\n",
      "Epoch: 961, Training loss: 1.385798, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 962, Training loss: 1.420130, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 963, Training loss: 1.375665, Validation loss: 1.3679, lr: 0.0000\n",
      "Epoch: 964, Training loss: 1.386491, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 965, Training loss: 1.361363, Validation loss: 1.3748, lr: 0.0000\n",
      "Epoch: 966, Training loss: 1.384315, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 967, Training loss: 1.376882, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 968, Training loss: 1.385367, Validation loss: 1.3906, lr: 0.0000\n",
      "Epoch: 969, Training loss: 1.385194, Validation loss: 1.3785, lr: 0.0000\n",
      "Epoch: 970, Training loss: 1.379449, Validation loss: 1.3687, lr: 0.0000\n",
      "Epoch: 971, Training loss: 1.411059, Validation loss: 1.3897, lr: 0.0000\n",
      "Epoch: 972, Training loss: 1.376682, Validation loss: 1.3771, lr: 0.0000\n",
      "Epoch: 973, Training loss: 1.394696, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 974, Training loss: 1.368737, Validation loss: 1.3668, lr: 0.0000\n",
      "Epoch: 975, Training loss: 1.385115, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 976, Training loss: 1.372137, Validation loss: 1.4980, lr: 0.0000\n",
      "Epoch: 977, Training loss: 1.391288, Validation loss: 1.3875, lr: 0.0000\n",
      "Epoch: 978, Training loss: 1.407375, Validation loss: 1.3876, lr: 0.0000\n",
      "Epoch: 979, Training loss: 1.378914, Validation loss: 1.3793, lr: 0.0000\n",
      "Epoch: 980, Training loss: 1.394997, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 981, Training loss: 1.365988, Validation loss: 1.3598, lr: 0.0000\n",
      "Epoch: 982, Training loss: 1.388698, Validation loss: 1.4113, lr: 0.0000\n",
      "Epoch: 983, Training loss: 1.398424, Validation loss: 1.3769, lr: 0.0000\n",
      "Epoch: 984, Training loss: 1.373513, Validation loss: 1.3753, lr: 0.0000\n",
      "Epoch: 985, Training loss: 1.392669, Validation loss: 1.3883, lr: 0.0000\n",
      "Epoch: 986, Training loss: 1.375524, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 987, Training loss: 1.526924, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 988, Training loss: 1.376178, Validation loss: 1.3770, lr: 0.0000\n",
      "Epoch: 989, Training loss: 1.358897, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 990, Training loss: 1.406064, Validation loss: 1.3628, lr: 0.0000\n",
      "Epoch: 991, Training loss: 1.383781, Validation loss: 1.4672, lr: 0.0000\n",
      "Epoch: 992, Training loss: 1.398681, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 993, Training loss: 1.400852, Validation loss: 1.3746, lr: 0.0000\n",
      "Epoch: 994, Training loss: 1.381661, Validation loss: 1.3884, lr: 0.0000\n",
      "Epoch: 995, Training loss: 1.392472, Validation loss: 1.3878, lr: 0.0000\n",
      "Epoch: 996, Training loss: 1.388604, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 997, Training loss: 1.375930, Validation loss: 1.3664, lr: 0.0000\n",
      "Epoch: 998, Training loss: 1.380732, Validation loss: 1.3723, lr: 0.0000\n",
      "Epoch: 999, Training loss: 1.366291, Validation loss: 1.3835, lr: 0.0000\n",
      "Final test loss: 1.3821\n",
      "=== Run 02/10 ===\n",
      "\n",
      "---- Settings: \n",
      "\n",
      "epochs : 1000\n",
      "hidden_channels : [32]\n",
      "out_channels : 10\n",
      "inner_product_features : False\n",
      "batch_size : 64\n",
      "lr : 0.01\n",
      "momentum : 0.9\n",
      "dropout : 0.0\n",
      "batch_norm : batch_norm\n",
      "bias : True\n",
      "order : 2\n",
      "diffusion : True\n",
      "frac_sampled_nb : -1\n",
      "include_positions : False\n",
      "include_self : True\n",
      "vec_norm : False\n",
      "emb_norm : False\n",
      "seed : 0\n",
      "dim_signal : 100\n",
      "dim_emb : 100\n",
      "n_sampled_nb : -1\n",
      "\n",
      "---- Number of features to pass to the MLP:  1010100\n",
      "---- Total number of parameters:  32323627\n",
      "\n",
      "Using device cuda:0\n",
      "\n",
      "---- Training network ...\n",
      "\n",
      "---- Timestamp: 20250613-205151\n",
      "\n",
      " *och: 0, Training loss: 1.491083, Validation loss: 1.3743, lr: 0.0100\n",
      " *och: 1, Training loss: 1.425743, Validation loss: 1.3471, lr: 0.0100\n",
      "Epoch: 2, Training loss: 1.401401, Validation loss: 1.3759, lr: 0.0100\n",
      "Epoch: 3, Training loss: 1.420483, Validation loss: 1.3528, lr: 0.0100\n",
      "Epoch: 4, Training loss: 1.391971, Validation loss: 1.4555, lr: 0.0100\n",
      "Epoch: 5, Training loss: 1.375398, Validation loss: 1.3958, lr: 0.0100\n",
      "Epoch: 6, Training loss: 1.397939, Validation loss: 1.3586, lr: 0.0100\n",
      "Epoch: 7, Training loss: 1.381764, Validation loss: 1.3708, lr: 0.0100\n",
      "Epoch: 8, Training loss: 1.390617, Validation loss: 1.3813, lr: 0.0100\n",
      "Epoch: 9, Training loss: 1.411657, Validation loss: 1.3995, lr: 0.0100\n",
      "Epoch: 10, Training loss: 1.367598, Validation loss: 1.3980, lr: 0.0100\n",
      "Epoch: 11, Training loss: 1.356448, Validation loss: 1.3883, lr: 0.0100\n",
      "Epoch: 12, Training loss: 1.367783, Validation loss: 1.3861, lr: 0.0100\n",
      "Epoch: 13, Training loss: 1.375379, Validation loss: 1.3864, lr: 0.0100\n",
      "Epoch: 14, Training loss: 1.532426, Validation loss: 1.3837, lr: 0.0100\n",
      "Epoch: 15, Training loss: 1.379116, Validation loss: 1.3834, lr: 0.0100\n",
      "Epoch: 16, Training loss: 1.434386, Validation loss: 1.3647, lr: 0.0100\n",
      "Epoch: 17, Training loss: 1.388178, Validation loss: 1.3737, lr: 0.0100\n",
      "Epoch: 18, Training loss: 1.401144, Validation loss: 1.4728, lr: 0.0100\n",
      "Epoch: 19, Training loss: 1.401359, Validation loss: 1.3735, lr: 0.0100\n",
      "Epoch: 20, Training loss: 1.380428, Validation loss: 1.3818, lr: 0.0100\n",
      "Epoch: 21, Training loss: 1.349539, Validation loss: 1.3824, lr: 0.0100\n",
      "Epoch: 22, Training loss: 1.382565, Validation loss: 1.3955, lr: 0.0100\n",
      "Epoch: 23, Training loss: 1.361131, Validation loss: 1.3900, lr: 0.0100\n",
      "Epoch: 24, Training loss: 1.378663, Validation loss: 1.3838, lr: 0.0100\n",
      "Epoch: 25, Training loss: 1.376727, Validation loss: 1.3816, lr: 0.0100\n",
      "Epoch: 26, Training loss: 1.370694, Validation loss: 1.3736, lr: 0.0100\n",
      "Epoch: 27, Training loss: 1.404991, Validation loss: 1.3852, lr: 0.0100\n",
      "Epoch: 28, Training loss: 1.392319, Validation loss: 1.3827, lr: 0.0100\n",
      "Epoch: 29, Training loss: 1.381957, Validation loss: 1.3774, lr: 0.0100\n",
      "Epoch: 30, Training loss: 1.370221, Validation loss: 1.3812, lr: 0.0100\n",
      "Epoch: 31, Training loss: 1.362654, Validation loss: 1.3829, lr: 0.0100\n",
      "Epoch: 32, Training loss: 1.371336, Validation loss: 1.3822, lr: 0.0010\n",
      "Epoch: 33, Training loss: 1.369601, Validation loss: 1.3997, lr: 0.0010\n",
      "Epoch: 34, Training loss: 1.388499, Validation loss: 1.3817, lr: 0.0010\n",
      "Epoch: 35, Training loss: 1.373718, Validation loss: 1.3768, lr: 0.0010\n",
      "Epoch: 36, Training loss: 1.380479, Validation loss: 1.3877, lr: 0.0010\n",
      "Epoch: 37, Training loss: 1.374776, Validation loss: 1.3833, lr: 0.0010\n",
      "Epoch: 38, Training loss: 1.356058, Validation loss: 1.3827, lr: 0.0010\n",
      "Epoch: 39, Training loss: 1.381215, Validation loss: 1.3811, lr: 0.0010\n",
      "Epoch: 40, Training loss: 1.371061, Validation loss: 1.3794, lr: 0.0010\n",
      "Epoch: 41, Training loss: 1.361854, Validation loss: 1.3828, lr: 0.0010\n",
      "Epoch: 42, Training loss: 1.377278, Validation loss: 1.3838, lr: 0.0010\n",
      "Epoch: 43, Training loss: 1.385149, Validation loss: 1.3748, lr: 0.0001\n",
      "Epoch: 44, Training loss: 1.384299, Validation loss: 1.3824, lr: 0.0001\n",
      "Epoch: 45, Training loss: 1.351601, Validation loss: 1.3838, lr: 0.0001\n",
      "Epoch: 46, Training loss: 1.373112, Validation loss: 1.3968, lr: 0.0001\n",
      "Epoch: 47, Training loss: 1.381735, Validation loss: 1.3872, lr: 0.0001\n",
      "Epoch: 48, Training loss: 1.375167, Validation loss: 1.3784, lr: 0.0001\n",
      "Epoch: 49, Training loss: 1.367285, Validation loss: 1.4095, lr: 0.0001\n",
      "Epoch: 50, Training loss: 1.392103, Validation loss: 1.3859, lr: 0.0001\n",
      "Epoch: 51, Training loss: 1.357813, Validation loss: 1.3835, lr: 0.0001\n",
      "Epoch: 52, Training loss: 1.372787, Validation loss: 1.3838, lr: 0.0001\n",
      "Epoch: 53, Training loss: 1.379161, Validation loss: 1.3885, lr: 0.0001\n",
      "Epoch: 54, Training loss: 1.372943, Validation loss: 1.3787, lr: 0.0000\n",
      "Epoch: 55, Training loss: 1.371062, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 56, Training loss: 1.371073, Validation loss: 1.3788, lr: 0.0000\n",
      "Epoch: 57, Training loss: 1.369371, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 58, Training loss: 1.393420, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 59, Training loss: 1.380872, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 60, Training loss: 1.375394, Validation loss: 1.3802, lr: 0.0000\n",
      "Epoch: 61, Training loss: 1.383687, Validation loss: 1.3902, lr: 0.0000\n",
      "Epoch: 62, Training loss: 1.364917, Validation loss: 1.3671, lr: 0.0000\n",
      "Epoch: 63, Training loss: 1.379818, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 64, Training loss: 1.374233, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 65, Training loss: 1.372638, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 66, Training loss: 1.367653, Validation loss: 1.3736, lr: 0.0000\n",
      "Epoch: 67, Training loss: 1.370753, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 68, Training loss: 1.374516, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 69, Training loss: 1.383912, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 70, Training loss: 1.368441, Validation loss: 1.3701, lr: 0.0000\n",
      "Epoch: 71, Training loss: 1.365606, Validation loss: 1.3734, lr: 0.0000\n",
      "Epoch: 72, Training loss: 1.365573, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 73, Training loss: 1.367005, Validation loss: 1.3771, lr: 0.0000\n",
      "Epoch: 74, Training loss: 1.381369, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 75, Training loss: 1.368715, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 76, Training loss: 1.353198, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 77, Training loss: 1.354031, Validation loss: 1.6177, lr: 0.0000\n",
      "Epoch: 78, Training loss: 1.364725, Validation loss: 1.3637, lr: 0.0000\n",
      "Epoch: 79, Training loss: 1.377547, Validation loss: 1.3502, lr: 0.0000\n",
      "Epoch: 80, Training loss: 1.353129, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 81, Training loss: 1.369917, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 82, Training loss: 1.361328, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 83, Training loss: 1.418225, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 84, Training loss: 1.382830, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 85, Training loss: 1.371427, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 86, Training loss: 1.423938, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 87, Training loss: 1.363634, Validation loss: 1.3777, lr: 0.0000\n",
      "Epoch: 88, Training loss: 1.415689, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 89, Training loss: 1.360650, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 90, Training loss: 1.364494, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 91, Training loss: 1.388906, Validation loss: 1.4111, lr: 0.0000\n",
      "Epoch: 92, Training loss: 1.345368, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 93, Training loss: 1.354728, Validation loss: 1.3771, lr: 0.0000\n",
      "Epoch: 94, Training loss: 1.386050, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 95, Training loss: 1.406360, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 96, Training loss: 1.360400, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 97, Training loss: 1.364304, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 98, Training loss: 1.386398, Validation loss: 1.3768, lr: 0.0000\n",
      "Epoch: 99, Training loss: 1.380551, Validation loss: 1.3713, lr: 0.0000\n",
      "Epoch: 100, Training loss: 1.367995, Validation loss: 1.3945, lr: 0.0000\n",
      "Epoch: 101, Training loss: 1.359701, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 102, Training loss: 1.379528, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 103, Training loss: 1.395446, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 104, Training loss: 1.388068, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 105, Training loss: 1.391345, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 106, Training loss: 1.365425, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 107, Training loss: 1.374829, Validation loss: 1.3736, lr: 0.0000\n",
      "Epoch: 108, Training loss: 1.415514, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 109, Training loss: 1.391127, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 110, Training loss: 1.369583, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 111, Training loss: 1.378559, Validation loss: 1.3938, lr: 0.0000\n",
      "Epoch: 112, Training loss: 1.371371, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 113, Training loss: 1.363259, Validation loss: 1.3794, lr: 0.0000\n",
      "Epoch: 114, Training loss: 1.364044, Validation loss: 1.3809, lr: 0.0000\n",
      "Epoch: 115, Training loss: 1.362951, Validation loss: 1.3784, lr: 0.0000\n",
      "Epoch: 116, Training loss: 1.372796, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 117, Training loss: 1.377082, Validation loss: 1.3757, lr: 0.0000\n",
      "Epoch: 118, Training loss: 1.387944, Validation loss: 1.3688, lr: 0.0000\n",
      "Epoch: 119, Training loss: 1.365602, Validation loss: 1.3675, lr: 0.0000\n",
      "Epoch: 120, Training loss: 1.360509, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 121, Training loss: 1.382662, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 122, Training loss: 1.385648, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 123, Training loss: 1.359847, Validation loss: 1.3683, lr: 0.0000\n",
      "Epoch: 124, Training loss: 1.360514, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 125, Training loss: 1.378001, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 126, Training loss: 1.362618, Validation loss: 1.3658, lr: 0.0000\n",
      "Epoch: 127, Training loss: 1.377387, Validation loss: 1.3501, lr: 0.0000\n",
      " *och: 128, Training loss: 1.376969, Validation loss: 1.3433, lr: 0.0000\n",
      "Epoch: 129, Training loss: 1.343022, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 130, Training loss: 1.367587, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 131, Training loss: 1.372669, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 132, Training loss: 1.378317, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 133, Training loss: 1.393735, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 134, Training loss: 1.373131, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 135, Training loss: 1.374084, Validation loss: 1.3753, lr: 0.0000\n",
      "Epoch: 136, Training loss: 1.379747, Validation loss: 1.3783, lr: 0.0000\n",
      "Epoch: 137, Training loss: 1.371274, Validation loss: 1.3872, lr: 0.0000\n",
      "Epoch: 138, Training loss: 1.393060, Validation loss: 1.3694, lr: 0.0000\n",
      "Epoch: 139, Training loss: 1.353436, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 140, Training loss: 1.364810, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 141, Training loss: 1.366124, Validation loss: 1.3749, lr: 0.0000\n",
      "Epoch: 142, Training loss: 1.389121, Validation loss: 1.3877, lr: 0.0000\n",
      "Epoch: 143, Training loss: 1.373539, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 144, Training loss: 1.371107, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 145, Training loss: 1.370195, Validation loss: 1.3730, lr: 0.0000\n",
      "Epoch: 146, Training loss: 1.369388, Validation loss: 1.3761, lr: 0.0000\n",
      "Epoch: 147, Training loss: 1.365290, Validation loss: 1.3739, lr: 0.0000\n",
      "Epoch: 148, Training loss: 1.387915, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 149, Training loss: 1.389877, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 150, Training loss: 1.361604, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 151, Training loss: 1.363877, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 152, Training loss: 1.370957, Validation loss: 1.3884, lr: 0.0000\n",
      "Epoch: 153, Training loss: 1.367305, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 154, Training loss: 1.360587, Validation loss: 1.3650, lr: 0.0000\n",
      "Epoch: 155, Training loss: 1.364347, Validation loss: 1.3723, lr: 0.0000\n",
      "Epoch: 156, Training loss: 1.369631, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 157, Training loss: 1.363629, Validation loss: 1.3937, lr: 0.0000\n",
      "Epoch: 158, Training loss: 1.371943, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 159, Training loss: 1.355538, Validation loss: 1.3772, lr: 0.0000\n",
      "Epoch: 160, Training loss: 1.376586, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 161, Training loss: 1.418978, Validation loss: 1.3805, lr: 0.0000\n",
      " *och: 162, Training loss: 1.385672, Validation loss: 1.3258, lr: 0.0000\n",
      "Epoch: 163, Training loss: 1.377314, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 164, Training loss: 1.373894, Validation loss: 1.3782, lr: 0.0000\n",
      "Epoch: 165, Training loss: 1.369464, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 166, Training loss: 1.372945, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 167, Training loss: 1.381377, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 168, Training loss: 1.387989, Validation loss: 1.3791, lr: 0.0000\n",
      "Epoch: 169, Training loss: 1.370763, Validation loss: 1.3693, lr: 0.0000\n",
      "Epoch: 170, Training loss: 1.368254, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 171, Training loss: 1.364713, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 172, Training loss: 1.388799, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 173, Training loss: 1.361665, Validation loss: 1.3799, lr: 0.0000\n",
      "Epoch: 174, Training loss: 1.390373, Validation loss: 1.3964, lr: 0.0000\n",
      "Epoch: 175, Training loss: 1.366150, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 176, Training loss: 1.344154, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 177, Training loss: 1.382823, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 178, Training loss: 1.370237, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 179, Training loss: 1.370514, Validation loss: 1.3883, lr: 0.0000\n",
      "Epoch: 180, Training loss: 1.368477, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 181, Training loss: 1.378375, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 182, Training loss: 1.366229, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 183, Training loss: 1.386469, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 184, Training loss: 1.346392, Validation loss: 1.3877, lr: 0.0000\n",
      "Epoch: 185, Training loss: 1.472233, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 186, Training loss: 1.357754, Validation loss: 1.3809, lr: 0.0000\n",
      "Epoch: 187, Training loss: 1.381277, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 188, Training loss: 1.382850, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 189, Training loss: 1.357705, Validation loss: 1.8541, lr: 0.0000\n",
      "Epoch: 190, Training loss: 1.358412, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 191, Training loss: 1.360060, Validation loss: 1.3881, lr: 0.0000\n",
      "Epoch: 192, Training loss: 1.370366, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 193, Training loss: 1.367612, Validation loss: 1.4057, lr: 0.0000\n",
      "Epoch: 194, Training loss: 1.388927, Validation loss: 1.3786, lr: 0.0000\n",
      "Epoch: 195, Training loss: 1.363191, Validation loss: 1.3877, lr: 0.0000\n",
      "Epoch: 196, Training loss: 1.363899, Validation loss: 1.3794, lr: 0.0000\n",
      "Epoch: 197, Training loss: 1.399725, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 198, Training loss: 1.374031, Validation loss: 1.3799, lr: 0.0000\n",
      "Epoch: 199, Training loss: 1.370895, Validation loss: 1.3514, lr: 0.0000\n",
      "Epoch: 200, Training loss: 1.364409, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 201, Training loss: 1.366508, Validation loss: 1.3882, lr: 0.0000\n",
      "Epoch: 202, Training loss: 1.378955, Validation loss: 1.3788, lr: 0.0000\n",
      "Epoch: 203, Training loss: 1.375880, Validation loss: 1.3908, lr: 0.0000\n",
      "Epoch: 204, Training loss: 1.380195, Validation loss: 1.3875, lr: 0.0000\n",
      "Epoch: 205, Training loss: 1.387685, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 206, Training loss: 1.350893, Validation loss: 1.3880, lr: 0.0000\n",
      "Epoch: 207, Training loss: 1.399747, Validation loss: 1.3788, lr: 0.0000\n",
      "Epoch: 208, Training loss: 1.379645, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 209, Training loss: 1.372999, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 210, Training loss: 1.367167, Validation loss: 1.3588, lr: 0.0000\n",
      "Epoch: 211, Training loss: 1.398714, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 212, Training loss: 1.382319, Validation loss: 1.3941, lr: 0.0000\n",
      "Epoch: 213, Training loss: 1.371222, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 214, Training loss: 1.367994, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 215, Training loss: 1.408144, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 216, Training loss: 1.383155, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 217, Training loss: 1.367768, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 218, Training loss: 1.373749, Validation loss: 1.3995, lr: 0.0000\n",
      "Epoch: 219, Training loss: 1.376016, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 220, Training loss: 1.363045, Validation loss: 1.3576, lr: 0.0000\n",
      "Epoch: 221, Training loss: 1.362496, Validation loss: 1.3532, lr: 0.0000\n",
      "Epoch: 222, Training loss: 1.367505, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 223, Training loss: 1.373053, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 224, Training loss: 1.451734, Validation loss: 1.3875, lr: 0.0000\n",
      "Epoch: 225, Training loss: 1.374883, Validation loss: 1.3695, lr: 0.0000\n",
      "Epoch: 226, Training loss: 1.370658, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 227, Training loss: 1.391970, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 228, Training loss: 1.376775, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 229, Training loss: 1.369630, Validation loss: 1.3754, lr: 0.0000\n",
      "Epoch: 230, Training loss: 1.397724, Validation loss: 1.3877, lr: 0.0000\n",
      "Epoch: 231, Training loss: 1.368710, Validation loss: 1.3874, lr: 0.0000\n",
      "Epoch: 232, Training loss: 1.368794, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 233, Training loss: 1.351361, Validation loss: 1.3707, lr: 0.0000\n",
      "Epoch: 234, Training loss: 1.412520, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 235, Training loss: 1.383845, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 236, Training loss: 1.381933, Validation loss: 1.3711, lr: 0.0000\n",
      "Epoch: 237, Training loss: 1.374414, Validation loss: 1.3725, lr: 0.0000\n",
      "Epoch: 238, Training loss: 1.363427, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 239, Training loss: 1.378653, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 240, Training loss: 1.368738, Validation loss: 1.3756, lr: 0.0000\n",
      "Epoch: 241, Training loss: 1.356747, Validation loss: 1.3876, lr: 0.0000\n",
      "Epoch: 242, Training loss: 1.367150, Validation loss: 1.3357, lr: 0.0000\n",
      "Epoch: 243, Training loss: 1.381901, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 244, Training loss: 1.397782, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 245, Training loss: 1.395018, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 246, Training loss: 1.370961, Validation loss: 1.4073, lr: 0.0000\n",
      "Epoch: 247, Training loss: 1.363798, Validation loss: 1.3891, lr: 0.0000\n",
      "Epoch: 248, Training loss: 1.362045, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 249, Training loss: 1.379090, Validation loss: 1.3878, lr: 0.0000\n",
      "Epoch: 250, Training loss: 1.385177, Validation loss: 1.3880, lr: 0.0000\n",
      "Epoch: 251, Training loss: 1.397006, Validation loss: 1.3680, lr: 0.0000\n",
      "Epoch: 252, Training loss: 1.364162, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 253, Training loss: 1.404916, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 254, Training loss: 1.351056, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 255, Training loss: 1.371152, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 256, Training loss: 1.382358, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 257, Training loss: 1.374136, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 258, Training loss: 1.362778, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 259, Training loss: 1.383496, Validation loss: 1.3794, lr: 0.0000\n",
      "Epoch: 260, Training loss: 1.372685, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 261, Training loss: 1.394959, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 262, Training loss: 1.376797, Validation loss: 1.3874, lr: 0.0000\n",
      "Epoch: 263, Training loss: 1.369428, Validation loss: 1.3752, lr: 0.0000\n",
      "Epoch: 264, Training loss: 1.373166, Validation loss: 1.3587, lr: 0.0000\n",
      "Epoch: 265, Training loss: 1.375091, Validation loss: 1.3781, lr: 0.0000\n",
      "Epoch: 266, Training loss: 1.358064, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 267, Training loss: 1.370440, Validation loss: 1.3734, lr: 0.0000\n",
      "Epoch: 268, Training loss: 1.383830, Validation loss: 1.3771, lr: 0.0000\n",
      "Epoch: 269, Training loss: 1.371047, Validation loss: 1.3783, lr: 0.0000\n",
      "Epoch: 270, Training loss: 1.408984, Validation loss: 1.3755, lr: 0.0000\n",
      "Epoch: 271, Training loss: 1.358233, Validation loss: 1.3392, lr: 0.0000\n",
      "Epoch: 272, Training loss: 1.383115, Validation loss: 1.3777, lr: 0.0000\n",
      "Epoch: 273, Training loss: 1.375485, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 274, Training loss: 1.394182, Validation loss: 1.3784, lr: 0.0000\n",
      "Epoch: 275, Training loss: 1.360930, Validation loss: 1.3742, lr: 0.0000\n",
      "Epoch: 276, Training loss: 1.404729, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 277, Training loss: 1.385078, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 278, Training loss: 1.366332, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 279, Training loss: 1.376749, Validation loss: 1.3781, lr: 0.0000\n",
      "Epoch: 280, Training loss: 1.346024, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 281, Training loss: 1.374411, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 282, Training loss: 1.374845, Validation loss: 1.3777, lr: 0.0000\n",
      "Epoch: 283, Training loss: 1.382928, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 284, Training loss: 1.372999, Validation loss: 1.3753, lr: 0.0000\n",
      "Epoch: 285, Training loss: 1.364848, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 286, Training loss: 1.370150, Validation loss: 1.3791, lr: 0.0000\n",
      "Epoch: 287, Training loss: 1.371842, Validation loss: 1.3809, lr: 0.0000\n",
      "Epoch: 288, Training loss: 1.376285, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 289, Training loss: 1.368616, Validation loss: 1.3714, lr: 0.0000\n",
      "Epoch: 290, Training loss: 1.360265, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 291, Training loss: 1.374042, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 292, Training loss: 1.381224, Validation loss: 1.3995, lr: 0.0000\n",
      "Epoch: 293, Training loss: 1.379038, Validation loss: 1.3789, lr: 0.0000\n",
      "Epoch: 294, Training loss: 1.361030, Validation loss: 1.3792, lr: 0.0000\n",
      "Epoch: 295, Training loss: 1.362574, Validation loss: 1.3760, lr: 0.0000\n",
      "Epoch: 296, Training loss: 1.367516, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 297, Training loss: 1.351558, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 298, Training loss: 1.379305, Validation loss: 1.3878, lr: 0.0000\n",
      "Epoch: 299, Training loss: 1.380951, Validation loss: 1.3988, lr: 0.0000\n",
      "Epoch: 300, Training loss: 1.362741, Validation loss: 1.3904, lr: 0.0000\n",
      "Epoch: 301, Training loss: 1.387550, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 302, Training loss: 1.389102, Validation loss: 1.3798, lr: 0.0000\n",
      "Epoch: 303, Training loss: 1.382245, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 304, Training loss: 1.364168, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 305, Training loss: 1.362957, Validation loss: 1.3650, lr: 0.0000\n",
      "Epoch: 306, Training loss: 1.397448, Validation loss: 1.3762, lr: 0.0000\n",
      "Epoch: 307, Training loss: 1.360081, Validation loss: 1.3894, lr: 0.0000\n",
      "Epoch: 308, Training loss: 1.392378, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 309, Training loss: 1.358146, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 310, Training loss: 1.387551, Validation loss: 1.3792, lr: 0.0000\n",
      "Epoch: 311, Training loss: 1.371666, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 312, Training loss: 1.391320, Validation loss: 1.3873, lr: 0.0000\n",
      "Epoch: 313, Training loss: 1.370168, Validation loss: 1.3784, lr: 0.0000\n",
      "Epoch: 314, Training loss: 1.380855, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 315, Training loss: 1.345084, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 316, Training loss: 1.357401, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 317, Training loss: 1.386893, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 318, Training loss: 1.392275, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 319, Training loss: 1.402307, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 320, Training loss: 1.405324, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 321, Training loss: 1.346553, Validation loss: 1.3809, lr: 0.0000\n",
      "Epoch: 322, Training loss: 1.359518, Validation loss: 1.3657, lr: 0.0000\n",
      "Epoch: 323, Training loss: 1.371360, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 324, Training loss: 1.366827, Validation loss: 1.3771, lr: 0.0000\n",
      "Epoch: 325, Training loss: 1.385123, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 326, Training loss: 1.383260, Validation loss: 1.3799, lr: 0.0000\n",
      "Epoch: 327, Training loss: 1.353550, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 328, Training loss: 1.383045, Validation loss: 1.3609, lr: 0.0000\n",
      "Epoch: 329, Training loss: 1.363931, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 330, Training loss: 1.353277, Validation loss: 1.3759, lr: 0.0000\n",
      "Epoch: 331, Training loss: 1.374452, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 332, Training loss: 1.366669, Validation loss: 1.3802, lr: 0.0000\n",
      "Epoch: 333, Training loss: 1.354338, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 334, Training loss: 1.369314, Validation loss: 1.3906, lr: 0.0000\n",
      "Epoch: 335, Training loss: 1.374110, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 336, Training loss: 1.386548, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 337, Training loss: 1.374131, Validation loss: 1.3882, lr: 0.0000\n",
      "Epoch: 338, Training loss: 1.358219, Validation loss: 1.3701, lr: 0.0000\n",
      "Epoch: 339, Training loss: 1.356278, Validation loss: 1.3682, lr: 0.0000\n",
      "Epoch: 340, Training loss: 1.384345, Validation loss: 1.3754, lr: 0.0000\n",
      "Epoch: 341, Training loss: 1.387121, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 342, Training loss: 1.374648, Validation loss: 1.3703, lr: 0.0000\n",
      "Epoch: 343, Training loss: 1.359172, Validation loss: 1.4005, lr: 0.0000\n",
      "Epoch: 344, Training loss: 1.358577, Validation loss: 1.3780, lr: 0.0000\n",
      "Epoch: 345, Training loss: 1.364681, Validation loss: 1.3906, lr: 0.0000\n",
      "Epoch: 346, Training loss: 1.390044, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 347, Training loss: 1.371525, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 348, Training loss: 1.372262, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 349, Training loss: 1.384605, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 350, Training loss: 1.389131, Validation loss: 1.4179, lr: 0.0000\n",
      "Epoch: 351, Training loss: 1.382269, Validation loss: 1.3631, lr: 0.0000\n",
      "Epoch: 352, Training loss: 1.349568, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 353, Training loss: 1.350146, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 354, Training loss: 1.352303, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 355, Training loss: 1.397938, Validation loss: 1.3779, lr: 0.0000\n",
      "Epoch: 356, Training loss: 1.364403, Validation loss: 1.3898, lr: 0.0000\n",
      "Epoch: 357, Training loss: 1.361565, Validation loss: 1.3802, lr: 0.0000\n",
      "Epoch: 358, Training loss: 1.378700, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 359, Training loss: 1.361390, Validation loss: 1.3777, lr: 0.0000\n",
      "Epoch: 360, Training loss: 1.353428, Validation loss: 1.3753, lr: 0.0000\n",
      "Epoch: 361, Training loss: 1.361870, Validation loss: 1.3742, lr: 0.0000\n",
      "Epoch: 362, Training loss: 1.364693, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 363, Training loss: 1.395182, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 364, Training loss: 1.386220, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 365, Training loss: 1.398548, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 366, Training loss: 1.383278, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 367, Training loss: 1.362039, Validation loss: 1.3791, lr: 0.0000\n",
      "Epoch: 368, Training loss: 1.375588, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 369, Training loss: 1.384297, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 370, Training loss: 1.384881, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 371, Training loss: 1.374539, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 372, Training loss: 1.366924, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 373, Training loss: 1.368783, Validation loss: 1.3767, lr: 0.0000\n",
      "Epoch: 374, Training loss: 1.406633, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 375, Training loss: 1.374574, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 376, Training loss: 1.387494, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 377, Training loss: 1.383189, Validation loss: 1.3876, lr: 0.0000\n",
      "Epoch: 378, Training loss: 1.410071, Validation loss: 1.3798, lr: 0.0000\n",
      "Epoch: 379, Training loss: 1.368872, Validation loss: 1.3935, lr: 0.0000\n",
      "Epoch: 380, Training loss: 1.379653, Validation loss: 1.3916, lr: 0.0000\n",
      "Epoch: 381, Training loss: 1.378619, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 382, Training loss: 1.378105, Validation loss: 1.3878, lr: 0.0000\n",
      "Epoch: 383, Training loss: 1.375065, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 384, Training loss: 1.367343, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 385, Training loss: 1.413346, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 386, Training loss: 1.364866, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 387, Training loss: 1.382884, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 388, Training loss: 1.366577, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 389, Training loss: 1.361617, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 390, Training loss: 1.378532, Validation loss: 1.3902, lr: 0.0000\n",
      "Epoch: 391, Training loss: 1.386557, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 392, Training loss: 1.382185, Validation loss: 1.3778, lr: 0.0000\n",
      "Epoch: 393, Training loss: 1.391884, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 394, Training loss: 1.404842, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 395, Training loss: 1.356269, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 396, Training loss: 1.348819, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 397, Training loss: 1.366777, Validation loss: 1.3649, lr: 0.0000\n",
      "Epoch: 398, Training loss: 1.367751, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 399, Training loss: 1.390297, Validation loss: 1.3794, lr: 0.0000\n",
      "Epoch: 400, Training loss: 1.387900, Validation loss: 1.3660, lr: 0.0000\n",
      "Epoch: 401, Training loss: 1.367498, Validation loss: 1.3561, lr: 0.0000\n",
      "Epoch: 402, Training loss: 1.408412, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 403, Training loss: 1.385315, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 404, Training loss: 1.334809, Validation loss: 1.3794, lr: 0.0000\n",
      "Epoch: 405, Training loss: 1.365980, Validation loss: 1.3663, lr: 0.0000\n",
      "Epoch: 406, Training loss: 1.360681, Validation loss: 1.3799, lr: 0.0000\n",
      "Epoch: 407, Training loss: 1.369735, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 408, Training loss: 1.373726, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 409, Training loss: 1.364859, Validation loss: 1.3749, lr: 0.0000\n",
      "Epoch: 410, Training loss: 1.363384, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 411, Training loss: 1.381304, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 412, Training loss: 1.382844, Validation loss: 1.3959, lr: 0.0000\n",
      "Epoch: 413, Training loss: 1.360512, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 414, Training loss: 1.369133, Validation loss: 1.3732, lr: 0.0000\n",
      "Epoch: 415, Training loss: 1.373935, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 416, Training loss: 1.368573, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 417, Training loss: 1.354621, Validation loss: 1.3747, lr: 0.0000\n",
      "Epoch: 418, Training loss: 1.357114, Validation loss: 1.3743, lr: 0.0000\n",
      "Epoch: 419, Training loss: 1.352131, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 420, Training loss: 1.412471, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 421, Training loss: 1.369644, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 422, Training loss: 1.388164, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 423, Training loss: 1.382257, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 424, Training loss: 1.384767, Validation loss: 1.3911, lr: 0.0000\n",
      "Epoch: 425, Training loss: 1.376530, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 426, Training loss: 1.364585, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 427, Training loss: 1.380150, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 428, Training loss: 1.369676, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 429, Training loss: 1.364178, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 430, Training loss: 1.373292, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 431, Training loss: 1.383448, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 432, Training loss: 1.381417, Validation loss: 1.3910, lr: 0.0000\n",
      "Epoch: 433, Training loss: 1.406808, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 434, Training loss: 1.368577, Validation loss: 1.3549, lr: 0.0000\n",
      "Epoch: 435, Training loss: 1.355903, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 436, Training loss: 1.371610, Validation loss: 1.3809, lr: 0.0000\n",
      "Epoch: 437, Training loss: 1.365338, Validation loss: 1.3890, lr: 0.0000\n",
      "Epoch: 438, Training loss: 1.368496, Validation loss: 1.3788, lr: 0.0000\n",
      "Epoch: 439, Training loss: 1.346584, Validation loss: 1.3884, lr: 0.0000\n",
      "Epoch: 440, Training loss: 1.378850, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 441, Training loss: 1.368173, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 442, Training loss: 1.370642, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 443, Training loss: 1.437669, Validation loss: 1.3809, lr: 0.0000\n",
      "Epoch: 444, Training loss: 1.370289, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 445, Training loss: 1.371089, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 446, Training loss: 1.377418, Validation loss: 1.3686, lr: 0.0000\n",
      "Epoch: 447, Training loss: 1.338528, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 448, Training loss: 1.367545, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 449, Training loss: 1.399129, Validation loss: 1.3800, lr: 0.0000\n",
      "Epoch: 450, Training loss: 1.379212, Validation loss: 1.3776, lr: 0.0000\n",
      "Epoch: 451, Training loss: 1.378199, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 452, Training loss: 1.364987, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 453, Training loss: 1.404279, Validation loss: 1.3598, lr: 0.0000\n",
      "Epoch: 454, Training loss: 1.370833, Validation loss: 1.3701, lr: 0.0000\n",
      "Epoch: 455, Training loss: 1.367535, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 456, Training loss: 1.365129, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 457, Training loss: 1.357710, Validation loss: 1.3883, lr: 0.0000\n",
      "Epoch: 458, Training loss: 1.372601, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 459, Training loss: 1.386397, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 460, Training loss: 1.376216, Validation loss: 1.3774, lr: 0.0000\n",
      "Epoch: 461, Training loss: 1.355938, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 462, Training loss: 1.346693, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 463, Training loss: 1.393229, Validation loss: 1.3803, lr: 0.0000\n",
      "Epoch: 464, Training loss: 1.382093, Validation loss: 1.3643, lr: 0.0000\n",
      "Epoch: 465, Training loss: 1.341893, Validation loss: 1.3707, lr: 0.0000\n",
      "Epoch: 466, Training loss: 1.383704, Validation loss: 1.3883, lr: 0.0000\n",
      "Epoch: 467, Training loss: 1.363332, Validation loss: 1.3734, lr: 0.0000\n",
      "Epoch: 468, Training loss: 1.364113, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 469, Training loss: 1.379460, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 470, Training loss: 1.388154, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 471, Training loss: 1.379500, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 472, Training loss: 1.380805, Validation loss: 1.3725, lr: 0.0000\n",
      "Epoch: 473, Training loss: 1.393852, Validation loss: 1.3755, lr: 0.0000\n",
      "Epoch: 474, Training loss: 1.367764, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 475, Training loss: 1.377915, Validation loss: 1.3906, lr: 0.0000\n",
      "Epoch: 476, Training loss: 1.371761, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 477, Training loss: 1.376504, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 478, Training loss: 1.361205, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 479, Training loss: 1.379093, Validation loss: 1.3786, lr: 0.0000\n",
      "Epoch: 480, Training loss: 1.383732, Validation loss: 1.3755, lr: 0.0000\n",
      "Epoch: 481, Training loss: 1.364298, Validation loss: 1.3948, lr: 0.0000\n",
      "Epoch: 482, Training loss: 1.375104, Validation loss: 1.3788, lr: 0.0000\n",
      "Epoch: 483, Training loss: 1.386661, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 484, Training loss: 1.389944, Validation loss: 1.3708, lr: 0.0000\n",
      "Epoch: 485, Training loss: 1.356250, Validation loss: 1.3736, lr: 0.0000\n",
      "Epoch: 486, Training loss: 1.362586, Validation loss: 1.3664, lr: 0.0000\n",
      "Epoch: 487, Training loss: 1.379927, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 488, Training loss: 1.390777, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 489, Training loss: 1.391009, Validation loss: 1.4318, lr: 0.0000\n",
      "Epoch: 490, Training loss: 1.381054, Validation loss: 1.3746, lr: 0.0000\n",
      "Epoch: 491, Training loss: 1.367579, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 492, Training loss: 1.368925, Validation loss: 1.3729, lr: 0.0000\n",
      "Epoch: 493, Training loss: 1.370960, Validation loss: 1.4085, lr: 0.0000\n",
      "Epoch: 494, Training loss: 1.386223, Validation loss: 1.3788, lr: 0.0000\n",
      "Epoch: 495, Training loss: 1.362903, Validation loss: 1.3758, lr: 0.0000\n",
      "Epoch: 496, Training loss: 1.390954, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 497, Training loss: 1.367890, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 498, Training loss: 1.424063, Validation loss: 1.3709, lr: 0.0000\n",
      "Epoch: 499, Training loss: 1.369249, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 500, Training loss: 1.371862, Validation loss: 1.3792, lr: 0.0000\n",
      "Epoch: 501, Training loss: 1.359234, Validation loss: 1.3803, lr: 0.0000\n",
      "Epoch: 502, Training loss: 1.355632, Validation loss: 1.3688, lr: 0.0000\n",
      "Epoch: 503, Training loss: 1.373951, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 504, Training loss: 1.382563, Validation loss: 1.3793, lr: 0.0000\n",
      "Epoch: 505, Training loss: 1.361245, Validation loss: 1.3876, lr: 0.0000\n",
      "Epoch: 506, Training loss: 1.368290, Validation loss: 1.3701, lr: 0.0000\n",
      "Epoch: 507, Training loss: 1.381192, Validation loss: 1.3799, lr: 0.0000\n",
      "Epoch: 508, Training loss: 1.384857, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 509, Training loss: 1.379053, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 510, Training loss: 1.371491, Validation loss: 1.3882, lr: 0.0000\n",
      "Epoch: 511, Training loss: 1.385896, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 512, Training loss: 1.369171, Validation loss: 1.3769, lr: 0.0000\n",
      "Epoch: 513, Training loss: 1.383039, Validation loss: 1.3797, lr: 0.0000\n",
      "Epoch: 514, Training loss: 1.382365, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 515, Training loss: 1.354212, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 516, Training loss: 1.381689, Validation loss: 1.3918, lr: 0.0000\n",
      "Epoch: 517, Training loss: 1.361575, Validation loss: 1.3883, lr: 0.0000\n",
      "Epoch: 518, Training loss: 1.370748, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 519, Training loss: 1.357640, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 520, Training loss: 1.384543, Validation loss: 1.3788, lr: 0.0000\n",
      "Epoch: 521, Training loss: 1.378718, Validation loss: 1.3790, lr: 0.0000\n",
      "Epoch: 522, Training loss: 1.371446, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 523, Training loss: 1.362470, Validation loss: 1.3786, lr: 0.0000\n",
      "Epoch: 524, Training loss: 1.371087, Validation loss: 1.3717, lr: 0.0000\n",
      "Epoch: 525, Training loss: 1.352700, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 526, Training loss: 1.373865, Validation loss: 1.3785, lr: 0.0000\n",
      "Epoch: 527, Training loss: 1.377547, Validation loss: 1.3662, lr: 0.0000\n",
      "Epoch: 528, Training loss: 1.384969, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 529, Training loss: 1.368564, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 530, Training loss: 1.373789, Validation loss: 1.3699, lr: 0.0000\n",
      "Epoch: 531, Training loss: 1.375716, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 532, Training loss: 1.375743, Validation loss: 1.3800, lr: 0.0000\n",
      "Epoch: 533, Training loss: 1.365300, Validation loss: 1.3908, lr: 0.0000\n",
      "Epoch: 534, Training loss: 1.368054, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 535, Training loss: 1.410869, Validation loss: 1.3644, lr: 0.0000\n",
      "Epoch: 536, Training loss: 1.360461, Validation loss: 1.3809, lr: 0.0000\n",
      "Epoch: 537, Training loss: 1.369495, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 538, Training loss: 1.346831, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 539, Training loss: 1.367806, Validation loss: 1.3570, lr: 0.0000\n",
      "Epoch: 540, Training loss: 1.363914, Validation loss: 1.3793, lr: 0.0000\n",
      "Epoch: 541, Training loss: 1.371811, Validation loss: 1.3904, lr: 0.0000\n",
      "Epoch: 542, Training loss: 1.384290, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 543, Training loss: 1.384465, Validation loss: 1.3737, lr: 0.0000\n",
      "Epoch: 544, Training loss: 1.401676, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 545, Training loss: 1.383368, Validation loss: 1.3881, lr: 0.0000\n",
      "Epoch: 546, Training loss: 1.369766, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 547, Training loss: 1.371391, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 548, Training loss: 1.369998, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 549, Training loss: 1.374249, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 550, Training loss: 1.372818, Validation loss: 1.4072, lr: 0.0000\n",
      "Epoch: 551, Training loss: 1.367304, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 552, Training loss: 1.356115, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 553, Training loss: 1.350861, Validation loss: 1.4016, lr: 0.0000\n",
      "Epoch: 554, Training loss: 1.388855, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 555, Training loss: 1.377132, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 556, Training loss: 1.485748, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 557, Training loss: 1.364483, Validation loss: 1.3795, lr: 0.0000\n",
      "Epoch: 558, Training loss: 1.372870, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 559, Training loss: 1.359923, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 560, Training loss: 1.378643, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 561, Training loss: 1.397588, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 562, Training loss: 1.361767, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 563, Training loss: 1.402046, Validation loss: 1.3993, lr: 0.0000\n",
      "Epoch: 564, Training loss: 1.345954, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 565, Training loss: 1.381873, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 566, Training loss: 1.378727, Validation loss: 1.3706, lr: 0.0000\n",
      "Epoch: 567, Training loss: 1.358414, Validation loss: 1.3694, lr: 0.0000\n",
      "Epoch: 568, Training loss: 1.376684, Validation loss: 1.3798, lr: 0.0000\n",
      "Epoch: 569, Training loss: 1.388209, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 570, Training loss: 1.379195, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 571, Training loss: 1.350057, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 572, Training loss: 1.367612, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 573, Training loss: 1.370040, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 574, Training loss: 1.383251, Validation loss: 1.3790, lr: 0.0000\n",
      "Epoch: 575, Training loss: 1.380353, Validation loss: 1.3785, lr: 0.0000\n",
      "Epoch: 576, Training loss: 1.409523, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 577, Training loss: 1.364970, Validation loss: 1.3996, lr: 0.0000\n",
      "Epoch: 578, Training loss: 1.384006, Validation loss: 1.3756, lr: 0.0000\n",
      "Epoch: 579, Training loss: 1.378685, Validation loss: 1.3900, lr: 0.0000\n",
      "Epoch: 580, Training loss: 1.366416, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 581, Training loss: 1.372205, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 582, Training loss: 1.391229, Validation loss: 1.3790, lr: 0.0000\n",
      "Epoch: 583, Training loss: 1.381083, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 584, Training loss: 1.382650, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 585, Training loss: 1.371535, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 586, Training loss: 1.369292, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 587, Training loss: 1.367023, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 588, Training loss: 1.401008, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 589, Training loss: 1.381396, Validation loss: 1.3675, lr: 0.0000\n",
      "Epoch: 590, Training loss: 1.372719, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 591, Training loss: 1.364779, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 592, Training loss: 1.382997, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 593, Training loss: 1.433037, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 594, Training loss: 1.383087, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 595, Training loss: 1.367344, Validation loss: 1.3770, lr: 0.0000\n",
      "Epoch: 596, Training loss: 1.367355, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 597, Training loss: 1.373181, Validation loss: 1.3693, lr: 0.0000\n",
      "Epoch: 598, Training loss: 1.359935, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 599, Training loss: 1.370374, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 600, Training loss: 1.383999, Validation loss: 1.3703, lr: 0.0000\n",
      "Epoch: 601, Training loss: 1.353093, Validation loss: 1.3796, lr: 0.0000\n",
      "Epoch: 602, Training loss: 1.377536, Validation loss: 1.3791, lr: 0.0000\n",
      "Epoch: 603, Training loss: 1.362037, Validation loss: 1.3803, lr: 0.0000\n",
      "Epoch: 604, Training loss: 1.384671, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 605, Training loss: 1.381973, Validation loss: 1.3610, lr: 0.0000\n",
      "Epoch: 606, Training loss: 1.386058, Validation loss: 1.3530, lr: 0.0000\n",
      "Epoch: 607, Training loss: 1.369412, Validation loss: 1.3782, lr: 0.0000\n",
      "Epoch: 608, Training loss: 1.394346, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 609, Training loss: 1.355438, Validation loss: 1.3885, lr: 0.0000\n",
      "Epoch: 610, Training loss: 1.356356, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 611, Training loss: 1.382951, Validation loss: 1.3718, lr: 0.0000\n",
      "Epoch: 612, Training loss: 1.369970, Validation loss: 1.3645, lr: 0.0000\n",
      "Epoch: 613, Training loss: 1.372955, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 614, Training loss: 1.367712, Validation loss: 1.3777, lr: 0.0000\n",
      "Epoch: 615, Training loss: 1.371819, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 616, Training loss: 1.355405, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 617, Training loss: 1.365577, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 618, Training loss: 1.358208, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 619, Training loss: 1.371515, Validation loss: 1.3969, lr: 0.0000\n",
      "Epoch: 620, Training loss: 1.389837, Validation loss: 1.3888, lr: 0.0000\n",
      "Epoch: 621, Training loss: 1.373068, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 622, Training loss: 1.377432, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 623, Training loss: 1.363732, Validation loss: 1.3741, lr: 0.0000\n",
      "Epoch: 624, Training loss: 1.377424, Validation loss: 1.3774, lr: 0.0000\n",
      "Epoch: 625, Training loss: 1.364251, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 626, Training loss: 1.374942, Validation loss: 1.3915, lr: 0.0000\n",
      "Epoch: 627, Training loss: 1.359940, Validation loss: 1.3762, lr: 0.0000\n",
      "Epoch: 628, Training loss: 1.370180, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 629, Training loss: 1.355028, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 630, Training loss: 1.362412, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 631, Training loss: 1.359792, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 632, Training loss: 1.368864, Validation loss: 1.3765, lr: 0.0000\n",
      "Epoch: 633, Training loss: 1.367381, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 634, Training loss: 1.366514, Validation loss: 1.3790, lr: 0.0000\n",
      "Epoch: 635, Training loss: 1.370533, Validation loss: 1.3891, lr: 0.0000\n",
      "Epoch: 636, Training loss: 1.377640, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 637, Training loss: 1.376975, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 638, Training loss: 1.359133, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 639, Training loss: 1.381246, Validation loss: 1.3924, lr: 0.0000\n",
      "Epoch: 640, Training loss: 1.367031, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 641, Training loss: 1.374404, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 642, Training loss: 1.376912, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 643, Training loss: 1.373617, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 644, Training loss: 1.366315, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 645, Training loss: 1.426535, Validation loss: 1.3802, lr: 0.0000\n",
      "Epoch: 646, Training loss: 1.384193, Validation loss: 1.3887, lr: 0.0000\n",
      "Epoch: 647, Training loss: 1.375781, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 648, Training loss: 1.377794, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 649, Training loss: 1.377305, Validation loss: 1.3796, lr: 0.0000\n",
      "Epoch: 650, Training loss: 1.360084, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 651, Training loss: 1.373451, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 652, Training loss: 1.376692, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 653, Training loss: 1.378895, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 654, Training loss: 1.385486, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 655, Training loss: 1.418065, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 656, Training loss: 1.368070, Validation loss: 1.3874, lr: 0.0000\n",
      "Epoch: 657, Training loss: 1.382441, Validation loss: 1.3764, lr: 0.0000\n",
      "Epoch: 658, Training loss: 1.384059, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 659, Training loss: 1.378537, Validation loss: 1.3696, lr: 0.0000\n",
      "Epoch: 660, Training loss: 1.389794, Validation loss: 1.3737, lr: 0.0000\n",
      "Epoch: 661, Training loss: 1.377730, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 662, Training loss: 1.367190, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 663, Training loss: 1.370642, Validation loss: 1.3794, lr: 0.0000\n",
      "Epoch: 664, Training loss: 1.356305, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 665, Training loss: 1.384040, Validation loss: 1.3789, lr: 0.0000\n",
      "Epoch: 666, Training loss: 1.355637, Validation loss: 1.3715, lr: 0.0000\n",
      "Epoch: 667, Training loss: 1.382310, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 668, Training loss: 1.372935, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 669, Training loss: 1.364899, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 670, Training loss: 1.380780, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 671, Training loss: 1.358662, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 672, Training loss: 1.377082, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 673, Training loss: 1.357821, Validation loss: 1.3882, lr: 0.0000\n",
      "Epoch: 674, Training loss: 1.348758, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 675, Training loss: 1.368662, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 676, Training loss: 1.376640, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 677, Training loss: 1.371070, Validation loss: 1.3881, lr: 0.0000\n",
      "Epoch: 678, Training loss: 1.362616, Validation loss: 1.3792, lr: 0.0000\n",
      "Epoch: 679, Training loss: 1.367989, Validation loss: 1.3729, lr: 0.0000\n",
      "Epoch: 680, Training loss: 1.367263, Validation loss: 1.3645, lr: 0.0000\n",
      "Epoch: 681, Training loss: 1.422540, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 682, Training loss: 1.366815, Validation loss: 1.3779, lr: 0.0000\n",
      "Epoch: 683, Training loss: 1.367607, Validation loss: 1.3786, lr: 0.0000\n",
      "Epoch: 684, Training loss: 1.354204, Validation loss: 1.3893, lr: 0.0000\n",
      "Epoch: 685, Training loss: 1.370187, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 686, Training loss: 1.399023, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 687, Training loss: 1.345469, Validation loss: 1.3752, lr: 0.0000\n",
      "Epoch: 688, Training loss: 1.410761, Validation loss: 1.3782, lr: 0.0000\n",
      "Epoch: 689, Training loss: 1.379613, Validation loss: 1.3770, lr: 0.0000\n",
      "Epoch: 690, Training loss: 1.394033, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 691, Training loss: 1.371473, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 692, Training loss: 1.361761, Validation loss: 1.3783, lr: 0.0000\n",
      "Epoch: 693, Training loss: 1.365425, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 694, Training loss: 1.379116, Validation loss: 1.3798, lr: 0.0000\n",
      "Epoch: 695, Training loss: 1.385173, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 696, Training loss: 1.385933, Validation loss: 1.3792, lr: 0.0000\n",
      "Epoch: 697, Training loss: 1.366400, Validation loss: 1.3755, lr: 0.0000\n",
      "Epoch: 698, Training loss: 1.364981, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 699, Training loss: 1.381200, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 700, Training loss: 1.351517, Validation loss: 1.3786, lr: 0.0000\n",
      "Epoch: 701, Training loss: 1.345732, Validation loss: 1.3799, lr: 0.0000\n",
      "Epoch: 702, Training loss: 1.399302, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 703, Training loss: 1.373590, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 704, Training loss: 1.386314, Validation loss: 1.3581, lr: 0.0000\n",
      "Epoch: 705, Training loss: 1.365737, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 706, Training loss: 1.397440, Validation loss: 1.3809, lr: 0.0000\n",
      "Epoch: 707, Training loss: 1.363459, Validation loss: 1.3568, lr: 0.0000\n",
      "Epoch: 708, Training loss: 1.377804, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 709, Training loss: 1.383387, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 710, Training loss: 1.356058, Validation loss: 1.3789, lr: 0.0000\n",
      "Epoch: 711, Training loss: 1.356648, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 712, Training loss: 1.368077, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 713, Training loss: 1.360941, Validation loss: 1.3774, lr: 0.0000\n",
      "Epoch: 714, Training loss: 1.371887, Validation loss: 1.3692, lr: 0.0000\n",
      "Epoch: 715, Training loss: 1.527724, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 716, Training loss: 1.404302, Validation loss: 1.3655, lr: 0.0000\n",
      "Epoch: 717, Training loss: 1.373142, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 718, Training loss: 1.370218, Validation loss: 1.3646, lr: 0.0000\n",
      "Epoch: 719, Training loss: 1.373880, Validation loss: 1.3756, lr: 0.0000\n",
      "Epoch: 720, Training loss: 1.370073, Validation loss: 1.3758, lr: 0.0000\n",
      "Epoch: 721, Training loss: 1.353179, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 722, Training loss: 1.371784, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 723, Training loss: 1.374548, Validation loss: 1.3546, lr: 0.0000\n",
      "Epoch: 724, Training loss: 1.364434, Validation loss: 1.3747, lr: 0.0000\n",
      "Epoch: 725, Training loss: 1.410507, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 726, Training loss: 1.377482, Validation loss: 1.3557, lr: 0.0000\n",
      "Epoch: 727, Training loss: 1.363269, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 728, Training loss: 1.352473, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 729, Training loss: 1.376363, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 730, Training loss: 1.352658, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 731, Training loss: 1.362339, Validation loss: 1.3741, lr: 0.0000\n",
      "Epoch: 732, Training loss: 1.364455, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 733, Training loss: 1.362419, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 734, Training loss: 1.371487, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 735, Training loss: 1.392283, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 736, Training loss: 1.365348, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 737, Training loss: 1.372783, Validation loss: 1.3797, lr: 0.0000\n",
      "Epoch: 738, Training loss: 1.340864, Validation loss: 1.3708, lr: 0.0000\n",
      "Epoch: 739, Training loss: 1.386940, Validation loss: 1.3656, lr: 0.0000\n",
      "Epoch: 740, Training loss: 1.389528, Validation loss: 1.3803, lr: 0.0000\n",
      "Epoch: 741, Training loss: 1.368836, Validation loss: 1.3754, lr: 0.0000\n",
      "Epoch: 742, Training loss: 1.376233, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 743, Training loss: 1.342433, Validation loss: 1.3928, lr: 0.0000\n",
      "Epoch: 744, Training loss: 1.379413, Validation loss: 1.4162, lr: 0.0000\n",
      "Epoch: 745, Training loss: 1.372377, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 746, Training loss: 1.372589, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 747, Training loss: 1.377989, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 748, Training loss: 1.362981, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 749, Training loss: 1.357563, Validation loss: 1.3755, lr: 0.0000\n",
      "Epoch: 750, Training loss: 1.352234, Validation loss: 1.3877, lr: 0.0000\n",
      "Epoch: 751, Training loss: 1.368270, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 752, Training loss: 1.359787, Validation loss: 1.3888, lr: 0.0000\n",
      "Epoch: 753, Training loss: 1.387078, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 754, Training loss: 1.373716, Validation loss: 1.4621, lr: 0.0000\n",
      "Epoch: 755, Training loss: 1.341447, Validation loss: 1.3782, lr: 0.0000\n",
      "Epoch: 756, Training loss: 1.360788, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 757, Training loss: 1.372529, Validation loss: 1.3751, lr: 0.0000\n",
      "Epoch: 758, Training loss: 1.379082, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 759, Training loss: 1.370822, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 760, Training loss: 1.380111, Validation loss: 1.3762, lr: 0.0000\n",
      "Epoch: 761, Training loss: 1.363576, Validation loss: 1.3691, lr: 0.0000\n",
      "Epoch: 762, Training loss: 1.366999, Validation loss: 1.4177, lr: 0.0000\n",
      "Epoch: 763, Training loss: 1.415656, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 764, Training loss: 1.380097, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 765, Training loss: 1.381730, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 766, Training loss: 1.363397, Validation loss: 1.3612, lr: 0.0000\n",
      "Epoch: 767, Training loss: 1.385892, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 768, Training loss: 1.374169, Validation loss: 1.3711, lr: 0.0000\n",
      "Epoch: 769, Training loss: 1.383674, Validation loss: 1.3748, lr: 0.0000\n",
      "Epoch: 770, Training loss: 1.371534, Validation loss: 1.3875, lr: 0.0000\n",
      "Epoch: 771, Training loss: 1.399167, Validation loss: 1.3728, lr: 0.0000\n",
      "Epoch: 772, Training loss: 1.378705, Validation loss: 1.3779, lr: 0.0000\n",
      "Epoch: 773, Training loss: 1.368235, Validation loss: 1.3874, lr: 0.0000\n",
      "Epoch: 774, Training loss: 1.338485, Validation loss: 1.3778, lr: 0.0000\n",
      "Epoch: 775, Training loss: 1.372946, Validation loss: 1.3724, lr: 0.0000\n",
      "Epoch: 776, Training loss: 1.366081, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 777, Training loss: 1.362206, Validation loss: 1.3721, lr: 0.0000\n",
      "Epoch: 778, Training loss: 1.375184, Validation loss: 1.3658, lr: 0.0000\n",
      "Epoch: 779, Training loss: 1.373244, Validation loss: 1.3900, lr: 0.0000\n",
      "Epoch: 780, Training loss: 1.374805, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 781, Training loss: 1.369451, Validation loss: 1.3944, lr: 0.0000\n",
      "Epoch: 782, Training loss: 1.390302, Validation loss: 1.3803, lr: 0.0000\n",
      "Epoch: 783, Training loss: 1.381804, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 784, Training loss: 1.391991, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 785, Training loss: 1.384030, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 786, Training loss: 1.369285, Validation loss: 1.3712, lr: 0.0000\n",
      "Epoch: 787, Training loss: 1.389333, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 788, Training loss: 1.362496, Validation loss: 1.3938, lr: 0.0000\n",
      "Epoch: 789, Training loss: 1.368085, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 790, Training loss: 1.371428, Validation loss: 1.3703, lr: 0.0000\n",
      "Epoch: 791, Training loss: 1.376235, Validation loss: 1.3632, lr: 0.0000\n",
      "Epoch: 792, Training loss: 1.389543, Validation loss: 1.3591, lr: 0.0000\n",
      "Epoch: 793, Training loss: 1.364213, Validation loss: 1.3734, lr: 0.0000\n",
      "Epoch: 794, Training loss: 1.357309, Validation loss: 1.3778, lr: 0.0000\n",
      "Epoch: 795, Training loss: 1.355540, Validation loss: 1.3757, lr: 0.0000\n",
      "Epoch: 796, Training loss: 1.372702, Validation loss: 1.3769, lr: 0.0000\n",
      "Epoch: 797, Training loss: 1.369337, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 798, Training loss: 1.383767, Validation loss: 1.3908, lr: 0.0000\n",
      "Epoch: 799, Training loss: 1.361566, Validation loss: 1.3792, lr: 0.0000\n",
      "Epoch: 800, Training loss: 1.393247, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 801, Training loss: 1.368545, Validation loss: 1.4034, lr: 0.0000\n",
      "Epoch: 802, Training loss: 1.359610, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 803, Training loss: 1.356307, Validation loss: 1.3783, lr: 0.0000\n",
      "Epoch: 804, Training loss: 1.375438, Validation loss: 1.3899, lr: 0.0000\n",
      "Epoch: 805, Training loss: 1.386896, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 806, Training loss: 1.366490, Validation loss: 1.3795, lr: 0.0000\n",
      "Epoch: 807, Training loss: 1.368774, Validation loss: 1.4008, lr: 0.0000\n",
      "Epoch: 808, Training loss: 1.378490, Validation loss: 1.3798, lr: 0.0000\n",
      "Epoch: 809, Training loss: 1.342505, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 810, Training loss: 1.365110, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 811, Training loss: 1.371942, Validation loss: 1.3777, lr: 0.0000\n",
      "Epoch: 812, Training loss: 1.366358, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 813, Training loss: 1.377938, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 814, Training loss: 1.391921, Validation loss: 1.3753, lr: 0.0000\n",
      "Epoch: 815, Training loss: 1.369377, Validation loss: 1.3883, lr: 0.0000\n",
      "Epoch: 816, Training loss: 1.390385, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 817, Training loss: 1.382565, Validation loss: 1.3872, lr: 0.0000\n",
      "Epoch: 818, Training loss: 1.375709, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 819, Training loss: 1.387163, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 820, Training loss: 1.367095, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 821, Training loss: 1.384893, Validation loss: 1.3759, lr: 0.0000\n",
      "Epoch: 822, Training loss: 1.391198, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 823, Training loss: 1.366338, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 824, Training loss: 1.395008, Validation loss: 1.3794, lr: 0.0000\n",
      "Epoch: 825, Training loss: 1.384468, Validation loss: 1.3691, lr: 0.0000\n",
      "Epoch: 826, Training loss: 1.384682, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 827, Training loss: 1.362685, Validation loss: 1.3432, lr: 0.0000\n",
      "Epoch: 828, Training loss: 1.365833, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 829, Training loss: 1.407121, Validation loss: 1.3545, lr: 0.0000\n",
      "Epoch: 830, Training loss: 1.361927, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 831, Training loss: 1.371774, Validation loss: 1.3748, lr: 0.0000\n",
      "Epoch: 832, Training loss: 1.407013, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 833, Training loss: 1.374248, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 834, Training loss: 1.376855, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 835, Training loss: 1.453896, Validation loss: 1.3778, lr: 0.0000\n",
      "Epoch: 836, Training loss: 1.378239, Validation loss: 1.3897, lr: 0.0000\n",
      "Epoch: 837, Training loss: 1.367696, Validation loss: 1.4234, lr: 0.0000\n",
      "Epoch: 838, Training loss: 1.378149, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 839, Training loss: 1.368968, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 840, Training loss: 1.384805, Validation loss: 1.3799, lr: 0.0000\n",
      "Epoch: 841, Training loss: 1.375424, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 842, Training loss: 1.373299, Validation loss: 1.3652, lr: 0.0000\n",
      "Epoch: 843, Training loss: 1.381158, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 844, Training loss: 1.368843, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 845, Training loss: 1.366773, Validation loss: 1.3694, lr: 0.0000\n",
      "Epoch: 846, Training loss: 1.372746, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 847, Training loss: 1.360384, Validation loss: 1.4668, lr: 0.0000\n",
      "Epoch: 848, Training loss: 1.372100, Validation loss: 1.4072, lr: 0.0000\n",
      "Epoch: 849, Training loss: 1.390167, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 850, Training loss: 1.360444, Validation loss: 1.3778, lr: 0.0000\n",
      "Epoch: 851, Training loss: 1.369803, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 852, Training loss: 1.375746, Validation loss: 1.3762, lr: 0.0000\n",
      "Epoch: 853, Training loss: 1.348631, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 854, Training loss: 1.386476, Validation loss: 1.3888, lr: 0.0000\n",
      "Epoch: 855, Training loss: 1.369804, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 856, Training loss: 1.388378, Validation loss: 1.3790, lr: 0.0000\n",
      "Epoch: 857, Training loss: 1.381246, Validation loss: 1.3794, lr: 0.0000\n",
      "Epoch: 858, Training loss: 1.371307, Validation loss: 1.3774, lr: 0.0000\n",
      "Epoch: 859, Training loss: 1.372590, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 860, Training loss: 1.377539, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 861, Training loss: 1.405242, Validation loss: 1.3793, lr: 0.0000\n",
      "Epoch: 862, Training loss: 1.362074, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 863, Training loss: 1.411601, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 864, Training loss: 1.373746, Validation loss: 1.4035, lr: 0.0000\n",
      "Epoch: 865, Training loss: 1.368808, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 866, Training loss: 1.366939, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 867, Training loss: 1.371824, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 868, Training loss: 1.363985, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 869, Training loss: 1.386025, Validation loss: 1.3672, lr: 0.0000\n",
      "Epoch: 870, Training loss: 1.380380, Validation loss: 1.3667, lr: 0.0000\n",
      "Epoch: 871, Training loss: 1.424441, Validation loss: 1.3884, lr: 0.0000\n",
      "Epoch: 872, Training loss: 1.352332, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 873, Training loss: 1.378331, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 874, Training loss: 1.358399, Validation loss: 1.3767, lr: 0.0000\n",
      "Epoch: 875, Training loss: 1.376115, Validation loss: 1.3896, lr: 0.0000\n",
      "Epoch: 876, Training loss: 1.366296, Validation loss: 1.3643, lr: 0.0000\n",
      "Epoch: 877, Training loss: 1.366606, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 878, Training loss: 1.377341, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 879, Training loss: 1.373428, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 880, Training loss: 1.382250, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 881, Training loss: 1.365664, Validation loss: 1.3784, lr: 0.0000\n",
      "Epoch: 882, Training loss: 1.400204, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 883, Training loss: 1.365687, Validation loss: 1.3710, lr: 0.0000\n",
      "Epoch: 884, Training loss: 1.381372, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 885, Training loss: 1.363665, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 886, Training loss: 1.389060, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 887, Training loss: 1.366295, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 888, Training loss: 1.368336, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 889, Training loss: 1.354349, Validation loss: 1.3793, lr: 0.0000\n",
      "Epoch: 890, Training loss: 1.391037, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 891, Training loss: 1.376490, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 892, Training loss: 1.401033, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 893, Training loss: 1.375757, Validation loss: 1.3895, lr: 0.0000\n",
      "Epoch: 894, Training loss: 1.372773, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 895, Training loss: 1.422953, Validation loss: 1.3769, lr: 0.0000\n",
      "Epoch: 896, Training loss: 1.381928, Validation loss: 1.3737, lr: 0.0000\n",
      "Epoch: 897, Training loss: 1.384517, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 898, Training loss: 1.366496, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 899, Training loss: 1.383992, Validation loss: 1.3778, lr: 0.0000\n",
      "Epoch: 900, Training loss: 1.375063, Validation loss: 1.3774, lr: 0.0000\n",
      "Epoch: 901, Training loss: 1.368586, Validation loss: 1.3773, lr: 0.0000\n",
      "Epoch: 902, Training loss: 1.375079, Validation loss: 1.3767, lr: 0.0000\n",
      "Epoch: 903, Training loss: 1.357729, Validation loss: 1.3716, lr: 0.0000\n",
      "Epoch: 904, Training loss: 1.373629, Validation loss: 1.3701, lr: 0.0000\n",
      "Epoch: 905, Training loss: 1.388430, Validation loss: 1.3739, lr: 0.0000\n",
      "Epoch: 906, Training loss: 1.369411, Validation loss: 1.3745, lr: 0.0000\n",
      "Epoch: 907, Training loss: 1.366429, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 908, Training loss: 1.358469, Validation loss: 1.3960, lr: 0.0000\n",
      "Epoch: 909, Training loss: 1.382531, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 910, Training loss: 1.380723, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 911, Training loss: 1.389893, Validation loss: 1.3878, lr: 0.0000\n",
      "Epoch: 912, Training loss: 1.378798, Validation loss: 1.3762, lr: 0.0000\n",
      "Epoch: 913, Training loss: 1.378737, Validation loss: 1.3698, lr: 0.0000\n",
      "Epoch: 914, Training loss: 1.353192, Validation loss: 1.3669, lr: 0.0000\n",
      "Epoch: 915, Training loss: 1.408671, Validation loss: 1.3795, lr: 0.0000\n",
      "Epoch: 916, Training loss: 1.369265, Validation loss: 1.3896, lr: 0.0000\n",
      "Epoch: 917, Training loss: 1.356413, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 918, Training loss: 1.358194, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 919, Training loss: 1.381155, Validation loss: 1.3626, lr: 0.0000\n",
      "Epoch: 920, Training loss: 1.376583, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 921, Training loss: 1.357006, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 922, Training loss: 1.362531, Validation loss: 1.4004, lr: 0.0000\n",
      "Epoch: 923, Training loss: 1.353715, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 924, Training loss: 1.363722, Validation loss: 1.3711, lr: 0.0000\n",
      "Epoch: 925, Training loss: 1.364877, Validation loss: 1.3759, lr: 0.0000\n",
      "Epoch: 926, Training loss: 1.377667, Validation loss: 1.3757, lr: 0.0000\n",
      "Epoch: 927, Training loss: 1.385035, Validation loss: 1.3710, lr: 0.0000\n",
      "Epoch: 928, Training loss: 1.394004, Validation loss: 1.5002, lr: 0.0000\n",
      "Epoch: 929, Training loss: 1.376303, Validation loss: 1.3877, lr: 0.0000\n",
      "Epoch: 930, Training loss: 1.377198, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 931, Training loss: 1.366879, Validation loss: 1.3539, lr: 0.0000\n",
      "Epoch: 932, Training loss: 1.358338, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 933, Training loss: 1.364589, Validation loss: 1.3751, lr: 0.0000\n",
      "Epoch: 934, Training loss: 1.375713, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 935, Training loss: 1.381969, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 936, Training loss: 1.368187, Validation loss: 1.3746, lr: 0.0000\n",
      "Epoch: 937, Training loss: 1.344081, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 938, Training loss: 1.365244, Validation loss: 1.3803, lr: 0.0000\n",
      "Epoch: 939, Training loss: 1.368800, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 940, Training loss: 1.371768, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 941, Training loss: 1.381287, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 942, Training loss: 1.369025, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 943, Training loss: 1.345245, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 944, Training loss: 1.381740, Validation loss: 1.3971, lr: 0.0000\n",
      "Epoch: 945, Training loss: 1.380147, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 946, Training loss: 1.387201, Validation loss: 1.3640, lr: 0.0000\n",
      "Epoch: 947, Training loss: 1.390609, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 948, Training loss: 1.381226, Validation loss: 1.3781, lr: 0.0000\n",
      "Epoch: 949, Training loss: 1.364523, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 950, Training loss: 1.379431, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 951, Training loss: 1.358031, Validation loss: 1.3905, lr: 0.0000\n",
      "Epoch: 952, Training loss: 1.374669, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 953, Training loss: 1.371715, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 954, Training loss: 1.364330, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 955, Training loss: 1.370540, Validation loss: 1.4222, lr: 0.0000\n",
      "Epoch: 956, Training loss: 1.377924, Validation loss: 1.3727, lr: 0.0000\n",
      "Epoch: 957, Training loss: 1.353779, Validation loss: 1.3711, lr: 0.0000\n",
      "Epoch: 958, Training loss: 1.394072, Validation loss: 1.3767, lr: 0.0000\n",
      "Epoch: 959, Training loss: 1.366891, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 960, Training loss: 1.370856, Validation loss: 1.3796, lr: 0.0000\n",
      "Epoch: 961, Training loss: 1.390219, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 962, Training loss: 1.351751, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 963, Training loss: 1.373363, Validation loss: 1.3872, lr: 0.0000\n",
      "Epoch: 964, Training loss: 1.350790, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 965, Training loss: 1.375679, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 966, Training loss: 1.363333, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 967, Training loss: 1.377331, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 968, Training loss: 1.414427, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 969, Training loss: 1.364479, Validation loss: 1.3586, lr: 0.0000\n",
      "Epoch: 970, Training loss: 1.401314, Validation loss: 1.3778, lr: 0.0000\n",
      "Epoch: 971, Training loss: 1.384233, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 972, Training loss: 1.382109, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 973, Training loss: 1.377676, Validation loss: 1.3779, lr: 0.0000\n",
      "Epoch: 974, Training loss: 1.384758, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 975, Training loss: 1.429400, Validation loss: 1.3724, lr: 0.0000\n",
      "Epoch: 976, Training loss: 1.358761, Validation loss: 1.3799, lr: 0.0000\n",
      "Epoch: 977, Training loss: 1.359495, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 978, Training loss: 1.394214, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 979, Training loss: 1.368441, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 980, Training loss: 1.364371, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 981, Training loss: 1.374295, Validation loss: 1.3792, lr: 0.0000\n",
      "Epoch: 982, Training loss: 1.367192, Validation loss: 1.3640, lr: 0.0000\n",
      "Epoch: 983, Training loss: 1.372157, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 984, Training loss: 1.362426, Validation loss: 1.3727, lr: 0.0000\n",
      "Epoch: 985, Training loss: 1.361784, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 986, Training loss: 1.376603, Validation loss: 1.3696, lr: 0.0000\n",
      "Epoch: 987, Training loss: 1.366313, Validation loss: 1.3774, lr: 0.0000\n",
      "Epoch: 988, Training loss: 1.391086, Validation loss: 1.3663, lr: 0.0000\n",
      "Epoch: 989, Training loss: 1.372989, Validation loss: 1.3648, lr: 0.0000\n",
      "Epoch: 990, Training loss: 1.384202, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 991, Training loss: 1.359805, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 992, Training loss: 1.361174, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 993, Training loss: 1.407512, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 994, Training loss: 1.354404, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 995, Training loss: 1.356953, Validation loss: 1.3882, lr: 0.0000\n",
      "Epoch: 996, Training loss: 1.371850, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 997, Training loss: 1.357535, Validation loss: 1.3927, lr: 0.0000\n",
      "Epoch: 998, Training loss: 1.376141, Validation loss: 1.3955, lr: 0.0000\n",
      "Epoch: 999, Training loss: 1.386943, Validation loss: 1.3826, lr: 0.0000\n",
      "Final test loss: 1.3813\n",
      "=== Run 03/10 ===\n",
      "\n",
      "---- Settings: \n",
      "\n",
      "epochs : 1000\n",
      "hidden_channels : [32]\n",
      "out_channels : 10\n",
      "inner_product_features : False\n",
      "batch_size : 64\n",
      "lr : 0.01\n",
      "momentum : 0.9\n",
      "dropout : 0.0\n",
      "batch_norm : batch_norm\n",
      "bias : True\n",
      "order : 2\n",
      "diffusion : True\n",
      "frac_sampled_nb : -1\n",
      "include_positions : False\n",
      "include_self : True\n",
      "vec_norm : False\n",
      "emb_norm : False\n",
      "seed : 0\n",
      "dim_signal : 100\n",
      "dim_emb : 100\n",
      "n_sampled_nb : -1\n",
      "\n",
      "---- Number of features to pass to the MLP:  1010100\n",
      "---- Total number of parameters:  32323627\n",
      "\n",
      "Using device cuda:0\n",
      "\n",
      "---- Training network ...\n",
      "\n",
      "---- Timestamp: 20250613-220339\n",
      "\n",
      " *och: 0, Training loss: 1.509734, Validation loss: 1.5004, lr: 0.0100\n",
      " *och: 1, Training loss: 1.420133, Validation loss: 1.3565, lr: 0.0100\n",
      "Epoch: 2, Training loss: 1.418358, Validation loss: 1.3882, lr: 0.0100\n",
      "Epoch: 3, Training loss: 1.391521, Validation loss: 1.3939, lr: 0.0100\n",
      "Epoch: 4, Training loss: 1.390075, Validation loss: 1.3711, lr: 0.0100\n",
      "Epoch: 5, Training loss: 1.401186, Validation loss: 1.3878, lr: 0.0100\n",
      "Epoch: 6, Training loss: 1.370594, Validation loss: 1.3837, lr: 0.0100\n",
      "Epoch: 7, Training loss: 1.381017, Validation loss: 1.3759, lr: 0.0100\n",
      "Epoch: 8, Training loss: 1.437348, Validation loss: 1.3788, lr: 0.0100\n",
      "Epoch: 9, Training loss: 1.426151, Validation loss: 1.3781, lr: 0.0100\n",
      "Epoch: 10, Training loss: 1.397552, Validation loss: 1.3859, lr: 0.0100\n",
      "Epoch: 11, Training loss: 1.390515, Validation loss: 1.3643, lr: 0.0100\n",
      "Epoch: 12, Training loss: 1.421835, Validation loss: 1.3760, lr: 0.0100\n",
      " *och: 13, Training loss: 1.408860, Validation loss: 1.3517, lr: 0.0100\n",
      "Epoch: 14, Training loss: 1.387675, Validation loss: 1.3861, lr: 0.0100\n",
      "Epoch: 15, Training loss: 1.394275, Validation loss: 1.3843, lr: 0.0100\n",
      "Epoch: 16, Training loss: 1.387176, Validation loss: 1.3888, lr: 0.0100\n",
      "Epoch: 17, Training loss: 1.381010, Validation loss: 1.3884, lr: 0.0010\n",
      "Epoch: 18, Training loss: 1.395877, Validation loss: 1.3984, lr: 0.0010\n",
      "Epoch: 19, Training loss: 1.412364, Validation loss: 1.3856, lr: 0.0010\n",
      "Epoch: 20, Training loss: 1.364895, Validation loss: 1.3873, lr: 0.0010\n",
      "Epoch: 21, Training loss: 1.424983, Validation loss: 1.3864, lr: 0.0010\n",
      "Epoch: 22, Training loss: 1.376963, Validation loss: 1.3848, lr: 0.0010\n",
      "Epoch: 23, Training loss: 1.380317, Validation loss: 1.3899, lr: 0.0010\n",
      "Epoch: 24, Training loss: 1.373981, Validation loss: 1.3833, lr: 0.0010\n",
      "Epoch: 25, Training loss: 1.396845, Validation loss: 1.3813, lr: 0.0010\n",
      "Epoch: 26, Training loss: 1.368845, Validation loss: 1.4011, lr: 0.0010\n",
      "Epoch: 27, Training loss: 1.395683, Validation loss: 1.3932, lr: 0.0010\n",
      "Epoch: 28, Training loss: 1.381910, Validation loss: 1.5221, lr: 0.0010\n",
      "Epoch: 29, Training loss: 1.380789, Validation loss: 1.3704, lr: 0.0010\n",
      "Epoch: 30, Training loss: 1.375228, Validation loss: 1.3787, lr: 0.0010\n",
      "Epoch: 31, Training loss: 1.380739, Validation loss: 1.3849, lr: 0.0001\n",
      "Epoch: 32, Training loss: 1.371530, Validation loss: 1.3836, lr: 0.0001\n",
      "Epoch: 33, Training loss: 1.382105, Validation loss: 1.3866, lr: 0.0001\n",
      "Epoch: 34, Training loss: 1.386477, Validation loss: 1.3758, lr: 0.0001\n",
      "Epoch: 35, Training loss: 1.378355, Validation loss: 1.3902, lr: 0.0001\n",
      "Epoch: 36, Training loss: 1.378783, Validation loss: 1.3743, lr: 0.0001\n",
      "Epoch: 37, Training loss: 1.381168, Validation loss: 1.3813, lr: 0.0001\n",
      "Epoch: 38, Training loss: 1.376733, Validation loss: 1.3850, lr: 0.0001\n",
      "Epoch: 39, Training loss: 1.364238, Validation loss: 1.3840, lr: 0.0001\n",
      "Epoch: 40, Training loss: 1.400513, Validation loss: 1.3849, lr: 0.0001\n",
      "Epoch: 41, Training loss: 1.380390, Validation loss: 1.3851, lr: 0.0001\n",
      "Epoch: 42, Training loss: 1.373596, Validation loss: 1.3843, lr: 0.0001\n",
      "Epoch: 43, Training loss: 1.416484, Validation loss: 1.3864, lr: 0.0001\n",
      "Epoch: 44, Training loss: 1.404606, Validation loss: 1.3869, lr: 0.0001\n",
      "Epoch: 45, Training loss: 1.378644, Validation loss: 1.3836, lr: 0.0001\n",
      "Epoch: 46, Training loss: 1.366133, Validation loss: 1.3829, lr: 0.0001\n",
      "Epoch: 47, Training loss: 1.369821, Validation loss: 1.3852, lr: 0.0001\n",
      "Epoch: 48, Training loss: 1.387204, Validation loss: 1.3824, lr: 0.0001\n",
      "Epoch: 49, Training loss: 1.379890, Validation loss: 1.3873, lr: 0.0001\n",
      "Epoch: 50, Training loss: 1.375803, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 51, Training loss: 1.364085, Validation loss: 1.3935, lr: 0.0000\n",
      "Epoch: 52, Training loss: 1.386547, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 53, Training loss: 1.381937, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 54, Training loss: 1.381636, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 55, Training loss: 1.378963, Validation loss: 1.3798, lr: 0.0000\n",
      "Epoch: 56, Training loss: 1.379918, Validation loss: 1.3919, lr: 0.0000\n",
      "Epoch: 57, Training loss: 1.382247, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 58, Training loss: 1.379993, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 59, Training loss: 1.388481, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 60, Training loss: 1.379302, Validation loss: 1.3893, lr: 0.0000\n",
      "Epoch: 61, Training loss: 1.393108, Validation loss: 1.3702, lr: 0.0000\n",
      "Epoch: 62, Training loss: 1.428046, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 63, Training loss: 1.384091, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 64, Training loss: 1.385069, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 65, Training loss: 1.361865, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 66, Training loss: 1.376529, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 67, Training loss: 1.400442, Validation loss: 1.3907, lr: 0.0000\n",
      "Epoch: 68, Training loss: 1.374617, Validation loss: 1.3873, lr: 0.0000\n",
      "Epoch: 69, Training loss: 1.374099, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 70, Training loss: 1.393805, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 71, Training loss: 1.384309, Validation loss: 1.3660, lr: 0.0000\n",
      "Epoch: 72, Training loss: 1.409620, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 73, Training loss: 1.393038, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 74, Training loss: 1.380562, Validation loss: 1.3742, lr: 0.0000\n",
      "Epoch: 75, Training loss: 1.394165, Validation loss: 1.3598, lr: 0.0000\n",
      "Epoch: 76, Training loss: 1.384087, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 77, Training loss: 1.378946, Validation loss: 1.3740, lr: 0.0000\n",
      "Epoch: 78, Training loss: 1.382740, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 79, Training loss: 1.369476, Validation loss: 1.3792, lr: 0.0000\n",
      "Epoch: 80, Training loss: 1.395141, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 81, Training loss: 1.376875, Validation loss: 1.3719, lr: 0.0000\n",
      "Epoch: 82, Training loss: 1.380276, Validation loss: 1.3881, lr: 0.0000\n",
      "Epoch: 83, Training loss: 1.409098, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 84, Training loss: 1.377390, Validation loss: 1.3754, lr: 0.0000\n",
      "Epoch: 85, Training loss: 1.412925, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 86, Training loss: 1.378829, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 87, Training loss: 1.386756, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 88, Training loss: 1.381088, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 89, Training loss: 1.374508, Validation loss: 1.3887, lr: 0.0000\n",
      "Epoch: 90, Training loss: 1.379709, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 91, Training loss: 1.380613, Validation loss: 1.3785, lr: 0.0000\n",
      "Epoch: 92, Training loss: 1.382602, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 93, Training loss: 1.384956, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 94, Training loss: 1.379884, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 95, Training loss: 1.368667, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 96, Training loss: 1.381130, Validation loss: 1.3710, lr: 0.0000\n",
      "Epoch: 97, Training loss: 1.399912, Validation loss: 1.3779, lr: 0.0000\n",
      "Epoch: 98, Training loss: 1.376115, Validation loss: 1.3726, lr: 0.0000\n",
      "Epoch: 99, Training loss: 1.395449, Validation loss: 1.3877, lr: 0.0000\n",
      "Epoch: 100, Training loss: 1.375541, Validation loss: 1.3880, lr: 0.0000\n",
      "Epoch: 101, Training loss: 1.391413, Validation loss: 1.3685, lr: 0.0000\n",
      "Epoch: 102, Training loss: 1.375878, Validation loss: 1.3738, lr: 0.0000\n",
      "Epoch: 103, Training loss: 1.375100, Validation loss: 1.3748, lr: 0.0000\n",
      "Epoch: 104, Training loss: 1.379721, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 105, Training loss: 1.396138, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 106, Training loss: 1.371685, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 107, Training loss: 1.385545, Validation loss: 1.3883, lr: 0.0000\n",
      "Epoch: 108, Training loss: 1.375947, Validation loss: 1.3692, lr: 0.0000\n",
      "Epoch: 109, Training loss: 1.371506, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 110, Training loss: 1.386748, Validation loss: 1.3701, lr: 0.0000\n",
      "Epoch: 111, Training loss: 1.378711, Validation loss: 1.3705, lr: 0.0000\n",
      "Epoch: 112, Training loss: 1.377362, Validation loss: 1.3653, lr: 0.0000\n",
      "Epoch: 113, Training loss: 1.376485, Validation loss: 1.4123, lr: 0.0000\n",
      "Epoch: 114, Training loss: 1.388099, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 115, Training loss: 1.441879, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 116, Training loss: 1.390028, Validation loss: 1.4072, lr: 0.0000\n",
      "Epoch: 117, Training loss: 1.382597, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 118, Training loss: 1.393264, Validation loss: 1.3544, lr: 0.0000\n",
      "Epoch: 119, Training loss: 1.376801, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 120, Training loss: 1.381405, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 121, Training loss: 1.373062, Validation loss: 1.3790, lr: 0.0000\n",
      "Epoch: 122, Training loss: 1.376916, Validation loss: 1.3874, lr: 0.0000\n",
      "Epoch: 123, Training loss: 1.376164, Validation loss: 1.3784, lr: 0.0000\n",
      "Epoch: 124, Training loss: 1.399081, Validation loss: 1.3693, lr: 0.0000\n",
      "Epoch: 125, Training loss: 1.383026, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 126, Training loss: 1.416226, Validation loss: 1.3880, lr: 0.0000\n",
      "Epoch: 127, Training loss: 1.378995, Validation loss: 1.3777, lr: 0.0000\n",
      "Epoch: 128, Training loss: 1.390499, Validation loss: 1.3794, lr: 0.0000\n",
      "Epoch: 129, Training loss: 1.364795, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 130, Training loss: 1.369186, Validation loss: 1.3771, lr: 0.0000\n",
      "Epoch: 131, Training loss: 1.359648, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 132, Training loss: 1.371827, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 133, Training loss: 1.380374, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 134, Training loss: 1.372300, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 135, Training loss: 1.394283, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 136, Training loss: 1.378253, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 137, Training loss: 1.383153, Validation loss: 1.3776, lr: 0.0000\n",
      "Epoch: 138, Training loss: 1.394451, Validation loss: 1.3792, lr: 0.0000\n",
      "Epoch: 139, Training loss: 1.418142, Validation loss: 1.3982, lr: 0.0000\n",
      "Epoch: 140, Training loss: 1.390516, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 141, Training loss: 1.399168, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 142, Training loss: 1.379858, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 143, Training loss: 1.379564, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 144, Training loss: 1.377213, Validation loss: 1.3703, lr: 0.0000\n",
      "Epoch: 145, Training loss: 1.382333, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 146, Training loss: 1.370723, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 147, Training loss: 1.369370, Validation loss: 1.3925, lr: 0.0000\n",
      "Epoch: 148, Training loss: 1.382707, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 149, Training loss: 1.380565, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 150, Training loss: 1.373347, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 151, Training loss: 1.381096, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 152, Training loss: 1.393567, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 153, Training loss: 1.369833, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 154, Training loss: 1.397883, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 155, Training loss: 1.379491, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 156, Training loss: 1.417287, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 157, Training loss: 1.381660, Validation loss: 1.3877, lr: 0.0000\n",
      "Epoch: 158, Training loss: 1.387839, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 159, Training loss: 1.388622, Validation loss: 1.3803, lr: 0.0000\n",
      "Epoch: 160, Training loss: 1.400744, Validation loss: 1.4178, lr: 0.0000\n",
      "Epoch: 161, Training loss: 1.393442, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 162, Training loss: 1.380032, Validation loss: 1.3883, lr: 0.0000\n",
      "Epoch: 163, Training loss: 1.387683, Validation loss: 1.3880, lr: 0.0000\n",
      "Epoch: 164, Training loss: 1.396373, Validation loss: 1.3783, lr: 0.0000\n",
      "Epoch: 165, Training loss: 1.364776, Validation loss: 1.3714, lr: 0.0000\n",
      "Epoch: 166, Training loss: 1.383687, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 167, Training loss: 1.392982, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 168, Training loss: 1.402583, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 169, Training loss: 1.387136, Validation loss: 1.3960, lr: 0.0000\n",
      "Epoch: 170, Training loss: 1.399631, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 171, Training loss: 1.372525, Validation loss: 1.3706, lr: 0.0000\n",
      "Epoch: 172, Training loss: 1.383783, Validation loss: 1.3873, lr: 0.0000\n",
      "Epoch: 173, Training loss: 1.388460, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 174, Training loss: 1.391985, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 175, Training loss: 1.375626, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 176, Training loss: 1.387723, Validation loss: 1.3772, lr: 0.0000\n",
      "Epoch: 177, Training loss: 1.379839, Validation loss: 1.3784, lr: 0.0000\n",
      "Epoch: 178, Training loss: 1.370837, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 179, Training loss: 1.386328, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 180, Training loss: 1.403294, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 181, Training loss: 1.382034, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 182, Training loss: 1.380811, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 183, Training loss: 1.422907, Validation loss: 1.3875, lr: 0.0000\n",
      "Epoch: 184, Training loss: 1.430246, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 185, Training loss: 1.374142, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 186, Training loss: 1.409339, Validation loss: 1.3803, lr: 0.0000\n",
      "Epoch: 187, Training loss: 1.415413, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 188, Training loss: 1.390409, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 189, Training loss: 1.384702, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 190, Training loss: 1.380569, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 191, Training loss: 1.374634, Validation loss: 1.3889, lr: 0.0000\n",
      "Epoch: 192, Training loss: 1.382272, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 193, Training loss: 1.381737, Validation loss: 1.3720, lr: 0.0000\n",
      "Epoch: 194, Training loss: 1.379676, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 195, Training loss: 1.366286, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 196, Training loss: 1.368195, Validation loss: 1.3879, lr: 0.0000\n",
      "Epoch: 197, Training loss: 1.395260, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 198, Training loss: 1.363928, Validation loss: 1.3871, lr: 0.0000\n",
      "Epoch: 199, Training loss: 1.397042, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 200, Training loss: 1.394649, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 201, Training loss: 1.386875, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 202, Training loss: 1.389188, Validation loss: 1.3800, lr: 0.0000\n",
      "Epoch: 203, Training loss: 1.407284, Validation loss: 1.3777, lr: 0.0000\n",
      "Epoch: 204, Training loss: 1.375268, Validation loss: 1.3928, lr: 0.0000\n",
      "Epoch: 205, Training loss: 1.370266, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 206, Training loss: 1.376183, Validation loss: 1.3794, lr: 0.0000\n",
      "Epoch: 207, Training loss: 1.395496, Validation loss: 1.3768, lr: 0.0000\n",
      "Epoch: 208, Training loss: 1.383235, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 209, Training loss: 1.376535, Validation loss: 1.3796, lr: 0.0000\n",
      "Epoch: 210, Training loss: 1.397976, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 211, Training loss: 1.387001, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 212, Training loss: 1.390865, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 213, Training loss: 1.376363, Validation loss: 1.3769, lr: 0.0000\n",
      "Epoch: 214, Training loss: 1.369317, Validation loss: 1.3883, lr: 0.0000\n",
      "Epoch: 215, Training loss: 1.381827, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 216, Training loss: 1.395623, Validation loss: 1.3787, lr: 0.0000\n",
      "Epoch: 217, Training loss: 1.391015, Validation loss: 1.3874, lr: 0.0000\n",
      "Epoch: 218, Training loss: 1.377379, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 219, Training loss: 1.382248, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 220, Training loss: 1.372174, Validation loss: 1.3896, lr: 0.0000\n",
      "Epoch: 221, Training loss: 1.391162, Validation loss: 1.3741, lr: 0.0000\n",
      "Epoch: 222, Training loss: 1.369169, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 223, Training loss: 1.375751, Validation loss: 1.3794, lr: 0.0000\n",
      "Epoch: 224, Training loss: 1.382622, Validation loss: 1.3809, lr: 0.0000\n",
      "Epoch: 225, Training loss: 1.374304, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 226, Training loss: 1.385238, Validation loss: 1.3898, lr: 0.0000\n",
      "Epoch: 227, Training loss: 1.400043, Validation loss: 1.3764, lr: 0.0000\n",
      "Epoch: 228, Training loss: 1.386605, Validation loss: 1.3752, lr: 0.0000\n",
      "Epoch: 229, Training loss: 1.379000, Validation loss: 1.3697, lr: 0.0000\n",
      "Epoch: 230, Training loss: 1.395210, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 231, Training loss: 1.384580, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 232, Training loss: 1.371119, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 233, Training loss: 1.393760, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 234, Training loss: 1.377102, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 235, Training loss: 1.374987, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 236, Training loss: 1.384732, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 237, Training loss: 1.371194, Validation loss: 1.3952, lr: 0.0000\n",
      "Epoch: 238, Training loss: 1.377906, Validation loss: 1.3897, lr: 0.0000\n",
      "Epoch: 239, Training loss: 1.380090, Validation loss: 1.3973, lr: 0.0000\n",
      "Epoch: 240, Training loss: 1.432027, Validation loss: 1.3726, lr: 0.0000\n",
      "Epoch: 241, Training loss: 1.382055, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 242, Training loss: 1.369562, Validation loss: 1.3952, lr: 0.0000\n",
      "Epoch: 243, Training loss: 1.440811, Validation loss: 1.3800, lr: 0.0000\n",
      "Epoch: 244, Training loss: 1.371262, Validation loss: 1.3628, lr: 0.0000\n",
      "Epoch: 245, Training loss: 1.366882, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 246, Training loss: 1.382420, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 247, Training loss: 1.379036, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 248, Training loss: 1.361658, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 249, Training loss: 1.375815, Validation loss: 1.3882, lr: 0.0000\n",
      "Epoch: 250, Training loss: 1.391425, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 251, Training loss: 1.375414, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 252, Training loss: 1.385010, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 253, Training loss: 1.379488, Validation loss: 1.3791, lr: 0.0000\n",
      "Epoch: 254, Training loss: 1.370351, Validation loss: 1.3784, lr: 0.0000\n",
      "Epoch: 255, Training loss: 1.376974, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 256, Training loss: 1.365092, Validation loss: 1.3753, lr: 0.0000\n",
      "Epoch: 257, Training loss: 1.371646, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 258, Training loss: 1.385985, Validation loss: 1.3785, lr: 0.0000\n",
      "Epoch: 259, Training loss: 1.372450, Validation loss: 1.3901, lr: 0.0000\n",
      "Epoch: 260, Training loss: 1.372546, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 261, Training loss: 1.388934, Validation loss: 1.3875, lr: 0.0000\n",
      "Epoch: 262, Training loss: 1.388439, Validation loss: 1.3745, lr: 0.0000\n",
      "Epoch: 263, Training loss: 1.373759, Validation loss: 1.3940, lr: 0.0000\n",
      "Epoch: 264, Training loss: 1.380507, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 265, Training loss: 1.373297, Validation loss: 1.3890, lr: 0.0000\n",
      "Epoch: 266, Training loss: 1.367741, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 267, Training loss: 1.384514, Validation loss: 1.3792, lr: 0.0000\n",
      "Epoch: 268, Training loss: 1.371496, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 269, Training loss: 1.386368, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 270, Training loss: 1.387304, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 271, Training loss: 1.404857, Validation loss: 1.3638, lr: 0.0000\n",
      "Epoch: 272, Training loss: 1.370901, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 273, Training loss: 1.393431, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 274, Training loss: 1.389295, Validation loss: 1.3772, lr: 0.0000\n",
      "Epoch: 275, Training loss: 1.371848, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 276, Training loss: 1.375321, Validation loss: 1.3876, lr: 0.0000\n",
      "Epoch: 277, Training loss: 1.388878, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 278, Training loss: 1.377413, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 279, Training loss: 1.383919, Validation loss: 1.3674, lr: 0.0000\n",
      "Epoch: 280, Training loss: 1.374123, Validation loss: 1.3715, lr: 0.0000\n",
      "Epoch: 281, Training loss: 1.370047, Validation loss: 1.3701, lr: 0.0000\n",
      "Epoch: 282, Training loss: 1.384208, Validation loss: 1.3777, lr: 0.0000\n",
      "Epoch: 283, Training loss: 1.396121, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 284, Training loss: 1.384911, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 285, Training loss: 1.422430, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 286, Training loss: 1.394424, Validation loss: 1.3888, lr: 0.0000\n",
      "Epoch: 287, Training loss: 1.371405, Validation loss: 1.3792, lr: 0.0000\n",
      "Epoch: 288, Training loss: 1.381921, Validation loss: 1.3872, lr: 0.0000\n",
      "Epoch: 289, Training loss: 1.393661, Validation loss: 1.3694, lr: 0.0000\n",
      "Epoch: 290, Training loss: 1.382960, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 291, Training loss: 1.375150, Validation loss: 1.3753, lr: 0.0000\n",
      "Epoch: 292, Training loss: 1.381240, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 293, Training loss: 1.378420, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 294, Training loss: 1.372715, Validation loss: 1.3788, lr: 0.0000\n",
      "Epoch: 295, Training loss: 1.422600, Validation loss: 1.3704, lr: 0.0000\n",
      "Epoch: 296, Training loss: 1.367223, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 297, Training loss: 1.383695, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 298, Training loss: 1.374209, Validation loss: 1.3790, lr: 0.0000\n",
      "Epoch: 299, Training loss: 1.377961, Validation loss: 1.3789, lr: 0.0000\n",
      "Epoch: 300, Training loss: 1.388217, Validation loss: 1.3759, lr: 0.0000\n",
      "Epoch: 301, Training loss: 1.376169, Validation loss: 1.3877, lr: 0.0000\n",
      "Epoch: 302, Training loss: 1.381027, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 303, Training loss: 1.391689, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 304, Training loss: 1.436675, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 305, Training loss: 1.367518, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 306, Training loss: 1.373667, Validation loss: 1.3681, lr: 0.0000\n",
      "Epoch: 307, Training loss: 1.378127, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 308, Training loss: 1.370154, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 309, Training loss: 1.370950, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 310, Training loss: 1.381735, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 311, Training loss: 1.380029, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 312, Training loss: 1.382066, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 313, Training loss: 1.373131, Validation loss: 1.3877, lr: 0.0000\n",
      "Epoch: 314, Training loss: 1.394062, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 315, Training loss: 1.376745, Validation loss: 1.3894, lr: 0.0000\n",
      "Epoch: 316, Training loss: 1.380975, Validation loss: 1.3880, lr: 0.0000\n",
      "Epoch: 317, Training loss: 1.371671, Validation loss: 1.4408, lr: 0.0000\n",
      "Epoch: 318, Training loss: 1.381523, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 319, Training loss: 1.378225, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 320, Training loss: 1.378419, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 321, Training loss: 1.377829, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 322, Training loss: 1.380533, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 323, Training loss: 1.412701, Validation loss: 1.3779, lr: 0.0000\n",
      "Epoch: 324, Training loss: 1.380115, Validation loss: 1.3750, lr: 0.0000\n",
      "Epoch: 325, Training loss: 1.375509, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 326, Training loss: 1.367967, Validation loss: 1.3703, lr: 0.0000\n",
      "Epoch: 327, Training loss: 1.374787, Validation loss: 1.3891, lr: 0.0000\n",
      "Epoch: 328, Training loss: 1.396624, Validation loss: 1.3725, lr: 0.0000\n",
      "Epoch: 329, Training loss: 1.384622, Validation loss: 1.3900, lr: 0.0000\n",
      "Epoch: 330, Training loss: 1.387072, Validation loss: 1.3882, lr: 0.0000\n",
      "Epoch: 331, Training loss: 1.376334, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 332, Training loss: 1.392053, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 333, Training loss: 1.411375, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 334, Training loss: 1.384676, Validation loss: 1.3876, lr: 0.0000\n",
      "Epoch: 335, Training loss: 1.374638, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 336, Training loss: 1.410689, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 337, Training loss: 1.382619, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 338, Training loss: 1.363358, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 339, Training loss: 1.384450, Validation loss: 1.3730, lr: 0.0000\n",
      "Epoch: 340, Training loss: 1.370536, Validation loss: 1.3764, lr: 0.0000\n",
      "Epoch: 341, Training loss: 1.372496, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 342, Training loss: 1.379682, Validation loss: 1.3878, lr: 0.0000\n",
      "Epoch: 343, Training loss: 1.386424, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 344, Training loss: 1.371563, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 345, Training loss: 1.366619, Validation loss: 1.3787, lr: 0.0000\n",
      "Epoch: 346, Training loss: 1.378637, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 347, Training loss: 1.371498, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 348, Training loss: 1.377745, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 349, Training loss: 1.378494, Validation loss: 1.3896, lr: 0.0000\n",
      "Epoch: 350, Training loss: 1.394073, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 351, Training loss: 1.394429, Validation loss: 1.3883, lr: 0.0000\n",
      "Epoch: 352, Training loss: 1.398369, Validation loss: 1.3731, lr: 0.0000\n",
      "Epoch: 353, Training loss: 1.396072, Validation loss: 1.3753, lr: 0.0000\n",
      "Epoch: 354, Training loss: 1.376004, Validation loss: 1.3897, lr: 0.0000\n",
      "Epoch: 355, Training loss: 1.378657, Validation loss: 1.3903, lr: 0.0000\n",
      "Epoch: 356, Training loss: 1.379133, Validation loss: 1.3872, lr: 0.0000\n",
      "Epoch: 357, Training loss: 1.384493, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 358, Training loss: 1.385106, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 359, Training loss: 1.390590, Validation loss: 1.3995, lr: 0.0000\n",
      "Epoch: 360, Training loss: 1.370270, Validation loss: 1.3688, lr: 0.0000\n",
      "Epoch: 361, Training loss: 1.402598, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 362, Training loss: 1.367728, Validation loss: 1.3915, lr: 0.0000\n",
      "Epoch: 363, Training loss: 1.384343, Validation loss: 1.3899, lr: 0.0000\n",
      "Epoch: 364, Training loss: 1.375044, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 365, Training loss: 1.388406, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 366, Training loss: 1.389183, Validation loss: 1.3787, lr: 0.0000\n",
      "Epoch: 367, Training loss: 1.384109, Validation loss: 1.3790, lr: 0.0000\n",
      "Epoch: 368, Training loss: 1.391316, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 369, Training loss: 1.381707, Validation loss: 1.3908, lr: 0.0000\n",
      "Epoch: 370, Training loss: 1.374937, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 371, Training loss: 1.371739, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 372, Training loss: 1.379039, Validation loss: 1.3788, lr: 0.0000\n",
      "Epoch: 373, Training loss: 1.400832, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 374, Training loss: 1.380468, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 375, Training loss: 1.410424, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 376, Training loss: 1.389807, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 377, Training loss: 1.382452, Validation loss: 1.3878, lr: 0.0000\n",
      "Epoch: 378, Training loss: 1.383691, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 379, Training loss: 1.379271, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 380, Training loss: 1.374215, Validation loss: 1.3788, lr: 0.0000\n",
      "Epoch: 381, Training loss: 1.405576, Validation loss: 1.3796, lr: 0.0000\n",
      "Epoch: 382, Training loss: 1.385275, Validation loss: 1.3935, lr: 0.0000\n",
      "Epoch: 383, Training loss: 1.383840, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 384, Training loss: 1.409584, Validation loss: 1.3891, lr: 0.0000\n",
      "Epoch: 385, Training loss: 1.370592, Validation loss: 1.3832, lr: 0.0000\n",
      " *och: 386, Training loss: 1.375646, Validation loss: 1.3503, lr: 0.0000\n",
      "Epoch: 387, Training loss: 1.383746, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 388, Training loss: 1.387795, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 389, Training loss: 1.369847, Validation loss: 1.3793, lr: 0.0000\n",
      "Epoch: 390, Training loss: 1.381350, Validation loss: 1.3887, lr: 0.0000\n",
      "Epoch: 391, Training loss: 1.405672, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 392, Training loss: 1.375615, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 393, Training loss: 1.399223, Validation loss: 1.3710, lr: 0.0000\n",
      "Epoch: 394, Training loss: 1.372132, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 395, Training loss: 1.375668, Validation loss: 1.3871, lr: 0.0000\n",
      "Epoch: 396, Training loss: 1.368431, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 397, Training loss: 1.370973, Validation loss: 1.4257, lr: 0.0000\n",
      "Epoch: 398, Training loss: 1.380267, Validation loss: 1.3782, lr: 0.0000\n",
      "Epoch: 399, Training loss: 1.377979, Validation loss: 1.3761, lr: 0.0000\n",
      "Epoch: 400, Training loss: 1.379880, Validation loss: 1.3873, lr: 0.0000\n",
      "Epoch: 401, Training loss: 1.390599, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 402, Training loss: 1.394088, Validation loss: 1.3900, lr: 0.0000\n",
      "Epoch: 403, Training loss: 1.383699, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 404, Training loss: 1.373544, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 405, Training loss: 1.378192, Validation loss: 1.3840, lr: 0.0000\n",
      " *och: 406, Training loss: 1.378866, Validation loss: 1.3400, lr: 0.0000\n",
      "Epoch: 407, Training loss: 1.384798, Validation loss: 1.3914, lr: 0.0000\n",
      "Epoch: 408, Training loss: 1.383723, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 409, Training loss: 1.371895, Validation loss: 1.3874, lr: 0.0000\n",
      "Epoch: 410, Training loss: 1.386445, Validation loss: 1.3908, lr: 0.0000\n",
      "Epoch: 411, Training loss: 1.408378, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 412, Training loss: 1.390357, Validation loss: 1.7472, lr: 0.0000\n",
      "Epoch: 413, Training loss: 1.373771, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 414, Training loss: 1.370903, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 415, Training loss: 1.366865, Validation loss: 1.3886, lr: 0.0000\n",
      "Epoch: 416, Training loss: 1.373019, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 417, Training loss: 1.383066, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 418, Training loss: 1.393577, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 419, Training loss: 1.394664, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 420, Training loss: 1.425272, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 421, Training loss: 1.375119, Validation loss: 1.3802, lr: 0.0000\n",
      "Epoch: 422, Training loss: 1.372256, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 423, Training loss: 1.363049, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 424, Training loss: 1.387938, Validation loss: 1.3872, lr: 0.0000\n",
      "Epoch: 425, Training loss: 1.370841, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 426, Training loss: 1.382799, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 427, Training loss: 1.385645, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 428, Training loss: 1.377917, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 429, Training loss: 1.375652, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 430, Training loss: 1.382031, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 431, Training loss: 1.378166, Validation loss: 1.3888, lr: 0.0000\n",
      "Epoch: 432, Training loss: 1.373690, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 433, Training loss: 1.374728, Validation loss: 1.3788, lr: 0.0000\n",
      "Epoch: 434, Training loss: 1.428544, Validation loss: 1.3775, lr: 0.0000\n",
      "Epoch: 435, Training loss: 1.392491, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 436, Training loss: 1.415108, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 437, Training loss: 1.371516, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 438, Training loss: 1.371218, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 439, Training loss: 1.374713, Validation loss: 1.3783, lr: 0.0000\n",
      "Epoch: 440, Training loss: 1.374323, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 441, Training loss: 1.385397, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 442, Training loss: 1.380220, Validation loss: 1.3791, lr: 0.0000\n",
      "Epoch: 443, Training loss: 1.375991, Validation loss: 1.3900, lr: 0.0000\n",
      "Epoch: 444, Training loss: 1.384804, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 445, Training loss: 1.381560, Validation loss: 1.3920, lr: 0.0000\n",
      "Epoch: 446, Training loss: 1.376159, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 447, Training loss: 1.382421, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 448, Training loss: 1.379252, Validation loss: 1.3879, lr: 0.0000\n",
      "Epoch: 449, Training loss: 1.388162, Validation loss: 1.3948, lr: 0.0000\n",
      "Epoch: 450, Training loss: 1.393618, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 451, Training loss: 1.378119, Validation loss: 1.3882, lr: 0.0000\n",
      "Epoch: 452, Training loss: 1.387553, Validation loss: 1.3797, lr: 0.0000\n",
      "Epoch: 453, Training loss: 1.370859, Validation loss: 1.3874, lr: 0.0000\n",
      "Epoch: 454, Training loss: 1.390686, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 455, Training loss: 1.372775, Validation loss: 1.3934, lr: 0.0000\n",
      "Epoch: 456, Training loss: 1.387859, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 457, Training loss: 1.382921, Validation loss: 1.3788, lr: 0.0000\n",
      "Epoch: 458, Training loss: 1.371577, Validation loss: 1.3771, lr: 0.0000\n",
      "Epoch: 459, Training loss: 1.367692, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 460, Training loss: 1.416374, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 461, Training loss: 1.388783, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 462, Training loss: 1.400379, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 463, Training loss: 1.385305, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 464, Training loss: 1.372362, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 465, Training loss: 1.478319, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 466, Training loss: 1.371611, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 467, Training loss: 1.384440, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 468, Training loss: 1.373500, Validation loss: 1.3872, lr: 0.0000\n",
      "Epoch: 469, Training loss: 1.383143, Validation loss: 1.3588, lr: 0.0000\n",
      "Epoch: 470, Training loss: 1.392372, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 471, Training loss: 1.396424, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 472, Training loss: 1.368339, Validation loss: 1.3873, lr: 0.0000\n",
      "Epoch: 473, Training loss: 1.380090, Validation loss: 1.3731, lr: 0.0000\n",
      "Epoch: 474, Training loss: 1.372671, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 475, Training loss: 1.382068, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 476, Training loss: 1.377429, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 477, Training loss: 1.376029, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 478, Training loss: 1.370299, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 479, Training loss: 1.372829, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 480, Training loss: 1.367530, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 481, Training loss: 1.379009, Validation loss: 2.5988, lr: 0.0000\n",
      "Epoch: 482, Training loss: 1.372979, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 483, Training loss: 1.389017, Validation loss: 1.3905, lr: 0.0000\n",
      "Epoch: 484, Training loss: 1.374035, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 485, Training loss: 1.384960, Validation loss: 1.3756, lr: 0.0000\n",
      "Epoch: 486, Training loss: 1.393474, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 487, Training loss: 1.368721, Validation loss: 1.3645, lr: 0.0000\n",
      "Epoch: 488, Training loss: 1.376389, Validation loss: 1.3787, lr: 0.0000\n",
      "Epoch: 489, Training loss: 1.383465, Validation loss: 1.3773, lr: 0.0000\n",
      "Epoch: 490, Training loss: 1.394510, Validation loss: 1.3793, lr: 0.0000\n",
      "Epoch: 491, Training loss: 1.381128, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 492, Training loss: 1.378820, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 493, Training loss: 1.375116, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 494, Training loss: 1.387653, Validation loss: 1.3798, lr: 0.0000\n",
      "Epoch: 495, Training loss: 1.449097, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 496, Training loss: 1.368940, Validation loss: 1.3736, lr: 0.0000\n",
      "Epoch: 497, Training loss: 1.374707, Validation loss: 1.3886, lr: 0.0000\n",
      "Epoch: 498, Training loss: 1.367463, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 499, Training loss: 1.380583, Validation loss: 1.3755, lr: 0.0000\n",
      "Epoch: 500, Training loss: 1.390920, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 501, Training loss: 1.380524, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 502, Training loss: 1.384808, Validation loss: 1.3780, lr: 0.0000\n",
      "Epoch: 503, Training loss: 1.376220, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 504, Training loss: 1.378380, Validation loss: 1.3756, lr: 0.0000\n",
      "Epoch: 505, Training loss: 1.376145, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 506, Training loss: 1.374424, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 507, Training loss: 1.377916, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 508, Training loss: 1.395588, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 509, Training loss: 1.394129, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 510, Training loss: 1.380118, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 511, Training loss: 1.410108, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 512, Training loss: 1.373880, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 513, Training loss: 1.369740, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 514, Training loss: 1.386994, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 515, Training loss: 1.375264, Validation loss: 1.3611, lr: 0.0000\n",
      "Epoch: 516, Training loss: 1.374465, Validation loss: 1.3784, lr: 0.0000\n",
      "Epoch: 517, Training loss: 1.376030, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 518, Training loss: 1.373432, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 519, Training loss: 1.394976, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 520, Training loss: 1.396936, Validation loss: 1.3873, lr: 0.0000\n",
      "Epoch: 521, Training loss: 1.411271, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 522, Training loss: 1.376864, Validation loss: 1.3723, lr: 0.0000\n",
      "Epoch: 523, Training loss: 1.390067, Validation loss: 1.3772, lr: 0.0000\n",
      "Epoch: 524, Training loss: 1.379548, Validation loss: 1.3881, lr: 0.0000\n",
      "Epoch: 525, Training loss: 1.381320, Validation loss: 1.3898, lr: 0.0000\n",
      "Epoch: 526, Training loss: 1.377975, Validation loss: 1.3792, lr: 0.0000\n",
      "Epoch: 527, Training loss: 1.372678, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 528, Training loss: 1.394608, Validation loss: 1.3749, lr: 0.0000\n",
      "Epoch: 529, Training loss: 1.375637, Validation loss: 1.3872, lr: 0.0000\n",
      "Epoch: 530, Training loss: 1.391888, Validation loss: 1.3767, lr: 0.0000\n",
      "Epoch: 531, Training loss: 1.388484, Validation loss: 1.3756, lr: 0.0000\n",
      "Epoch: 532, Training loss: 1.386071, Validation loss: 1.3998, lr: 0.0000\n",
      "Epoch: 533, Training loss: 1.388193, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 534, Training loss: 1.388048, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 535, Training loss: 1.391470, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 536, Training loss: 1.375283, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 537, Training loss: 1.388111, Validation loss: 1.3891, lr: 0.0000\n",
      "Epoch: 538, Training loss: 1.383082, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 539, Training loss: 1.394559, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 540, Training loss: 1.382881, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 541, Training loss: 1.399306, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 542, Training loss: 1.394446, Validation loss: 1.3909, lr: 0.0000\n",
      "Epoch: 543, Training loss: 1.374542, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 544, Training loss: 1.374809, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 545, Training loss: 1.392531, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 546, Training loss: 1.379956, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 547, Training loss: 1.403903, Validation loss: 1.3758, lr: 0.0000\n",
      "Epoch: 548, Training loss: 1.373376, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 549, Training loss: 1.380051, Validation loss: 1.3798, lr: 0.0000\n",
      "Epoch: 550, Training loss: 1.387205, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 551, Training loss: 1.369413, Validation loss: 1.3800, lr: 0.0000\n",
      "Epoch: 552, Training loss: 1.369815, Validation loss: 1.3891, lr: 0.0000\n",
      "Epoch: 553, Training loss: 1.385175, Validation loss: 1.3714, lr: 0.0000\n",
      "Epoch: 554, Training loss: 1.394968, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 555, Training loss: 1.383520, Validation loss: 1.3896, lr: 0.0000\n",
      "Epoch: 556, Training loss: 1.404002, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 557, Training loss: 1.386052, Validation loss: 1.4064, lr: 0.0000\n",
      "Epoch: 558, Training loss: 1.388385, Validation loss: 1.3669, lr: 0.0000\n",
      "Epoch: 559, Training loss: 1.363478, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 560, Training loss: 1.392223, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 561, Training loss: 1.388888, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 562, Training loss: 1.431746, Validation loss: 1.3784, lr: 0.0000\n",
      "Epoch: 563, Training loss: 1.378699, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 564, Training loss: 1.368009, Validation loss: 1.3744, lr: 0.0000\n",
      "Epoch: 565, Training loss: 1.391249, Validation loss: 1.3761, lr: 0.0000\n",
      "Epoch: 566, Training loss: 1.391718, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 567, Training loss: 1.373503, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 568, Training loss: 1.426227, Validation loss: 1.3768, lr: 0.0000\n",
      "Epoch: 569, Training loss: 1.382765, Validation loss: 1.3732, lr: 0.0000\n",
      "Epoch: 570, Training loss: 1.376920, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 571, Training loss: 1.376710, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 572, Training loss: 1.378468, Validation loss: 1.3680, lr: 0.0000\n",
      "Epoch: 573, Training loss: 1.387264, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 574, Training loss: 1.390653, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 575, Training loss: 1.382471, Validation loss: 1.4147, lr: 0.0000\n",
      "Epoch: 576, Training loss: 1.381012, Validation loss: 1.3803, lr: 0.0000\n",
      "Epoch: 577, Training loss: 1.396225, Validation loss: 1.3876, lr: 0.0000\n",
      "Epoch: 578, Training loss: 1.390803, Validation loss: 1.3717, lr: 0.0000\n",
      "Epoch: 579, Training loss: 1.381546, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 580, Training loss: 1.387547, Validation loss: 1.3809, lr: 0.0000\n",
      "Epoch: 581, Training loss: 1.378984, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 582, Training loss: 1.383583, Validation loss: 1.3781, lr: 0.0000\n",
      "Epoch: 583, Training loss: 1.378896, Validation loss: 1.3883, lr: 0.0000\n",
      "Epoch: 584, Training loss: 1.380624, Validation loss: 1.3872, lr: 0.0000\n",
      "Epoch: 585, Training loss: 1.381315, Validation loss: 1.3802, lr: 0.0000\n",
      "Epoch: 586, Training loss: 1.374580, Validation loss: 1.3890, lr: 0.0000\n",
      "Epoch: 587, Training loss: 1.380666, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 588, Training loss: 1.372164, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 589, Training loss: 1.384214, Validation loss: 1.3881, lr: 0.0000\n",
      "Epoch: 590, Training loss: 1.393578, Validation loss: 1.3607, lr: 0.0000\n",
      "Epoch: 591, Training loss: 1.409494, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 592, Training loss: 1.397339, Validation loss: 1.3672, lr: 0.0000\n",
      "Epoch: 593, Training loss: 1.386685, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 594, Training loss: 1.393894, Validation loss: 1.3809, lr: 0.0000\n",
      "Epoch: 595, Training loss: 1.386872, Validation loss: 1.3887, lr: 0.0000\n",
      "Epoch: 596, Training loss: 1.385422, Validation loss: 1.3736, lr: 0.0000\n",
      "Epoch: 597, Training loss: 1.371098, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 598, Training loss: 1.494724, Validation loss: 1.3729, lr: 0.0000\n",
      "Epoch: 599, Training loss: 1.379920, Validation loss: 1.3924, lr: 0.0000\n",
      "Epoch: 600, Training loss: 1.404944, Validation loss: 1.3927, lr: 0.0000\n",
      "Epoch: 601, Training loss: 1.412210, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 602, Training loss: 1.382278, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 603, Training loss: 1.396424, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 604, Training loss: 1.378516, Validation loss: 1.4033, lr: 0.0000\n",
      "Epoch: 605, Training loss: 1.381193, Validation loss: 1.3782, lr: 0.0000\n",
      "Epoch: 606, Training loss: 1.373701, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 607, Training loss: 1.387162, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 608, Training loss: 1.391344, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 609, Training loss: 1.382253, Validation loss: 1.3772, lr: 0.0000\n",
      "Epoch: 610, Training loss: 1.372208, Validation loss: 1.3935, lr: 0.0000\n",
      "Epoch: 611, Training loss: 1.391412, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 612, Training loss: 1.391221, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 613, Training loss: 1.381926, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 614, Training loss: 1.381480, Validation loss: 1.3921, lr: 0.0000\n",
      "Epoch: 615, Training loss: 1.383301, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 616, Training loss: 1.385158, Validation loss: 1.3755, lr: 0.0000\n",
      "Epoch: 617, Training loss: 1.388250, Validation loss: 1.3664, lr: 0.0000\n",
      "Epoch: 618, Training loss: 1.386491, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 619, Training loss: 1.432446, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 620, Training loss: 1.420791, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 621, Training loss: 1.376147, Validation loss: 1.3875, lr: 0.0000\n",
      "Epoch: 622, Training loss: 1.379095, Validation loss: 1.3873, lr: 0.0000\n",
      "Epoch: 623, Training loss: 1.391327, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 624, Training loss: 1.400632, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 625, Training loss: 1.363522, Validation loss: 1.3767, lr: 0.0000\n",
      "Epoch: 626, Training loss: 1.379639, Validation loss: 1.3693, lr: 0.0000\n",
      "Epoch: 627, Training loss: 1.382553, Validation loss: 1.3911, lr: 0.0000\n",
      "Epoch: 628, Training loss: 1.377454, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 629, Training loss: 1.390098, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 630, Training loss: 1.387758, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 631, Training loss: 1.391097, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 632, Training loss: 1.364076, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 633, Training loss: 1.371179, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 634, Training loss: 1.374627, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 635, Training loss: 1.358318, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 636, Training loss: 1.386640, Validation loss: 1.3664, lr: 0.0000\n",
      "Epoch: 637, Training loss: 1.384880, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 638, Training loss: 1.384110, Validation loss: 1.3767, lr: 0.0000\n",
      "Epoch: 639, Training loss: 1.388590, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 640, Training loss: 1.380042, Validation loss: 1.3718, lr: 0.0000\n",
      "Epoch: 641, Training loss: 1.384112, Validation loss: 1.3781, lr: 0.0000\n",
      "Epoch: 642, Training loss: 1.391714, Validation loss: 1.3670, lr: 0.0000\n",
      "Epoch: 643, Training loss: 1.373488, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 644, Training loss: 1.374433, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 645, Training loss: 1.381596, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 646, Training loss: 1.378623, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 647, Training loss: 1.378265, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 648, Training loss: 1.374165, Validation loss: 1.3662, lr: 0.0000\n",
      "Epoch: 649, Training loss: 1.390995, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 650, Training loss: 1.382256, Validation loss: 1.3875, lr: 0.0000\n",
      "Epoch: 651, Training loss: 1.365892, Validation loss: 1.3873, lr: 0.0000\n",
      "Epoch: 652, Training loss: 1.377234, Validation loss: 1.3898, lr: 0.0000\n",
      "Epoch: 653, Training loss: 1.387116, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 654, Training loss: 1.383563, Validation loss: 1.3900, lr: 0.0000\n",
      "Epoch: 655, Training loss: 1.398545, Validation loss: 1.3793, lr: 0.0000\n",
      "Epoch: 656, Training loss: 1.374902, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 657, Training loss: 1.362151, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 658, Training loss: 1.379998, Validation loss: 1.3795, lr: 0.0000\n",
      "Epoch: 659, Training loss: 1.391858, Validation loss: 1.3785, lr: 0.0000\n",
      "Epoch: 660, Training loss: 1.396202, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 661, Training loss: 1.383270, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 662, Training loss: 1.394902, Validation loss: 1.3884, lr: 0.0000\n",
      "Epoch: 663, Training loss: 1.391436, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 664, Training loss: 1.382708, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 665, Training loss: 1.385444, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 666, Training loss: 1.391452, Validation loss: 1.3750, lr: 0.0000\n",
      "Epoch: 667, Training loss: 1.368776, Validation loss: 1.4181, lr: 0.0000\n",
      "Epoch: 668, Training loss: 1.373443, Validation loss: 1.3901, lr: 0.0000\n",
      "Epoch: 669, Training loss: 1.390209, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 670, Training loss: 1.385315, Validation loss: 1.3875, lr: 0.0000\n",
      "Epoch: 671, Training loss: 1.382357, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 672, Training loss: 1.371734, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 673, Training loss: 1.368199, Validation loss: 1.3780, lr: 0.0000\n",
      "Epoch: 674, Training loss: 1.370692, Validation loss: 1.3780, lr: 0.0000\n",
      "Epoch: 675, Training loss: 1.378067, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 676, Training loss: 1.386954, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 677, Training loss: 1.377385, Validation loss: 1.3792, lr: 0.0000\n",
      "Epoch: 678, Training loss: 1.369084, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 679, Training loss: 1.376382, Validation loss: 1.3779, lr: 0.0000\n",
      "Epoch: 680, Training loss: 1.379249, Validation loss: 1.3883, lr: 0.0000\n",
      "Epoch: 681, Training loss: 1.384871, Validation loss: 1.3893, lr: 0.0000\n",
      "Epoch: 682, Training loss: 1.374261, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 683, Training loss: 1.373802, Validation loss: 1.3799, lr: 0.0000\n",
      "Epoch: 684, Training loss: 1.385845, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 685, Training loss: 1.392725, Validation loss: 1.3746, lr: 0.0000\n",
      "Epoch: 686, Training loss: 1.378077, Validation loss: 1.3772, lr: 0.0000\n",
      "Epoch: 687, Training loss: 1.386490, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 688, Training loss: 1.378179, Validation loss: 1.3872, lr: 0.0000\n",
      "Epoch: 689, Training loss: 1.398695, Validation loss: 1.3878, lr: 0.0000\n",
      "Epoch: 690, Training loss: 1.394852, Validation loss: 1.3902, lr: 0.0000\n",
      "Epoch: 691, Training loss: 1.386840, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 692, Training loss: 1.410749, Validation loss: 1.3778, lr: 0.0000\n",
      "Epoch: 693, Training loss: 1.387582, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 694, Training loss: 1.386835, Validation loss: 1.3651, lr: 0.0000\n",
      "Epoch: 695, Training loss: 1.378739, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 696, Training loss: 1.383567, Validation loss: 1.3873, lr: 0.0000\n",
      "Epoch: 697, Training loss: 1.382324, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 698, Training loss: 1.381311, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 699, Training loss: 1.368436, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 700, Training loss: 1.375104, Validation loss: 1.3774, lr: 0.0000\n",
      "Epoch: 701, Training loss: 1.394166, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 702, Training loss: 1.422773, Validation loss: 1.3788, lr: 0.0000\n",
      "Epoch: 703, Training loss: 1.393856, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 704, Training loss: 1.384436, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 705, Training loss: 1.402605, Validation loss: 1.3890, lr: 0.0000\n",
      "Epoch: 706, Training loss: 1.373865, Validation loss: 1.3763, lr: 0.0000\n",
      "Epoch: 707, Training loss: 1.395436, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 708, Training loss: 1.486552, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 709, Training loss: 1.381543, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 710, Training loss: 1.397251, Validation loss: 1.3740, lr: 0.0000\n",
      "Epoch: 711, Training loss: 1.371016, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 712, Training loss: 1.381971, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 713, Training loss: 1.382391, Validation loss: 1.3876, lr: 0.0000\n",
      "Epoch: 714, Training loss: 1.380753, Validation loss: 1.3764, lr: 0.0000\n",
      "Epoch: 715, Training loss: 1.374088, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 716, Training loss: 1.363714, Validation loss: 1.3752, lr: 0.0000\n",
      "Epoch: 717, Training loss: 1.384445, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 718, Training loss: 1.388331, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 719, Training loss: 1.386692, Validation loss: 1.3905, lr: 0.0000\n",
      "Epoch: 720, Training loss: 1.381772, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 721, Training loss: 1.409255, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 722, Training loss: 1.385207, Validation loss: 1.3802, lr: 0.0000\n",
      "Epoch: 723, Training loss: 1.396302, Validation loss: 1.3880, lr: 0.0000\n",
      "Epoch: 724, Training loss: 1.373638, Validation loss: 1.3702, lr: 0.0000\n",
      "Epoch: 725, Training loss: 1.395947, Validation loss: 1.3753, lr: 0.0000\n",
      "Epoch: 726, Training loss: 1.390640, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 727, Training loss: 1.418202, Validation loss: 1.3780, lr: 0.0000\n",
      "Epoch: 728, Training loss: 1.369881, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 729, Training loss: 1.375288, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 730, Training loss: 1.382924, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 731, Training loss: 1.369897, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 732, Training loss: 1.375089, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 733, Training loss: 1.379787, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 734, Training loss: 1.386953, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 735, Training loss: 1.367500, Validation loss: 1.3788, lr: 0.0000\n",
      "Epoch: 736, Training loss: 1.363551, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 737, Training loss: 1.384822, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 738, Training loss: 1.371981, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 739, Training loss: 1.379768, Validation loss: 1.3779, lr: 0.0000\n",
      "Epoch: 740, Training loss: 1.387331, Validation loss: 1.3719, lr: 0.0000\n",
      "Epoch: 741, Training loss: 1.432130, Validation loss: 1.3983, lr: 0.0000\n",
      "Epoch: 742, Training loss: 1.372817, Validation loss: 1.3994, lr: 0.0000\n",
      "Epoch: 743, Training loss: 1.377305, Validation loss: 1.3791, lr: 0.0000\n",
      "Epoch: 744, Training loss: 1.373031, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 745, Training loss: 1.383510, Validation loss: 1.3790, lr: 0.0000\n",
      "Epoch: 746, Training loss: 1.402691, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 747, Training loss: 1.408163, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 748, Training loss: 1.378504, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 749, Training loss: 1.391723, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 750, Training loss: 1.381926, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 751, Training loss: 1.413892, Validation loss: 1.3786, lr: 0.0000\n",
      "Epoch: 752, Training loss: 1.393088, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 753, Training loss: 1.378690, Validation loss: 1.3699, lr: 0.0000\n",
      "Epoch: 754, Training loss: 1.373143, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 755, Training loss: 1.385925, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 756, Training loss: 1.386789, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 757, Training loss: 1.387191, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 758, Training loss: 1.380606, Validation loss: 1.3736, lr: 0.0000\n",
      "Epoch: 759, Training loss: 1.370937, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 760, Training loss: 1.394723, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 761, Training loss: 1.380666, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 762, Training loss: 1.373007, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 763, Training loss: 1.403975, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 764, Training loss: 1.394691, Validation loss: 1.3792, lr: 0.0000\n",
      "Epoch: 765, Training loss: 1.387276, Validation loss: 1.3882, lr: 0.0000\n",
      "Epoch: 766, Training loss: 1.394518, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 767, Training loss: 1.383731, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 768, Training loss: 1.383709, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 769, Training loss: 1.390365, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 770, Training loss: 1.381440, Validation loss: 1.3705, lr: 0.0000\n",
      "Epoch: 771, Training loss: 1.391732, Validation loss: 1.3791, lr: 0.0000\n",
      "Epoch: 772, Training loss: 1.418941, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 773, Training loss: 1.366471, Validation loss: 1.3877, lr: 0.0000\n",
      "Epoch: 774, Training loss: 1.381629, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 775, Training loss: 1.370675, Validation loss: 1.3622, lr: 0.0000\n",
      "Epoch: 776, Training loss: 1.389673, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 777, Training loss: 1.377439, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 778, Training loss: 1.379000, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 779, Training loss: 1.375405, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 780, Training loss: 1.381722, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 781, Training loss: 1.369606, Validation loss: 1.3884, lr: 0.0000\n",
      "Epoch: 782, Training loss: 1.402885, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 783, Training loss: 1.383055, Validation loss: 1.3881, lr: 0.0000\n",
      "Epoch: 784, Training loss: 1.376787, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 785, Training loss: 1.370781, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 786, Training loss: 1.372487, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 787, Training loss: 1.397829, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 788, Training loss: 1.370301, Validation loss: 1.3897, lr: 0.0000\n",
      "Epoch: 789, Training loss: 1.387301, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 790, Training loss: 1.370408, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 791, Training loss: 1.396064, Validation loss: 1.3898, lr: 0.0000\n",
      "Epoch: 792, Training loss: 1.369442, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 793, Training loss: 1.372482, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 794, Training loss: 1.379398, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 795, Training loss: 1.385718, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 796, Training loss: 1.408988, Validation loss: 1.3581, lr: 0.0000\n",
      "Epoch: 797, Training loss: 1.395197, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 798, Training loss: 1.374348, Validation loss: 1.3775, lr: 0.0000\n",
      "Epoch: 799, Training loss: 1.388797, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 800, Training loss: 1.370397, Validation loss: 1.3741, lr: 0.0000\n",
      "Epoch: 801, Training loss: 1.376716, Validation loss: 1.3877, lr: 0.0000\n",
      "Epoch: 802, Training loss: 1.400820, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 803, Training loss: 1.381654, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 804, Training loss: 1.367994, Validation loss: 1.3778, lr: 0.0000\n",
      "Epoch: 805, Training loss: 1.386529, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 806, Training loss: 1.381907, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 807, Training loss: 1.385667, Validation loss: 1.3792, lr: 0.0000\n",
      "Epoch: 808, Training loss: 1.380115, Validation loss: 1.3877, lr: 0.0000\n",
      "Epoch: 809, Training loss: 1.400555, Validation loss: 1.3887, lr: 0.0000\n",
      "Epoch: 810, Training loss: 1.365186, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 811, Training loss: 1.381633, Validation loss: 1.3476, lr: 0.0000\n",
      "Epoch: 812, Training loss: 1.432466, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 813, Training loss: 1.377923, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 814, Training loss: 1.375912, Validation loss: 1.3741, lr: 0.0000\n",
      "Epoch: 815, Training loss: 1.398174, Validation loss: 1.3764, lr: 0.0000\n",
      "Epoch: 816, Training loss: 1.384507, Validation loss: 1.3750, lr: 0.0000\n",
      "Epoch: 817, Training loss: 1.379904, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 818, Training loss: 1.372902, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 819, Training loss: 1.390214, Validation loss: 1.3795, lr: 0.0000\n",
      "Epoch: 820, Training loss: 1.364457, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 821, Training loss: 1.375933, Validation loss: 1.3889, lr: 0.0000\n",
      "Epoch: 822, Training loss: 1.380871, Validation loss: 1.3885, lr: 0.0000\n",
      "Epoch: 823, Training loss: 1.365549, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 824, Training loss: 1.377265, Validation loss: 1.3809, lr: 0.0000\n",
      "Epoch: 825, Training loss: 1.376790, Validation loss: 1.3896, lr: 0.0000\n",
      "Epoch: 826, Training loss: 1.391000, Validation loss: 1.3727, lr: 0.0000\n",
      "Epoch: 827, Training loss: 1.380000, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 828, Training loss: 1.373362, Validation loss: 1.3791, lr: 0.0000\n",
      "Epoch: 829, Training loss: 1.371505, Validation loss: 1.3775, lr: 0.0000\n",
      "Epoch: 830, Training loss: 1.387868, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 831, Training loss: 1.389951, Validation loss: 1.3742, lr: 0.0000\n",
      "Epoch: 832, Training loss: 1.376197, Validation loss: 1.3652, lr: 0.0000\n",
      "Epoch: 833, Training loss: 1.359973, Validation loss: 1.3914, lr: 0.0000\n",
      "Epoch: 834, Training loss: 1.386121, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 835, Training loss: 1.390504, Validation loss: 1.3883, lr: 0.0000\n",
      "Epoch: 836, Training loss: 1.376372, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 837, Training loss: 1.378122, Validation loss: 1.3880, lr: 0.0000\n",
      "Epoch: 838, Training loss: 1.391679, Validation loss: 1.3779, lr: 0.0000\n",
      "Epoch: 839, Training loss: 1.379426, Validation loss: 1.3757, lr: 0.0000\n",
      "Epoch: 840, Training loss: 1.383223, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 841, Training loss: 1.381669, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 842, Training loss: 1.370829, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 843, Training loss: 1.389715, Validation loss: 1.3692, lr: 0.0000\n",
      "Epoch: 844, Training loss: 1.387077, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 845, Training loss: 1.396879, Validation loss: 1.3764, lr: 0.0000\n",
      "Epoch: 846, Training loss: 1.385586, Validation loss: 1.3655, lr: 0.0000\n",
      "Epoch: 847, Training loss: 1.368159, Validation loss: 1.3780, lr: 0.0000\n",
      "Epoch: 848, Training loss: 1.383083, Validation loss: 1.3891, lr: 0.0000\n",
      "Epoch: 849, Training loss: 1.385526, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 850, Training loss: 1.393869, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 851, Training loss: 1.377313, Validation loss: 1.3734, lr: 0.0000\n",
      "Epoch: 852, Training loss: 1.382112, Validation loss: 1.3797, lr: 0.0000\n",
      "Epoch: 853, Training loss: 1.376045, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 854, Training loss: 1.371893, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 855, Training loss: 1.378935, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 856, Training loss: 1.371623, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 857, Training loss: 1.392838, Validation loss: 1.3754, lr: 0.0000\n",
      "Epoch: 858, Training loss: 1.382182, Validation loss: 1.3606, lr: 0.0000\n",
      "Epoch: 859, Training loss: 1.377205, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 860, Training loss: 1.380090, Validation loss: 1.3803, lr: 0.0000\n",
      "Epoch: 861, Training loss: 1.380217, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 862, Training loss: 1.380777, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 863, Training loss: 1.377484, Validation loss: 1.3885, lr: 0.0000\n",
      "Epoch: 864, Training loss: 1.384098, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 865, Training loss: 1.372958, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 866, Training loss: 1.372960, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 867, Training loss: 1.405440, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 868, Training loss: 1.402491, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 869, Training loss: 1.378624, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 870, Training loss: 1.371023, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 871, Training loss: 1.378507, Validation loss: 1.3769, lr: 0.0000\n",
      "Epoch: 872, Training loss: 1.376835, Validation loss: 1.3727, lr: 0.0000\n",
      "Epoch: 873, Training loss: 1.407430, Validation loss: 1.3878, lr: 0.0000\n",
      "Epoch: 874, Training loss: 1.375875, Validation loss: 1.3745, lr: 0.0000\n",
      "Epoch: 875, Training loss: 1.371151, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 876, Training loss: 1.386159, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 877, Training loss: 1.379666, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 878, Training loss: 1.376530, Validation loss: 1.3792, lr: 0.0000\n",
      "Epoch: 879, Training loss: 1.379571, Validation loss: 1.3809, lr: 0.0000\n",
      "Epoch: 880, Training loss: 1.409229, Validation loss: 1.3883, lr: 0.0000\n",
      "Epoch: 881, Training loss: 1.415466, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 882, Training loss: 1.380187, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 883, Training loss: 1.374691, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 884, Training loss: 1.411775, Validation loss: 1.3409, lr: 0.0000\n",
      "Epoch: 885, Training loss: 1.377577, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 886, Training loss: 1.373644, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 887, Training loss: 1.390189, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 888, Training loss: 1.372293, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 889, Training loss: 1.387702, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 890, Training loss: 1.375798, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 891, Training loss: 1.374284, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 892, Training loss: 1.377690, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 893, Training loss: 1.395868, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 894, Training loss: 1.376357, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 895, Training loss: 1.417042, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 896, Training loss: 1.378689, Validation loss: 1.3616, lr: 0.0000\n",
      "Epoch: 897, Training loss: 1.376522, Validation loss: 1.3895, lr: 0.0000\n",
      "Epoch: 898, Training loss: 1.383955, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 899, Training loss: 1.369966, Validation loss: 1.3781, lr: 0.0000\n",
      "Epoch: 900, Training loss: 1.378072, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 901, Training loss: 1.370313, Validation loss: 1.3620, lr: 0.0000\n",
      "Epoch: 902, Training loss: 1.359920, Validation loss: 1.3877, lr: 0.0000\n",
      "Epoch: 903, Training loss: 1.380813, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 904, Training loss: 1.372843, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 905, Training loss: 1.395560, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 906, Training loss: 1.386382, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 907, Training loss: 1.372937, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 908, Training loss: 1.383233, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 909, Training loss: 1.390459, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 910, Training loss: 1.398384, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 911, Training loss: 1.375962, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 912, Training loss: 1.372720, Validation loss: 1.3890, lr: 0.0000\n",
      "Epoch: 913, Training loss: 1.384594, Validation loss: 1.3757, lr: 0.0000\n",
      "Epoch: 914, Training loss: 1.380995, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 915, Training loss: 1.379519, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 916, Training loss: 1.391697, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 917, Training loss: 1.373156, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 918, Training loss: 1.396073, Validation loss: 1.4110, lr: 0.0000\n",
      "Epoch: 919, Training loss: 1.384059, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 920, Training loss: 1.379214, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 921, Training loss: 1.389719, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 922, Training loss: 1.387935, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 923, Training loss: 1.370441, Validation loss: 1.3793, lr: 0.0000\n",
      "Epoch: 924, Training loss: 1.372365, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 925, Training loss: 1.395376, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 926, Training loss: 1.377728, Validation loss: 1.3888, lr: 0.0000\n",
      "Epoch: 927, Training loss: 1.380140, Validation loss: 1.3651, lr: 0.0000\n",
      "Epoch: 928, Training loss: 1.377572, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 929, Training loss: 1.396196, Validation loss: 1.3692, lr: 0.0000\n",
      "Epoch: 930, Training loss: 1.407637, Validation loss: 1.3753, lr: 0.0000\n",
      "Epoch: 931, Training loss: 1.393298, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 932, Training loss: 1.389533, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 933, Training loss: 1.385863, Validation loss: 1.3715, lr: 0.0000\n",
      "Epoch: 934, Training loss: 1.384954, Validation loss: 1.3780, lr: 0.0000\n",
      "Epoch: 935, Training loss: 1.384780, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 936, Training loss: 1.390670, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 937, Training loss: 1.380207, Validation loss: 1.3658, lr: 0.0000\n",
      "Epoch: 938, Training loss: 1.384485, Validation loss: 1.3759, lr: 0.0000\n",
      "Epoch: 939, Training loss: 1.381277, Validation loss: 1.3628, lr: 0.0000\n",
      "Epoch: 940, Training loss: 1.364958, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 941, Training loss: 1.384793, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 942, Training loss: 1.564482, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 943, Training loss: 1.377950, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 944, Training loss: 1.371378, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 945, Training loss: 1.375953, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 946, Training loss: 1.369937, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 947, Training loss: 1.379642, Validation loss: 1.3886, lr: 0.0000\n",
      "Epoch: 948, Training loss: 1.375209, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 949, Training loss: 1.391491, Validation loss: 1.3772, lr: 0.0000\n",
      "Epoch: 950, Training loss: 1.382288, Validation loss: 1.3799, lr: 0.0000\n",
      "Epoch: 951, Training loss: 1.364261, Validation loss: 1.3782, lr: 0.0000\n",
      "Epoch: 952, Training loss: 1.384838, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 953, Training loss: 1.392361, Validation loss: 1.3878, lr: 0.0000\n",
      "Epoch: 954, Training loss: 1.383580, Validation loss: 1.3784, lr: 0.0000\n",
      "Epoch: 955, Training loss: 1.379987, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 956, Training loss: 1.393321, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 957, Training loss: 1.386616, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 958, Training loss: 1.378168, Validation loss: 1.8485, lr: 0.0000\n",
      "Epoch: 959, Training loss: 1.377934, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 960, Training loss: 1.381020, Validation loss: 1.3679, lr: 0.0000\n",
      "Epoch: 961, Training loss: 1.383262, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 962, Training loss: 1.417070, Validation loss: 1.4041, lr: 0.0000\n",
      "Epoch: 963, Training loss: 1.383069, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 964, Training loss: 1.371249, Validation loss: 1.3891, lr: 0.0000\n",
      "Epoch: 965, Training loss: 1.374815, Validation loss: 1.3672, lr: 0.0000\n",
      "Epoch: 966, Training loss: 1.376368, Validation loss: 1.3898, lr: 0.0000\n",
      "Epoch: 967, Training loss: 1.382625, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 968, Training loss: 1.370501, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 969, Training loss: 1.372568, Validation loss: 1.3902, lr: 0.0000\n",
      "Epoch: 970, Training loss: 1.376063, Validation loss: 1.3803, lr: 0.0000\n",
      "Epoch: 971, Training loss: 1.371229, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 972, Training loss: 1.372823, Validation loss: 1.3988, lr: 0.0000\n",
      "Epoch: 973, Training loss: 1.379610, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 974, Training loss: 1.374281, Validation loss: 1.3779, lr: 0.0000\n",
      "Epoch: 975, Training loss: 1.385118, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 976, Training loss: 1.376044, Validation loss: 1.3779, lr: 0.0000\n",
      "Epoch: 977, Training loss: 1.389562, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 978, Training loss: 1.375113, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 979, Training loss: 1.375917, Validation loss: 1.3775, lr: 0.0000\n",
      "Epoch: 980, Training loss: 1.399950, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 981, Training loss: 1.393574, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 982, Training loss: 1.406572, Validation loss: 1.3683, lr: 0.0000\n",
      "Epoch: 983, Training loss: 1.375105, Validation loss: 1.3760, lr: 0.0000\n",
      "Epoch: 984, Training loss: 1.376823, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 985, Training loss: 1.379556, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 986, Training loss: 1.399771, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 987, Training loss: 1.390191, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 988, Training loss: 1.383602, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 989, Training loss: 1.387873, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 990, Training loss: 1.393638, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 991, Training loss: 1.381057, Validation loss: 1.3792, lr: 0.0000\n",
      "Epoch: 992, Training loss: 1.376971, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 993, Training loss: 1.367349, Validation loss: 1.3790, lr: 0.0000\n",
      "Epoch: 994, Training loss: 1.378092, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 995, Training loss: 1.390634, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 996, Training loss: 1.367338, Validation loss: 1.3904, lr: 0.0000\n",
      "Epoch: 997, Training loss: 1.388152, Validation loss: 1.3731, lr: 0.0000\n",
      "Epoch: 998, Training loss: 1.388310, Validation loss: 1.3750, lr: 0.0000\n",
      "Epoch: 999, Training loss: 1.374810, Validation loss: 1.3876, lr: 0.0000\n",
      "Final test loss: 1.3891\n",
      "=== Run 04/10 ===\n",
      "\n",
      "---- Settings: \n",
      "\n",
      "epochs : 1000\n",
      "hidden_channels : [32]\n",
      "out_channels : 10\n",
      "inner_product_features : False\n",
      "batch_size : 64\n",
      "lr : 0.01\n",
      "momentum : 0.9\n",
      "dropout : 0.0\n",
      "batch_norm : batch_norm\n",
      "bias : True\n",
      "order : 2\n",
      "diffusion : True\n",
      "frac_sampled_nb : -1\n",
      "include_positions : False\n",
      "include_self : True\n",
      "vec_norm : False\n",
      "emb_norm : False\n",
      "seed : 0\n",
      "dim_signal : 100\n",
      "dim_emb : 100\n",
      "n_sampled_nb : -1\n",
      "\n",
      "---- Number of features to pass to the MLP:  1010100\n",
      "---- Total number of parameters:  32323627\n",
      "\n",
      "Using device cuda:0\n",
      "\n",
      "---- Training network ...\n",
      "\n",
      "---- Timestamp: 20250613-231525\n",
      "\n",
      " *och: 0, Training loss: 1.426808, Validation loss: 1.5528, lr: 0.0100\n",
      " *och: 1, Training loss: 1.429582, Validation loss: 1.4141, lr: 0.0100\n",
      " *och: 2, Training loss: 1.408346, Validation loss: 1.3854, lr: 0.0100\n",
      " *och: 3, Training loss: 1.402874, Validation loss: 1.3841, lr: 0.0100\n",
      " *och: 4, Training loss: 1.389336, Validation loss: 1.3791, lr: 0.0100\n",
      " *och: 5, Training loss: 1.409529, Validation loss: 1.3754, lr: 0.0100\n",
      " *och: 6, Training loss: 1.377154, Validation loss: 1.3754, lr: 0.0100\n",
      "Epoch: 7, Training loss: 1.400966, Validation loss: 1.3921, lr: 0.0100\n",
      "Epoch: 8, Training loss: 1.386323, Validation loss: 1.3802, lr: 0.0100\n",
      "Epoch: 9, Training loss: 1.399471, Validation loss: 1.3832, lr: 0.0100\n",
      "Epoch: 10, Training loss: 1.391729, Validation loss: 1.3774, lr: 0.0100\n",
      " *och: 11, Training loss: 1.365383, Validation loss: 1.3702, lr: 0.0100\n",
      "Epoch: 12, Training loss: 1.364225, Validation loss: 1.3751, lr: 0.0100\n",
      "Epoch: 13, Training loss: 1.399256, Validation loss: 1.3887, lr: 0.0100\n",
      "Epoch: 14, Training loss: 1.388648, Validation loss: 1.4015, lr: 0.0100\n",
      "Epoch: 15, Training loss: 1.386607, Validation loss: 1.3815, lr: 0.0100\n",
      "Epoch: 16, Training loss: 1.389040, Validation loss: 1.3759, lr: 0.0100\n",
      " *och: 17, Training loss: 1.388516, Validation loss: 1.3536, lr: 0.0100\n",
      "Epoch: 18, Training loss: 1.388148, Validation loss: 1.3835, lr: 0.0100\n",
      "Epoch: 19, Training loss: 1.408321, Validation loss: 1.3691, lr: 0.0100\n",
      "Epoch: 20, Training loss: 1.394655, Validation loss: 1.3847, lr: 0.0100\n",
      "Epoch: 21, Training loss: 1.397201, Validation loss: 1.3784, lr: 0.0100\n",
      "Epoch: 22, Training loss: 1.381464, Validation loss: 1.4214, lr: 0.0100\n",
      "Epoch: 23, Training loss: 1.389038, Validation loss: 1.3800, lr: 0.0010\n",
      "Epoch: 24, Training loss: 1.386226, Validation loss: 1.3901, lr: 0.0010\n",
      "Epoch: 25, Training loss: 1.417029, Validation loss: 1.3896, lr: 0.0010\n",
      "Epoch: 26, Training loss: 1.377107, Validation loss: 1.4172, lr: 0.0010\n",
      "Epoch: 27, Training loss: 1.370901, Validation loss: 1.3733, lr: 0.0010\n",
      "Epoch: 28, Training loss: 1.379421, Validation loss: 1.3815, lr: 0.0010\n",
      "Epoch: 29, Training loss: 1.371034, Validation loss: 1.3688, lr: 0.0010\n",
      "Epoch: 30, Training loss: 1.372349, Validation loss: 1.3639, lr: 0.0010\n",
      "Epoch: 31, Training loss: 1.384115, Validation loss: 1.3843, lr: 0.0010\n",
      "Epoch: 32, Training loss: 1.386634, Validation loss: 1.3672, lr: 0.0010\n",
      "Epoch: 33, Training loss: 1.374838, Validation loss: 1.3864, lr: 0.0010\n",
      "Epoch: 34, Training loss: 1.380708, Validation loss: 1.4026, lr: 0.0001\n",
      "Epoch: 35, Training loss: 1.377623, Validation loss: 1.3900, lr: 0.0001\n",
      "Epoch: 36, Training loss: 1.386866, Validation loss: 1.3803, lr: 0.0001\n",
      "Epoch: 37, Training loss: 1.385201, Validation loss: 1.3921, lr: 0.0001\n",
      "Epoch: 38, Training loss: 1.368396, Validation loss: 1.4027, lr: 0.0001\n",
      "Epoch: 39, Training loss: 1.379306, Validation loss: 1.3820, lr: 0.0001\n",
      "Epoch: 40, Training loss: 1.373812, Validation loss: 1.3725, lr: 0.0001\n",
      "Epoch: 41, Training loss: 1.379822, Validation loss: 1.3910, lr: 0.0001\n",
      "Epoch: 42, Training loss: 1.380214, Validation loss: 1.3888, lr: 0.0001\n",
      "Epoch: 43, Training loss: 1.379715, Validation loss: 1.3713, lr: 0.0001\n",
      "Epoch: 44, Training loss: 1.368442, Validation loss: 1.3660, lr: 0.0001\n",
      "Epoch: 45, Training loss: 1.417985, Validation loss: 1.3656, lr: 0.0000\n",
      "Epoch: 46, Training loss: 1.383798, Validation loss: 1.3791, lr: 0.0000\n",
      "Epoch: 47, Training loss: 1.405990, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 48, Training loss: 1.379822, Validation loss: 1.3726, lr: 0.0000\n",
      "Epoch: 49, Training loss: 1.381168, Validation loss: 1.3630, lr: 0.0000\n",
      "Epoch: 50, Training loss: 1.373225, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 51, Training loss: 1.378987, Validation loss: 1.4815, lr: 0.0000\n",
      "Epoch: 52, Training loss: 1.366173, Validation loss: 1.3715, lr: 0.0000\n",
      "Epoch: 53, Training loss: 1.381628, Validation loss: 1.3677, lr: 0.0000\n",
      "Epoch: 54, Training loss: 1.378295, Validation loss: 1.3881, lr: 0.0000\n",
      "Epoch: 55, Training loss: 1.377015, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 56, Training loss: 1.394902, Validation loss: 1.3656, lr: 0.0000\n",
      "Epoch: 57, Training loss: 1.447969, Validation loss: 1.3735, lr: 0.0000\n",
      "Epoch: 58, Training loss: 1.357683, Validation loss: 1.3931, lr: 0.0000\n",
      "Epoch: 59, Training loss: 1.388241, Validation loss: 1.3590, lr: 0.0000\n",
      "Epoch: 60, Training loss: 1.378232, Validation loss: 1.3799, lr: 0.0000\n",
      "Epoch: 61, Training loss: 1.368738, Validation loss: 1.3680, lr: 0.0000\n",
      "Epoch: 62, Training loss: 1.364265, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 63, Training loss: 1.362678, Validation loss: 1.3857, lr: 0.0000\n",
      " *och: 64, Training loss: 1.383539, Validation loss: 1.3281, lr: 0.0000\n",
      "Epoch: 65, Training loss: 1.394705, Validation loss: 1.5094, lr: 0.0000\n",
      "Epoch: 66, Training loss: 1.404310, Validation loss: 1.3802, lr: 0.0000\n",
      "Epoch: 67, Training loss: 1.385642, Validation loss: 1.3751, lr: 0.0000\n",
      "Epoch: 68, Training loss: 1.382035, Validation loss: 1.3621, lr: 0.0000\n",
      "Epoch: 69, Training loss: 1.376352, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 70, Training loss: 1.362833, Validation loss: 1.3760, lr: 0.0000\n",
      "Epoch: 71, Training loss: 1.409987, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 72, Training loss: 1.382473, Validation loss: 1.3944, lr: 0.0000\n",
      "Epoch: 73, Training loss: 1.382744, Validation loss: 1.3927, lr: 0.0000\n",
      "Epoch: 74, Training loss: 1.381153, Validation loss: 1.3783, lr: 0.0000\n",
      "Epoch: 75, Training loss: 1.397242, Validation loss: 1.4405, lr: 0.0000\n",
      "Epoch: 76, Training loss: 1.392843, Validation loss: 1.3895, lr: 0.0000\n",
      "Epoch: 77, Training loss: 1.407074, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 78, Training loss: 1.382849, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 79, Training loss: 1.390163, Validation loss: 1.3682, lr: 0.0000\n",
      "Epoch: 80, Training loss: 1.372477, Validation loss: 1.3643, lr: 0.0000\n",
      "Epoch: 81, Training loss: 1.367602, Validation loss: 1.3900, lr: 0.0000\n",
      "Epoch: 82, Training loss: 1.372994, Validation loss: 1.3539, lr: 0.0000\n",
      "Epoch: 83, Training loss: 1.400648, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 84, Training loss: 1.360900, Validation loss: 1.3876, lr: 0.0000\n",
      "Epoch: 85, Training loss: 1.386428, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 86, Training loss: 1.385922, Validation loss: 1.3721, lr: 0.0000\n",
      "Epoch: 87, Training loss: 1.377947, Validation loss: 1.3774, lr: 0.0000\n",
      "Epoch: 88, Training loss: 1.374671, Validation loss: 1.3795, lr: 0.0000\n",
      "Epoch: 89, Training loss: 1.366773, Validation loss: 1.3741, lr: 0.0000\n",
      "Epoch: 90, Training loss: 1.378005, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 91, Training loss: 1.372633, Validation loss: 1.4447, lr: 0.0000\n",
      "Epoch: 92, Training loss: 1.371602, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 93, Training loss: 1.367094, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 94, Training loss: 1.410233, Validation loss: 1.3871, lr: 0.0000\n",
      "Epoch: 95, Training loss: 1.377640, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 96, Training loss: 1.387639, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 97, Training loss: 1.550972, Validation loss: 1.3678, lr: 0.0000\n",
      "Epoch: 98, Training loss: 1.379393, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 99, Training loss: 1.369884, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 100, Training loss: 1.388418, Validation loss: 1.3763, lr: 0.0000\n",
      "Epoch: 101, Training loss: 1.376824, Validation loss: 1.3692, lr: 0.0000\n",
      "Epoch: 102, Training loss: 1.392923, Validation loss: 1.3919, lr: 0.0000\n",
      "Epoch: 103, Training loss: 1.383387, Validation loss: 1.3722, lr: 0.0000\n",
      "Epoch: 104, Training loss: 1.379027, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 105, Training loss: 1.371912, Validation loss: 1.3912, lr: 0.0000\n",
      "Epoch: 106, Training loss: 1.382754, Validation loss: 1.3790, lr: 0.0000\n",
      "Epoch: 107, Training loss: 1.391692, Validation loss: 1.3961, lr: 0.0000\n",
      "Epoch: 108, Training loss: 1.366226, Validation loss: 1.3723, lr: 0.0000\n",
      "Epoch: 109, Training loss: 1.369188, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 110, Training loss: 1.377700, Validation loss: 1.3884, lr: 0.0000\n",
      "Epoch: 111, Training loss: 1.381554, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 112, Training loss: 1.380192, Validation loss: 1.3597, lr: 0.0000\n",
      "Epoch: 113, Training loss: 1.365461, Validation loss: 1.3883, lr: 0.0000\n",
      "Epoch: 114, Training loss: 1.367138, Validation loss: 1.3765, lr: 0.0000\n",
      "Epoch: 115, Training loss: 1.369376, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 116, Training loss: 1.361906, Validation loss: 1.3894, lr: 0.0000\n",
      "Epoch: 117, Training loss: 1.375658, Validation loss: 1.3750, lr: 0.0000\n",
      "Epoch: 118, Training loss: 1.376840, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 119, Training loss: 1.360345, Validation loss: 1.3670, lr: 0.0000\n",
      "Epoch: 120, Training loss: 1.360436, Validation loss: 1.4554, lr: 0.0000\n",
      "Epoch: 121, Training loss: 1.376488, Validation loss: 1.3920, lr: 0.0000\n",
      "Epoch: 122, Training loss: 1.370788, Validation loss: 1.3744, lr: 0.0000\n",
      "Epoch: 123, Training loss: 1.363595, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 124, Training loss: 1.378714, Validation loss: 1.3751, lr: 0.0000\n",
      "Epoch: 125, Training loss: 1.369430, Validation loss: 1.3793, lr: 0.0000\n",
      "Epoch: 126, Training loss: 1.372076, Validation loss: 1.3894, lr: 0.0000\n",
      "Epoch: 127, Training loss: 1.416360, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 128, Training loss: 1.399871, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 129, Training loss: 1.368065, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 130, Training loss: 1.366112, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 131, Training loss: 1.381890, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 132, Training loss: 1.373837, Validation loss: 1.3367, lr: 0.0000\n",
      "Epoch: 133, Training loss: 1.389211, Validation loss: 1.3802, lr: 0.0000\n",
      "Epoch: 134, Training loss: 1.370243, Validation loss: 1.3710, lr: 0.0000\n",
      "Epoch: 135, Training loss: 1.361274, Validation loss: 1.3967, lr: 0.0000\n",
      "Epoch: 136, Training loss: 1.372972, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 137, Training loss: 1.373499, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 138, Training loss: 1.369168, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 139, Training loss: 1.353970, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 140, Training loss: 1.378517, Validation loss: 1.3717, lr: 0.0000\n",
      "Epoch: 141, Training loss: 1.384014, Validation loss: 1.4001, lr: 0.0000\n",
      "Epoch: 142, Training loss: 1.384155, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 143, Training loss: 1.390299, Validation loss: 1.3781, lr: 0.0000\n",
      "Epoch: 144, Training loss: 1.374795, Validation loss: 1.4057, lr: 0.0000\n",
      "Epoch: 145, Training loss: 1.377880, Validation loss: 1.3803, lr: 0.0000\n",
      "Epoch: 146, Training loss: 1.369768, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 147, Training loss: 1.385682, Validation loss: 1.3800, lr: 0.0000\n",
      "Epoch: 148, Training loss: 1.376912, Validation loss: 1.3600, lr: 0.0000\n",
      "Epoch: 149, Training loss: 1.372757, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 150, Training loss: 1.374947, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 151, Training loss: 1.382779, Validation loss: 1.3909, lr: 0.0000\n",
      "Epoch: 152, Training loss: 1.371476, Validation loss: 1.3768, lr: 0.0000\n",
      "Epoch: 153, Training loss: 1.370747, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 154, Training loss: 1.360538, Validation loss: 1.3924, lr: 0.0000\n",
      "Epoch: 155, Training loss: 1.379321, Validation loss: 1.3707, lr: 0.0000\n",
      "Epoch: 156, Training loss: 1.427019, Validation loss: 1.3614, lr: 0.0000\n",
      "Epoch: 157, Training loss: 1.360532, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 158, Training loss: 1.380415, Validation loss: 1.3623, lr: 0.0000\n",
      "Epoch: 159, Training loss: 1.378475, Validation loss: 1.3875, lr: 0.0000\n",
      "Epoch: 160, Training loss: 1.378842, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 161, Training loss: 1.365912, Validation loss: 1.3874, lr: 0.0000\n",
      "Epoch: 162, Training loss: 1.394774, Validation loss: 1.3927, lr: 0.0000\n",
      "Epoch: 163, Training loss: 1.371964, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 164, Training loss: 1.397830, Validation loss: 1.3874, lr: 0.0000\n",
      "Epoch: 165, Training loss: 1.367023, Validation loss: 1.3745, lr: 0.0000\n",
      "Epoch: 166, Training loss: 1.387802, Validation loss: 1.3862, lr: 0.0000\n",
      " *och: 167, Training loss: 1.368312, Validation loss: 1.3250, lr: 0.0000\n",
      "Epoch: 168, Training loss: 1.374721, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 169, Training loss: 1.369416, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 170, Training loss: 1.369509, Validation loss: 1.3724, lr: 0.0000\n",
      "Epoch: 171, Training loss: 1.386320, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 172, Training loss: 1.399312, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 173, Training loss: 1.405340, Validation loss: 1.3919, lr: 0.0000\n",
      "Epoch: 174, Training loss: 1.376503, Validation loss: 1.3873, lr: 0.0000\n",
      "Epoch: 175, Training loss: 1.367749, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 176, Training loss: 1.370153, Validation loss: 1.3457, lr: 0.0000\n",
      "Epoch: 177, Training loss: 1.380207, Validation loss: 1.3892, lr: 0.0000\n",
      "Epoch: 178, Training loss: 1.388862, Validation loss: 1.7107, lr: 0.0000\n",
      "Epoch: 179, Training loss: 1.375569, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 180, Training loss: 1.384428, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 181, Training loss: 1.372320, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 182, Training loss: 1.378498, Validation loss: 1.3677, lr: 0.0000\n",
      "Epoch: 183, Training loss: 1.375553, Validation loss: 1.3616, lr: 0.0000\n",
      "Epoch: 184, Training loss: 1.367505, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 185, Training loss: 1.363754, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 186, Training loss: 1.358794, Validation loss: 1.3873, lr: 0.0000\n",
      "Epoch: 187, Training loss: 1.379643, Validation loss: 1.3638, lr: 0.0000\n",
      "Epoch: 188, Training loss: 1.383613, Validation loss: 1.3723, lr: 0.0000\n",
      "Epoch: 189, Training loss: 1.370524, Validation loss: 1.3688, lr: 0.0000\n",
      "Epoch: 190, Training loss: 1.418515, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 191, Training loss: 1.425374, Validation loss: 1.3607, lr: 0.0000\n",
      "Epoch: 192, Training loss: 1.367047, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 193, Training loss: 1.382076, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 194, Training loss: 1.376389, Validation loss: 1.3809, lr: 0.0000\n",
      "Epoch: 195, Training loss: 1.370658, Validation loss: 1.3478, lr: 0.0000\n",
      "Epoch: 196, Training loss: 1.365777, Validation loss: 1.3646, lr: 0.0000\n",
      "Epoch: 197, Training loss: 1.366760, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 198, Training loss: 1.398334, Validation loss: 1.3876, lr: 0.0000\n",
      "Epoch: 199, Training loss: 1.371289, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 200, Training loss: 1.376053, Validation loss: 1.4045, lr: 0.0000\n",
      "Epoch: 201, Training loss: 1.368727, Validation loss: 1.3803, lr: 0.0000\n",
      "Epoch: 202, Training loss: 1.369137, Validation loss: 1.3366, lr: 0.0000\n",
      "Epoch: 203, Training loss: 1.372197, Validation loss: 1.3920, lr: 0.0000\n",
      "Epoch: 204, Training loss: 1.378439, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 205, Training loss: 1.358074, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 206, Training loss: 1.376638, Validation loss: 1.3787, lr: 0.0000\n",
      "Epoch: 207, Training loss: 1.383451, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 208, Training loss: 1.368670, Validation loss: 1.3761, lr: 0.0000\n",
      "Epoch: 209, Training loss: 1.387404, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 210, Training loss: 1.353639, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 211, Training loss: 1.397402, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 212, Training loss: 1.353071, Validation loss: 1.3793, lr: 0.0000\n",
      "Epoch: 213, Training loss: 1.366453, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 214, Training loss: 1.386564, Validation loss: 1.3435, lr: 0.0000\n",
      "Epoch: 215, Training loss: 1.374202, Validation loss: 1.4993, lr: 0.0000\n",
      "Epoch: 216, Training loss: 1.364153, Validation loss: 1.3697, lr: 0.0000\n",
      "Epoch: 217, Training loss: 1.354975, Validation loss: 1.3879, lr: 0.0000\n",
      "Epoch: 218, Training loss: 1.374494, Validation loss: 1.3874, lr: 0.0000\n",
      "Epoch: 219, Training loss: 1.375857, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 220, Training loss: 1.372898, Validation loss: 1.4089, lr: 0.0000\n",
      "Epoch: 221, Training loss: 1.377800, Validation loss: 1.4213, lr: 0.0000\n",
      "Epoch: 222, Training loss: 1.365252, Validation loss: 1.3794, lr: 0.0000\n",
      "Epoch: 223, Training loss: 1.371740, Validation loss: 1.3786, lr: 0.0000\n",
      "Epoch: 224, Training loss: 1.380159, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 225, Training loss: 1.380004, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 226, Training loss: 1.400313, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 227, Training loss: 1.380306, Validation loss: 1.3710, lr: 0.0000\n",
      "Epoch: 228, Training loss: 1.384102, Validation loss: 1.3995, lr: 0.0000\n",
      "Epoch: 229, Training loss: 1.383462, Validation loss: 1.3765, lr: 0.0000\n",
      "Epoch: 230, Training loss: 1.390391, Validation loss: 1.3725, lr: 0.0000\n",
      "Epoch: 231, Training loss: 1.378704, Validation loss: 1.3757, lr: 0.0000\n",
      "Epoch: 232, Training loss: 1.389028, Validation loss: 1.3884, lr: 0.0000\n",
      "Epoch: 233, Training loss: 1.391368, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 234, Training loss: 1.366102, Validation loss: 1.3666, lr: 0.0000\n",
      "Epoch: 235, Training loss: 1.383303, Validation loss: 1.3773, lr: 0.0000\n",
      "Epoch: 236, Training loss: 1.389918, Validation loss: 1.3694, lr: 0.0000\n",
      "Epoch: 237, Training loss: 1.364555, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 238, Training loss: 1.401038, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 239, Training loss: 1.380246, Validation loss: 1.3626, lr: 0.0000\n",
      "Epoch: 240, Training loss: 1.370714, Validation loss: 1.3781, lr: 0.0000\n",
      "Epoch: 241, Training loss: 1.400238, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 242, Training loss: 1.389367, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 243, Training loss: 1.387341, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 244, Training loss: 1.376460, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 245, Training loss: 1.379120, Validation loss: 1.3797, lr: 0.0000\n",
      "Epoch: 246, Training loss: 1.416106, Validation loss: 1.3686, lr: 0.0000\n",
      "Epoch: 247, Training loss: 1.394907, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 248, Training loss: 1.374993, Validation loss: 1.4880, lr: 0.0000\n",
      "Epoch: 249, Training loss: 1.379191, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 250, Training loss: 1.376237, Validation loss: 1.3532, lr: 0.0000\n",
      "Epoch: 251, Training loss: 1.384516, Validation loss: 1.3757, lr: 0.0000\n",
      "Epoch: 252, Training loss: 1.367938, Validation loss: 1.3526, lr: 0.0000\n",
      "Epoch: 253, Training loss: 1.387052, Validation loss: 1.4877, lr: 0.0000\n",
      "Epoch: 254, Training loss: 1.394732, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 255, Training loss: 1.362613, Validation loss: 1.3799, lr: 0.0000\n",
      "Epoch: 256, Training loss: 1.431255, Validation loss: 1.3696, lr: 0.0000\n",
      "Epoch: 257, Training loss: 1.368131, Validation loss: 1.3694, lr: 0.0000\n",
      "Epoch: 258, Training loss: 1.360603, Validation loss: 1.3751, lr: 0.0000\n",
      "Epoch: 259, Training loss: 1.372871, Validation loss: 1.3547, lr: 0.0000\n",
      "Epoch: 260, Training loss: 1.373394, Validation loss: 1.3593, lr: 0.0000\n",
      "Epoch: 261, Training loss: 1.367351, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 262, Training loss: 1.384497, Validation loss: 1.3785, lr: 0.0000\n",
      "Epoch: 263, Training loss: 1.385998, Validation loss: 1.3931, lr: 0.0000\n",
      "Epoch: 264, Training loss: 1.388224, Validation loss: 1.3780, lr: 0.0000\n",
      "Epoch: 265, Training loss: 1.380938, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 266, Training loss: 1.379714, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 267, Training loss: 1.394744, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 268, Training loss: 1.377028, Validation loss: 1.3940, lr: 0.0000\n",
      "Epoch: 269, Training loss: 1.372105, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 270, Training loss: 1.406471, Validation loss: 1.3777, lr: 0.0000\n",
      "Epoch: 271, Training loss: 1.374753, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 272, Training loss: 1.397298, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 273, Training loss: 1.519244, Validation loss: 1.3891, lr: 0.0000\n",
      "Epoch: 274, Training loss: 1.375187, Validation loss: 1.3786, lr: 0.0000\n",
      "Epoch: 275, Training loss: 1.368578, Validation loss: 1.3710, lr: 0.0000\n",
      "Epoch: 276, Training loss: 1.383601, Validation loss: 1.3741, lr: 0.0000\n",
      "Epoch: 277, Training loss: 1.365368, Validation loss: 1.3928, lr: 0.0000\n",
      "Epoch: 278, Training loss: 1.368829, Validation loss: 1.3883, lr: 0.0000\n",
      "Epoch: 279, Training loss: 1.377769, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 280, Training loss: 1.363359, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 281, Training loss: 1.380186, Validation loss: 1.3891, lr: 0.0000\n",
      "Epoch: 282, Training loss: 1.378179, Validation loss: 1.3616, lr: 0.0000\n",
      "Epoch: 283, Training loss: 1.387369, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 284, Training loss: 1.396604, Validation loss: 1.4102, lr: 0.0000\n",
      "Epoch: 285, Training loss: 1.383399, Validation loss: 1.3916, lr: 0.0000\n",
      "Epoch: 286, Training loss: 1.388673, Validation loss: 1.3306, lr: 0.0000\n",
      "Epoch: 287, Training loss: 1.376941, Validation loss: 1.3948, lr: 0.0000\n",
      "Epoch: 288, Training loss: 1.388314, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 289, Training loss: 1.379958, Validation loss: 1.3761, lr: 0.0000\n",
      "Epoch: 290, Training loss: 1.381927, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 291, Training loss: 1.369219, Validation loss: 1.3596, lr: 0.0000\n",
      "Epoch: 292, Training loss: 1.367485, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 293, Training loss: 1.370772, Validation loss: 1.3736, lr: 0.0000\n",
      "Epoch: 294, Training loss: 1.438634, Validation loss: 1.3754, lr: 0.0000\n",
      "Epoch: 295, Training loss: 1.393871, Validation loss: 1.3759, lr: 0.0000\n",
      "Epoch: 296, Training loss: 1.374850, Validation loss: 1.3736, lr: 0.0000\n",
      "Epoch: 297, Training loss: 1.406066, Validation loss: 1.3741, lr: 0.0000\n",
      "Epoch: 298, Training loss: 1.411880, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 299, Training loss: 1.371884, Validation loss: 1.3755, lr: 0.0000\n",
      "Epoch: 300, Training loss: 1.375305, Validation loss: 1.3803, lr: 0.0000\n",
      "Epoch: 301, Training loss: 1.370610, Validation loss: 1.3754, lr: 0.0000\n",
      "Epoch: 302, Training loss: 1.377045, Validation loss: 1.3786, lr: 0.0000\n",
      "Epoch: 303, Training loss: 1.385997, Validation loss: 1.3672, lr: 0.0000\n",
      "Epoch: 304, Training loss: 1.372155, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 305, Training loss: 1.394557, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 306, Training loss: 1.381828, Validation loss: 1.3773, lr: 0.0000\n",
      "Epoch: 307, Training loss: 1.369311, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 308, Training loss: 1.361854, Validation loss: 1.3795, lr: 0.0000\n",
      "Epoch: 309, Training loss: 1.389427, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 310, Training loss: 1.379923, Validation loss: 1.3607, lr: 0.0000\n",
      "Epoch: 311, Training loss: 1.380131, Validation loss: 1.4043, lr: 0.0000\n",
      "Epoch: 312, Training loss: 1.370606, Validation loss: 1.3344, lr: 0.0000\n",
      "Epoch: 313, Training loss: 1.385656, Validation loss: 1.3492, lr: 0.0000\n",
      "Epoch: 314, Training loss: 1.401485, Validation loss: 1.3669, lr: 0.0000\n",
      "Epoch: 315, Training loss: 1.363993, Validation loss: 1.3773, lr: 0.0000\n",
      "Epoch: 316, Training loss: 1.390714, Validation loss: 1.3628, lr: 0.0000\n",
      "Epoch: 317, Training loss: 1.384942, Validation loss: 1.3715, lr: 0.0000\n",
      "Epoch: 318, Training loss: 1.381057, Validation loss: 1.3732, lr: 0.0000\n",
      "Epoch: 319, Training loss: 1.378032, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 320, Training loss: 1.383013, Validation loss: 1.3785, lr: 0.0000\n",
      "Epoch: 321, Training loss: 1.382113, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 322, Training loss: 1.391484, Validation loss: 1.3702, lr: 0.0000\n",
      "Epoch: 323, Training loss: 1.394798, Validation loss: 1.3537, lr: 0.0000\n",
      "Epoch: 324, Training loss: 1.369020, Validation loss: 1.3686, lr: 0.0000\n",
      "Epoch: 325, Training loss: 1.400515, Validation loss: 1.4294, lr: 0.0000\n",
      "Epoch: 326, Training loss: 1.462250, Validation loss: 1.3764, lr: 0.0000\n",
      "Epoch: 327, Training loss: 1.386031, Validation loss: 1.4142, lr: 0.0000\n",
      "Epoch: 328, Training loss: 1.388372, Validation loss: 1.3781, lr: 0.0000\n",
      "Epoch: 329, Training loss: 1.394511, Validation loss: 1.3773, lr: 0.0000\n",
      "Epoch: 330, Training loss: 1.356011, Validation loss: 1.3538, lr: 0.0000\n",
      "Epoch: 331, Training loss: 1.394387, Validation loss: 1.3679, lr: 0.0000\n",
      "Epoch: 332, Training loss: 1.371151, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 333, Training loss: 1.360605, Validation loss: 1.3745, lr: 0.0000\n",
      "Epoch: 334, Training loss: 1.391926, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 335, Training loss: 1.365886, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 336, Training loss: 1.379055, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 337, Training loss: 1.375458, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 338, Training loss: 1.381254, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 339, Training loss: 1.407260, Validation loss: 1.3871, lr: 0.0000\n",
      "Epoch: 340, Training loss: 1.380441, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 341, Training loss: 1.374077, Validation loss: 1.3773, lr: 0.0000\n",
      "Epoch: 342, Training loss: 1.359971, Validation loss: 1.3745, lr: 0.0000\n",
      "Epoch: 343, Training loss: 1.363109, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 344, Training loss: 1.364112, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 345, Training loss: 1.366587, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 346, Training loss: 1.405499, Validation loss: 1.3906, lr: 0.0000\n",
      "Epoch: 347, Training loss: 1.376168, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 348, Training loss: 1.394401, Validation loss: 1.3877, lr: 0.0000\n",
      "Epoch: 349, Training loss: 1.397026, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 350, Training loss: 1.394463, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 351, Training loss: 1.359681, Validation loss: 1.3701, lr: 0.0000\n",
      "Epoch: 352, Training loss: 1.383442, Validation loss: 1.3796, lr: 0.0000\n",
      "Epoch: 353, Training loss: 1.388230, Validation loss: 1.3888, lr: 0.0000\n",
      "Epoch: 354, Training loss: 1.388143, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 355, Training loss: 1.367548, Validation loss: 1.3730, lr: 0.0000\n",
      "Epoch: 356, Training loss: 1.374599, Validation loss: 1.3580, lr: 0.0000\n",
      "Epoch: 357, Training loss: 1.374942, Validation loss: 1.3987, lr: 0.0000\n",
      "Epoch: 358, Training loss: 1.377150, Validation loss: 1.3874, lr: 0.0000\n",
      "Epoch: 359, Training loss: 1.388162, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 360, Training loss: 1.380146, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 361, Training loss: 1.366485, Validation loss: 1.3795, lr: 0.0000\n",
      "Epoch: 362, Training loss: 1.375215, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 363, Training loss: 1.382644, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 364, Training loss: 1.393592, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 365, Training loss: 1.370771, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 366, Training loss: 1.372025, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 367, Training loss: 1.376523, Validation loss: 1.4253, lr: 0.0000\n",
      "Epoch: 368, Training loss: 1.443986, Validation loss: 1.3718, lr: 0.0000\n",
      "Epoch: 369, Training loss: 1.375464, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 370, Training loss: 1.369144, Validation loss: 1.4117, lr: 0.0000\n",
      "Epoch: 371, Training loss: 1.381036, Validation loss: 1.3751, lr: 0.0000\n",
      "Epoch: 372, Training loss: 1.365650, Validation loss: 1.3291, lr: 0.0000\n",
      "Epoch: 373, Training loss: 1.386612, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 374, Training loss: 1.362035, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 375, Training loss: 1.378475, Validation loss: 1.3785, lr: 0.0000\n",
      "Epoch: 376, Training loss: 1.374920, Validation loss: 1.3611, lr: 0.0000\n",
      "Epoch: 377, Training loss: 1.370557, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 378, Training loss: 1.384604, Validation loss: 1.3640, lr: 0.0000\n",
      "Epoch: 379, Training loss: 1.375523, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 380, Training loss: 1.378562, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 381, Training loss: 1.370020, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 382, Training loss: 1.386950, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 383, Training loss: 1.389897, Validation loss: 1.3763, lr: 0.0000\n",
      "Epoch: 384, Training loss: 1.374594, Validation loss: 1.3585, lr: 0.0000\n",
      "Epoch: 385, Training loss: 1.375923, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 386, Training loss: 1.376587, Validation loss: 1.3559, lr: 0.0000\n",
      "Epoch: 387, Training loss: 1.369899, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 388, Training loss: 1.348526, Validation loss: 1.3710, lr: 0.0000\n",
      "Epoch: 389, Training loss: 1.387283, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 390, Training loss: 1.386709, Validation loss: 1.3739, lr: 0.0000\n",
      "Epoch: 391, Training loss: 1.408238, Validation loss: 1.3757, lr: 0.0000\n",
      "Epoch: 392, Training loss: 1.368804, Validation loss: 1.4447, lr: 0.0000\n",
      "Epoch: 393, Training loss: 1.395415, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 394, Training loss: 1.436370, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 395, Training loss: 1.371948, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 396, Training loss: 1.384093, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 397, Training loss: 1.381072, Validation loss: 1.3876, lr: 0.0000\n",
      "Epoch: 398, Training loss: 1.357192, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 399, Training loss: 1.417497, Validation loss: 1.3761, lr: 0.0000\n",
      "Epoch: 400, Training loss: 1.375922, Validation loss: 1.4760, lr: 0.0000\n",
      "Epoch: 401, Training loss: 1.386212, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 402, Training loss: 1.377610, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 403, Training loss: 1.350172, Validation loss: 1.3772, lr: 0.0000\n",
      "Epoch: 404, Training loss: 1.377840, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 405, Training loss: 1.429833, Validation loss: 1.3744, lr: 0.0000\n",
      "Epoch: 406, Training loss: 1.395318, Validation loss: 1.3884, lr: 0.0000\n",
      "Epoch: 407, Training loss: 1.373090, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 408, Training loss: 1.396800, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 409, Training loss: 1.370979, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 410, Training loss: 1.377595, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 411, Training loss: 1.360372, Validation loss: 1.3942, lr: 0.0000\n",
      "Epoch: 412, Training loss: 1.379450, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 413, Training loss: 1.389721, Validation loss: 1.3753, lr: 0.0000\n",
      "Epoch: 414, Training loss: 1.364896, Validation loss: 1.3892, lr: 0.0000\n",
      "Epoch: 415, Training loss: 1.377660, Validation loss: 1.3782, lr: 0.0000\n",
      "Epoch: 416, Training loss: 1.368726, Validation loss: 1.3875, lr: 0.0000\n",
      "Epoch: 417, Training loss: 1.468592, Validation loss: 1.3800, lr: 0.0000\n",
      "Epoch: 418, Training loss: 1.382675, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 419, Training loss: 1.362137, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 420, Training loss: 1.399512, Validation loss: 1.3888, lr: 0.0000\n",
      "Epoch: 421, Training loss: 1.363549, Validation loss: 1.3727, lr: 0.0000\n",
      "Epoch: 422, Training loss: 1.386668, Validation loss: 1.3684, lr: 0.0000\n",
      "Epoch: 423, Training loss: 1.391881, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 424, Training loss: 1.392503, Validation loss: 1.3583, lr: 0.0000\n",
      "Epoch: 425, Training loss: 1.370926, Validation loss: 1.3758, lr: 0.0000\n",
      "Epoch: 426, Training loss: 1.400084, Validation loss: 1.3797, lr: 0.0000\n",
      "Epoch: 427, Training loss: 1.362959, Validation loss: 1.3544, lr: 0.0000\n",
      "Epoch: 428, Training loss: 1.375708, Validation loss: 1.3728, lr: 0.0000\n",
      "Epoch: 429, Training loss: 1.363008, Validation loss: 1.3647, lr: 0.0000\n",
      "Epoch: 430, Training loss: 1.388289, Validation loss: 1.3756, lr: 0.0000\n",
      "Epoch: 431, Training loss: 1.375011, Validation loss: 1.3878, lr: 0.0000\n",
      "Epoch: 432, Training loss: 1.377075, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 433, Training loss: 1.379550, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 434, Training loss: 1.389746, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 435, Training loss: 1.388495, Validation loss: 1.3776, lr: 0.0000\n",
      "Epoch: 436, Training loss: 1.378590, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 437, Training loss: 1.371520, Validation loss: 1.3871, lr: 0.0000\n",
      "Epoch: 438, Training loss: 1.375407, Validation loss: 1.3758, lr: 0.0000\n",
      "Epoch: 439, Training loss: 1.374527, Validation loss: 1.3719, lr: 0.0000\n",
      "Epoch: 440, Training loss: 1.373871, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 441, Training loss: 1.390248, Validation loss: 1.3941, lr: 0.0000\n",
      "Epoch: 442, Training loss: 1.370686, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 443, Training loss: 1.377584, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 444, Training loss: 1.370903, Validation loss: 1.3883, lr: 0.0000\n",
      "Epoch: 445, Training loss: 1.370660, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 446, Training loss: 1.403304, Validation loss: 1.3794, lr: 0.0000\n",
      "Epoch: 447, Training loss: 1.417211, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 448, Training loss: 1.359602, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 449, Training loss: 1.364214, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 450, Training loss: 1.372983, Validation loss: 1.3710, lr: 0.0000\n",
      "Epoch: 451, Training loss: 1.353610, Validation loss: 1.4776, lr: 0.0000\n",
      "Epoch: 452, Training loss: 1.366226, Validation loss: 1.3611, lr: 0.0000\n",
      "Epoch: 453, Training loss: 1.374336, Validation loss: 1.3729, lr: 0.0000\n",
      "Epoch: 454, Training loss: 1.388865, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 455, Training loss: 1.370817, Validation loss: 1.3546, lr: 0.0000\n",
      "Epoch: 456, Training loss: 1.389615, Validation loss: 1.3708, lr: 0.0000\n",
      "Epoch: 457, Training loss: 1.369971, Validation loss: 1.4086, lr: 0.0000\n",
      "Epoch: 458, Training loss: 1.372310, Validation loss: 1.3683, lr: 0.0000\n",
      "Epoch: 459, Training loss: 1.374033, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 460, Training loss: 1.380111, Validation loss: 1.3621, lr: 0.0000\n",
      "Epoch: 461, Training loss: 1.374485, Validation loss: 1.3919, lr: 0.0000\n",
      "Epoch: 462, Training loss: 1.353768, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 463, Training loss: 1.370719, Validation loss: 1.3638, lr: 0.0000\n",
      "Epoch: 464, Training loss: 1.384030, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 465, Training loss: 1.378961, Validation loss: 1.3584, lr: 0.0000\n",
      "Epoch: 466, Training loss: 1.356668, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 467, Training loss: 1.387782, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 468, Training loss: 1.369894, Validation loss: 1.3742, lr: 0.0000\n",
      "Epoch: 469, Training loss: 1.391591, Validation loss: 1.3776, lr: 0.0000\n",
      "Epoch: 470, Training loss: 1.371809, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 471, Training loss: 1.460792, Validation loss: 1.3887, lr: 0.0000\n",
      "Epoch: 472, Training loss: 1.375176, Validation loss: 1.3901, lr: 0.0000\n",
      "Epoch: 473, Training loss: 1.358779, Validation loss: 1.3644, lr: 0.0000\n",
      "Epoch: 474, Training loss: 1.363225, Validation loss: 1.3689, lr: 0.0000\n",
      "Epoch: 475, Training loss: 1.375384, Validation loss: 1.3541, lr: 0.0000\n",
      "Epoch: 476, Training loss: 1.378874, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 477, Training loss: 1.374255, Validation loss: 1.3720, lr: 0.0000\n",
      "Epoch: 478, Training loss: 1.361614, Validation loss: 1.3803, lr: 0.0000\n",
      "Epoch: 479, Training loss: 1.364503, Validation loss: 1.3739, lr: 0.0000\n",
      "Epoch: 480, Training loss: 1.379799, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 481, Training loss: 1.439043, Validation loss: 1.3705, lr: 0.0000\n",
      "Epoch: 482, Training loss: 1.369165, Validation loss: 1.4071, lr: 0.0000\n",
      "Epoch: 483, Training loss: 1.384340, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 484, Training loss: 1.404086, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 485, Training loss: 1.371439, Validation loss: 1.4056, lr: 0.0000\n",
      "Epoch: 486, Training loss: 1.378374, Validation loss: 1.3513, lr: 0.0000\n",
      "Epoch: 487, Training loss: 1.366300, Validation loss: 1.7935, lr: 0.0000\n",
      "Epoch: 488, Training loss: 1.381671, Validation loss: 1.3612, lr: 0.0000\n",
      "Epoch: 489, Training loss: 1.385265, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 490, Training loss: 1.440742, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 491, Training loss: 1.369223, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 492, Training loss: 1.401802, Validation loss: 1.3747, lr: 0.0000\n",
      "Epoch: 493, Training loss: 1.372534, Validation loss: 1.3882, lr: 0.0000\n",
      "Epoch: 494, Training loss: 1.386478, Validation loss: 1.3558, lr: 0.0000\n",
      "Epoch: 495, Training loss: 1.369644, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 496, Training loss: 1.379097, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 497, Training loss: 1.375460, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 498, Training loss: 1.357725, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 499, Training loss: 1.391610, Validation loss: 1.3591, lr: 0.0000\n",
      "Epoch: 500, Training loss: 1.380938, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 501, Training loss: 1.390519, Validation loss: 1.3458, lr: 0.0000\n",
      "Epoch: 502, Training loss: 1.371067, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 503, Training loss: 1.394891, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 504, Training loss: 1.373950, Validation loss: 1.3721, lr: 0.0000\n",
      "Epoch: 505, Training loss: 1.380485, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 506, Training loss: 1.408541, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 507, Training loss: 1.379583, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 508, Training loss: 1.363805, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 509, Training loss: 1.364511, Validation loss: 1.3763, lr: 0.0000\n",
      "Epoch: 510, Training loss: 1.385555, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 511, Training loss: 1.367273, Validation loss: 1.3621, lr: 0.0000\n",
      "Epoch: 512, Training loss: 1.367153, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 513, Training loss: 1.376119, Validation loss: 1.3771, lr: 0.0000\n",
      "Epoch: 514, Training loss: 1.375859, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 515, Training loss: 1.387882, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 516, Training loss: 1.378977, Validation loss: 1.3656, lr: 0.0000\n",
      "Epoch: 517, Training loss: 1.358718, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 518, Training loss: 1.367778, Validation loss: 1.4258, lr: 0.0000\n",
      "Epoch: 519, Training loss: 1.372358, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 520, Training loss: 1.385078, Validation loss: 1.3791, lr: 0.0000\n",
      "Epoch: 521, Training loss: 1.387447, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 522, Training loss: 1.372382, Validation loss: 1.3894, lr: 0.0000\n",
      "Epoch: 523, Training loss: 1.378143, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 524, Training loss: 1.381552, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 525, Training loss: 1.378185, Validation loss: 1.3796, lr: 0.0000\n",
      "Epoch: 526, Training loss: 1.360242, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 527, Training loss: 1.385381, Validation loss: 1.3798, lr: 0.0000\n",
      "Epoch: 528, Training loss: 1.373467, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 529, Training loss: 1.410994, Validation loss: 1.3732, lr: 0.0000\n",
      "Epoch: 530, Training loss: 1.400173, Validation loss: 1.3477, lr: 0.0000\n",
      "Epoch: 531, Training loss: 1.381693, Validation loss: 1.3760, lr: 0.0000\n",
      "Epoch: 532, Training loss: 1.382341, Validation loss: 1.3765, lr: 0.0000\n",
      "Epoch: 533, Training loss: 1.383722, Validation loss: 1.3878, lr: 0.0000\n",
      "Epoch: 534, Training loss: 1.383774, Validation loss: 1.3284, lr: 0.0000\n",
      "Epoch: 535, Training loss: 1.390765, Validation loss: 1.5272, lr: 0.0000\n",
      "Epoch: 536, Training loss: 1.365829, Validation loss: 1.3789, lr: 0.0000\n",
      "Epoch: 537, Training loss: 1.384815, Validation loss: 1.3779, lr: 0.0000\n",
      "Epoch: 538, Training loss: 1.390744, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 539, Training loss: 1.392255, Validation loss: 1.3446, lr: 0.0000\n",
      "Epoch: 540, Training loss: 1.379931, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 541, Training loss: 1.394508, Validation loss: 1.3697, lr: 0.0000\n",
      "Epoch: 542, Training loss: 1.369027, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 543, Training loss: 1.375551, Validation loss: 1.3738, lr: 0.0000\n",
      "Epoch: 544, Training loss: 1.393348, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 545, Training loss: 1.370903, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 546, Training loss: 1.374439, Validation loss: 1.4073, lr: 0.0000\n",
      "Epoch: 547, Training loss: 1.388726, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 548, Training loss: 1.389266, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 549, Training loss: 1.371936, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 550, Training loss: 1.374328, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 551, Training loss: 1.384994, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 552, Training loss: 1.389694, Validation loss: 1.3651, lr: 0.0000\n",
      "Epoch: 553, Training loss: 1.410558, Validation loss: 1.3893, lr: 0.0000\n",
      "Epoch: 554, Training loss: 1.379738, Validation loss: 1.3742, lr: 0.0000\n",
      "Epoch: 555, Training loss: 1.377104, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 556, Training loss: 1.401478, Validation loss: 1.4299, lr: 0.0000\n",
      "Epoch: 557, Training loss: 1.389909, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 558, Training loss: 1.373527, Validation loss: 1.3747, lr: 0.0000\n",
      "Epoch: 559, Training loss: 1.368888, Validation loss: 1.3673, lr: 0.0000\n",
      "Epoch: 560, Training loss: 1.367368, Validation loss: 1.3718, lr: 0.0000\n",
      "Epoch: 561, Training loss: 1.393752, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 562, Training loss: 1.456302, Validation loss: 1.3606, lr: 0.0000\n",
      "Epoch: 563, Training loss: 1.369961, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 564, Training loss: 1.387563, Validation loss: 1.3695, lr: 0.0000\n",
      "Epoch: 565, Training loss: 1.370458, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 566, Training loss: 1.454759, Validation loss: 1.3791, lr: 0.0000\n",
      "Epoch: 567, Training loss: 1.368943, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 568, Training loss: 1.382649, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 569, Training loss: 1.369612, Validation loss: 1.3921, lr: 0.0000\n",
      "Epoch: 570, Training loss: 1.375845, Validation loss: 1.3659, lr: 0.0000\n",
      "Epoch: 571, Training loss: 1.371620, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 572, Training loss: 1.384631, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 573, Training loss: 1.379840, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 574, Training loss: 1.375826, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 575, Training loss: 1.377872, Validation loss: 1.3995, lr: 0.0000\n",
      "Epoch: 576, Training loss: 1.374976, Validation loss: 1.3882, lr: 0.0000\n",
      "Epoch: 577, Training loss: 1.381127, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 578, Training loss: 1.400370, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 579, Training loss: 1.373492, Validation loss: 1.4011, lr: 0.0000\n",
      "Epoch: 580, Training loss: 1.358813, Validation loss: 1.3559, lr: 0.0000\n",
      "Epoch: 581, Training loss: 1.375641, Validation loss: 1.3726, lr: 0.0000\n",
      "Epoch: 582, Training loss: 1.392754, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 583, Training loss: 1.377159, Validation loss: 1.3734, lr: 0.0000\n",
      "Epoch: 584, Training loss: 1.377700, Validation loss: 1.3782, lr: 0.0000\n",
      "Epoch: 585, Training loss: 1.365923, Validation loss: 1.3652, lr: 0.0000\n",
      "Epoch: 586, Training loss: 1.383479, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 587, Training loss: 1.366475, Validation loss: 1.3783, lr: 0.0000\n",
      "Epoch: 588, Training loss: 1.373022, Validation loss: 1.3653, lr: 0.0000\n",
      "Epoch: 589, Training loss: 1.398007, Validation loss: 1.3886, lr: 0.0000\n",
      "Epoch: 590, Training loss: 1.365341, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 591, Training loss: 1.396257, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 592, Training loss: 1.393713, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 593, Training loss: 1.366922, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 594, Training loss: 1.373464, Validation loss: 1.3764, lr: 0.0000\n",
      "Epoch: 595, Training loss: 1.367204, Validation loss: 1.3721, lr: 0.0000\n",
      "Epoch: 596, Training loss: 1.396622, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 597, Training loss: 1.381764, Validation loss: 1.4107, lr: 0.0000\n",
      "Epoch: 598, Training loss: 1.365508, Validation loss: 1.3760, lr: 0.0000\n",
      "Epoch: 599, Training loss: 1.376023, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 600, Training loss: 1.388741, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 601, Training loss: 1.360670, Validation loss: 1.3981, lr: 0.0000\n",
      "Epoch: 602, Training loss: 1.383806, Validation loss: 1.3706, lr: 0.0000\n",
      "Epoch: 603, Training loss: 1.383624, Validation loss: 1.3665, lr: 0.0000\n",
      "Epoch: 604, Training loss: 1.371307, Validation loss: 1.3656, lr: 0.0000\n",
      "Epoch: 605, Training loss: 1.380263, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 606, Training loss: 1.370749, Validation loss: 1.3763, lr: 0.0000\n",
      "Epoch: 607, Training loss: 1.414722, Validation loss: 1.3672, lr: 0.0000\n",
      "Epoch: 608, Training loss: 1.357699, Validation loss: 1.3505, lr: 0.0000\n",
      "Epoch: 609, Training loss: 1.363218, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 610, Training loss: 1.384487, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 611, Training loss: 1.379403, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 612, Training loss: 1.374172, Validation loss: 1.3735, lr: 0.0000\n",
      "Epoch: 613, Training loss: 1.370291, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 614, Training loss: 1.377478, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 615, Training loss: 1.364617, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 616, Training loss: 1.382755, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 617, Training loss: 1.377782, Validation loss: 1.3633, lr: 0.0000\n",
      "Epoch: 618, Training loss: 1.382314, Validation loss: 1.3700, lr: 0.0000\n",
      "Epoch: 619, Training loss: 1.368211, Validation loss: 1.3809, lr: 0.0000\n",
      "Epoch: 620, Training loss: 1.380672, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 621, Training loss: 1.378712, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 622, Training loss: 1.361817, Validation loss: 1.3767, lr: 0.0000\n",
      "Epoch: 623, Training loss: 1.374440, Validation loss: 1.3686, lr: 0.0000\n",
      "Epoch: 624, Training loss: 1.393888, Validation loss: 1.3489, lr: 0.0000\n",
      "Epoch: 625, Training loss: 1.363633, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 626, Training loss: 1.370957, Validation loss: 1.3909, lr: 0.0000\n",
      "Epoch: 627, Training loss: 1.381961, Validation loss: 1.3748, lr: 0.0000\n",
      "Epoch: 628, Training loss: 1.371289, Validation loss: 1.3753, lr: 0.0000\n",
      "Epoch: 629, Training loss: 1.372729, Validation loss: 1.3802, lr: 0.0000\n",
      "Epoch: 630, Training loss: 1.387046, Validation loss: 1.3705, lr: 0.0000\n",
      "Epoch: 631, Training loss: 1.414793, Validation loss: 1.3763, lr: 0.0000\n",
      "Epoch: 632, Training loss: 1.388739, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 633, Training loss: 1.355784, Validation loss: 1.4446, lr: 0.0000\n",
      "Epoch: 634, Training loss: 1.374537, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 635, Training loss: 1.376918, Validation loss: 1.3709, lr: 0.0000\n",
      "Epoch: 636, Training loss: 1.375206, Validation loss: 1.3692, lr: 0.0000\n",
      "Epoch: 637, Training loss: 1.405487, Validation loss: 1.3698, lr: 0.0000\n",
      "Epoch: 638, Training loss: 1.373170, Validation loss: 1.3783, lr: 0.0000\n",
      "Epoch: 639, Training loss: 1.379479, Validation loss: 1.3794, lr: 0.0000\n",
      "Epoch: 640, Training loss: 1.369852, Validation loss: 1.3956, lr: 0.0000\n",
      "Epoch: 641, Training loss: 1.373153, Validation loss: 1.3887, lr: 0.0000\n",
      "Epoch: 642, Training loss: 1.376348, Validation loss: 1.3704, lr: 0.0000\n",
      "Epoch: 643, Training loss: 1.424828, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 644, Training loss: 1.378274, Validation loss: 1.4040, lr: 0.0000\n",
      "Epoch: 645, Training loss: 1.376740, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 646, Training loss: 1.368557, Validation loss: 1.3454, lr: 0.0000\n",
      "Epoch: 647, Training loss: 1.386509, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 648, Training loss: 1.376832, Validation loss: 1.3751, lr: 0.0000\n",
      "Epoch: 649, Training loss: 1.365868, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 650, Training loss: 1.373851, Validation loss: 1.3667, lr: 0.0000\n",
      "Epoch: 651, Training loss: 1.388456, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 652, Training loss: 1.389004, Validation loss: 1.3639, lr: 0.0000\n",
      "Epoch: 653, Training loss: 1.372468, Validation loss: 1.3802, lr: 0.0000\n",
      "Epoch: 654, Training loss: 1.348042, Validation loss: 1.3809, lr: 0.0000\n",
      "Epoch: 655, Training loss: 1.387969, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 656, Training loss: 1.376229, Validation loss: 1.3638, lr: 0.0000\n",
      "Epoch: 657, Training loss: 1.383578, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 658, Training loss: 1.375795, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 659, Training loss: 1.370831, Validation loss: 1.3884, lr: 0.0000\n",
      "Epoch: 660, Training loss: 1.416420, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 661, Training loss: 1.393642, Validation loss: 1.3762, lr: 0.0000\n",
      "Epoch: 662, Training loss: 1.414471, Validation loss: 1.3591, lr: 0.0000\n",
      "Epoch: 663, Training loss: 1.374775, Validation loss: 1.3809, lr: 0.0000\n",
      "Epoch: 664, Training loss: 1.375365, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 665, Training loss: 1.390815, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 666, Training loss: 1.373623, Validation loss: 1.3609, lr: 0.0000\n",
      "Epoch: 667, Training loss: 1.369334, Validation loss: 1.3646, lr: 0.0000\n",
      "Epoch: 668, Training loss: 1.389572, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 669, Training loss: 1.374110, Validation loss: 1.3626, lr: 0.0000\n",
      "Epoch: 670, Training loss: 1.367874, Validation loss: 1.3885, lr: 0.0000\n",
      "Epoch: 671, Training loss: 1.372008, Validation loss: 1.3678, lr: 0.0000\n",
      "Epoch: 672, Training loss: 1.385345, Validation loss: 1.3710, lr: 0.0000\n",
      "Epoch: 673, Training loss: 1.376505, Validation loss: 1.3871, lr: 0.0000\n",
      "Epoch: 674, Training loss: 1.365061, Validation loss: 1.3639, lr: 0.0000\n",
      "Epoch: 675, Training loss: 1.367091, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 676, Training loss: 1.386413, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 677, Training loss: 1.391372, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 678, Training loss: 1.370747, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 679, Training loss: 1.386199, Validation loss: 1.3592, lr: 0.0000\n",
      "Epoch: 680, Training loss: 1.387054, Validation loss: 1.3789, lr: 0.0000\n",
      "Epoch: 681, Training loss: 1.388082, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 682, Training loss: 1.377603, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 683, Training loss: 1.375129, Validation loss: 1.3969, lr: 0.0000\n",
      "Epoch: 684, Training loss: 1.370418, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 685, Training loss: 1.396205, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 686, Training loss: 1.361324, Validation loss: 1.3788, lr: 0.0000\n",
      "Epoch: 687, Training loss: 1.368596, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 688, Training loss: 1.361908, Validation loss: 1.3760, lr: 0.0000\n",
      "Epoch: 689, Training loss: 1.377177, Validation loss: 1.3707, lr: 0.0000\n",
      "Epoch: 690, Training loss: 1.375471, Validation loss: 1.3933, lr: 0.0000\n",
      "Epoch: 691, Training loss: 1.368507, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 692, Training loss: 1.390828, Validation loss: 1.3684, lr: 0.0000\n",
      "Epoch: 693, Training loss: 1.378442, Validation loss: 1.3509, lr: 0.0000\n",
      "Epoch: 694, Training loss: 1.393815, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 695, Training loss: 1.366156, Validation loss: 1.4046, lr: 0.0000\n",
      "Epoch: 696, Training loss: 1.356484, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 697, Training loss: 1.381458, Validation loss: 1.3493, lr: 0.0000\n",
      "Epoch: 698, Training loss: 1.386545, Validation loss: 1.3785, lr: 0.0000\n",
      "Epoch: 699, Training loss: 1.401723, Validation loss: 1.3668, lr: 0.0000\n",
      "Epoch: 700, Training loss: 1.377661, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 701, Training loss: 1.395683, Validation loss: 1.3893, lr: 0.0000\n",
      "Epoch: 702, Training loss: 1.388504, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 703, Training loss: 1.381422, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 704, Training loss: 1.396003, Validation loss: 1.3919, lr: 0.0000\n",
      "Epoch: 705, Training loss: 1.378302, Validation loss: 1.3782, lr: 0.0000\n",
      "Epoch: 706, Training loss: 1.377684, Validation loss: 1.3750, lr: 0.0000\n",
      "Epoch: 707, Training loss: 1.368354, Validation loss: 1.3759, lr: 0.0000\n",
      "Epoch: 708, Training loss: 1.371238, Validation loss: 1.4103, lr: 0.0000\n",
      "Epoch: 709, Training loss: 1.363604, Validation loss: 1.3760, lr: 0.0000\n",
      "Epoch: 710, Training loss: 1.382069, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 711, Training loss: 1.378763, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 712, Training loss: 1.381872, Validation loss: 1.4089, lr: 0.0000\n",
      "Epoch: 713, Training loss: 1.394865, Validation loss: 1.3786, lr: 0.0000\n",
      "Epoch: 714, Training loss: 1.385792, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 715, Training loss: 1.376305, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 716, Training loss: 1.410396, Validation loss: 1.3793, lr: 0.0000\n",
      "Epoch: 717, Training loss: 1.376514, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 718, Training loss: 1.386249, Validation loss: 1.3988, lr: 0.0000\n",
      "Epoch: 719, Training loss: 1.366732, Validation loss: 1.3600, lr: 0.0000\n",
      "Epoch: 720, Training loss: 1.442883, Validation loss: 1.3598, lr: 0.0000\n",
      "Epoch: 721, Training loss: 1.385106, Validation loss: 1.3903, lr: 0.0000\n",
      "Epoch: 722, Training loss: 1.388615, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 723, Training loss: 1.380641, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 724, Training loss: 1.376013, Validation loss: 1.3792, lr: 0.0000\n",
      "Epoch: 725, Training loss: 1.437337, Validation loss: 1.3523, lr: 0.0000\n",
      "Epoch: 726, Training loss: 1.377032, Validation loss: 1.3782, lr: 0.0000\n",
      "Epoch: 727, Training loss: 1.394745, Validation loss: 1.4024, lr: 0.0000\n",
      "Epoch: 728, Training loss: 1.375812, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 729, Training loss: 1.385685, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 730, Training loss: 1.360678, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 731, Training loss: 1.446627, Validation loss: 1.4033, lr: 0.0000\n",
      "Epoch: 732, Training loss: 1.362644, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 733, Training loss: 1.371029, Validation loss: 1.3777, lr: 0.0000\n",
      "Epoch: 734, Training loss: 1.381089, Validation loss: 1.3731, lr: 0.0000\n",
      "Epoch: 735, Training loss: 1.370176, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 736, Training loss: 1.368203, Validation loss: 1.3721, lr: 0.0000\n",
      "Epoch: 737, Training loss: 1.381046, Validation loss: 1.3634, lr: 0.0000\n",
      "Epoch: 738, Training loss: 1.367705, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 739, Training loss: 1.387453, Validation loss: 1.3600, lr: 0.0000\n",
      "Epoch: 740, Training loss: 1.368194, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 741, Training loss: 1.389483, Validation loss: 1.3635, lr: 0.0000\n",
      "Epoch: 742, Training loss: 1.362333, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 743, Training loss: 1.400013, Validation loss: 1.3603, lr: 0.0000\n",
      "Epoch: 744, Training loss: 1.385857, Validation loss: 1.3772, lr: 0.0000\n",
      "Epoch: 745, Training loss: 1.381405, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 746, Training loss: 1.368773, Validation loss: 1.3704, lr: 0.0000\n",
      "Epoch: 747, Training loss: 1.351789, Validation loss: 1.3749, lr: 0.0000\n",
      "Epoch: 748, Training loss: 1.387732, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 749, Training loss: 1.354749, Validation loss: 1.3641, lr: 0.0000\n",
      "Epoch: 750, Training loss: 1.375624, Validation loss: 1.3980, lr: 0.0000\n",
      "Epoch: 751, Training loss: 1.354975, Validation loss: 1.3781, lr: 0.0000\n",
      "Epoch: 752, Training loss: 1.388804, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 753, Training loss: 1.364867, Validation loss: 1.5217, lr: 0.0000\n",
      "Epoch: 754, Training loss: 1.383722, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 755, Training loss: 1.373331, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 756, Training loss: 1.371987, Validation loss: 1.4474, lr: 0.0000\n",
      "Epoch: 757, Training loss: 1.371305, Validation loss: 1.3890, lr: 0.0000\n",
      "Epoch: 758, Training loss: 1.357202, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 759, Training loss: 1.379093, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 760, Training loss: 1.385115, Validation loss: 1.4859, lr: 0.0000\n",
      "Epoch: 761, Training loss: 1.360299, Validation loss: 1.3448, lr: 0.0000\n",
      "Epoch: 762, Training loss: 1.386797, Validation loss: 1.3737, lr: 0.0000\n",
      "Epoch: 763, Training loss: 1.361852, Validation loss: 1.3785, lr: 0.0000\n",
      "Epoch: 764, Training loss: 1.377963, Validation loss: 1.3696, lr: 0.0000\n",
      "Epoch: 765, Training loss: 1.377832, Validation loss: 1.3712, lr: 0.0000\n",
      "Epoch: 766, Training loss: 1.380789, Validation loss: 1.3730, lr: 0.0000\n",
      "Epoch: 767, Training loss: 1.384915, Validation loss: 1.3909, lr: 0.0000\n",
      "Epoch: 768, Training loss: 1.372481, Validation loss: 1.4077, lr: 0.0000\n",
      "Epoch: 769, Training loss: 1.378003, Validation loss: 1.3685, lr: 0.0000\n",
      "Epoch: 770, Training loss: 1.371507, Validation loss: 1.3786, lr: 0.0000\n",
      "Epoch: 771, Training loss: 1.369889, Validation loss: 1.4097, lr: 0.0000\n",
      "Epoch: 772, Training loss: 1.356387, Validation loss: 1.8507, lr: 0.0000\n",
      "Epoch: 773, Training loss: 1.372450, Validation loss: 1.3800, lr: 0.0000\n",
      "Epoch: 774, Training loss: 1.378604, Validation loss: 1.3796, lr: 0.0000\n",
      "Epoch: 775, Training loss: 1.383352, Validation loss: 1.3890, lr: 0.0000\n",
      "Epoch: 776, Training loss: 1.374217, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 777, Training loss: 1.384191, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 778, Training loss: 1.383491, Validation loss: 1.3709, lr: 0.0000\n",
      "Epoch: 779, Training loss: 1.379318, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 780, Training loss: 1.406081, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 781, Training loss: 1.375953, Validation loss: 1.3703, lr: 0.0000\n",
      "Epoch: 782, Training loss: 1.378027, Validation loss: 1.3746, lr: 0.0000\n",
      "Epoch: 783, Training loss: 1.382740, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 784, Training loss: 1.356294, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 785, Training loss: 1.361788, Validation loss: 1.3799, lr: 0.0000\n",
      "Epoch: 786, Training loss: 1.374669, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 787, Training loss: 1.383137, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 788, Training loss: 1.378697, Validation loss: 1.3934, lr: 0.0000\n",
      "Epoch: 789, Training loss: 1.379010, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 790, Training loss: 1.359184, Validation loss: 1.3665, lr: 0.0000\n",
      "Epoch: 791, Training loss: 1.390292, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 792, Training loss: 1.369281, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 793, Training loss: 1.382395, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 794, Training loss: 1.387183, Validation loss: 1.3751, lr: 0.0000\n",
      "Epoch: 795, Training loss: 1.370519, Validation loss: 1.3788, lr: 0.0000\n",
      "Epoch: 796, Training loss: 1.360049, Validation loss: 1.3727, lr: 0.0000\n",
      "Epoch: 797, Training loss: 1.365907, Validation loss: 1.3683, lr: 0.0000\n",
      "Epoch: 798, Training loss: 1.363577, Validation loss: 1.3559, lr: 0.0000\n",
      "Epoch: 799, Training loss: 1.377304, Validation loss: 3.3208, lr: 0.0000\n",
      "Epoch: 800, Training loss: 1.385960, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 801, Training loss: 1.382227, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 802, Training loss: 1.366092, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 803, Training loss: 1.350754, Validation loss: 1.5363, lr: 0.0000\n",
      "Epoch: 804, Training loss: 1.395059, Validation loss: 1.3687, lr: 0.0000\n",
      "Epoch: 805, Training loss: 1.365464, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 806, Training loss: 1.373615, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 807, Training loss: 1.383876, Validation loss: 1.4011, lr: 0.0000\n",
      "Epoch: 808, Training loss: 1.378608, Validation loss: 1.3627, lr: 0.0000\n",
      "Epoch: 809, Training loss: 1.379906, Validation loss: 1.3753, lr: 0.0000\n",
      "Epoch: 810, Training loss: 1.352734, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 811, Training loss: 1.382347, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 812, Training loss: 1.385505, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 813, Training loss: 1.384698, Validation loss: 1.3758, lr: 0.0000\n",
      "Epoch: 814, Training loss: 1.373566, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 815, Training loss: 1.389498, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 816, Training loss: 1.375464, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 817, Training loss: 1.379317, Validation loss: 1.3890, lr: 0.0000\n",
      "Epoch: 818, Training loss: 1.383771, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 819, Training loss: 1.368597, Validation loss: 1.3886, lr: 0.0000\n",
      "Epoch: 820, Training loss: 1.392673, Validation loss: 1.3938, lr: 0.0000\n",
      "Epoch: 821, Training loss: 1.395479, Validation loss: 1.3529, lr: 0.0000\n",
      "Epoch: 822, Training loss: 1.361521, Validation loss: 1.3921, lr: 0.0000\n",
      "Epoch: 823, Training loss: 1.388525, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 824, Training loss: 1.365044, Validation loss: 1.4142, lr: 0.0000\n",
      "Epoch: 825, Training loss: 1.376476, Validation loss: 1.4097, lr: 0.0000\n",
      "Epoch: 826, Training loss: 1.357976, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 827, Training loss: 1.366668, Validation loss: 1.3658, lr: 0.0000\n",
      "Epoch: 828, Training loss: 1.375150, Validation loss: 1.4026, lr: 0.0000\n",
      "Epoch: 829, Training loss: 1.373486, Validation loss: 1.3733, lr: 0.0000\n",
      "Epoch: 830, Training loss: 1.388761, Validation loss: 1.3878, lr: 0.0000\n",
      "Epoch: 831, Training loss: 1.370580, Validation loss: 1.4026, lr: 0.0000\n",
      " *och: 832, Training loss: 1.386831, Validation loss: 1.3065, lr: 0.0000\n",
      "Epoch: 833, Training loss: 1.408752, Validation loss: 1.3718, lr: 0.0000\n",
      "Epoch: 834, Training loss: 1.379546, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 835, Training loss: 1.382080, Validation loss: 1.5063, lr: 0.0000\n",
      "Epoch: 836, Training loss: 1.356601, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 837, Training loss: 1.376228, Validation loss: 1.3735, lr: 0.0000\n",
      "Epoch: 838, Training loss: 1.379192, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 839, Training loss: 1.390399, Validation loss: 1.3628, lr: 0.0000\n",
      "Epoch: 840, Training loss: 1.386552, Validation loss: 1.3788, lr: 0.0000\n",
      "Epoch: 841, Training loss: 1.384560, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 842, Training loss: 1.367592, Validation loss: 1.3703, lr: 0.0000\n",
      "Epoch: 843, Training loss: 1.363122, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 844, Training loss: 1.393798, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 845, Training loss: 1.380237, Validation loss: 1.3762, lr: 0.0000\n",
      "Epoch: 846, Training loss: 1.396656, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 847, Training loss: 1.385026, Validation loss: 1.3799, lr: 0.0000\n",
      "Epoch: 848, Training loss: 1.392327, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 849, Training loss: 1.373671, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 850, Training loss: 1.371188, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 851, Training loss: 1.391880, Validation loss: 1.3760, lr: 0.0000\n",
      "Epoch: 852, Training loss: 1.362568, Validation loss: 1.3723, lr: 0.0000\n",
      "Epoch: 853, Training loss: 1.373670, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 854, Training loss: 1.375685, Validation loss: 1.3725, lr: 0.0000\n",
      "Epoch: 855, Training loss: 1.406400, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 856, Training loss: 1.378938, Validation loss: 1.3739, lr: 0.0000\n",
      "Epoch: 857, Training loss: 1.375964, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 858, Training loss: 1.395056, Validation loss: 1.4520, lr: 0.0000\n",
      "Epoch: 859, Training loss: 1.381840, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 860, Training loss: 1.369958, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 861, Training loss: 1.372389, Validation loss: 1.4314, lr: 0.0000\n",
      "Epoch: 862, Training loss: 1.363857, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 863, Training loss: 1.393455, Validation loss: 1.4604, lr: 0.0000\n",
      "Epoch: 864, Training loss: 1.369863, Validation loss: 1.3790, lr: 0.0000\n",
      "Epoch: 865, Training loss: 1.370666, Validation loss: 1.3751, lr: 0.0000\n",
      "Epoch: 866, Training loss: 1.510443, Validation loss: 1.3797, lr: 0.0000\n",
      "Epoch: 867, Training loss: 1.372992, Validation loss: 1.3713, lr: 0.0000\n",
      "Epoch: 868, Training loss: 1.366545, Validation loss: 1.3799, lr: 0.0000\n",
      "Epoch: 869, Training loss: 1.386856, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 870, Training loss: 1.375904, Validation loss: 1.3955, lr: 0.0000\n",
      "Epoch: 871, Training loss: 1.375017, Validation loss: 1.3889, lr: 0.0000\n",
      "Epoch: 872, Training loss: 1.383386, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 873, Training loss: 1.388089, Validation loss: 1.3776, lr: 0.0000\n",
      "Epoch: 874, Training loss: 1.465284, Validation loss: 1.4218, lr: 0.0000\n",
      "Epoch: 875, Training loss: 1.392213, Validation loss: 1.3779, lr: 0.0000\n",
      "Epoch: 876, Training loss: 1.369538, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 877, Training loss: 1.394883, Validation loss: 1.3686, lr: 0.0000\n",
      "Epoch: 878, Training loss: 1.362577, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 879, Training loss: 1.375826, Validation loss: 1.3872, lr: 0.0000\n",
      "Epoch: 880, Training loss: 1.377935, Validation loss: 1.3759, lr: 0.0000\n",
      "Epoch: 881, Training loss: 1.464152, Validation loss: 1.3716, lr: 0.0000\n",
      "Epoch: 882, Training loss: 1.373141, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 883, Training loss: 1.359956, Validation loss: 1.3614, lr: 0.0000\n",
      "Epoch: 884, Training loss: 1.373289, Validation loss: 1.3913, lr: 0.0000\n",
      "Epoch: 885, Training loss: 1.363230, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 886, Training loss: 1.377872, Validation loss: 1.3761, lr: 0.0000\n",
      "Epoch: 887, Training loss: 1.397108, Validation loss: 1.3583, lr: 0.0000\n",
      "Epoch: 888, Training loss: 1.385562, Validation loss: 1.3809, lr: 0.0000\n",
      "Epoch: 889, Training loss: 1.384479, Validation loss: 1.3783, lr: 0.0000\n",
      "Epoch: 890, Training loss: 1.374092, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 891, Training loss: 1.395914, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 892, Training loss: 1.468075, Validation loss: 1.4001, lr: 0.0000\n",
      "Epoch: 893, Training loss: 1.388231, Validation loss: 1.3341, lr: 0.0000\n",
      "Epoch: 894, Training loss: 1.388401, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 895, Training loss: 1.411269, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 896, Training loss: 1.378831, Validation loss: 1.3765, lr: 0.0000\n",
      "Epoch: 897, Training loss: 1.371762, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 898, Training loss: 1.355962, Validation loss: 1.5429, lr: 0.0000\n",
      "Epoch: 899, Training loss: 1.373653, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 900, Training loss: 1.410322, Validation loss: 1.3622, lr: 0.0000\n",
      "Epoch: 901, Training loss: 1.372927, Validation loss: 1.3678, lr: 0.0000\n",
      "Epoch: 902, Training loss: 1.365709, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 903, Training loss: 1.396703, Validation loss: 1.3591, lr: 0.0000\n",
      "Epoch: 904, Training loss: 1.383211, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 905, Training loss: 1.371963, Validation loss: 1.3988, lr: 0.0000\n",
      "Epoch: 906, Training loss: 1.378199, Validation loss: 1.3691, lr: 0.0000\n",
      "Epoch: 907, Training loss: 1.393405, Validation loss: 1.3642, lr: 0.0000\n",
      "Epoch: 908, Training loss: 1.370973, Validation loss: 1.3878, lr: 0.0000\n",
      "Epoch: 909, Training loss: 1.385214, Validation loss: 1.3895, lr: 0.0000\n",
      "Epoch: 910, Training loss: 1.366222, Validation loss: 1.3916, lr: 0.0000\n",
      "Epoch: 911, Training loss: 1.359023, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 912, Training loss: 1.376244, Validation loss: 1.3753, lr: 0.0000\n",
      "Epoch: 913, Training loss: 1.378345, Validation loss: 1.3508, lr: 0.0000\n",
      "Epoch: 914, Training loss: 1.387874, Validation loss: 1.3691, lr: 0.0000\n",
      "Epoch: 915, Training loss: 1.387182, Validation loss: 1.3763, lr: 0.0000\n",
      "Epoch: 916, Training loss: 1.400607, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 917, Training loss: 1.369236, Validation loss: 1.3889, lr: 0.0000\n",
      "Epoch: 918, Training loss: 1.354875, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 919, Training loss: 1.388916, Validation loss: 1.5010, lr: 0.0000\n",
      "Epoch: 920, Training loss: 1.374356, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 921, Training loss: 1.394416, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 922, Training loss: 1.387401, Validation loss: 1.3690, lr: 0.0000\n",
      "Epoch: 923, Training loss: 1.394723, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 924, Training loss: 1.390912, Validation loss: 1.3884, lr: 0.0000\n",
      "Epoch: 925, Training loss: 1.368211, Validation loss: 1.3931, lr: 0.0000\n",
      "Epoch: 926, Training loss: 1.359598, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 927, Training loss: 1.378443, Validation loss: 1.3753, lr: 0.0000\n",
      "Epoch: 928, Training loss: 1.366108, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 929, Training loss: 1.400663, Validation loss: 1.3718, lr: 0.0000\n",
      "Epoch: 930, Training loss: 1.378758, Validation loss: 1.3788, lr: 0.0000\n",
      "Epoch: 931, Training loss: 1.388847, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 932, Training loss: 1.409732, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 933, Training loss: 1.376768, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 934, Training loss: 1.378740, Validation loss: 1.3725, lr: 0.0000\n",
      "Epoch: 935, Training loss: 1.384828, Validation loss: 1.3654, lr: 0.0000\n",
      "Epoch: 936, Training loss: 1.380408, Validation loss: 1.4389, lr: 0.0000\n",
      "Epoch: 937, Training loss: 1.397363, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 938, Training loss: 1.395348, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 939, Training loss: 1.380977, Validation loss: 1.3778, lr: 0.0000\n",
      "Epoch: 940, Training loss: 1.388014, Validation loss: 1.3744, lr: 0.0000\n",
      "Epoch: 941, Training loss: 1.380349, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 942, Training loss: 1.363404, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 943, Training loss: 1.366990, Validation loss: 1.3797, lr: 0.0000\n",
      "Epoch: 944, Training loss: 1.521158, Validation loss: 1.4134, lr: 0.0000\n",
      "Epoch: 945, Training loss: 1.374158, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 946, Training loss: 1.363745, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 947, Training loss: 1.374539, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 948, Training loss: 1.388168, Validation loss: 1.3736, lr: 0.0000\n",
      "Epoch: 949, Training loss: 1.375496, Validation loss: 1.3752, lr: 0.0000\n",
      "Epoch: 950, Training loss: 1.394038, Validation loss: 1.3756, lr: 0.0000\n",
      "Epoch: 951, Training loss: 1.370887, Validation loss: 1.3790, lr: 0.0000\n",
      "Epoch: 952, Training loss: 1.372088, Validation loss: 1.4579, lr: 0.0000\n",
      "Epoch: 953, Training loss: 1.378933, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 954, Training loss: 1.367365, Validation loss: 1.3796, lr: 0.0000\n",
      "Epoch: 955, Training loss: 1.400740, Validation loss: 1.3881, lr: 0.0000\n",
      "Epoch: 956, Training loss: 1.385497, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 957, Training loss: 1.370640, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 958, Training loss: 1.378562, Validation loss: 1.3693, lr: 0.0000\n",
      "Epoch: 959, Training loss: 1.395386, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 960, Training loss: 1.383575, Validation loss: 1.3765, lr: 0.0000\n",
      "Epoch: 961, Training loss: 1.397324, Validation loss: 1.3519, lr: 0.0000\n",
      "Epoch: 962, Training loss: 1.391015, Validation loss: 1.3588, lr: 0.0000\n",
      "Epoch: 963, Training loss: 1.382023, Validation loss: 1.3778, lr: 0.0000\n",
      "Epoch: 964, Training loss: 1.366532, Validation loss: 1.3722, lr: 0.0000\n",
      "Epoch: 965, Training loss: 1.387269, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 966, Training loss: 1.368754, Validation loss: 1.3752, lr: 0.0000\n",
      "Epoch: 967, Training loss: 1.367114, Validation loss: 1.3930, lr: 0.0000\n",
      "Epoch: 968, Training loss: 1.369267, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 969, Training loss: 1.374102, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 970, Training loss: 1.366201, Validation loss: 1.3598, lr: 0.0000\n",
      "Epoch: 971, Training loss: 1.373890, Validation loss: 1.3296, lr: 0.0000\n",
      "Epoch: 972, Training loss: 1.374891, Validation loss: 1.3649, lr: 0.0000\n",
      "Epoch: 973, Training loss: 1.384699, Validation loss: 1.3658, lr: 0.0000\n",
      "Epoch: 974, Training loss: 1.380017, Validation loss: 1.3656, lr: 0.0000\n",
      "Epoch: 975, Training loss: 1.382722, Validation loss: 1.3890, lr: 0.0000\n",
      "Epoch: 976, Training loss: 1.350457, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 977, Training loss: 1.349970, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 978, Training loss: 1.378471, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 979, Training loss: 1.389752, Validation loss: 1.3762, lr: 0.0000\n",
      "Epoch: 980, Training loss: 1.380617, Validation loss: 1.3651, lr: 0.0000\n",
      "Epoch: 981, Training loss: 1.379583, Validation loss: 1.3637, lr: 0.0000\n",
      "Epoch: 982, Training loss: 1.381127, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 983, Training loss: 1.367988, Validation loss: 1.3776, lr: 0.0000\n",
      "Epoch: 984, Training loss: 1.363692, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 985, Training loss: 1.376748, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 986, Training loss: 1.361797, Validation loss: 1.3386, lr: 0.0000\n",
      "Epoch: 987, Training loss: 1.362442, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 988, Training loss: 1.370265, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 989, Training loss: 1.372556, Validation loss: 1.3365, lr: 0.0000\n",
      "Epoch: 990, Training loss: 1.387392, Validation loss: 1.4761, lr: 0.0000\n",
      "Epoch: 991, Training loss: 1.393800, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 992, Training loss: 1.394770, Validation loss: 1.3803, lr: 0.0000\n",
      "Epoch: 993, Training loss: 1.383108, Validation loss: 1.3737, lr: 0.0000\n",
      "Epoch: 994, Training loss: 1.394561, Validation loss: 1.3692, lr: 0.0000\n",
      "Epoch: 995, Training loss: 1.380450, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 996, Training loss: 1.360498, Validation loss: 1.3748, lr: 0.0000\n",
      "Epoch: 997, Training loss: 1.363589, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 998, Training loss: 1.376808, Validation loss: 1.3737, lr: 0.0000\n",
      "Epoch: 999, Training loss: 1.371333, Validation loss: 1.3835, lr: 0.0000\n",
      "Final test loss: 1.3856\n",
      "=== Run 05/10 ===\n",
      "\n",
      "---- Settings: \n",
      "\n",
      "epochs : 1000\n",
      "hidden_channels : [32]\n",
      "out_channels : 10\n",
      "inner_product_features : False\n",
      "batch_size : 64\n",
      "lr : 0.01\n",
      "momentum : 0.9\n",
      "dropout : 0.0\n",
      "batch_norm : batch_norm\n",
      "bias : True\n",
      "order : 2\n",
      "diffusion : True\n",
      "frac_sampled_nb : -1\n",
      "include_positions : False\n",
      "include_self : True\n",
      "vec_norm : False\n",
      "emb_norm : False\n",
      "seed : 0\n",
      "dim_signal : 100\n",
      "dim_emb : 100\n",
      "n_sampled_nb : -1\n",
      "\n",
      "---- Number of features to pass to the MLP:  1010100\n",
      "---- Total number of parameters:  32323627\n",
      "\n",
      "Using device cuda:0\n",
      "\n",
      "---- Training network ...\n",
      "\n",
      "---- Timestamp: 20250614-002734\n",
      "\n",
      " *och: 0, Training loss: 1.438192, Validation loss: 1.6614, lr: 0.0100\n",
      " *och: 1, Training loss: 1.427990, Validation loss: 1.3994, lr: 0.0100\n",
      " *och: 2, Training loss: 1.418647, Validation loss: 1.3743, lr: 0.0100\n",
      "Epoch: 3, Training loss: 1.415906, Validation loss: 1.3820, lr: 0.0100\n",
      "Epoch: 4, Training loss: 1.380423, Validation loss: 1.3858, lr: 0.0100\n",
      "Epoch: 5, Training loss: 1.381546, Validation loss: 1.3844, lr: 0.0100\n",
      "Epoch: 6, Training loss: 1.406686, Validation loss: 1.3856, lr: 0.0100\n",
      "Epoch: 7, Training loss: 1.383412, Validation loss: 1.3841, lr: 0.0100\n",
      "Epoch: 8, Training loss: 1.393125, Validation loss: 1.3834, lr: 0.0100\n",
      "Epoch: 9, Training loss: 1.366569, Validation loss: 1.3768, lr: 0.0100\n",
      "Epoch: 10, Training loss: 1.387131, Validation loss: 1.3843, lr: 0.0100\n",
      "Epoch: 11, Training loss: 1.387308, Validation loss: 1.3760, lr: 0.0100\n",
      "Epoch: 12, Training loss: 1.397605, Validation loss: 1.3943, lr: 0.0100\n",
      "Epoch: 13, Training loss: 1.366003, Validation loss: 1.3800, lr: 0.0100\n",
      "Epoch: 14, Training loss: 1.392938, Validation loss: 1.3792, lr: 0.0100\n",
      "Epoch: 15, Training loss: 1.397939, Validation loss: 1.3884, lr: 0.0100\n",
      " *och: 16, Training loss: 1.375727, Validation loss: 1.3542, lr: 0.0100\n",
      "Epoch: 17, Training loss: 1.376923, Validation loss: 1.3720, lr: 0.0100\n",
      "Epoch: 18, Training loss: 1.366008, Validation loss: 1.3826, lr: 0.0100\n",
      "Epoch: 19, Training loss: 1.413472, Validation loss: 1.3765, lr: 0.0100\n",
      "Epoch: 20, Training loss: 1.416147, Validation loss: 1.3820, lr: 0.0100\n",
      "Epoch: 21, Training loss: 1.374677, Validation loss: 1.3869, lr: 0.0100\n",
      "Epoch: 22, Training loss: 1.396814, Validation loss: 1.3851, lr: 0.0100\n",
      "Epoch: 23, Training loss: 1.371899, Validation loss: 1.3805, lr: 0.0100\n",
      "Epoch: 24, Training loss: 1.374032, Validation loss: 1.3782, lr: 0.0010\n",
      "Epoch: 25, Training loss: 1.367814, Validation loss: 1.3900, lr: 0.0010\n",
      "Epoch: 26, Training loss: 1.382623, Validation loss: 1.3719, lr: 0.0010\n",
      "Epoch: 27, Training loss: 1.390047, Validation loss: 1.3830, lr: 0.0010\n",
      "Epoch: 28, Training loss: 1.334367, Validation loss: 1.3716, lr: 0.0010\n",
      "Epoch: 29, Training loss: 1.374789, Validation loss: 1.3865, lr: 0.0010\n",
      "Epoch: 30, Training loss: 1.370380, Validation loss: 1.3879, lr: 0.0010\n",
      "Epoch: 31, Training loss: 1.371619, Validation loss: 1.3797, lr: 0.0010\n",
      "Epoch: 32, Training loss: 1.363132, Validation loss: 1.3852, lr: 0.0010\n",
      "Epoch: 33, Training loss: 1.389310, Validation loss: 1.3865, lr: 0.0010\n",
      "Epoch: 34, Training loss: 1.367927, Validation loss: 1.3821, lr: 0.0010\n",
      "Epoch: 35, Training loss: 1.362822, Validation loss: 1.3864, lr: 0.0010\n",
      "Epoch: 36, Training loss: 1.368435, Validation loss: 1.3786, lr: 0.0010\n",
      "Epoch: 37, Training loss: 1.402559, Validation loss: 1.3696, lr: 0.0010\n",
      "Epoch: 38, Training loss: 1.373367, Validation loss: 1.3781, lr: 0.0010\n",
      "Epoch: 39, Training loss: 1.362042, Validation loss: 1.3821, lr: 0.0001\n",
      "Epoch: 40, Training loss: 1.381958, Validation loss: 1.3825, lr: 0.0001\n",
      "Epoch: 41, Training loss: 1.365658, Validation loss: 1.3807, lr: 0.0001\n",
      "Epoch: 42, Training loss: 1.390246, Validation loss: 1.3822, lr: 0.0001\n",
      "Epoch: 43, Training loss: 1.363774, Validation loss: 1.3843, lr: 0.0001\n",
      "Epoch: 44, Training loss: 1.404385, Validation loss: 1.3746, lr: 0.0001\n",
      "Epoch: 45, Training loss: 1.356521, Validation loss: 1.3764, lr: 0.0001\n",
      "Epoch: 46, Training loss: 1.365211, Validation loss: 1.3812, lr: 0.0001\n",
      "Epoch: 47, Training loss: 1.389786, Validation loss: 1.3821, lr: 0.0001\n",
      "Epoch: 48, Training loss: 1.394845, Validation loss: 1.3844, lr: 0.0001\n",
      "Epoch: 49, Training loss: 1.372597, Validation loss: 1.3861, lr: 0.0001\n",
      "Epoch: 50, Training loss: 1.376354, Validation loss: 1.3875, lr: 0.0000\n",
      "Epoch: 51, Training loss: 1.372066, Validation loss: 1.3798, lr: 0.0000\n",
      "Epoch: 52, Training loss: 1.380313, Validation loss: 1.3927, lr: 0.0000\n",
      "Epoch: 53, Training loss: 1.370921, Validation loss: 1.3779, lr: 0.0000\n",
      "Epoch: 54, Training loss: 1.415477, Validation loss: 1.3614, lr: 0.0000\n",
      "Epoch: 55, Training loss: 1.366971, Validation loss: 1.3900, lr: 0.0000\n",
      "Epoch: 56, Training loss: 1.381425, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 57, Training loss: 1.367045, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 58, Training loss: 1.410401, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 59, Training loss: 1.379141, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 60, Training loss: 1.421793, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 61, Training loss: 1.409237, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 62, Training loss: 1.379324, Validation loss: 1.3780, lr: 0.0000\n",
      "Epoch: 63, Training loss: 1.406954, Validation loss: 1.3915, lr: 0.0000\n",
      "Epoch: 64, Training loss: 1.374866, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 65, Training loss: 1.363244, Validation loss: 1.3733, lr: 0.0000\n",
      "Epoch: 66, Training loss: 1.374322, Validation loss: 1.3881, lr: 0.0000\n",
      "Epoch: 67, Training loss: 1.346203, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 68, Training loss: 1.387088, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 69, Training loss: 1.386228, Validation loss: 1.4908, lr: 0.0000\n",
      "Epoch: 70, Training loss: 1.380943, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 71, Training loss: 1.378924, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 72, Training loss: 1.366332, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 73, Training loss: 1.378666, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 74, Training loss: 1.365010, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 75, Training loss: 1.352532, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 76, Training loss: 1.367323, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 77, Training loss: 1.373465, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 78, Training loss: 1.384111, Validation loss: 1.3675, lr: 0.0000\n",
      "Epoch: 79, Training loss: 1.388722, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 80, Training loss: 1.381130, Validation loss: 1.3780, lr: 0.0000\n",
      "Epoch: 81, Training loss: 1.456072, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 82, Training loss: 1.375848, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 83, Training loss: 1.362631, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 84, Training loss: 1.378199, Validation loss: 1.3795, lr: 0.0000\n",
      "Epoch: 85, Training loss: 1.375293, Validation loss: 1.4012, lr: 0.0000\n",
      "Epoch: 86, Training loss: 1.380930, Validation loss: 1.3894, lr: 0.0000\n",
      "Epoch: 87, Training loss: 1.389026, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 88, Training loss: 1.364512, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 89, Training loss: 1.426433, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 90, Training loss: 1.373756, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 91, Training loss: 1.359688, Validation loss: 1.3793, lr: 0.0000\n",
      "Epoch: 92, Training loss: 1.364871, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 93, Training loss: 1.381698, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 94, Training loss: 1.364604, Validation loss: 1.3793, lr: 0.0000\n",
      "Epoch: 95, Training loss: 1.368009, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 96, Training loss: 1.542370, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 97, Training loss: 1.378842, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 98, Training loss: 1.376921, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 99, Training loss: 1.419571, Validation loss: 1.3926, lr: 0.0000\n",
      "Epoch: 100, Training loss: 1.388449, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 101, Training loss: 1.373720, Validation loss: 1.4492, lr: 0.0000\n",
      "Epoch: 102, Training loss: 1.365868, Validation loss: 1.3787, lr: 0.0000\n",
      "Epoch: 103, Training loss: 1.390341, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 104, Training loss: 1.355905, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 105, Training loss: 1.353902, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 106, Training loss: 1.359560, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 107, Training loss: 1.383098, Validation loss: 1.3793, lr: 0.0000\n",
      "Epoch: 108, Training loss: 1.371484, Validation loss: 1.3722, lr: 0.0000\n",
      "Epoch: 109, Training loss: 1.375248, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 110, Training loss: 1.363749, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 111, Training loss: 1.373003, Validation loss: 1.3766, lr: 0.0000\n",
      "Epoch: 112, Training loss: 1.366366, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 113, Training loss: 1.377320, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 114, Training loss: 1.365870, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 115, Training loss: 1.395832, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 116, Training loss: 1.359977, Validation loss: 1.3767, lr: 0.0000\n",
      "Epoch: 117, Training loss: 1.350524, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 118, Training loss: 1.468362, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 119, Training loss: 1.371139, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 120, Training loss: 1.363367, Validation loss: 1.3816, lr: 0.0000\n",
      " *och: 121, Training loss: 1.376621, Validation loss: 1.3355, lr: 0.0000\n",
      "Epoch: 122, Training loss: 1.367794, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 123, Training loss: 1.362184, Validation loss: 1.3760, lr: 0.0000\n",
      "Epoch: 124, Training loss: 1.373770, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 125, Training loss: 1.383291, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 126, Training loss: 1.362164, Validation loss: 1.3791, lr: 0.0000\n",
      "Epoch: 127, Training loss: 1.353490, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 128, Training loss: 1.348945, Validation loss: 1.3913, lr: 0.0000\n",
      "Epoch: 129, Training loss: 1.359085, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 130, Training loss: 1.380388, Validation loss: 1.3684, lr: 0.0000\n",
      "Epoch: 131, Training loss: 1.405410, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 132, Training loss: 1.360892, Validation loss: 1.3693, lr: 0.0000\n",
      "Epoch: 133, Training loss: 1.362616, Validation loss: 1.3437, lr: 0.0000\n",
      "Epoch: 134, Training loss: 1.395122, Validation loss: 1.3877, lr: 0.0000\n",
      "Epoch: 135, Training loss: 1.362152, Validation loss: 1.3779, lr: 0.0000\n",
      "Epoch: 136, Training loss: 1.365909, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 137, Training loss: 1.370570, Validation loss: 1.3777, lr: 0.0000\n",
      "Epoch: 138, Training loss: 1.365537, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 139, Training loss: 1.353643, Validation loss: 1.3766, lr: 0.0000\n",
      "Epoch: 140, Training loss: 1.366764, Validation loss: 1.3699, lr: 0.0000\n",
      "Epoch: 141, Training loss: 1.369174, Validation loss: 1.3765, lr: 0.0000\n",
      "Epoch: 142, Training loss: 1.356999, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 143, Training loss: 1.398613, Validation loss: 1.3952, lr: 0.0000\n",
      "Epoch: 144, Training loss: 1.379029, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 145, Training loss: 1.367135, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 146, Training loss: 1.392272, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 147, Training loss: 1.376599, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 148, Training loss: 1.373757, Validation loss: 1.3738, lr: 0.0000\n",
      "Epoch: 149, Training loss: 1.377394, Validation loss: 1.3768, lr: 0.0000\n",
      "Epoch: 150, Training loss: 1.369173, Validation loss: 1.3767, lr: 0.0000\n",
      "Epoch: 151, Training loss: 1.369665, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 152, Training loss: 1.406722, Validation loss: 1.3796, lr: 0.0000\n",
      "Epoch: 153, Training loss: 1.379854, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 154, Training loss: 1.357374, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 155, Training loss: 1.363336, Validation loss: 1.3701, lr: 0.0000\n",
      "Epoch: 156, Training loss: 1.372446, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 157, Training loss: 1.361076, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 158, Training loss: 1.374956, Validation loss: 1.3770, lr: 0.0000\n",
      "Epoch: 159, Training loss: 1.355127, Validation loss: 1.3496, lr: 0.0000\n",
      "Epoch: 160, Training loss: 1.357046, Validation loss: 1.3888, lr: 0.0000\n",
      "Epoch: 161, Training loss: 1.384818, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 162, Training loss: 1.386778, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 163, Training loss: 1.336106, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 164, Training loss: 1.407481, Validation loss: 1.3881, lr: 0.0000\n",
      "Epoch: 165, Training loss: 1.357661, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 166, Training loss: 1.376201, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 167, Training loss: 1.427235, Validation loss: 1.3789, lr: 0.0000\n",
      "Epoch: 168, Training loss: 1.363825, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 169, Training loss: 1.399265, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 170, Training loss: 1.373267, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 171, Training loss: 1.376405, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 172, Training loss: 1.383205, Validation loss: 1.3794, lr: 0.0000\n",
      "Epoch: 173, Training loss: 1.367319, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 174, Training loss: 1.379264, Validation loss: 1.3750, lr: 0.0000\n",
      "Epoch: 175, Training loss: 1.366338, Validation loss: 1.3784, lr: 0.0000\n",
      "Epoch: 176, Training loss: 1.357469, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 177, Training loss: 1.371725, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 178, Training loss: 1.373130, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 179, Training loss: 1.370549, Validation loss: 1.3756, lr: 0.0000\n",
      "Epoch: 180, Training loss: 1.364421, Validation loss: 1.3779, lr: 0.0000\n",
      "Epoch: 181, Training loss: 1.377823, Validation loss: 1.3800, lr: 0.0000\n",
      "Epoch: 182, Training loss: 1.340397, Validation loss: 1.3796, lr: 0.0000\n",
      "Epoch: 183, Training loss: 1.351651, Validation loss: 1.3794, lr: 0.0000\n",
      "Epoch: 184, Training loss: 1.366476, Validation loss: 1.3685, lr: 0.0000\n",
      "Epoch: 185, Training loss: 1.381226, Validation loss: 1.3789, lr: 0.0000\n",
      "Epoch: 186, Training loss: 1.395433, Validation loss: 1.3697, lr: 0.0000\n",
      "Epoch: 187, Training loss: 1.406466, Validation loss: 1.3774, lr: 0.0000\n",
      "Epoch: 188, Training loss: 1.398130, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 189, Training loss: 1.377407, Validation loss: 1.3786, lr: 0.0000\n",
      "Epoch: 190, Training loss: 1.374839, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 191, Training loss: 1.363970, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 192, Training loss: 1.365836, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 193, Training loss: 1.363347, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 194, Training loss: 1.372442, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 195, Training loss: 1.365535, Validation loss: 1.3897, lr: 0.0000\n",
      "Epoch: 196, Training loss: 1.408727, Validation loss: 1.3748, lr: 0.0000\n",
      "Epoch: 197, Training loss: 1.417070, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 198, Training loss: 1.364257, Validation loss: 1.3789, lr: 0.0000\n",
      "Epoch: 199, Training loss: 1.368657, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 200, Training loss: 1.356645, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 201, Training loss: 1.364520, Validation loss: 1.3802, lr: 0.0000\n",
      "Epoch: 202, Training loss: 1.383290, Validation loss: 1.3910, lr: 0.0000\n",
      "Epoch: 203, Training loss: 1.378079, Validation loss: 1.3739, lr: 0.0000\n",
      "Epoch: 204, Training loss: 1.381392, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 205, Training loss: 1.373594, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 206, Training loss: 1.395165, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 207, Training loss: 1.380579, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 208, Training loss: 1.383543, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 209, Training loss: 1.380438, Validation loss: 1.3742, lr: 0.0000\n",
      "Epoch: 210, Training loss: 1.369562, Validation loss: 1.3950, lr: 0.0000\n",
      "Epoch: 211, Training loss: 1.367181, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 212, Training loss: 1.375883, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 213, Training loss: 1.388020, Validation loss: 1.3690, lr: 0.0000\n",
      "Epoch: 214, Training loss: 1.385964, Validation loss: 1.3787, lr: 0.0000\n",
      "Epoch: 215, Training loss: 1.356623, Validation loss: 1.3658, lr: 0.0000\n",
      "Epoch: 216, Training loss: 1.359488, Validation loss: 1.3682, lr: 0.0000\n",
      "Epoch: 217, Training loss: 1.375462, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 218, Training loss: 1.355193, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 219, Training loss: 1.379374, Validation loss: 1.3634, lr: 0.0000\n",
      "Epoch: 220, Training loss: 1.386545, Validation loss: 1.3698, lr: 0.0000\n",
      "Epoch: 221, Training loss: 1.374973, Validation loss: 1.3778, lr: 0.0000\n",
      "Epoch: 222, Training loss: 1.364751, Validation loss: 1.3704, lr: 0.0000\n",
      "Epoch: 223, Training loss: 1.368802, Validation loss: 1.3777, lr: 0.0000\n",
      "Epoch: 224, Training loss: 1.366828, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 225, Training loss: 1.365971, Validation loss: 1.3796, lr: 0.0000\n",
      "Epoch: 226, Training loss: 1.372669, Validation loss: 1.3876, lr: 0.0000\n",
      "Epoch: 227, Training loss: 1.383787, Validation loss: 1.3770, lr: 0.0000\n",
      "Epoch: 228, Training loss: 1.416230, Validation loss: 1.3753, lr: 0.0000\n",
      "Epoch: 229, Training loss: 1.384407, Validation loss: 1.3956, lr: 0.0000\n",
      "Epoch: 230, Training loss: 1.441459, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 231, Training loss: 1.384868, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 232, Training loss: 1.396133, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 233, Training loss: 1.368018, Validation loss: 1.3779, lr: 0.0000\n",
      "Epoch: 234, Training loss: 1.418512, Validation loss: 1.3695, lr: 0.0000\n",
      "Epoch: 235, Training loss: 1.395471, Validation loss: 1.3744, lr: 0.0000\n",
      "Epoch: 236, Training loss: 1.365497, Validation loss: 1.3883, lr: 0.0000\n",
      "Epoch: 237, Training loss: 1.356305, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 238, Training loss: 1.366622, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 239, Training loss: 1.380405, Validation loss: 1.3769, lr: 0.0000\n",
      "Epoch: 240, Training loss: 1.378182, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 241, Training loss: 1.368994, Validation loss: 1.3780, lr: 0.0000\n",
      "Epoch: 242, Training loss: 1.371566, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 243, Training loss: 1.346960, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 244, Training loss: 1.358327, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 245, Training loss: 1.360384, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 246, Training loss: 1.405590, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 247, Training loss: 1.389008, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 248, Training loss: 1.384941, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 249, Training loss: 1.374618, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 250, Training loss: 1.391813, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 251, Training loss: 1.374280, Validation loss: 1.3605, lr: 0.0000\n",
      "Epoch: 252, Training loss: 1.354592, Validation loss: 1.3748, lr: 0.0000\n",
      "Epoch: 253, Training loss: 1.414804, Validation loss: 1.3912, lr: 0.0000\n",
      "Epoch: 254, Training loss: 1.372257, Validation loss: 1.3760, lr: 0.0000\n",
      "Epoch: 255, Training loss: 1.359465, Validation loss: 1.3773, lr: 0.0000\n",
      "Epoch: 256, Training loss: 1.382623, Validation loss: 1.3786, lr: 0.0000\n",
      "Epoch: 257, Training loss: 1.404557, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 258, Training loss: 1.375629, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 259, Training loss: 1.355230, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 260, Training loss: 1.366867, Validation loss: 1.3874, lr: 0.0000\n",
      "Epoch: 261, Training loss: 1.367881, Validation loss: 1.3893, lr: 0.0000\n",
      "Epoch: 262, Training loss: 1.377067, Validation loss: 1.3756, lr: 0.0000\n",
      "Epoch: 263, Training loss: 1.355692, Validation loss: 1.3903, lr: 0.0000\n",
      "Epoch: 264, Training loss: 1.382786, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 265, Training loss: 1.384049, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 266, Training loss: 1.384322, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 267, Training loss: 1.373191, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 268, Training loss: 1.376003, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 269, Training loss: 1.369395, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 270, Training loss: 1.397355, Validation loss: 1.3722, lr: 0.0000\n",
      "Epoch: 271, Training loss: 1.372112, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 272, Training loss: 1.377195, Validation loss: 1.3721, lr: 0.0000\n",
      "Epoch: 273, Training loss: 1.376753, Validation loss: 1.3745, lr: 0.0000\n",
      "Epoch: 274, Training loss: 1.386969, Validation loss: 1.3674, lr: 0.0000\n",
      "Epoch: 275, Training loss: 1.386949, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 276, Training loss: 1.377563, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 277, Training loss: 1.357397, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 278, Training loss: 1.351576, Validation loss: 1.3639, lr: 0.0000\n",
      "Epoch: 279, Training loss: 1.365201, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 280, Training loss: 1.369247, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 281, Training loss: 1.370377, Validation loss: 1.3791, lr: 0.0000\n",
      "Epoch: 282, Training loss: 1.355149, Validation loss: 1.3586, lr: 0.0000\n",
      "Epoch: 283, Training loss: 1.387071, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 284, Training loss: 1.369904, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 285, Training loss: 1.398881, Validation loss: 1.3782, lr: 0.0000\n",
      "Epoch: 286, Training loss: 1.361933, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 287, Training loss: 1.399675, Validation loss: 1.3781, lr: 0.0000\n",
      "Epoch: 288, Training loss: 1.369822, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 289, Training loss: 1.380212, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 290, Training loss: 1.387859, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 291, Training loss: 1.365135, Validation loss: 1.3800, lr: 0.0000\n",
      "Epoch: 292, Training loss: 1.357960, Validation loss: 1.3789, lr: 0.0000\n",
      "Epoch: 293, Training loss: 1.368745, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 294, Training loss: 1.366252, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 295, Training loss: 1.370668, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 296, Training loss: 1.362290, Validation loss: 1.3874, lr: 0.0000\n",
      "Epoch: 297, Training loss: 1.408662, Validation loss: 1.3770, lr: 0.0000\n",
      "Epoch: 298, Training loss: 1.372306, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 299, Training loss: 1.371239, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 300, Training loss: 1.383026, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 301, Training loss: 1.367754, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 302, Training loss: 1.371887, Validation loss: 1.3722, lr: 0.0000\n",
      "Epoch: 303, Training loss: 1.361672, Validation loss: 1.3889, lr: 0.0000\n",
      "Epoch: 304, Training loss: 1.373090, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 305, Training loss: 1.375831, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 306, Training loss: 1.371580, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 307, Training loss: 1.367409, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 308, Training loss: 1.368551, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 309, Training loss: 1.367584, Validation loss: 1.3798, lr: 0.0000\n",
      "Epoch: 310, Training loss: 1.381005, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 311, Training loss: 1.381138, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 312, Training loss: 1.373324, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 313, Training loss: 1.412736, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 314, Training loss: 1.372120, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 315, Training loss: 1.359635, Validation loss: 1.3902, lr: 0.0000\n",
      "Epoch: 316, Training loss: 1.381485, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 317, Training loss: 1.360894, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 318, Training loss: 1.369609, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 319, Training loss: 1.369101, Validation loss: 1.3894, lr: 0.0000\n",
      "Epoch: 320, Training loss: 1.371464, Validation loss: 1.3768, lr: 0.0000\n",
      "Epoch: 321, Training loss: 1.367277, Validation loss: 1.3718, lr: 0.0000\n",
      "Epoch: 322, Training loss: 1.382553, Validation loss: 1.3721, lr: 0.0000\n",
      "Epoch: 323, Training loss: 1.360160, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 324, Training loss: 1.378013, Validation loss: 1.3785, lr: 0.0000\n",
      "Epoch: 325, Training loss: 1.382576, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 326, Training loss: 1.377070, Validation loss: 1.3772, lr: 0.0000\n",
      "Epoch: 327, Training loss: 1.382657, Validation loss: 1.3767, lr: 0.0000\n",
      "Epoch: 328, Training loss: 1.387647, Validation loss: 1.3743, lr: 0.0000\n",
      "Epoch: 329, Training loss: 1.363007, Validation loss: 1.3894, lr: 0.0000\n",
      "Epoch: 330, Training loss: 1.382724, Validation loss: 1.3754, lr: 0.0000\n",
      "Epoch: 331, Training loss: 1.387299, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 332, Training loss: 1.398844, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 333, Training loss: 1.387194, Validation loss: 1.3643, lr: 0.0000\n",
      "Epoch: 334, Training loss: 1.374747, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 335, Training loss: 1.374514, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 336, Training loss: 1.373770, Validation loss: 1.3803, lr: 0.0000\n",
      "Epoch: 337, Training loss: 1.358589, Validation loss: 1.3927, lr: 0.0000\n",
      "Epoch: 338, Training loss: 1.399431, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 339, Training loss: 1.386646, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 340, Training loss: 1.415339, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 341, Training loss: 1.347819, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 342, Training loss: 1.401024, Validation loss: 1.3745, lr: 0.0000\n",
      "Epoch: 343, Training loss: 1.458129, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 344, Training loss: 1.351506, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 345, Training loss: 1.365731, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 346, Training loss: 1.377675, Validation loss: 1.3904, lr: 0.0000\n",
      "Epoch: 347, Training loss: 1.377097, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 348, Training loss: 1.350738, Validation loss: 1.3872, lr: 0.0000\n",
      "Epoch: 349, Training loss: 1.359542, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 350, Training loss: 1.367397, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 351, Training loss: 1.358557, Validation loss: 1.3884, lr: 0.0000\n",
      "Epoch: 352, Training loss: 1.387142, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 353, Training loss: 1.387414, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 354, Training loss: 1.382599, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 355, Training loss: 1.368932, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 356, Training loss: 1.382225, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 357, Training loss: 1.415705, Validation loss: 1.3560, lr: 0.0000\n",
      "Epoch: 358, Training loss: 1.387212, Validation loss: 1.3787, lr: 0.0000\n",
      "Epoch: 359, Training loss: 1.364607, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 360, Training loss: 1.362260, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 361, Training loss: 1.373047, Validation loss: 1.3799, lr: 0.0000\n",
      "Epoch: 362, Training loss: 1.327222, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 363, Training loss: 1.355859, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 364, Training loss: 1.387053, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 365, Training loss: 1.361946, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 366, Training loss: 1.368846, Validation loss: 1.3795, lr: 0.0000\n",
      "Epoch: 367, Training loss: 1.362527, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 368, Training loss: 1.384763, Validation loss: 1.3792, lr: 0.0000\n",
      "Epoch: 369, Training loss: 1.373604, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 370, Training loss: 1.374696, Validation loss: 1.3769, lr: 0.0000\n",
      "Epoch: 371, Training loss: 1.355083, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 372, Training loss: 1.373536, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 373, Training loss: 1.396039, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 374, Training loss: 1.369302, Validation loss: 1.3790, lr: 0.0000\n",
      "Epoch: 375, Training loss: 1.373977, Validation loss: 1.3785, lr: 0.0000\n",
      "Epoch: 376, Training loss: 1.360833, Validation loss: 1.3777, lr: 0.0000\n",
      "Epoch: 377, Training loss: 1.373616, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 378, Training loss: 1.375950, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 379, Training loss: 1.378059, Validation loss: 1.3910, lr: 0.0000\n",
      "Epoch: 380, Training loss: 1.363340, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 381, Training loss: 1.367386, Validation loss: 1.3775, lr: 0.0000\n",
      "Epoch: 382, Training loss: 1.383481, Validation loss: 1.3802, lr: 0.0000\n",
      "Epoch: 383, Training loss: 1.387750, Validation loss: 1.3872, lr: 0.0000\n",
      "Epoch: 384, Training loss: 1.371927, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 385, Training loss: 1.406104, Validation loss: 1.3800, lr: 0.0000\n",
      "Epoch: 386, Training loss: 1.364062, Validation loss: 1.4061, lr: 0.0000\n",
      "Epoch: 387, Training loss: 1.393931, Validation loss: 1.3773, lr: 0.0000\n",
      "Epoch: 388, Training loss: 1.383686, Validation loss: 1.3770, lr: 0.0000\n",
      "Epoch: 389, Training loss: 1.369540, Validation loss: 1.3758, lr: 0.0000\n",
      "Epoch: 390, Training loss: 1.374246, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 391, Training loss: 1.391519, Validation loss: 1.3751, lr: 0.0000\n",
      "Epoch: 392, Training loss: 1.368670, Validation loss: 1.3888, lr: 0.0000\n",
      "Epoch: 393, Training loss: 1.374096, Validation loss: 1.3760, lr: 0.0000\n",
      "Epoch: 394, Training loss: 1.365786, Validation loss: 1.3684, lr: 0.0000\n",
      "Epoch: 395, Training loss: 1.387684, Validation loss: 1.3780, lr: 0.0000\n",
      "Epoch: 396, Training loss: 1.368958, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 397, Training loss: 1.383607, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 398, Training loss: 1.391493, Validation loss: 1.3717, lr: 0.0000\n",
      "Epoch: 399, Training loss: 1.367490, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 400, Training loss: 1.378001, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 401, Training loss: 1.373096, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 402, Training loss: 1.372448, Validation loss: 1.3695, lr: 0.0000\n",
      "Epoch: 403, Training loss: 1.369364, Validation loss: 1.3796, lr: 0.0000\n",
      "Epoch: 404, Training loss: 1.365646, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 405, Training loss: 1.372995, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 406, Training loss: 1.386044, Validation loss: 1.3882, lr: 0.0000\n",
      "Epoch: 407, Training loss: 1.364813, Validation loss: 1.3777, lr: 0.0000\n",
      "Epoch: 408, Training loss: 1.359705, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 409, Training loss: 1.366276, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 410, Training loss: 1.373475, Validation loss: 1.3766, lr: 0.0000\n",
      "Epoch: 411, Training loss: 1.386645, Validation loss: 1.3880, lr: 0.0000\n",
      "Epoch: 412, Training loss: 1.369341, Validation loss: 1.3700, lr: 0.0000\n",
      "Epoch: 413, Training loss: 1.362270, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 414, Training loss: 1.372429, Validation loss: 1.3686, lr: 0.0000\n",
      "Epoch: 415, Training loss: 1.384870, Validation loss: 1.3970, lr: 0.0000\n",
      "Epoch: 416, Training loss: 1.355434, Validation loss: 1.3888, lr: 0.0000\n",
      "Epoch: 417, Training loss: 1.367797, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 418, Training loss: 1.383970, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 419, Training loss: 1.374130, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 420, Training loss: 1.371493, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 421, Training loss: 1.366415, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 422, Training loss: 1.374140, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 423, Training loss: 1.373903, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 424, Training loss: 1.382368, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 425, Training loss: 1.368274, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 426, Training loss: 1.369884, Validation loss: 1.4098, lr: 0.0000\n",
      "Epoch: 427, Training loss: 1.366901, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 428, Training loss: 1.369419, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 429, Training loss: 1.354005, Validation loss: 1.3896, lr: 0.0000\n",
      "Epoch: 430, Training loss: 1.378712, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 431, Training loss: 1.381811, Validation loss: 1.3736, lr: 0.0000\n",
      "Epoch: 432, Training loss: 1.372286, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 433, Training loss: 1.390094, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 434, Training loss: 1.365559, Validation loss: 1.3884, lr: 0.0000\n",
      "Epoch: 435, Training loss: 1.378698, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 436, Training loss: 1.366232, Validation loss: 1.3661, lr: 0.0000\n",
      "Epoch: 437, Training loss: 1.375387, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 438, Training loss: 1.379679, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 439, Training loss: 1.374248, Validation loss: 1.3775, lr: 0.0000\n",
      "Epoch: 440, Training loss: 1.365396, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 441, Training loss: 1.373432, Validation loss: 1.3793, lr: 0.0000\n",
      "Epoch: 442, Training loss: 1.352683, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 443, Training loss: 1.389609, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 444, Training loss: 1.361020, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 445, Training loss: 1.370803, Validation loss: 1.3907, lr: 0.0000\n",
      "Epoch: 446, Training loss: 1.368820, Validation loss: 1.3788, lr: 0.0000\n",
      "Epoch: 447, Training loss: 1.350490, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 448, Training loss: 1.455521, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 449, Training loss: 1.350417, Validation loss: 1.3788, lr: 0.0000\n",
      "Epoch: 450, Training loss: 1.360986, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 451, Training loss: 1.379084, Validation loss: 1.3956, lr: 0.0000\n",
      "Epoch: 452, Training loss: 1.362285, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 453, Training loss: 1.382292, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 454, Training loss: 1.353962, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 455, Training loss: 1.369324, Validation loss: 1.3771, lr: 0.0000\n",
      "Epoch: 456, Training loss: 1.384537, Validation loss: 1.3546, lr: 0.0000\n",
      "Epoch: 457, Training loss: 1.354977, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 458, Training loss: 1.385898, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 459, Training loss: 1.358820, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 460, Training loss: 1.379315, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 461, Training loss: 1.370070, Validation loss: 1.3713, lr: 0.0000\n",
      "Epoch: 462, Training loss: 1.372674, Validation loss: 1.3655, lr: 0.0000\n",
      "Epoch: 463, Training loss: 1.351246, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 464, Training loss: 1.376977, Validation loss: 1.3733, lr: 0.0000\n",
      "Epoch: 465, Training loss: 1.390946, Validation loss: 1.3751, lr: 0.0000\n",
      "Epoch: 466, Training loss: 1.375129, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 467, Training loss: 1.379286, Validation loss: 1.3773, lr: 0.0000\n",
      "Epoch: 468, Training loss: 1.436359, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 469, Training loss: 1.393092, Validation loss: 1.3698, lr: 0.0000\n",
      "Epoch: 470, Training loss: 1.373706, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 471, Training loss: 1.370659, Validation loss: 1.3795, lr: 0.0000\n",
      "Epoch: 472, Training loss: 1.364998, Validation loss: 1.3794, lr: 0.0000\n",
      "Epoch: 473, Training loss: 1.357661, Validation loss: 1.3660, lr: 0.0000\n",
      "Epoch: 474, Training loss: 1.365890, Validation loss: 1.3797, lr: 0.0000\n",
      "Epoch: 475, Training loss: 1.375766, Validation loss: 1.4725, lr: 0.0000\n",
      "Epoch: 476, Training loss: 1.351795, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 477, Training loss: 1.373176, Validation loss: 1.3761, lr: 0.0000\n",
      "Epoch: 478, Training loss: 1.372221, Validation loss: 1.3793, lr: 0.0000\n",
      "Epoch: 479, Training loss: 1.379886, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 480, Training loss: 1.415880, Validation loss: 1.3961, lr: 0.0000\n",
      "Epoch: 481, Training loss: 1.372491, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 482, Training loss: 1.353637, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 483, Training loss: 1.378836, Validation loss: 1.3803, lr: 0.0000\n",
      "Epoch: 484, Training loss: 1.375233, Validation loss: 1.3874, lr: 0.0000\n",
      "Epoch: 485, Training loss: 1.350316, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 486, Training loss: 1.376466, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 487, Training loss: 1.379376, Validation loss: 1.3775, lr: 0.0000\n",
      "Epoch: 488, Training loss: 1.367916, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 489, Training loss: 1.365821, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 490, Training loss: 1.367856, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 491, Training loss: 1.389379, Validation loss: 1.3743, lr: 0.0000\n",
      "Epoch: 492, Training loss: 1.358362, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 493, Training loss: 1.363341, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 494, Training loss: 1.362646, Validation loss: 1.3892, lr: 0.0000\n",
      "Epoch: 495, Training loss: 1.370303, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 496, Training loss: 1.400773, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 497, Training loss: 1.371289, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 498, Training loss: 1.355605, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 499, Training loss: 1.446423, Validation loss: 1.3733, lr: 0.0000\n",
      "Epoch: 500, Training loss: 1.372238, Validation loss: 1.3730, lr: 0.0000\n",
      "Epoch: 501, Training loss: 1.393341, Validation loss: 1.3908, lr: 0.0000\n",
      "Epoch: 502, Training loss: 1.350833, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 503, Training loss: 1.375399, Validation loss: 1.3809, lr: 0.0000\n",
      "Epoch: 504, Training loss: 1.365388, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 505, Training loss: 1.368327, Validation loss: 1.3761, lr: 0.0000\n",
      "Epoch: 506, Training loss: 1.377378, Validation loss: 1.3780, lr: 0.0000\n",
      "Epoch: 507, Training loss: 1.378925, Validation loss: 1.3770, lr: 0.0000\n",
      "Epoch: 508, Training loss: 1.373943, Validation loss: 1.3782, lr: 0.0000\n",
      "Epoch: 509, Training loss: 1.376611, Validation loss: 1.4111, lr: 0.0000\n",
      "Epoch: 510, Training loss: 1.367791, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 511, Training loss: 1.357825, Validation loss: 1.3692, lr: 0.0000\n",
      "Epoch: 512, Training loss: 1.384287, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 513, Training loss: 1.364947, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 514, Training loss: 1.394929, Validation loss: 1.3872, lr: 0.0000\n",
      "Epoch: 515, Training loss: 1.376228, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 516, Training loss: 1.388595, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 517, Training loss: 1.391984, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 518, Training loss: 1.369454, Validation loss: 1.3755, lr: 0.0000\n",
      "Epoch: 519, Training loss: 1.368015, Validation loss: 1.3796, lr: 0.0000\n",
      "Epoch: 520, Training loss: 1.382085, Validation loss: 1.3876, lr: 0.0000\n",
      "Epoch: 521, Training loss: 1.434351, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 522, Training loss: 1.386469, Validation loss: 1.3875, lr: 0.0000\n",
      "Epoch: 523, Training loss: 1.356954, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 524, Training loss: 1.374934, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 525, Training loss: 1.375007, Validation loss: 1.3742, lr: 0.0000\n",
      "Epoch: 526, Training loss: 1.358756, Validation loss: 1.3773, lr: 0.0000\n",
      "Epoch: 527, Training loss: 1.376815, Validation loss: 1.3761, lr: 0.0000\n",
      "Epoch: 528, Training loss: 1.440477, Validation loss: 1.3764, lr: 0.0000\n",
      "Epoch: 529, Training loss: 1.372204, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 530, Training loss: 1.356062, Validation loss: 1.3742, lr: 0.0000\n",
      "Epoch: 531, Training loss: 1.376028, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 532, Training loss: 1.360769, Validation loss: 1.3894, lr: 0.0000\n",
      "Epoch: 533, Training loss: 1.372650, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 534, Training loss: 1.360001, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 535, Training loss: 1.385521, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 536, Training loss: 1.405512, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 537, Training loss: 1.381094, Validation loss: 1.3790, lr: 0.0000\n",
      "Epoch: 538, Training loss: 1.371844, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 539, Training loss: 1.381725, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 540, Training loss: 1.386301, Validation loss: 1.3748, lr: 0.0000\n",
      "Epoch: 541, Training loss: 1.374547, Validation loss: 1.4423, lr: 0.0000\n",
      "Epoch: 542, Training loss: 1.353690, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 543, Training loss: 1.357223, Validation loss: 1.3782, lr: 0.0000\n",
      "Epoch: 544, Training loss: 1.369512, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 545, Training loss: 1.401379, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 546, Training loss: 1.368808, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 547, Training loss: 1.363806, Validation loss: 1.3897, lr: 0.0000\n",
      "Epoch: 548, Training loss: 1.372732, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 549, Training loss: 1.366952, Validation loss: 1.3728, lr: 0.0000\n",
      "Epoch: 550, Training loss: 1.372211, Validation loss: 1.3744, lr: 0.0000\n",
      "Epoch: 551, Training loss: 1.391756, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 552, Training loss: 1.364419, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 553, Training loss: 1.366636, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 554, Training loss: 1.395769, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 555, Training loss: 1.396107, Validation loss: 1.3802, lr: 0.0000\n",
      "Epoch: 556, Training loss: 1.377258, Validation loss: 1.3790, lr: 0.0000\n",
      "Epoch: 557, Training loss: 1.365753, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 558, Training loss: 1.360340, Validation loss: 1.3779, lr: 0.0000\n",
      "Epoch: 559, Training loss: 1.385861, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 560, Training loss: 1.375913, Validation loss: 1.3800, lr: 0.0000\n",
      "Epoch: 561, Training loss: 1.388282, Validation loss: 1.3725, lr: 0.0000\n",
      "Epoch: 562, Training loss: 1.379510, Validation loss: 1.3978, lr: 0.0000\n",
      "Epoch: 563, Training loss: 1.376911, Validation loss: 1.3803, lr: 0.0000\n",
      "Epoch: 564, Training loss: 1.359635, Validation loss: 1.4362, lr: 0.0000\n",
      "Epoch: 565, Training loss: 1.363046, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 566, Training loss: 1.365114, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 567, Training loss: 1.394085, Validation loss: 1.3719, lr: 0.0000\n",
      "Epoch: 568, Training loss: 1.396462, Validation loss: 1.3677, lr: 0.0000\n",
      "Epoch: 569, Training loss: 1.348643, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 570, Training loss: 1.368665, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 571, Training loss: 1.379023, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 572, Training loss: 1.370796, Validation loss: 1.3739, lr: 0.0000\n",
      "Epoch: 573, Training loss: 1.383150, Validation loss: 1.3719, lr: 0.0000\n",
      "Epoch: 574, Training loss: 1.351181, Validation loss: 1.3771, lr: 0.0000\n",
      "Epoch: 575, Training loss: 1.398684, Validation loss: 1.3662, lr: 0.0000\n",
      "Epoch: 576, Training loss: 1.393622, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 577, Training loss: 1.372420, Validation loss: 1.3959, lr: 0.0000\n",
      "Epoch: 578, Training loss: 1.358101, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 579, Training loss: 1.357613, Validation loss: 1.3577, lr: 0.0000\n",
      "Epoch: 580, Training loss: 1.380152, Validation loss: 1.3618, lr: 0.0000\n",
      "Epoch: 581, Training loss: 1.366897, Validation loss: 1.3779, lr: 0.0000\n",
      "Epoch: 582, Training loss: 1.368316, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 583, Training loss: 1.416888, Validation loss: 1.3873, lr: 0.0000\n",
      "Epoch: 584, Training loss: 1.368682, Validation loss: 1.3778, lr: 0.0000\n",
      "Epoch: 585, Training loss: 1.341886, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 586, Training loss: 1.380509, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 587, Training loss: 1.373744, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 588, Training loss: 1.375290, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 589, Training loss: 1.412721, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 590, Training loss: 1.408872, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 591, Training loss: 1.386976, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 592, Training loss: 1.361143, Validation loss: 1.3773, lr: 0.0000\n",
      "Epoch: 593, Training loss: 1.385217, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 594, Training loss: 1.379139, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 595, Training loss: 1.370703, Validation loss: 1.3887, lr: 0.0000\n",
      "Epoch: 596, Training loss: 1.361259, Validation loss: 1.3669, lr: 0.0000\n",
      "Epoch: 597, Training loss: 1.417727, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 598, Training loss: 1.386554, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 599, Training loss: 1.364514, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 600, Training loss: 1.386381, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 601, Training loss: 1.354078, Validation loss: 1.4080, lr: 0.0000\n",
      "Epoch: 602, Training loss: 1.428426, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 603, Training loss: 1.352882, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 604, Training loss: 1.353986, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 605, Training loss: 1.373020, Validation loss: 1.3883, lr: 0.0000\n",
      "Epoch: 606, Training loss: 1.376480, Validation loss: 1.3569, lr: 0.0000\n",
      "Epoch: 607, Training loss: 1.369971, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 608, Training loss: 1.362761, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 609, Training loss: 1.370815, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 610, Training loss: 1.390552, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 611, Training loss: 1.381938, Validation loss: 1.3879, lr: 0.0000\n",
      "Epoch: 612, Training loss: 1.371321, Validation loss: 1.3653, lr: 0.0000\n",
      "Epoch: 613, Training loss: 1.407003, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 614, Training loss: 1.364895, Validation loss: 1.3874, lr: 0.0000\n",
      "Epoch: 615, Training loss: 1.386473, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 616, Training loss: 1.368817, Validation loss: 1.3885, lr: 0.0000\n",
      "Epoch: 617, Training loss: 1.355005, Validation loss: 1.3879, lr: 0.0000\n",
      "Epoch: 618, Training loss: 1.378143, Validation loss: 1.3877, lr: 0.0000\n",
      "Epoch: 619, Training loss: 1.358239, Validation loss: 1.3929, lr: 0.0000\n",
      "Epoch: 620, Training loss: 1.362956, Validation loss: 1.3773, lr: 0.0000\n",
      "Epoch: 621, Training loss: 1.380244, Validation loss: 1.3748, lr: 0.0000\n",
      "Epoch: 622, Training loss: 1.402725, Validation loss: 1.3787, lr: 0.0000\n",
      "Epoch: 623, Training loss: 1.373674, Validation loss: 1.3809, lr: 0.0000\n",
      "Epoch: 624, Training loss: 1.375937, Validation loss: 1.3780, lr: 0.0000\n",
      "Epoch: 625, Training loss: 1.397947, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 626, Training loss: 1.379092, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 627, Training loss: 1.413468, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 628, Training loss: 1.362847, Validation loss: 1.3878, lr: 0.0000\n",
      "Epoch: 629, Training loss: 1.375050, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 630, Training loss: 1.373543, Validation loss: 1.3722, lr: 0.0000\n",
      "Epoch: 631, Training loss: 1.376891, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 632, Training loss: 1.382318, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 633, Training loss: 1.367699, Validation loss: 1.3783, lr: 0.0000\n",
      "Epoch: 634, Training loss: 1.412412, Validation loss: 1.3733, lr: 0.0000\n",
      "Epoch: 635, Training loss: 1.378501, Validation loss: 1.3800, lr: 0.0000\n",
      "Epoch: 636, Training loss: 1.360514, Validation loss: 1.3878, lr: 0.0000\n",
      "Epoch: 637, Training loss: 1.370952, Validation loss: 1.3795, lr: 0.0000\n",
      "Epoch: 638, Training loss: 1.375703, Validation loss: 1.3745, lr: 0.0000\n",
      "Epoch: 639, Training loss: 1.385801, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 640, Training loss: 1.374423, Validation loss: 1.3789, lr: 0.0000\n",
      "Epoch: 641, Training loss: 1.374281, Validation loss: 1.3786, lr: 0.0000\n",
      "Epoch: 642, Training loss: 1.378356, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 643, Training loss: 1.371844, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 644, Training loss: 1.378823, Validation loss: 1.3753, lr: 0.0000\n",
      "Epoch: 645, Training loss: 1.372445, Validation loss: 1.3785, lr: 0.0000\n",
      "Epoch: 646, Training loss: 1.392455, Validation loss: 1.3701, lr: 0.0000\n",
      "Epoch: 647, Training loss: 1.412275, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 648, Training loss: 1.378348, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 649, Training loss: 1.370330, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 650, Training loss: 1.407286, Validation loss: 1.3800, lr: 0.0000\n",
      "Epoch: 651, Training loss: 1.365577, Validation loss: 1.3788, lr: 0.0000\n",
      "Epoch: 652, Training loss: 1.379446, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 653, Training loss: 1.458189, Validation loss: 1.3799, lr: 0.0000\n",
      "Epoch: 654, Training loss: 1.379551, Validation loss: 1.3884, lr: 0.0000\n",
      "Epoch: 655, Training loss: 1.356468, Validation loss: 1.3776, lr: 0.0000\n",
      "Epoch: 656, Training loss: 1.383980, Validation loss: 1.3889, lr: 0.0000\n",
      "Epoch: 657, Training loss: 1.406078, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 658, Training loss: 1.377962, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 659, Training loss: 1.369306, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 660, Training loss: 1.413424, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 661, Training loss: 1.378252, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 662, Training loss: 1.377646, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 663, Training loss: 1.370870, Validation loss: 1.3789, lr: 0.0000\n",
      "Epoch: 664, Training loss: 1.381951, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 665, Training loss: 1.368128, Validation loss: 1.3786, lr: 0.0000\n",
      "Epoch: 666, Training loss: 1.384327, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 667, Training loss: 1.389167, Validation loss: 1.3803, lr: 0.0000\n",
      "Epoch: 668, Training loss: 1.374551, Validation loss: 1.3728, lr: 0.0000\n",
      "Epoch: 669, Training loss: 1.363430, Validation loss: 1.3791, lr: 0.0000\n",
      "Epoch: 670, Training loss: 1.374564, Validation loss: 1.3732, lr: 0.0000\n",
      "Epoch: 671, Training loss: 1.365066, Validation loss: 1.3887, lr: 0.0000\n",
      "Epoch: 672, Training loss: 1.360109, Validation loss: 1.3979, lr: 0.0000\n",
      "Epoch: 673, Training loss: 1.356653, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 674, Training loss: 1.372572, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 675, Training loss: 1.420357, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 676, Training loss: 1.392266, Validation loss: 1.3766, lr: 0.0000\n",
      "Epoch: 677, Training loss: 1.381738, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 678, Training loss: 1.367778, Validation loss: 1.3670, lr: 0.0000\n",
      "Epoch: 679, Training loss: 1.476142, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 680, Training loss: 1.372140, Validation loss: 1.3785, lr: 0.0000\n",
      "Epoch: 681, Training loss: 1.374813, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 682, Training loss: 1.367523, Validation loss: 1.3876, lr: 0.0000\n",
      "Epoch: 683, Training loss: 1.362622, Validation loss: 1.3620, lr: 0.0000\n",
      "Epoch: 684, Training loss: 1.393394, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 685, Training loss: 1.385903, Validation loss: 1.3797, lr: 0.0000\n",
      "Epoch: 686, Training loss: 1.366625, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 687, Training loss: 1.382129, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 688, Training loss: 1.423174, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 689, Training loss: 1.332726, Validation loss: 1.3908, lr: 0.0000\n",
      "Epoch: 690, Training loss: 1.382473, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 691, Training loss: 1.363155, Validation loss: 1.3904, lr: 0.0000\n",
      "Epoch: 692, Training loss: 1.379020, Validation loss: 1.3767, lr: 0.0000\n",
      "Epoch: 693, Training loss: 1.427018, Validation loss: 1.3623, lr: 0.0000\n",
      "Epoch: 694, Training loss: 1.372777, Validation loss: 1.3919, lr: 0.0000\n",
      "Epoch: 695, Training loss: 1.409221, Validation loss: 1.4975, lr: 0.0000\n",
      "Epoch: 696, Training loss: 1.386633, Validation loss: 1.3784, lr: 0.0000\n",
      "Epoch: 697, Training loss: 1.386937, Validation loss: 1.3650, lr: 0.0000\n",
      "Epoch: 698, Training loss: 1.379296, Validation loss: 1.3803, lr: 0.0000\n",
      "Epoch: 699, Training loss: 1.354821, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 700, Training loss: 1.368077, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 701, Training loss: 1.381595, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 702, Training loss: 1.356733, Validation loss: 1.3792, lr: 0.0000\n",
      "Epoch: 703, Training loss: 1.366787, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 704, Training loss: 1.377099, Validation loss: 1.3721, lr: 0.0000\n",
      "Epoch: 705, Training loss: 1.436402, Validation loss: 1.3809, lr: 0.0000\n",
      "Epoch: 706, Training loss: 1.368625, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 707, Training loss: 1.372073, Validation loss: 1.3878, lr: 0.0000\n",
      "Epoch: 708, Training loss: 1.369778, Validation loss: 1.3803, lr: 0.0000\n",
      "Epoch: 709, Training loss: 1.356373, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 710, Training loss: 1.374367, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 711, Training loss: 1.361066, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 712, Training loss: 1.377501, Validation loss: 1.3593, lr: 0.0000\n",
      "Epoch: 713, Training loss: 1.369102, Validation loss: 1.3479, lr: 0.0000\n",
      "Epoch: 714, Training loss: 1.374750, Validation loss: 1.3762, lr: 0.0000\n",
      "Epoch: 715, Training loss: 1.379851, Validation loss: 1.3747, lr: 0.0000\n",
      "Epoch: 716, Training loss: 1.368329, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 717, Training loss: 1.371864, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 718, Training loss: 1.365096, Validation loss: 1.3978, lr: 0.0000\n",
      "Epoch: 719, Training loss: 1.353210, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 720, Training loss: 1.373358, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 721, Training loss: 1.367152, Validation loss: 1.3509, lr: 0.0000\n",
      "Epoch: 722, Training loss: 1.357806, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 723, Training loss: 1.370080, Validation loss: 1.3794, lr: 0.0000\n",
      "Epoch: 724, Training loss: 1.379874, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 725, Training loss: 1.381936, Validation loss: 1.3911, lr: 0.0000\n",
      "Epoch: 726, Training loss: 1.364557, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 727, Training loss: 1.359775, Validation loss: 1.3683, lr: 0.0000\n",
      "Epoch: 728, Training loss: 1.458658, Validation loss: 1.3652, lr: 0.0000\n",
      "Epoch: 729, Training loss: 1.377510, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 730, Training loss: 1.374546, Validation loss: 1.3740, lr: 0.0000\n",
      "Epoch: 731, Training loss: 1.385922, Validation loss: 1.3706, lr: 0.0000\n",
      "Epoch: 732, Training loss: 1.376357, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 733, Training loss: 1.333689, Validation loss: 1.3719, lr: 0.0000\n",
      "Epoch: 734, Training loss: 1.359125, Validation loss: 1.3723, lr: 0.0000\n",
      "Epoch: 735, Training loss: 1.390017, Validation loss: 1.3803, lr: 0.0000\n",
      "Epoch: 736, Training loss: 1.367068, Validation loss: 1.3781, lr: 0.0000\n",
      "Epoch: 737, Training loss: 1.359155, Validation loss: 1.3365, lr: 0.0000\n",
      "Epoch: 738, Training loss: 1.365533, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 739, Training loss: 1.372011, Validation loss: 1.3746, lr: 0.0000\n",
      "Epoch: 740, Training loss: 1.390559, Validation loss: 1.3663, lr: 0.0000\n",
      "Epoch: 741, Training loss: 1.381194, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 742, Training loss: 1.372079, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 743, Training loss: 1.367425, Validation loss: 1.3871, lr: 0.0000\n",
      "Epoch: 744, Training loss: 1.470824, Validation loss: 1.3768, lr: 0.0000\n",
      "Epoch: 745, Training loss: 1.368460, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 746, Training loss: 1.362403, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 747, Training loss: 1.396807, Validation loss: 1.3784, lr: 0.0000\n",
      "Epoch: 748, Training loss: 1.397722, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 749, Training loss: 1.366730, Validation loss: 1.3769, lr: 0.0000\n",
      "Epoch: 750, Training loss: 1.338630, Validation loss: 1.3753, lr: 0.0000\n",
      "Epoch: 751, Training loss: 1.362169, Validation loss: 1.3784, lr: 0.0000\n",
      "Epoch: 752, Training loss: 1.375470, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 753, Training loss: 1.363778, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 754, Training loss: 1.365482, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 755, Training loss: 1.383463, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 756, Training loss: 1.369381, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 757, Training loss: 1.385602, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 758, Training loss: 1.424660, Validation loss: 1.3944, lr: 0.0000\n",
      "Epoch: 759, Training loss: 1.394507, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 760, Training loss: 1.434602, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 761, Training loss: 1.390679, Validation loss: 1.3877, lr: 0.0000\n",
      "Epoch: 762, Training loss: 1.370349, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 763, Training loss: 1.373590, Validation loss: 1.3923, lr: 0.0000\n",
      "Epoch: 764, Training loss: 1.355625, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 765, Training loss: 1.370084, Validation loss: 1.3768, lr: 0.0000\n",
      "Epoch: 766, Training loss: 1.373754, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 767, Training loss: 1.374930, Validation loss: 1.3787, lr: 0.0000\n",
      "Epoch: 768, Training loss: 1.360256, Validation loss: 1.3899, lr: 0.0000\n",
      "Epoch: 769, Training loss: 1.378881, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 770, Training loss: 1.375492, Validation loss: 1.3799, lr: 0.0000\n",
      "Epoch: 771, Training loss: 1.373360, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 772, Training loss: 1.367813, Validation loss: 1.3802, lr: 0.0000\n",
      "Epoch: 773, Training loss: 1.371100, Validation loss: 1.3771, lr: 0.0000\n",
      "Epoch: 774, Training loss: 1.376179, Validation loss: 1.3799, lr: 0.0000\n",
      "Epoch: 775, Training loss: 1.371145, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 776, Training loss: 1.362061, Validation loss: 1.3884, lr: 0.0000\n",
      "Epoch: 777, Training loss: 1.375226, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 778, Training loss: 1.370743, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 779, Training loss: 1.379999, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 780, Training loss: 1.376410, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 781, Training loss: 1.387428, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 782, Training loss: 1.371287, Validation loss: 1.3882, lr: 0.0000\n",
      "Epoch: 783, Training loss: 1.377709, Validation loss: 1.3632, lr: 0.0000\n",
      "Epoch: 784, Training loss: 1.379303, Validation loss: 1.3877, lr: 0.0000\n",
      "Epoch: 785, Training loss: 1.368399, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 786, Training loss: 1.364818, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 787, Training loss: 1.366041, Validation loss: 1.3876, lr: 0.0000\n",
      "Epoch: 788, Training loss: 1.363553, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 789, Training loss: 1.368021, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 790, Training loss: 1.378238, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 791, Training loss: 1.386501, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 792, Training loss: 1.365995, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 793, Training loss: 1.384284, Validation loss: 1.3795, lr: 0.0000\n",
      "Epoch: 794, Training loss: 1.369364, Validation loss: 1.3798, lr: 0.0000\n",
      "Epoch: 795, Training loss: 1.362656, Validation loss: 1.3747, lr: 0.0000\n",
      "Epoch: 796, Training loss: 1.394683, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 797, Training loss: 1.412785, Validation loss: 1.3895, lr: 0.0000\n",
      "Epoch: 798, Training loss: 1.378541, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 799, Training loss: 1.385172, Validation loss: 1.3905, lr: 0.0000\n",
      "Epoch: 800, Training loss: 1.382554, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 801, Training loss: 1.371413, Validation loss: 1.3496, lr: 0.0000\n",
      "Epoch: 802, Training loss: 1.375762, Validation loss: 1.3719, lr: 0.0000\n",
      "Epoch: 803, Training loss: 1.369963, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 804, Training loss: 1.358977, Validation loss: 1.3745, lr: 0.0000\n",
      "Epoch: 805, Training loss: 1.379328, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 806, Training loss: 1.363186, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 807, Training loss: 1.356927, Validation loss: 1.3892, lr: 0.0000\n",
      "Epoch: 808, Training loss: 1.370118, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 809, Training loss: 1.375046, Validation loss: 1.3897, lr: 0.0000\n",
      "Epoch: 810, Training loss: 1.378686, Validation loss: 1.3608, lr: 0.0000\n",
      "Epoch: 811, Training loss: 1.373501, Validation loss: 1.3718, lr: 0.0000\n",
      "Epoch: 812, Training loss: 1.478691, Validation loss: 1.3559, lr: 0.0000\n",
      "Epoch: 813, Training loss: 1.368260, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 814, Training loss: 1.376238, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 815, Training loss: 1.384826, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 816, Training loss: 1.364606, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 817, Training loss: 1.376961, Validation loss: 1.3777, lr: 0.0000\n",
      "Epoch: 818, Training loss: 1.350864, Validation loss: 1.3746, lr: 0.0000\n",
      "Epoch: 819, Training loss: 1.374895, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 820, Training loss: 1.386364, Validation loss: 1.3728, lr: 0.0000\n",
      "Epoch: 821, Training loss: 1.384280, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 822, Training loss: 1.367687, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 823, Training loss: 1.379387, Validation loss: 1.3765, lr: 0.0000\n",
      "Epoch: 824, Training loss: 1.366604, Validation loss: 1.3803, lr: 0.0000\n",
      "Epoch: 825, Training loss: 1.361347, Validation loss: 1.3759, lr: 0.0000\n",
      "Epoch: 826, Training loss: 1.370964, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 827, Training loss: 1.393698, Validation loss: 1.3905, lr: 0.0000\n",
      "Epoch: 828, Training loss: 1.352987, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 829, Training loss: 1.422947, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 830, Training loss: 1.384861, Validation loss: 1.3778, lr: 0.0000\n",
      "Epoch: 831, Training loss: 1.371489, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 832, Training loss: 1.369918, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 833, Training loss: 1.378426, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 834, Training loss: 1.393703, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 835, Training loss: 1.367070, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 836, Training loss: 1.392293, Validation loss: 1.3795, lr: 0.0000\n",
      "Epoch: 837, Training loss: 1.382466, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 838, Training loss: 1.389951, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 839, Training loss: 1.348084, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 840, Training loss: 1.368232, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 841, Training loss: 1.369876, Validation loss: 1.3702, lr: 0.0000\n",
      "Epoch: 842, Training loss: 1.370691, Validation loss: 1.3791, lr: 0.0000\n",
      "Epoch: 843, Training loss: 1.374608, Validation loss: 1.3724, lr: 0.0000\n",
      "Epoch: 844, Training loss: 1.359158, Validation loss: 1.3611, lr: 0.0000\n",
      "Epoch: 845, Training loss: 1.382222, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 846, Training loss: 1.374471, Validation loss: 1.3576, lr: 0.0000\n",
      "Epoch: 847, Training loss: 1.371532, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 848, Training loss: 1.366038, Validation loss: 1.3880, lr: 0.0000\n",
      "Epoch: 849, Training loss: 1.366626, Validation loss: 1.3749, lr: 0.0000\n",
      "Epoch: 850, Training loss: 1.368025, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 851, Training loss: 1.370362, Validation loss: 1.3734, lr: 0.0000\n",
      "Epoch: 852, Training loss: 1.385068, Validation loss: 1.3791, lr: 0.0000\n",
      "Epoch: 853, Training loss: 1.370091, Validation loss: 1.3765, lr: 0.0000\n",
      "Epoch: 854, Training loss: 1.373328, Validation loss: 1.3740, lr: 0.0000\n",
      "Epoch: 855, Training loss: 1.363858, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 856, Training loss: 1.361524, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 857, Training loss: 1.379038, Validation loss: 1.3726, lr: 0.0000\n",
      "Epoch: 858, Training loss: 1.369523, Validation loss: 1.3781, lr: 0.0000\n",
      "Epoch: 859, Training loss: 1.381529, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 860, Training loss: 1.372991, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 861, Training loss: 1.355800, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 862, Training loss: 1.371327, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 863, Training loss: 1.371376, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 864, Training loss: 1.347561, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 865, Training loss: 1.429442, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 866, Training loss: 1.422968, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 867, Training loss: 1.364866, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 868, Training loss: 1.386442, Validation loss: 1.3756, lr: 0.0000\n",
      "Epoch: 869, Training loss: 1.367836, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 870, Training loss: 1.376117, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 871, Training loss: 1.364011, Validation loss: 1.3739, lr: 0.0000\n",
      "Epoch: 872, Training loss: 1.384696, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 873, Training loss: 1.350219, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 874, Training loss: 1.372012, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 875, Training loss: 1.364667, Validation loss: 1.3586, lr: 0.0000\n",
      "Epoch: 876, Training loss: 1.360100, Validation loss: 1.3780, lr: 0.0000\n",
      "Epoch: 877, Training loss: 1.385620, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 878, Training loss: 1.358177, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 879, Training loss: 1.371152, Validation loss: 1.3648, lr: 0.0000\n",
      "Epoch: 880, Training loss: 1.363002, Validation loss: 1.3882, lr: 0.0000\n",
      "Epoch: 881, Training loss: 1.371562, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 882, Training loss: 1.374010, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 883, Training loss: 1.380511, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 884, Training loss: 1.372576, Validation loss: 1.3707, lr: 0.0000\n",
      "Epoch: 885, Training loss: 1.359624, Validation loss: 1.3876, lr: 0.0000\n",
      "Epoch: 886, Training loss: 1.356905, Validation loss: 1.3798, lr: 0.0000\n",
      "Epoch: 887, Training loss: 1.376396, Validation loss: 1.3760, lr: 0.0000\n",
      "Epoch: 888, Training loss: 1.371179, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 889, Training loss: 1.391486, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 890, Training loss: 1.356191, Validation loss: 1.3874, lr: 0.0000\n",
      "Epoch: 891, Training loss: 1.368090, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 892, Training loss: 1.366945, Validation loss: 1.3764, lr: 0.0000\n",
      "Epoch: 893, Training loss: 1.363807, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 894, Training loss: 1.370712, Validation loss: 1.3713, lr: 0.0000\n",
      "Epoch: 895, Training loss: 1.403898, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 896, Training loss: 1.385552, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 897, Training loss: 1.368881, Validation loss: 1.3760, lr: 0.0000\n",
      "Epoch: 898, Training loss: 1.364125, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 899, Training loss: 1.387188, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 900, Training loss: 1.402834, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 901, Training loss: 1.378725, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 902, Training loss: 1.366856, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 903, Training loss: 1.376750, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 904, Training loss: 1.358803, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 905, Training loss: 1.375599, Validation loss: 1.3662, lr: 0.0000\n",
      "Epoch: 906, Training loss: 1.437949, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 907, Training loss: 1.382733, Validation loss: 1.4229, lr: 0.0000\n",
      "Epoch: 908, Training loss: 1.376409, Validation loss: 1.3927, lr: 0.0000\n",
      "Epoch: 909, Training loss: 1.418648, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 910, Training loss: 1.413036, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 911, Training loss: 1.362366, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 912, Training loss: 1.396216, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 913, Training loss: 1.394674, Validation loss: 1.3602, lr: 0.0000\n",
      "Epoch: 914, Training loss: 1.365458, Validation loss: 1.3792, lr: 0.0000\n",
      "Epoch: 915, Training loss: 1.372116, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 916, Training loss: 1.403218, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 917, Training loss: 1.367132, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 918, Training loss: 1.363086, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 919, Training loss: 1.362633, Validation loss: 1.3883, lr: 0.0000\n",
      "Epoch: 920, Training loss: 1.377755, Validation loss: 1.3892, lr: 0.0000\n",
      "Epoch: 921, Training loss: 1.388128, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 922, Training loss: 1.358493, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 923, Training loss: 1.378841, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 924, Training loss: 1.374034, Validation loss: 1.3766, lr: 0.0000\n",
      "Epoch: 925, Training loss: 1.345380, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 926, Training loss: 1.375319, Validation loss: 1.3760, lr: 0.0000\n",
      "Epoch: 927, Training loss: 1.387255, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 928, Training loss: 1.368360, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 929, Training loss: 1.360004, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 930, Training loss: 1.383162, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 931, Training loss: 1.368014, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 932, Training loss: 1.404164, Validation loss: 1.3882, lr: 0.0000\n",
      "Epoch: 933, Training loss: 1.369474, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 934, Training loss: 1.384653, Validation loss: 1.3765, lr: 0.0000\n",
      "Epoch: 935, Training loss: 1.362965, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 936, Training loss: 1.370605, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 937, Training loss: 1.391574, Validation loss: 1.3929, lr: 0.0000\n",
      "Epoch: 938, Training loss: 1.389502, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 939, Training loss: 1.367335, Validation loss: 1.4010, lr: 0.0000\n",
      "Epoch: 940, Training loss: 1.375071, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 941, Training loss: 1.368572, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 942, Training loss: 1.359457, Validation loss: 1.3992, lr: 0.0000\n",
      "Epoch: 943, Training loss: 1.378177, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 944, Training loss: 1.366501, Validation loss: 1.3789, lr: 0.0000\n",
      "Epoch: 945, Training loss: 1.371837, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 946, Training loss: 1.375504, Validation loss: 1.3741, lr: 0.0000\n",
      "Epoch: 947, Training loss: 1.373627, Validation loss: 1.3765, lr: 0.0000\n",
      "Epoch: 948, Training loss: 1.403843, Validation loss: 1.3788, lr: 0.0000\n",
      "Epoch: 949, Training loss: 1.386840, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 950, Training loss: 1.368162, Validation loss: 1.3787, lr: 0.0000\n",
      "Epoch: 951, Training loss: 1.377224, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 952, Training loss: 1.382196, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 953, Training loss: 1.373924, Validation loss: 1.3887, lr: 0.0000\n",
      "Epoch: 954, Training loss: 1.353141, Validation loss: 1.3724, lr: 0.0000\n",
      "Epoch: 955, Training loss: 1.349229, Validation loss: 1.3764, lr: 0.0000\n",
      "Epoch: 956, Training loss: 1.370489, Validation loss: 1.3792, lr: 0.0000\n",
      "Epoch: 957, Training loss: 1.365219, Validation loss: 1.3763, lr: 0.0000\n",
      "Epoch: 958, Training loss: 1.389142, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 959, Training loss: 1.363831, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 960, Training loss: 1.379410, Validation loss: 1.3672, lr: 0.0000\n",
      "Epoch: 961, Training loss: 1.370963, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 962, Training loss: 1.380714, Validation loss: 1.3777, lr: 0.0000\n",
      "Epoch: 963, Training loss: 1.377680, Validation loss: 1.3797, lr: 0.0000\n",
      "Epoch: 964, Training loss: 1.353528, Validation loss: 1.3891, lr: 0.0000\n",
      "Epoch: 965, Training loss: 1.374024, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 966, Training loss: 1.360599, Validation loss: 1.3769, lr: 0.0000\n",
      "Epoch: 967, Training loss: 1.362977, Validation loss: 1.3785, lr: 0.0000\n",
      "Epoch: 968, Training loss: 1.367652, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 969, Training loss: 1.369575, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 970, Training loss: 1.398622, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 971, Training loss: 1.372849, Validation loss: 1.3795, lr: 0.0000\n",
      "Epoch: 972, Training loss: 1.440496, Validation loss: 1.3885, lr: 0.0000\n",
      "Epoch: 973, Training loss: 1.385924, Validation loss: 1.3925, lr: 0.0000\n",
      "Epoch: 974, Training loss: 1.377960, Validation loss: 1.3871, lr: 0.0000\n",
      "Epoch: 975, Training loss: 1.381462, Validation loss: 1.3757, lr: 0.0000\n",
      "Epoch: 976, Training loss: 1.381169, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 977, Training loss: 1.386610, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 978, Training loss: 1.376017, Validation loss: 1.3787, lr: 0.0000\n",
      "Epoch: 979, Training loss: 1.363540, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 980, Training loss: 1.375478, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 981, Training loss: 1.379641, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 982, Training loss: 1.394334, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 983, Training loss: 1.370735, Validation loss: 1.4095, lr: 0.0000\n",
      "Epoch: 984, Training loss: 1.373261, Validation loss: 1.3692, lr: 0.0000\n",
      "Epoch: 985, Training loss: 1.382199, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 986, Training loss: 1.355966, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 987, Training loss: 1.372834, Validation loss: 1.3889, lr: 0.0000\n",
      "Epoch: 988, Training loss: 1.375721, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 989, Training loss: 1.374121, Validation loss: 1.3776, lr: 0.0000\n",
      "Epoch: 990, Training loss: 1.372142, Validation loss: 1.3802, lr: 0.0000\n",
      "Epoch: 991, Training loss: 1.367744, Validation loss: 1.3775, lr: 0.0000\n",
      "Epoch: 992, Training loss: 1.384558, Validation loss: 1.3726, lr: 0.0000\n",
      "Epoch: 993, Training loss: 1.455523, Validation loss: 1.3673, lr: 0.0000\n",
      "Epoch: 994, Training loss: 1.371716, Validation loss: 1.3780, lr: 0.0000\n",
      "Epoch: 995, Training loss: 1.362621, Validation loss: 1.3756, lr: 0.0000\n",
      "Epoch: 996, Training loss: 1.366088, Validation loss: 1.3877, lr: 0.0000\n",
      "Epoch: 997, Training loss: 1.370160, Validation loss: 1.3887, lr: 0.0000\n",
      "Epoch: 998, Training loss: 1.368176, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 999, Training loss: 1.375174, Validation loss: 1.3801, lr: 0.0000\n",
      "Final test loss: 1.3887\n",
      "=== Run 06/10 ===\n",
      "\n",
      "---- Settings: \n",
      "\n",
      "epochs : 1000\n",
      "hidden_channels : [32]\n",
      "out_channels : 10\n",
      "inner_product_features : False\n",
      "batch_size : 64\n",
      "lr : 0.01\n",
      "momentum : 0.9\n",
      "dropout : 0.0\n",
      "batch_norm : batch_norm\n",
      "bias : True\n",
      "order : 2\n",
      "diffusion : True\n",
      "frac_sampled_nb : -1\n",
      "include_positions : False\n",
      "include_self : True\n",
      "vec_norm : False\n",
      "emb_norm : False\n",
      "seed : 0\n",
      "dim_signal : 100\n",
      "dim_emb : 100\n",
      "n_sampled_nb : -1\n",
      "\n",
      "---- Number of features to pass to the MLP:  1010100\n",
      "---- Total number of parameters:  32323627\n",
      "\n",
      "Using device cuda:0\n",
      "\n",
      "---- Training network ...\n",
      "\n",
      "---- Timestamp: 20250614-013921\n",
      "\n",
      " *och: 0, Training loss: 1.403043, Validation loss: 1.4140, lr: 0.0100\n",
      " *och: 1, Training loss: 1.420389, Validation loss: 1.3973, lr: 0.0100\n",
      "Epoch: 2, Training loss: 1.506848, Validation loss: 1.6827, lr: 0.0100\n",
      " *och: 3, Training loss: 1.502563, Validation loss: 1.3782, lr: 0.0100\n",
      "Epoch: 4, Training loss: 1.458789, Validation loss: 1.3824, lr: 0.0100\n",
      " *och: 5, Training loss: 1.389312, Validation loss: 1.3566, lr: 0.0100\n",
      "Epoch: 6, Training loss: 1.399968, Validation loss: 1.3792, lr: 0.0100\n",
      "Epoch: 7, Training loss: 1.365398, Validation loss: 1.3846, lr: 0.0100\n",
      "Epoch: 8, Training loss: 1.385812, Validation loss: 1.3670, lr: 0.0100\n",
      "Epoch: 9, Training loss: 1.387131, Validation loss: 1.3804, lr: 0.0100\n",
      "Epoch: 10, Training loss: 1.367227, Validation loss: 1.3781, lr: 0.0100\n",
      "Epoch: 11, Training loss: 1.381631, Validation loss: 1.3791, lr: 0.0100\n",
      " *och: 12, Training loss: 1.395342, Validation loss: 1.3467, lr: 0.0100\n",
      "Epoch: 13, Training loss: 1.396480, Validation loss: 1.3761, lr: 0.0100\n",
      "Epoch: 14, Training loss: 1.381031, Validation loss: 1.3793, lr: 0.0100\n",
      "Epoch: 15, Training loss: 1.383110, Validation loss: 1.4075, lr: 0.0100\n",
      "Epoch: 16, Training loss: 1.377322, Validation loss: 1.3925, lr: 0.0100\n",
      "Epoch: 17, Training loss: 1.386956, Validation loss: 1.3784, lr: 0.0100\n",
      "Epoch: 18, Training loss: 1.377451, Validation loss: 1.3815, lr: 0.0010\n",
      "Epoch: 19, Training loss: 1.357867, Validation loss: 1.3846, lr: 0.0010\n",
      "Epoch: 20, Training loss: 1.400257, Validation loss: 1.3804, lr: 0.0010\n",
      "Epoch: 21, Training loss: 1.400570, Validation loss: 1.3868, lr: 0.0010\n",
      "Epoch: 22, Training loss: 1.376322, Validation loss: 1.3883, lr: 0.0010\n",
      "Epoch: 23, Training loss: 1.410861, Validation loss: 1.3823, lr: 0.0010\n",
      "Epoch: 24, Training loss: 1.369304, Validation loss: 1.3806, lr: 0.0010\n",
      "Epoch: 25, Training loss: 1.396739, Validation loss: 1.3864, lr: 0.0010\n",
      "Epoch: 26, Training loss: 1.374257, Validation loss: 1.3878, lr: 0.0010\n",
      "Epoch: 27, Training loss: 1.384123, Validation loss: 1.3852, lr: 0.0010\n",
      "Epoch: 28, Training loss: 1.365902, Validation loss: 1.3915, lr: 0.0010\n",
      "Epoch: 29, Training loss: 1.398724, Validation loss: 1.3729, lr: 0.0010\n",
      "Epoch: 30, Training loss: 1.405241, Validation loss: 1.3749, lr: 0.0001\n",
      "Epoch: 31, Training loss: 1.371949, Validation loss: 1.3781, lr: 0.0001\n",
      "Epoch: 32, Training loss: 1.388784, Validation loss: 1.3817, lr: 0.0001\n",
      "Epoch: 33, Training loss: 1.369132, Validation loss: 1.3833, lr: 0.0001\n",
      "Epoch: 34, Training loss: 1.359901, Validation loss: 1.3839, lr: 0.0001\n",
      "Epoch: 35, Training loss: 1.362530, Validation loss: 1.3762, lr: 0.0001\n",
      "Epoch: 36, Training loss: 1.383023, Validation loss: 1.3803, lr: 0.0001\n",
      "Epoch: 37, Training loss: 1.365299, Validation loss: 1.3846, lr: 0.0001\n",
      "Epoch: 38, Training loss: 1.399677, Validation loss: 1.3854, lr: 0.0001\n",
      "Epoch: 39, Training loss: 1.393754, Validation loss: 1.3804, lr: 0.0001\n",
      "Epoch: 40, Training loss: 1.394736, Validation loss: 1.4021, lr: 0.0001\n",
      "Epoch: 41, Training loss: 1.388102, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 42, Training loss: 1.412759, Validation loss: 1.3657, lr: 0.0000\n",
      "Epoch: 43, Training loss: 1.387362, Validation loss: 1.3809, lr: 0.0000\n",
      "Epoch: 44, Training loss: 1.372100, Validation loss: 1.3704, lr: 0.0000\n",
      "Epoch: 45, Training loss: 1.394914, Validation loss: 1.3976, lr: 0.0000\n",
      "Epoch: 46, Training loss: 1.379886, Validation loss: 1.3600, lr: 0.0000\n",
      "Epoch: 47, Training loss: 1.389665, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 48, Training loss: 1.381104, Validation loss: 1.3647, lr: 0.0000\n",
      "Epoch: 49, Training loss: 1.384404, Validation loss: 1.3873, lr: 0.0000\n",
      "Epoch: 50, Training loss: 1.375110, Validation loss: 1.3663, lr: 0.0000\n",
      "Epoch: 51, Training loss: 1.380364, Validation loss: 1.3796, lr: 0.0000\n",
      "Epoch: 52, Training loss: 1.401130, Validation loss: 1.3876, lr: 0.0000\n",
      "Epoch: 53, Training loss: 1.388911, Validation loss: 1.3695, lr: 0.0000\n",
      "Epoch: 54, Training loss: 1.387242, Validation loss: 1.3694, lr: 0.0000\n",
      "Epoch: 55, Training loss: 1.396298, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 56, Training loss: 1.398690, Validation loss: 1.3711, lr: 0.0000\n",
      "Epoch: 57, Training loss: 1.373519, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 58, Training loss: 1.399991, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 59, Training loss: 1.393008, Validation loss: 1.3714, lr: 0.0000\n",
      "Epoch: 60, Training loss: 1.377385, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 61, Training loss: 1.380611, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 62, Training loss: 1.358724, Validation loss: 1.3900, lr: 0.0000\n",
      "Epoch: 63, Training loss: 1.416061, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 64, Training loss: 1.376167, Validation loss: 1.3711, lr: 0.0000\n",
      "Epoch: 65, Training loss: 1.380400, Validation loss: 1.6164, lr: 0.0000\n",
      "Epoch: 66, Training loss: 1.380302, Validation loss: 1.3948, lr: 0.0000\n",
      "Epoch: 67, Training loss: 1.373618, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 68, Training loss: 1.379877, Validation loss: 1.3721, lr: 0.0000\n",
      "Epoch: 69, Training loss: 1.378833, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 70, Training loss: 1.370440, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 71, Training loss: 1.373124, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 72, Training loss: 1.388209, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 73, Training loss: 1.401960, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 74, Training loss: 1.376032, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 75, Training loss: 1.368729, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 76, Training loss: 1.385280, Validation loss: 1.3755, lr: 0.0000\n",
      "Epoch: 77, Training loss: 1.416237, Validation loss: 1.3583, lr: 0.0000\n",
      "Epoch: 78, Training loss: 1.398494, Validation loss: 1.3880, lr: 0.0000\n",
      "Epoch: 79, Training loss: 1.389513, Validation loss: 1.3780, lr: 0.0000\n",
      "Epoch: 80, Training loss: 1.373308, Validation loss: 1.3922, lr: 0.0000\n",
      "Epoch: 81, Training loss: 1.383736, Validation loss: 1.3610, lr: 0.0000\n",
      "Epoch: 82, Training loss: 1.363082, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 83, Training loss: 1.397569, Validation loss: 1.3693, lr: 0.0000\n",
      "Epoch: 84, Training loss: 1.427817, Validation loss: 1.3651, lr: 0.0000\n",
      "Epoch: 85, Training loss: 1.367525, Validation loss: 1.3900, lr: 0.0000\n",
      "Epoch: 86, Training loss: 1.379688, Validation loss: 1.3935, lr: 0.0000\n",
      "Epoch: 87, Training loss: 1.378710, Validation loss: 1.3790, lr: 0.0000\n",
      "Epoch: 88, Training loss: 1.391786, Validation loss: 1.3719, lr: 0.0000\n",
      "Epoch: 89, Training loss: 1.381764, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 90, Training loss: 1.375765, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 91, Training loss: 1.383894, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 92, Training loss: 1.406655, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 93, Training loss: 1.384553, Validation loss: 1.3798, lr: 0.0000\n",
      "Epoch: 94, Training loss: 1.383423, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 95, Training loss: 1.372501, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 96, Training loss: 1.405017, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 97, Training loss: 1.378665, Validation loss: 1.3971, lr: 0.0000\n",
      "Epoch: 98, Training loss: 1.378816, Validation loss: 1.5909, lr: 0.0000\n",
      "Epoch: 99, Training loss: 1.364026, Validation loss: 1.3760, lr: 0.0000\n",
      "Epoch: 100, Training loss: 1.411067, Validation loss: 1.3971, lr: 0.0000\n",
      "Epoch: 101, Training loss: 1.365369, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 102, Training loss: 1.374788, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 103, Training loss: 1.403607, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 104, Training loss: 1.399422, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 105, Training loss: 1.393295, Validation loss: 1.3646, lr: 0.0000\n",
      "Epoch: 106, Training loss: 1.425406, Validation loss: 1.3897, lr: 0.0000\n",
      "Epoch: 107, Training loss: 1.371994, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 108, Training loss: 1.382301, Validation loss: 1.3709, lr: 0.0000\n",
      "Epoch: 109, Training loss: 1.406982, Validation loss: 1.6124, lr: 0.0000\n",
      " *och: 110, Training loss: 1.401547, Validation loss: 1.3446, lr: 0.0000\n",
      "Epoch: 111, Training loss: 1.377683, Validation loss: 1.3786, lr: 0.0000\n",
      "Epoch: 112, Training loss: 1.388946, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 113, Training loss: 1.402490, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 114, Training loss: 1.375161, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 115, Training loss: 1.377195, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 116, Training loss: 1.351355, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 117, Training loss: 1.381566, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 118, Training loss: 1.393483, Validation loss: 1.3581, lr: 0.0000\n",
      "Epoch: 119, Training loss: 1.382879, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 120, Training loss: 1.389109, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 121, Training loss: 1.369652, Validation loss: 1.3798, lr: 0.0000\n",
      "Epoch: 122, Training loss: 1.398342, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 123, Training loss: 1.378120, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 124, Training loss: 1.382527, Validation loss: 1.3882, lr: 0.0000\n",
      "Epoch: 125, Training loss: 1.460038, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 126, Training loss: 1.377064, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 127, Training loss: 1.357454, Validation loss: 1.3975, lr: 0.0000\n",
      "Epoch: 128, Training loss: 1.400477, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 129, Training loss: 1.366222, Validation loss: 1.3546, lr: 0.0000\n",
      "Epoch: 130, Training loss: 1.392988, Validation loss: 1.3760, lr: 0.0000\n",
      "Epoch: 131, Training loss: 1.374370, Validation loss: 1.3920, lr: 0.0000\n",
      "Epoch: 132, Training loss: 1.385342, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 133, Training loss: 1.385411, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 134, Training loss: 1.376554, Validation loss: 1.3694, lr: 0.0000\n",
      "Epoch: 135, Training loss: 1.397520, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 136, Training loss: 1.381477, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 137, Training loss: 1.383106, Validation loss: 1.3745, lr: 0.0000\n",
      "Epoch: 138, Training loss: 1.376473, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 139, Training loss: 1.383977, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 140, Training loss: 1.400400, Validation loss: 1.3664, lr: 0.0000\n",
      "Epoch: 141, Training loss: 1.374324, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 142, Training loss: 1.446193, Validation loss: 1.3698, lr: 0.0000\n",
      "Epoch: 143, Training loss: 1.386371, Validation loss: 1.3911, lr: 0.0000\n",
      "Epoch: 144, Training loss: 1.402491, Validation loss: 1.3895, lr: 0.0000\n",
      "Epoch: 145, Training loss: 1.378425, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 146, Training loss: 1.371934, Validation loss: 1.3792, lr: 0.0000\n",
      "Epoch: 147, Training loss: 1.385053, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 148, Training loss: 1.380314, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 149, Training loss: 1.378205, Validation loss: 2.4692, lr: 0.0000\n",
      "Epoch: 150, Training loss: 1.372695, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 151, Training loss: 1.382039, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 152, Training loss: 1.388457, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 153, Training loss: 1.370596, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 154, Training loss: 1.372084, Validation loss: 1.3654, lr: 0.0000\n",
      "Epoch: 155, Training loss: 1.395561, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 156, Training loss: 1.428215, Validation loss: 1.3761, lr: 0.0000\n",
      "Epoch: 157, Training loss: 1.368274, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 158, Training loss: 1.373038, Validation loss: 1.3712, lr: 0.0000\n",
      "Epoch: 159, Training loss: 1.365739, Validation loss: 1.3708, lr: 0.0000\n",
      "Epoch: 160, Training loss: 1.393423, Validation loss: 1.3669, lr: 0.0000\n",
      "Epoch: 161, Training loss: 1.372772, Validation loss: 1.3876, lr: 0.0000\n",
      "Epoch: 162, Training loss: 1.394242, Validation loss: 1.3800, lr: 0.0000\n",
      "Epoch: 163, Training loss: 1.386520, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 164, Training loss: 1.408178, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 165, Training loss: 1.373449, Validation loss: 1.3599, lr: 0.0000\n",
      "Epoch: 166, Training loss: 1.374101, Validation loss: 1.3638, lr: 0.0000\n",
      "Epoch: 167, Training loss: 1.382985, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 168, Training loss: 1.387474, Validation loss: 1.3902, lr: 0.0000\n",
      "Epoch: 169, Training loss: 1.379526, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 170, Training loss: 1.398276, Validation loss: 1.4004, lr: 0.0000\n",
      "Epoch: 171, Training loss: 1.390690, Validation loss: 1.3881, lr: 0.0000\n",
      "Epoch: 172, Training loss: 1.372141, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 173, Training loss: 1.375222, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 174, Training loss: 1.396215, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 175, Training loss: 1.386031, Validation loss: 1.3772, lr: 0.0000\n",
      "Epoch: 176, Training loss: 1.367981, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 177, Training loss: 1.376675, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 178, Training loss: 1.427855, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 179, Training loss: 1.375396, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 180, Training loss: 1.384487, Validation loss: 1.4196, lr: 0.0000\n",
      "Epoch: 181, Training loss: 1.383354, Validation loss: 1.3896, lr: 0.0000\n",
      "Epoch: 182, Training loss: 1.460751, Validation loss: 1.3921, lr: 0.0000\n",
      "Epoch: 183, Training loss: 1.384263, Validation loss: 1.3875, lr: 0.0000\n",
      "Epoch: 184, Training loss: 1.382036, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 185, Training loss: 1.386104, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 186, Training loss: 1.372934, Validation loss: 1.3755, lr: 0.0000\n",
      "Epoch: 187, Training loss: 1.363144, Validation loss: 1.3792, lr: 0.0000\n",
      "Epoch: 188, Training loss: 1.416801, Validation loss: 1.3713, lr: 0.0000\n",
      "Epoch: 189, Training loss: 1.384010, Validation loss: 1.3871, lr: 0.0000\n",
      "Epoch: 190, Training loss: 1.382481, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 191, Training loss: 1.378127, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 192, Training loss: 1.384432, Validation loss: 1.3789, lr: 0.0000\n",
      "Epoch: 193, Training loss: 1.395036, Validation loss: 1.3789, lr: 0.0000\n",
      "Epoch: 194, Training loss: 1.410181, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 195, Training loss: 1.392260, Validation loss: 1.3902, lr: 0.0000\n",
      "Epoch: 196, Training loss: 1.378430, Validation loss: 1.3746, lr: 0.0000\n",
      "Epoch: 197, Training loss: 1.430578, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 198, Training loss: 1.398799, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 199, Training loss: 1.373316, Validation loss: 1.3745, lr: 0.0000\n",
      "Epoch: 200, Training loss: 1.394740, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 201, Training loss: 1.468866, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 202, Training loss: 1.376118, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 203, Training loss: 1.373208, Validation loss: 1.3553, lr: 0.0000\n",
      "Epoch: 204, Training loss: 1.379633, Validation loss: 1.3733, lr: 0.0000\n",
      "Epoch: 205, Training loss: 1.509453, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 206, Training loss: 1.404635, Validation loss: 1.4168, lr: 0.0000\n",
      "Epoch: 207, Training loss: 1.418509, Validation loss: 1.3773, lr: 0.0000\n",
      "Epoch: 208, Training loss: 1.379259, Validation loss: 1.3788, lr: 0.0000\n",
      "Epoch: 209, Training loss: 1.363270, Validation loss: 1.3798, lr: 0.0000\n",
      "Epoch: 210, Training loss: 1.378909, Validation loss: 1.3914, lr: 0.0000\n",
      "Epoch: 211, Training loss: 1.367746, Validation loss: 1.3702, lr: 0.0000\n",
      "Epoch: 212, Training loss: 1.375709, Validation loss: 1.4349, lr: 0.0000\n",
      "Epoch: 213, Training loss: 1.396648, Validation loss: 1.3697, lr: 0.0000\n",
      "Epoch: 214, Training loss: 1.371587, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 215, Training loss: 1.373047, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 216, Training loss: 1.367205, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 217, Training loss: 1.372616, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 218, Training loss: 1.372027, Validation loss: 1.3896, lr: 0.0000\n",
      "Epoch: 219, Training loss: 1.376084, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 220, Training loss: 1.377987, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 221, Training loss: 1.429880, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 222, Training loss: 1.478439, Validation loss: 1.3951, lr: 0.0000\n",
      "Epoch: 223, Training loss: 1.398586, Validation loss: 1.3786, lr: 0.0000\n",
      "Epoch: 224, Training loss: 1.380782, Validation loss: 1.3873, lr: 0.0000\n",
      "Epoch: 225, Training loss: 1.368404, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 226, Training loss: 1.372308, Validation loss: 1.3777, lr: 0.0000\n",
      "Epoch: 227, Training loss: 1.383434, Validation loss: 1.3784, lr: 0.0000\n",
      "Epoch: 228, Training loss: 1.382718, Validation loss: 1.3760, lr: 0.0000\n",
      "Epoch: 229, Training loss: 1.391193, Validation loss: 1.3605, lr: 0.0000\n",
      "Epoch: 230, Training loss: 1.389443, Validation loss: 1.3666, lr: 0.0000\n",
      "Epoch: 231, Training loss: 1.412861, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 232, Training loss: 1.397829, Validation loss: 1.3741, lr: 0.0000\n",
      "Epoch: 233, Training loss: 1.430807, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 234, Training loss: 1.367697, Validation loss: 1.3726, lr: 0.0000\n",
      "Epoch: 235, Training loss: 1.369880, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 236, Training loss: 1.384678, Validation loss: 1.3786, lr: 0.0000\n",
      "Epoch: 237, Training loss: 1.381049, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 238, Training loss: 1.390033, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 239, Training loss: 1.392555, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 240, Training loss: 1.409506, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 241, Training loss: 1.366067, Validation loss: 1.3809, lr: 0.0000\n",
      "Epoch: 242, Training loss: 1.381479, Validation loss: 1.3891, lr: 0.0000\n",
      "Epoch: 243, Training loss: 1.401710, Validation loss: 1.3890, lr: 0.0000\n",
      "Epoch: 244, Training loss: 1.387825, Validation loss: 1.3789, lr: 0.0000\n",
      "Epoch: 245, Training loss: 1.436102, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 246, Training loss: 1.380759, Validation loss: 1.4474, lr: 0.0000\n",
      "Epoch: 247, Training loss: 1.364495, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 248, Training loss: 1.399621, Validation loss: 1.3771, lr: 0.0000\n",
      "Epoch: 249, Training loss: 1.385225, Validation loss: 1.3752, lr: 0.0000\n",
      "Epoch: 250, Training loss: 1.406568, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 251, Training loss: 1.381362, Validation loss: 1.3881, lr: 0.0000\n",
      "Epoch: 252, Training loss: 1.396412, Validation loss: 1.3708, lr: 0.0000\n",
      " *och: 253, Training loss: 1.369041, Validation loss: 1.3297, lr: 0.0000\n",
      "Epoch: 254, Training loss: 1.376718, Validation loss: 1.3665, lr: 0.0000\n",
      "Epoch: 255, Training loss: 1.371123, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 256, Training loss: 1.382752, Validation loss: 1.3790, lr: 0.0000\n",
      "Epoch: 257, Training loss: 1.391087, Validation loss: 1.3749, lr: 0.0000\n",
      "Epoch: 258, Training loss: 1.375221, Validation loss: 1.3799, lr: 0.0000\n",
      "Epoch: 259, Training loss: 1.368892, Validation loss: 1.3796, lr: 0.0000\n",
      "Epoch: 260, Training loss: 1.367856, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 261, Training loss: 1.390421, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 262, Training loss: 1.371341, Validation loss: 1.3744, lr: 0.0000\n",
      "Epoch: 263, Training loss: 1.361763, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 264, Training loss: 1.384886, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 265, Training loss: 1.375545, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 266, Training loss: 1.439414, Validation loss: 1.3755, lr: 0.0000\n",
      "Epoch: 267, Training loss: 1.443751, Validation loss: 1.4372, lr: 0.0000\n",
      "Epoch: 268, Training loss: 1.382698, Validation loss: 1.3890, lr: 0.0000\n",
      "Epoch: 269, Training loss: 1.419881, Validation loss: 1.3916, lr: 0.0000\n",
      "Epoch: 270, Training loss: 1.412981, Validation loss: 1.3872, lr: 0.0000\n",
      "Epoch: 271, Training loss: 1.446472, Validation loss: 1.3881, lr: 0.0000\n",
      "Epoch: 272, Training loss: 1.388734, Validation loss: 1.3929, lr: 0.0000\n",
      "Epoch: 273, Training loss: 1.378086, Validation loss: 1.3553, lr: 0.0000\n",
      "Epoch: 274, Training loss: 1.371757, Validation loss: 1.3892, lr: 0.0000\n",
      "Epoch: 275, Training loss: 1.406431, Validation loss: 1.4934, lr: 0.0000\n",
      "Epoch: 276, Training loss: 1.362797, Validation loss: 1.3781, lr: 0.0000\n",
      "Epoch: 277, Training loss: 1.363025, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 278, Training loss: 1.394877, Validation loss: 1.3976, lr: 0.0000\n",
      "Epoch: 279, Training loss: 1.399824, Validation loss: 1.3666, lr: 0.0000\n",
      "Epoch: 280, Training loss: 1.398346, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 281, Training loss: 1.366767, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 282, Training loss: 1.380237, Validation loss: 1.3901, lr: 0.0000\n",
      "Epoch: 283, Training loss: 1.467662, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 284, Training loss: 1.385082, Validation loss: 1.3768, lr: 0.0000\n",
      "Epoch: 285, Training loss: 1.376797, Validation loss: 1.3789, lr: 0.0000\n",
      "Epoch: 286, Training loss: 1.366550, Validation loss: 1.3802, lr: 0.0000\n",
      "Epoch: 287, Training loss: 1.372555, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 288, Training loss: 1.418768, Validation loss: 1.3885, lr: 0.0000\n",
      "Epoch: 289, Training loss: 1.388696, Validation loss: 1.3738, lr: 0.0000\n",
      "Epoch: 290, Training loss: 1.376790, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 291, Training loss: 1.363302, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 292, Training loss: 1.387158, Validation loss: 1.3980, lr: 0.0000\n",
      "Epoch: 293, Training loss: 1.363938, Validation loss: 1.3768, lr: 0.0000\n",
      "Epoch: 294, Training loss: 1.427142, Validation loss: 1.3877, lr: 0.0000\n",
      "Epoch: 295, Training loss: 1.362572, Validation loss: 1.4120, lr: 0.0000\n",
      "Epoch: 296, Training loss: 1.396770, Validation loss: 1.4001, lr: 0.0000\n",
      "Epoch: 297, Training loss: 1.372998, Validation loss: 1.3885, lr: 0.0000\n",
      "Epoch: 298, Training loss: 1.385821, Validation loss: 1.3872, lr: 0.0000\n",
      "Epoch: 299, Training loss: 1.361298, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 300, Training loss: 1.381093, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 301, Training loss: 1.386999, Validation loss: 1.3711, lr: 0.0000\n",
      "Epoch: 302, Training loss: 1.379845, Validation loss: 1.3877, lr: 0.0000\n",
      "Epoch: 303, Training loss: 1.385659, Validation loss: 1.3683, lr: 0.0000\n",
      "Epoch: 304, Training loss: 1.397786, Validation loss: 1.3597, lr: 0.0000\n",
      "Epoch: 305, Training loss: 1.373848, Validation loss: 1.3693, lr: 0.0000\n",
      "Epoch: 306, Training loss: 1.378294, Validation loss: 1.3750, lr: 0.0000\n",
      "Epoch: 307, Training loss: 1.385404, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 308, Training loss: 1.379220, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 309, Training loss: 1.392369, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 310, Training loss: 1.363356, Validation loss: 1.3603, lr: 0.0000\n",
      "Epoch: 311, Training loss: 1.371570, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 312, Training loss: 1.376958, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 313, Training loss: 1.367236, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 314, Training loss: 1.371437, Validation loss: 1.3875, lr: 0.0000\n",
      "Epoch: 315, Training loss: 1.397930, Validation loss: 1.3708, lr: 0.0000\n",
      "Epoch: 316, Training loss: 1.383176, Validation loss: 1.3798, lr: 0.0000\n",
      "Epoch: 317, Training loss: 1.368415, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 318, Training loss: 1.383467, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 319, Training loss: 1.383442, Validation loss: 1.3613, lr: 0.0000\n",
      "Epoch: 320, Training loss: 1.379334, Validation loss: 1.3776, lr: 0.0000\n",
      "Epoch: 321, Training loss: 1.376922, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 322, Training loss: 1.374773, Validation loss: 1.3894, lr: 0.0000\n",
      "Epoch: 323, Training loss: 1.367688, Validation loss: 1.3884, lr: 0.0000\n",
      "Epoch: 324, Training loss: 1.365582, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 325, Training loss: 1.388091, Validation loss: 1.3732, lr: 0.0000\n",
      "Epoch: 326, Training loss: 1.380595, Validation loss: 1.3876, lr: 0.0000\n",
      "Epoch: 327, Training loss: 1.378779, Validation loss: 1.3745, lr: 0.0000\n",
      "Epoch: 328, Training loss: 1.388318, Validation loss: 1.3889, lr: 0.0000\n",
      "Epoch: 329, Training loss: 1.388556, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 330, Training loss: 1.368500, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 331, Training loss: 1.364482, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 332, Training loss: 1.389539, Validation loss: 1.3881, lr: 0.0000\n",
      "Epoch: 333, Training loss: 1.387051, Validation loss: 1.3883, lr: 0.0000\n",
      "Epoch: 334, Training loss: 1.380464, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 335, Training loss: 1.413475, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 336, Training loss: 1.381181, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 337, Training loss: 1.377110, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 338, Training loss: 1.363165, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 339, Training loss: 1.394947, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 340, Training loss: 1.376167, Validation loss: 1.3900, lr: 0.0000\n",
      "Epoch: 341, Training loss: 1.371571, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 342, Training loss: 1.394293, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 343, Training loss: 1.386033, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 344, Training loss: 1.403177, Validation loss: 1.3626, lr: 0.0000\n",
      " *och: 345, Training loss: 1.377031, Validation loss: 1.3158, lr: 0.0000\n",
      "Epoch: 346, Training loss: 1.375241, Validation loss: 1.3666, lr: 0.0000\n",
      "Epoch: 347, Training loss: 1.351351, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 348, Training loss: 1.398070, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 349, Training loss: 1.390009, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 350, Training loss: 1.385476, Validation loss: 1.3877, lr: 0.0000\n",
      "Epoch: 351, Training loss: 1.403234, Validation loss: 1.3871, lr: 0.0000\n",
      "Epoch: 352, Training loss: 1.362505, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 353, Training loss: 1.385623, Validation loss: 1.3914, lr: 0.0000\n",
      "Epoch: 354, Training loss: 1.405474, Validation loss: 1.3531, lr: 0.0000\n",
      "Epoch: 355, Training loss: 1.377703, Validation loss: 1.3876, lr: 0.0000\n",
      "Epoch: 356, Training loss: 1.391230, Validation loss: 1.3532, lr: 0.0000\n",
      "Epoch: 357, Training loss: 1.391605, Validation loss: 1.3797, lr: 0.0000\n",
      "Epoch: 358, Training loss: 1.363889, Validation loss: 1.3948, lr: 0.0000\n",
      "Epoch: 359, Training loss: 1.370454, Validation loss: 1.4289, lr: 0.0000\n",
      "Epoch: 360, Training loss: 1.374278, Validation loss: 1.3787, lr: 0.0000\n",
      "Epoch: 361, Training loss: 1.383009, Validation loss: 1.3716, lr: 0.0000\n",
      "Epoch: 362, Training loss: 1.375604, Validation loss: 1.3903, lr: 0.0000\n",
      "Epoch: 363, Training loss: 1.361208, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 364, Training loss: 1.379339, Validation loss: 1.3879, lr: 0.0000\n",
      "Epoch: 365, Training loss: 1.370537, Validation loss: 1.3669, lr: 0.0000\n",
      "Epoch: 366, Training loss: 1.377214, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 367, Training loss: 1.379885, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 368, Training loss: 1.384707, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 369, Training loss: 1.374585, Validation loss: 1.3679, lr: 0.0000\n",
      "Epoch: 370, Training loss: 1.381330, Validation loss: 1.3788, lr: 0.0000\n",
      "Epoch: 371, Training loss: 1.411732, Validation loss: 1.3722, lr: 0.0000\n",
      "Epoch: 372, Training loss: 1.433177, Validation loss: 1.3778, lr: 0.0000\n",
      "Epoch: 373, Training loss: 1.376984, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 374, Training loss: 1.384225, Validation loss: 1.3678, lr: 0.0000\n",
      "Epoch: 375, Training loss: 1.414348, Validation loss: 1.4487, lr: 0.0000\n",
      "Epoch: 376, Training loss: 1.374224, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 377, Training loss: 1.402488, Validation loss: 1.3689, lr: 0.0000\n",
      "Epoch: 378, Training loss: 1.368348, Validation loss: 1.3751, lr: 0.0000\n",
      "Epoch: 379, Training loss: 1.387241, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 380, Training loss: 1.370528, Validation loss: 1.3292, lr: 0.0000\n",
      "Epoch: 381, Training loss: 1.386839, Validation loss: 1.3776, lr: 0.0000\n",
      "Epoch: 382, Training loss: 1.374877, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 383, Training loss: 1.409638, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 384, Training loss: 1.391481, Validation loss: 1.3662, lr: 0.0000\n",
      "Epoch: 385, Training loss: 1.409901, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 386, Training loss: 1.383458, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 387, Training loss: 1.401537, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 388, Training loss: 1.346735, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 389, Training loss: 1.380502, Validation loss: 1.3685, lr: 0.0000\n",
      "Epoch: 390, Training loss: 1.368968, Validation loss: 1.3763, lr: 0.0000\n",
      "Epoch: 391, Training loss: 1.393911, Validation loss: 1.3779, lr: 0.0000\n",
      "Epoch: 392, Training loss: 1.359029, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 393, Training loss: 1.361503, Validation loss: 1.3729, lr: 0.0000\n",
      "Epoch: 394, Training loss: 1.385138, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 395, Training loss: 1.391934, Validation loss: 1.3517, lr: 0.0000\n",
      "Epoch: 396, Training loss: 1.401743, Validation loss: 1.3922, lr: 0.0000\n",
      "Epoch: 397, Training loss: 1.412772, Validation loss: 1.4070, lr: 0.0000\n",
      "Epoch: 398, Training loss: 1.468372, Validation loss: 1.3777, lr: 0.0000\n",
      "Epoch: 399, Training loss: 1.398600, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 400, Training loss: 1.368966, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 401, Training loss: 1.361304, Validation loss: 1.3782, lr: 0.0000\n",
      "Epoch: 402, Training loss: 1.387201, Validation loss: 1.3781, lr: 0.0000\n",
      "Epoch: 403, Training loss: 1.407504, Validation loss: 1.3434, lr: 0.0000\n",
      "Epoch: 404, Training loss: 1.397335, Validation loss: 1.3793, lr: 0.0000\n",
      "Epoch: 405, Training loss: 1.374967, Validation loss: 1.5018, lr: 0.0000\n",
      "Epoch: 406, Training loss: 1.365974, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 407, Training loss: 1.399266, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 408, Training loss: 1.379570, Validation loss: 1.3386, lr: 0.0000\n",
      "Epoch: 409, Training loss: 1.374008, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 410, Training loss: 1.375388, Validation loss: 1.3920, lr: 0.0000\n",
      "Epoch: 411, Training loss: 1.393321, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 412, Training loss: 1.381071, Validation loss: 1.3798, lr: 0.0000\n",
      "Epoch: 413, Training loss: 1.390531, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 414, Training loss: 1.377459, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 415, Training loss: 1.373309, Validation loss: 1.3913, lr: 0.0000\n",
      "Epoch: 416, Training loss: 1.368530, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 417, Training loss: 1.394249, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 418, Training loss: 1.395582, Validation loss: 1.3743, lr: 0.0000\n",
      "Epoch: 419, Training loss: 1.389545, Validation loss: 1.3753, lr: 0.0000\n",
      "Epoch: 420, Training loss: 1.401383, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 421, Training loss: 1.376415, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 422, Training loss: 1.390563, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 423, Training loss: 1.379030, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 424, Training loss: 1.376793, Validation loss: 1.3472, lr: 0.0000\n",
      "Epoch: 425, Training loss: 1.366488, Validation loss: 1.3728, lr: 0.0000\n",
      "Epoch: 426, Training loss: 1.369823, Validation loss: 1.3749, lr: 0.0000\n",
      "Epoch: 427, Training loss: 1.396326, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 428, Training loss: 1.401166, Validation loss: 1.3584, lr: 0.0000\n",
      "Epoch: 429, Training loss: 1.393793, Validation loss: 1.3730, lr: 0.0000\n",
      "Epoch: 430, Training loss: 1.385453, Validation loss: 1.3792, lr: 0.0000\n",
      "Epoch: 431, Training loss: 1.382777, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 432, Training loss: 1.407814, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 433, Training loss: 1.396857, Validation loss: 1.3784, lr: 0.0000\n",
      "Epoch: 434, Training loss: 1.369465, Validation loss: 1.3780, lr: 0.0000\n",
      "Epoch: 435, Training loss: 1.391365, Validation loss: 1.3905, lr: 0.0000\n",
      "Epoch: 436, Training loss: 1.373442, Validation loss: 1.3589, lr: 0.0000\n",
      "Epoch: 437, Training loss: 1.437826, Validation loss: 1.3662, lr: 0.0000\n",
      "Epoch: 438, Training loss: 1.396917, Validation loss: 1.3972, lr: 0.0000\n",
      "Epoch: 439, Training loss: 1.394372, Validation loss: 1.3885, lr: 0.0000\n",
      "Epoch: 440, Training loss: 1.376528, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 441, Training loss: 1.375986, Validation loss: 1.3960, lr: 0.0000\n",
      "Epoch: 442, Training loss: 1.379141, Validation loss: 1.3713, lr: 0.0000\n",
      "Epoch: 443, Training loss: 1.383262, Validation loss: 1.3789, lr: 0.0000\n",
      "Epoch: 444, Training loss: 1.386361, Validation loss: 1.3794, lr: 0.0000\n",
      "Epoch: 445, Training loss: 1.395399, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 446, Training loss: 1.363747, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 447, Training loss: 1.374739, Validation loss: 1.3996, lr: 0.0000\n",
      "Epoch: 448, Training loss: 1.387416, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 449, Training loss: 1.386080, Validation loss: 1.3764, lr: 0.0000\n",
      "Epoch: 450, Training loss: 1.379487, Validation loss: 1.3699, lr: 0.0000\n",
      "Epoch: 451, Training loss: 1.376338, Validation loss: 1.3795, lr: 0.0000\n",
      "Epoch: 452, Training loss: 1.387088, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 453, Training loss: 1.388585, Validation loss: 1.3626, lr: 0.0000\n",
      "Epoch: 454, Training loss: 1.375371, Validation loss: 1.3662, lr: 0.0000\n",
      "Epoch: 455, Training loss: 1.370702, Validation loss: 1.3781, lr: 0.0000\n",
      "Epoch: 456, Training loss: 1.384557, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 457, Training loss: 1.378079, Validation loss: 1.3794, lr: 0.0000\n",
      "Epoch: 458, Training loss: 1.437468, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 459, Training loss: 1.376532, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 460, Training loss: 1.373570, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 461, Training loss: 1.352745, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 462, Training loss: 1.407047, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 463, Training loss: 1.408853, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 464, Training loss: 1.389527, Validation loss: 1.3892, lr: 0.0000\n",
      "Epoch: 465, Training loss: 1.376214, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 466, Training loss: 1.364655, Validation loss: 1.3803, lr: 0.0000\n",
      "Epoch: 467, Training loss: 1.391819, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 468, Training loss: 1.359560, Validation loss: 1.3738, lr: 0.0000\n",
      "Epoch: 469, Training loss: 1.388310, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 470, Training loss: 1.379144, Validation loss: 1.3745, lr: 0.0000\n",
      "Epoch: 471, Training loss: 1.424586, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 472, Training loss: 1.363813, Validation loss: 1.3752, lr: 0.0000\n",
      "Epoch: 473, Training loss: 1.369488, Validation loss: 1.3910, lr: 0.0000\n",
      "Epoch: 474, Training loss: 1.383642, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 475, Training loss: 1.378177, Validation loss: 1.3763, lr: 0.0000\n",
      "Epoch: 476, Training loss: 1.368620, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 477, Training loss: 1.412593, Validation loss: 1.3803, lr: 0.0000\n",
      "Epoch: 478, Training loss: 1.365963, Validation loss: 1.4035, lr: 0.0000\n",
      "Epoch: 479, Training loss: 1.385900, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 480, Training loss: 1.362896, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 481, Training loss: 1.366036, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 482, Training loss: 1.384586, Validation loss: 1.3685, lr: 0.0000\n",
      "Epoch: 483, Training loss: 1.387343, Validation loss: 1.3981, lr: 0.0000\n",
      "Epoch: 484, Training loss: 1.394366, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 485, Training loss: 1.391085, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 486, Training loss: 1.361559, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 487, Training loss: 1.381759, Validation loss: 1.3933, lr: 0.0000\n",
      "Epoch: 488, Training loss: 1.390053, Validation loss: 1.3722, lr: 0.0000\n",
      "Epoch: 489, Training loss: 1.386057, Validation loss: 1.3631, lr: 0.0000\n",
      "Epoch: 490, Training loss: 1.368080, Validation loss: 1.3902, lr: 0.0000\n",
      "Epoch: 491, Training loss: 1.398528, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 492, Training loss: 1.397479, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 493, Training loss: 1.404738, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 494, Training loss: 1.379229, Validation loss: 1.3985, lr: 0.0000\n",
      "Epoch: 495, Training loss: 1.381962, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 496, Training loss: 1.382729, Validation loss: 1.3965, lr: 0.0000\n",
      "Epoch: 497, Training loss: 1.375078, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 498, Training loss: 1.366218, Validation loss: 1.5649, lr: 0.0000\n",
      "Epoch: 499, Training loss: 1.417465, Validation loss: 1.4053, lr: 0.0000\n",
      "Epoch: 500, Training loss: 1.375930, Validation loss: 1.3766, lr: 0.0000\n",
      "Epoch: 501, Training loss: 1.378185, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 502, Training loss: 1.412473, Validation loss: 1.3558, lr: 0.0000\n",
      "Epoch: 503, Training loss: 1.405297, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 504, Training loss: 1.413171, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 505, Training loss: 1.394438, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 506, Training loss: 1.379101, Validation loss: 1.3957, lr: 0.0000\n",
      "Epoch: 507, Training loss: 1.390422, Validation loss: 1.3944, lr: 0.0000\n",
      "Epoch: 508, Training loss: 1.374048, Validation loss: 1.3728, lr: 0.0000\n",
      "Epoch: 509, Training loss: 1.391184, Validation loss: 1.5173, lr: 0.0000\n",
      "Epoch: 510, Training loss: 1.397628, Validation loss: 1.3962, lr: 0.0000\n",
      "Epoch: 511, Training loss: 1.373719, Validation loss: 1.3735, lr: 0.0000\n",
      "Epoch: 512, Training loss: 1.363444, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 513, Training loss: 1.468233, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 514, Training loss: 1.378809, Validation loss: 1.3783, lr: 0.0000\n",
      "Epoch: 515, Training loss: 1.390108, Validation loss: 1.3789, lr: 0.0000\n",
      "Epoch: 516, Training loss: 1.368663, Validation loss: 1.3695, lr: 0.0000\n",
      "Epoch: 517, Training loss: 1.384006, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 518, Training loss: 1.403027, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 519, Training loss: 1.442797, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 520, Training loss: 1.383065, Validation loss: 1.3906, lr: 0.0000\n",
      "Epoch: 521, Training loss: 1.384913, Validation loss: 1.3896, lr: 0.0000\n",
      "Epoch: 522, Training loss: 1.415205, Validation loss: 1.3768, lr: 0.0000\n",
      "Epoch: 523, Training loss: 1.393418, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 524, Training loss: 1.386250, Validation loss: 1.3796, lr: 0.0000\n",
      "Epoch: 525, Training loss: 1.385229, Validation loss: 1.3712, lr: 0.0000\n",
      "Epoch: 526, Training loss: 1.368580, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 527, Training loss: 1.380348, Validation loss: 1.3759, lr: 0.0000\n",
      "Epoch: 528, Training loss: 1.404832, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 529, Training loss: 1.371066, Validation loss: 1.3885, lr: 0.0000\n",
      "Epoch: 530, Training loss: 1.390857, Validation loss: 1.3654, lr: 0.0000\n",
      "Epoch: 531, Training loss: 1.381202, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 532, Training loss: 1.399702, Validation loss: 1.3782, lr: 0.0000\n",
      "Epoch: 533, Training loss: 1.376735, Validation loss: 1.3798, lr: 0.0000\n",
      "Epoch: 534, Training loss: 1.387631, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 535, Training loss: 1.368269, Validation loss: 1.3797, lr: 0.0000\n",
      "Epoch: 536, Training loss: 1.381701, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 537, Training loss: 1.398808, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 538, Training loss: 1.387444, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 539, Training loss: 1.361236, Validation loss: 1.3771, lr: 0.0000\n",
      "Epoch: 540, Training loss: 1.378876, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 541, Training loss: 1.382415, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 542, Training loss: 1.416005, Validation loss: 1.3889, lr: 0.0000\n",
      "Epoch: 543, Training loss: 1.369767, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 544, Training loss: 1.445538, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 545, Training loss: 1.371272, Validation loss: 1.3394, lr: 0.0000\n",
      "Epoch: 546, Training loss: 1.391145, Validation loss: 1.3736, lr: 0.0000\n",
      "Epoch: 547, Training loss: 1.371619, Validation loss: 1.3887, lr: 0.0000\n",
      "Epoch: 548, Training loss: 1.393615, Validation loss: 1.3783, lr: 0.0000\n",
      "Epoch: 549, Training loss: 1.457001, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 550, Training loss: 1.406215, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 551, Training loss: 1.377951, Validation loss: 1.3778, lr: 0.0000\n",
      "Epoch: 552, Training loss: 1.425091, Validation loss: 1.3881, lr: 0.0000\n",
      "Epoch: 553, Training loss: 1.373288, Validation loss: 1.3908, lr: 0.0000\n",
      "Epoch: 554, Training loss: 1.387431, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 555, Training loss: 1.434554, Validation loss: 1.3799, lr: 0.0000\n",
      "Epoch: 556, Training loss: 1.381110, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 557, Training loss: 1.370675, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 558, Training loss: 1.392202, Validation loss: 1.3788, lr: 0.0000\n",
      "Epoch: 559, Training loss: 1.397044, Validation loss: 1.3759, lr: 0.0000\n",
      "Epoch: 560, Training loss: 1.378634, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 561, Training loss: 1.395425, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 562, Training loss: 1.385763, Validation loss: 1.3802, lr: 0.0000\n",
      "Epoch: 563, Training loss: 1.365116, Validation loss: 1.3871, lr: 0.0000\n",
      "Epoch: 564, Training loss: 1.409658, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 565, Training loss: 1.370433, Validation loss: 1.3798, lr: 0.0000\n",
      "Epoch: 566, Training loss: 1.375110, Validation loss: 1.3883, lr: 0.0000\n",
      "Epoch: 567, Training loss: 1.406544, Validation loss: 1.3691, lr: 0.0000\n",
      "Epoch: 568, Training loss: 1.387986, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 569, Training loss: 1.417039, Validation loss: 1.3798, lr: 0.0000\n",
      "Epoch: 570, Training loss: 1.379052, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 571, Training loss: 1.403332, Validation loss: 1.3757, lr: 0.0000\n",
      "Epoch: 572, Training loss: 1.399979, Validation loss: 1.3784, lr: 0.0000\n",
      "Epoch: 573, Training loss: 1.370272, Validation loss: 1.3929, lr: 0.0000\n",
      "Epoch: 574, Training loss: 1.383703, Validation loss: 1.3751, lr: 0.0000\n",
      "Epoch: 575, Training loss: 1.375302, Validation loss: 1.3652, lr: 0.0000\n",
      "Epoch: 576, Training loss: 1.399239, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 577, Training loss: 1.371646, Validation loss: 1.3913, lr: 0.0000\n",
      "Epoch: 578, Training loss: 1.378149, Validation loss: 1.3724, lr: 0.0000\n",
      "Epoch: 579, Training loss: 1.408644, Validation loss: 1.3732, lr: 0.0000\n",
      "Epoch: 580, Training loss: 1.376242, Validation loss: 1.3802, lr: 0.0000\n",
      "Epoch: 581, Training loss: 1.374098, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 582, Training loss: 1.378555, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 583, Training loss: 1.367531, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 584, Training loss: 1.386540, Validation loss: 1.3874, lr: 0.0000\n",
      "Epoch: 585, Training loss: 1.400787, Validation loss: 1.3901, lr: 0.0000\n",
      "Epoch: 586, Training loss: 1.368024, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 587, Training loss: 1.375778, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 588, Training loss: 1.392749, Validation loss: 1.3923, lr: 0.0000\n",
      "Epoch: 589, Training loss: 1.379933, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 590, Training loss: 1.366285, Validation loss: 1.3954, lr: 0.0000\n",
      "Epoch: 591, Training loss: 1.364759, Validation loss: 1.3809, lr: 0.0000\n",
      "Epoch: 592, Training loss: 1.386742, Validation loss: 1.3710, lr: 0.0000\n",
      "Epoch: 593, Training loss: 1.369553, Validation loss: 1.3642, lr: 0.0000\n",
      "Epoch: 594, Training loss: 1.375765, Validation loss: 1.3792, lr: 0.0000\n",
      "Epoch: 595, Training loss: 1.362662, Validation loss: 1.3540, lr: 0.0000\n",
      "Epoch: 596, Training loss: 1.401719, Validation loss: 1.3581, lr: 0.0000\n",
      "Epoch: 597, Training loss: 1.471836, Validation loss: 1.3759, lr: 0.0000\n",
      "Epoch: 598, Training loss: 1.388500, Validation loss: 1.3624, lr: 0.0000\n",
      "Epoch: 599, Training loss: 1.387910, Validation loss: 1.3760, lr: 0.0000\n",
      "Epoch: 600, Training loss: 1.382455, Validation loss: 1.3871, lr: 0.0000\n",
      "Epoch: 601, Training loss: 1.409246, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 602, Training loss: 1.373480, Validation loss: 1.3973, lr: 0.0000\n",
      "Epoch: 603, Training loss: 1.388970, Validation loss: 1.4245, lr: 0.0000\n",
      "Epoch: 604, Training loss: 1.380064, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 605, Training loss: 1.382463, Validation loss: 1.3663, lr: 0.0000\n",
      "Epoch: 606, Training loss: 1.394856, Validation loss: 1.3794, lr: 0.0000\n",
      "Epoch: 607, Training loss: 1.362088, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 608, Training loss: 1.401912, Validation loss: 1.3769, lr: 0.0000\n",
      "Epoch: 609, Training loss: 1.394288, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 610, Training loss: 1.365650, Validation loss: 1.3781, lr: 0.0000\n",
      "Epoch: 611, Training loss: 1.383765, Validation loss: 1.3715, lr: 0.0000\n",
      "Epoch: 612, Training loss: 1.403919, Validation loss: 1.3795, lr: 0.0000\n",
      "Epoch: 613, Training loss: 1.385186, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 614, Training loss: 1.386652, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 615, Training loss: 1.386339, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 616, Training loss: 1.369766, Validation loss: 1.3872, lr: 0.0000\n",
      "Epoch: 617, Training loss: 1.382105, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 618, Training loss: 1.408125, Validation loss: 1.3776, lr: 0.0000\n",
      "Epoch: 619, Training loss: 1.372839, Validation loss: 1.3681, lr: 0.0000\n",
      "Epoch: 620, Training loss: 1.363723, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 621, Training loss: 1.372463, Validation loss: 1.3715, lr: 0.0000\n",
      "Epoch: 622, Training loss: 1.386497, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 623, Training loss: 1.376627, Validation loss: 1.3876, lr: 0.0000\n",
      "Epoch: 624, Training loss: 1.380314, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 625, Training loss: 1.392040, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 626, Training loss: 1.383589, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 627, Training loss: 1.400084, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 628, Training loss: 1.369937, Validation loss: 1.3777, lr: 0.0000\n",
      "Epoch: 629, Training loss: 1.399153, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 630, Training loss: 1.388776, Validation loss: 1.3341, lr: 0.0000\n",
      "Epoch: 631, Training loss: 1.365966, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 632, Training loss: 1.393859, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 633, Training loss: 1.369068, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 634, Training loss: 1.394667, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 635, Training loss: 1.375888, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 636, Training loss: 1.384634, Validation loss: 1.3411, lr: 0.0000\n",
      "Epoch: 637, Training loss: 1.373132, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 638, Training loss: 1.373764, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 639, Training loss: 1.389566, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 640, Training loss: 1.382696, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 641, Training loss: 1.421747, Validation loss: 1.3724, lr: 0.0000\n",
      "Epoch: 642, Training loss: 1.375474, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 643, Training loss: 1.401493, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 644, Training loss: 1.481359, Validation loss: 1.3885, lr: 0.0000\n",
      "Epoch: 645, Training loss: 1.377956, Validation loss: 1.3363, lr: 0.0000\n",
      "Epoch: 646, Training loss: 1.403274, Validation loss: 1.4076, lr: 0.0000\n",
      "Epoch: 647, Training loss: 1.390194, Validation loss: 1.3613, lr: 0.0000\n",
      "Epoch: 648, Training loss: 1.375199, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 649, Training loss: 1.377383, Validation loss: 1.3803, lr: 0.0000\n",
      "Epoch: 650, Training loss: 1.406739, Validation loss: 1.3676, lr: 0.0000\n",
      "Epoch: 651, Training loss: 1.388434, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 652, Training loss: 1.384001, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 653, Training loss: 1.368732, Validation loss: 1.4007, lr: 0.0000\n",
      "Epoch: 654, Training loss: 1.391577, Validation loss: 1.3784, lr: 0.0000\n",
      "Epoch: 655, Training loss: 1.380311, Validation loss: 1.4351, lr: 0.0000\n",
      "Epoch: 656, Training loss: 1.380034, Validation loss: 1.3726, lr: 0.0000\n",
      "Epoch: 657, Training loss: 1.398069, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 658, Training loss: 1.363152, Validation loss: 1.3896, lr: 0.0000\n",
      "Epoch: 659, Training loss: 1.384352, Validation loss: 1.3763, lr: 0.0000\n",
      "Epoch: 660, Training loss: 1.383243, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 661, Training loss: 1.375757, Validation loss: 1.3699, lr: 0.0000\n",
      "Epoch: 662, Training loss: 1.386458, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 663, Training loss: 1.365123, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 664, Training loss: 1.378582, Validation loss: 1.3577, lr: 0.0000\n",
      "Epoch: 665, Training loss: 1.378370, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 666, Training loss: 1.416435, Validation loss: 1.3762, lr: 0.0000\n",
      "Epoch: 667, Training loss: 1.378318, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 668, Training loss: 1.374765, Validation loss: 1.3796, lr: 0.0000\n",
      "Epoch: 669, Training loss: 1.358961, Validation loss: 1.3702, lr: 0.0000\n",
      "Epoch: 670, Training loss: 1.400419, Validation loss: 1.3557, lr: 0.0000\n",
      "Epoch: 671, Training loss: 1.378573, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 672, Training loss: 1.381144, Validation loss: 1.3876, lr: 0.0000\n",
      "Epoch: 673, Training loss: 1.422125, Validation loss: 1.3799, lr: 0.0000\n",
      "Epoch: 674, Training loss: 1.398960, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 675, Training loss: 1.383894, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 676, Training loss: 1.366824, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 677, Training loss: 1.424687, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 678, Training loss: 1.376613, Validation loss: 1.3929, lr: 0.0000\n",
      "Epoch: 679, Training loss: 1.373669, Validation loss: 1.3915, lr: 0.0000\n",
      "Epoch: 680, Training loss: 1.407739, Validation loss: 1.4394, lr: 0.0000\n",
      "Epoch: 681, Training loss: 1.404576, Validation loss: 1.3795, lr: 0.0000\n",
      "Epoch: 682, Training loss: 1.372935, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 683, Training loss: 1.378280, Validation loss: 1.3644, lr: 0.0000\n",
      "Epoch: 684, Training loss: 1.364250, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 685, Training loss: 1.373072, Validation loss: 1.3882, lr: 0.0000\n",
      "Epoch: 686, Training loss: 1.377284, Validation loss: 1.3672, lr: 0.0000\n",
      "Epoch: 687, Training loss: 1.364270, Validation loss: 1.3936, lr: 0.0000\n",
      "Epoch: 688, Training loss: 1.358428, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 689, Training loss: 1.370752, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 690, Training loss: 1.379497, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 691, Training loss: 1.377484, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 692, Training loss: 1.379190, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 693, Training loss: 1.369991, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 694, Training loss: 1.410648, Validation loss: 1.3765, lr: 0.0000\n",
      "Epoch: 695, Training loss: 1.429746, Validation loss: 1.3777, lr: 0.0000\n",
      "Epoch: 696, Training loss: 1.380589, Validation loss: 1.3809, lr: 0.0000\n",
      "Epoch: 697, Training loss: 1.394764, Validation loss: 1.3649, lr: 0.0000\n",
      "Epoch: 698, Training loss: 1.387827, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 699, Training loss: 1.370742, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 700, Training loss: 1.402159, Validation loss: 1.3613, lr: 0.0000\n",
      "Epoch: 701, Training loss: 1.370798, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 702, Training loss: 1.383890, Validation loss: 1.3795, lr: 0.0000\n",
      "Epoch: 703, Training loss: 1.378184, Validation loss: 1.5828, lr: 0.0000\n",
      "Epoch: 704, Training loss: 1.376966, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 705, Training loss: 1.382844, Validation loss: 1.3896, lr: 0.0000\n",
      "Epoch: 706, Training loss: 1.377446, Validation loss: 1.3966, lr: 0.0000\n",
      "Epoch: 707, Training loss: 1.376807, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 708, Training loss: 1.357089, Validation loss: 1.3809, lr: 0.0000\n",
      "Epoch: 709, Training loss: 1.377463, Validation loss: 1.3592, lr: 0.0000\n",
      "Epoch: 710, Training loss: 1.415071, Validation loss: 1.3896, lr: 0.0000\n",
      "Epoch: 711, Training loss: 1.363774, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 712, Training loss: 1.492085, Validation loss: 1.3724, lr: 0.0000\n",
      "Epoch: 713, Training loss: 1.362924, Validation loss: 1.3975, lr: 0.0000\n",
      "Epoch: 714, Training loss: 1.394563, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 715, Training loss: 1.379096, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 716, Training loss: 1.381790, Validation loss: 1.3880, lr: 0.0000\n",
      "Epoch: 717, Training loss: 1.404838, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 718, Training loss: 1.372615, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 719, Training loss: 1.374554, Validation loss: 1.3700, lr: 0.0000\n",
      "Epoch: 720, Training loss: 1.363968, Validation loss: 1.3781, lr: 0.0000\n",
      "Epoch: 721, Training loss: 1.373372, Validation loss: 1.3770, lr: 0.0000\n",
      "Epoch: 722, Training loss: 1.424543, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 723, Training loss: 1.379019, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 724, Training loss: 1.358806, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 725, Training loss: 1.382846, Validation loss: 1.3713, lr: 0.0000\n",
      "Epoch: 726, Training loss: 1.384180, Validation loss: 1.3767, lr: 0.0000\n",
      "Epoch: 727, Training loss: 1.389134, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 728, Training loss: 1.382277, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 729, Training loss: 1.385976, Validation loss: 1.3736, lr: 0.0000\n",
      "Epoch: 730, Training loss: 1.367359, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 731, Training loss: 1.413877, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 732, Training loss: 1.390099, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 733, Training loss: 1.373059, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 734, Training loss: 1.368482, Validation loss: 1.3785, lr: 0.0000\n",
      "Epoch: 735, Training loss: 1.393302, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 736, Training loss: 1.391956, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 737, Training loss: 1.372795, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 738, Training loss: 1.484673, Validation loss: 1.3789, lr: 0.0000\n",
      "Epoch: 739, Training loss: 1.396288, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 740, Training loss: 1.379158, Validation loss: 1.3706, lr: 0.0000\n",
      "Epoch: 741, Training loss: 1.357153, Validation loss: 1.3699, lr: 0.0000\n",
      "Epoch: 742, Training loss: 1.381963, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 743, Training loss: 1.422327, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 744, Training loss: 1.377363, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 745, Training loss: 1.381421, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 746, Training loss: 1.406956, Validation loss: 1.3734, lr: 0.0000\n",
      "Epoch: 747, Training loss: 1.381130, Validation loss: 1.3655, lr: 0.0000\n",
      "Epoch: 748, Training loss: 1.376011, Validation loss: 1.3714, lr: 0.0000\n",
      "Epoch: 749, Training loss: 1.382597, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 750, Training loss: 1.384358, Validation loss: 1.3731, lr: 0.0000\n",
      "Epoch: 751, Training loss: 1.372571, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 752, Training loss: 1.370787, Validation loss: 1.3890, lr: 0.0000\n",
      "Epoch: 753, Training loss: 1.398664, Validation loss: 1.3653, lr: 0.0000\n",
      "Epoch: 754, Training loss: 1.374961, Validation loss: 1.3877, lr: 0.0000\n",
      "Epoch: 755, Training loss: 1.396550, Validation loss: 1.3760, lr: 0.0000\n",
      "Epoch: 756, Training loss: 1.371067, Validation loss: 1.3746, lr: 0.0000\n",
      "Epoch: 757, Training loss: 1.387646, Validation loss: 1.3647, lr: 0.0000\n",
      "Epoch: 758, Training loss: 1.364810, Validation loss: 1.3718, lr: 0.0000\n",
      "Epoch: 759, Training loss: 1.410884, Validation loss: 1.3647, lr: 0.0000\n",
      "Epoch: 760, Training loss: 1.463966, Validation loss: 1.3727, lr: 0.0000\n",
      "Epoch: 761, Training loss: 1.376017, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 762, Training loss: 1.376423, Validation loss: 1.3755, lr: 0.0000\n",
      "Epoch: 763, Training loss: 1.374040, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 764, Training loss: 1.367615, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 765, Training loss: 1.384458, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 766, Training loss: 1.370238, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 767, Training loss: 1.465086, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 768, Training loss: 1.371401, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 769, Training loss: 1.405647, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 770, Training loss: 1.379604, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 771, Training loss: 1.423606, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 772, Training loss: 1.388638, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 773, Training loss: 1.407349, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 774, Training loss: 1.377200, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 775, Training loss: 1.372913, Validation loss: 1.3938, lr: 0.0000\n",
      "Epoch: 776, Training loss: 1.388892, Validation loss: 1.3802, lr: 0.0000\n",
      "Epoch: 777, Training loss: 1.385260, Validation loss: 1.3786, lr: 0.0000\n",
      "Epoch: 778, Training loss: 1.374292, Validation loss: 1.3761, lr: 0.0000\n",
      "Epoch: 779, Training loss: 1.379328, Validation loss: 1.4120, lr: 0.0000\n",
      "Epoch: 780, Training loss: 1.395963, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 781, Training loss: 1.381259, Validation loss: 1.3575, lr: 0.0000\n",
      "Epoch: 782, Training loss: 1.438351, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 783, Training loss: 1.386353, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 784, Training loss: 1.375654, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 785, Training loss: 1.393493, Validation loss: 1.3984, lr: 0.0000\n",
      "Epoch: 786, Training loss: 1.400265, Validation loss: 1.3714, lr: 0.0000\n",
      "Epoch: 787, Training loss: 1.365314, Validation loss: 1.3741, lr: 0.0000\n",
      "Epoch: 788, Training loss: 1.352765, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 789, Training loss: 1.395347, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 790, Training loss: 1.363915, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 791, Training loss: 1.371211, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 792, Training loss: 1.404155, Validation loss: 1.3684, lr: 0.0000\n",
      "Epoch: 793, Training loss: 1.547763, Validation loss: 1.3781, lr: 0.0000\n",
      "Epoch: 794, Training loss: 1.364239, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 795, Training loss: 1.408775, Validation loss: 1.3798, lr: 0.0000\n",
      "Epoch: 796, Training loss: 1.370081, Validation loss: 1.3728, lr: 0.0000\n",
      "Epoch: 797, Training loss: 1.364403, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 798, Training loss: 1.378146, Validation loss: 1.6806, lr: 0.0000\n",
      "Epoch: 799, Training loss: 1.375185, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 800, Training loss: 1.401111, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 801, Training loss: 1.368829, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 802, Training loss: 1.373654, Validation loss: 1.3566, lr: 0.0000\n",
      "Epoch: 803, Training loss: 1.353153, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 804, Training loss: 1.408898, Validation loss: 1.3774, lr: 0.0000\n",
      "Epoch: 805, Training loss: 1.368543, Validation loss: 1.3750, lr: 0.0000\n",
      "Epoch: 806, Training loss: 1.391635, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 807, Training loss: 1.394197, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 808, Training loss: 1.376522, Validation loss: 1.3674, lr: 0.0000\n",
      "Epoch: 809, Training loss: 1.394425, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 810, Training loss: 1.376998, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 811, Training loss: 1.401119, Validation loss: 1.3697, lr: 0.0000\n",
      "Epoch: 812, Training loss: 1.371674, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 813, Training loss: 1.355316, Validation loss: 1.3795, lr: 0.0000\n",
      "Epoch: 814, Training loss: 1.380699, Validation loss: 1.3788, lr: 0.0000\n",
      "Epoch: 815, Training loss: 1.399269, Validation loss: 1.3351, lr: 0.0000\n",
      "Epoch: 816, Training loss: 1.368254, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 817, Training loss: 1.366352, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 818, Training loss: 1.395538, Validation loss: 1.3759, lr: 0.0000\n",
      "Epoch: 819, Training loss: 1.385275, Validation loss: 1.3775, lr: 0.0000\n",
      "Epoch: 820, Training loss: 1.377012, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 821, Training loss: 1.381395, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 822, Training loss: 1.395086, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 823, Training loss: 1.369978, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 824, Training loss: 1.394353, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 825, Training loss: 1.383907, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 826, Training loss: 1.383599, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 827, Training loss: 1.388260, Validation loss: 1.3879, lr: 0.0000\n",
      "Epoch: 828, Training loss: 1.421526, Validation loss: 1.3872, lr: 0.0000\n",
      "Epoch: 829, Training loss: 1.403950, Validation loss: 1.3721, lr: 0.0000\n",
      "Epoch: 830, Training loss: 1.367126, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 831, Training loss: 1.400780, Validation loss: 1.4065, lr: 0.0000\n",
      "Epoch: 832, Training loss: 1.385711, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 833, Training loss: 1.393531, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 834, Training loss: 1.386742, Validation loss: 1.3561, lr: 0.0000\n",
      "Epoch: 835, Training loss: 1.404970, Validation loss: 1.3904, lr: 0.0000\n",
      "Epoch: 836, Training loss: 1.409868, Validation loss: 1.3774, lr: 0.0000\n",
      "Epoch: 837, Training loss: 1.387358, Validation loss: 1.3782, lr: 0.0000\n",
      "Epoch: 838, Training loss: 1.388828, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 839, Training loss: 1.413249, Validation loss: 1.3727, lr: 0.0000\n",
      "Epoch: 840, Training loss: 1.400486, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 841, Training loss: 1.366172, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 842, Training loss: 1.380512, Validation loss: 1.4488, lr: 0.0000\n",
      "Epoch: 843, Training loss: 1.405226, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 844, Training loss: 1.371498, Validation loss: 1.3749, lr: 0.0000\n",
      "Epoch: 845, Training loss: 1.370251, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 846, Training loss: 1.362888, Validation loss: 1.3879, lr: 0.0000\n",
      "Epoch: 847, Training loss: 1.435934, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 848, Training loss: 1.380455, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 849, Training loss: 1.377797, Validation loss: 3.1158, lr: 0.0000\n",
      "Epoch: 850, Training loss: 1.375568, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 851, Training loss: 1.474256, Validation loss: 1.3716, lr: 0.0000\n",
      "Epoch: 852, Training loss: 1.348739, Validation loss: 1.3898, lr: 0.0000\n",
      "Epoch: 853, Training loss: 1.392984, Validation loss: 1.3803, lr: 0.0000\n",
      "Epoch: 854, Training loss: 1.377839, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 855, Training loss: 1.374337, Validation loss: 1.3722, lr: 0.0000\n",
      "Epoch: 856, Training loss: 1.367121, Validation loss: 1.3794, lr: 0.0000\n",
      "Epoch: 857, Training loss: 1.390161, Validation loss: 1.3876, lr: 0.0000\n",
      "Epoch: 858, Training loss: 1.379100, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 859, Training loss: 1.364808, Validation loss: 1.3936, lr: 0.0000\n",
      "Epoch: 860, Training loss: 1.370578, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 861, Training loss: 1.448550, Validation loss: 1.3693, lr: 0.0000\n",
      "Epoch: 862, Training loss: 1.382399, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 863, Training loss: 1.392714, Validation loss: 1.3789, lr: 0.0000\n",
      "Epoch: 864, Training loss: 1.387200, Validation loss: 1.3660, lr: 0.0000\n",
      "Epoch: 865, Training loss: 1.385667, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 866, Training loss: 1.453626, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 867, Training loss: 1.384280, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 868, Training loss: 1.385460, Validation loss: 1.3565, lr: 0.0000\n",
      "Epoch: 869, Training loss: 1.369430, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 870, Training loss: 1.397032, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 871, Training loss: 1.381251, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 872, Training loss: 1.368140, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 873, Training loss: 1.407131, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 874, Training loss: 1.421562, Validation loss: 1.3879, lr: 0.0000\n",
      "Epoch: 875, Training loss: 1.409011, Validation loss: 1.3762, lr: 0.0000\n",
      "Epoch: 876, Training loss: 1.375322, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 877, Training loss: 1.367708, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 878, Training loss: 1.368732, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 879, Training loss: 1.361449, Validation loss: 1.3877, lr: 0.0000\n",
      "Epoch: 880, Training loss: 1.375194, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 881, Training loss: 1.406171, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 882, Training loss: 1.383734, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 883, Training loss: 1.358468, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 884, Training loss: 1.381048, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 885, Training loss: 1.383528, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 886, Training loss: 1.408454, Validation loss: 1.3911, lr: 0.0000\n",
      "Epoch: 887, Training loss: 1.384214, Validation loss: 1.3517, lr: 0.0000\n",
      "Epoch: 888, Training loss: 1.381828, Validation loss: 1.3723, lr: 0.0000\n",
      "Epoch: 889, Training loss: 1.393383, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 890, Training loss: 1.411092, Validation loss: 1.3791, lr: 0.0000\n",
      "Epoch: 891, Training loss: 1.369919, Validation loss: 1.3888, lr: 0.0000\n",
      "Epoch: 892, Training loss: 1.444176, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 893, Training loss: 1.382985, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 894, Training loss: 1.393144, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 895, Training loss: 1.392997, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 896, Training loss: 1.375310, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 897, Training loss: 1.375887, Validation loss: 1.3734, lr: 0.0000\n",
      "Epoch: 898, Training loss: 1.406606, Validation loss: 1.3758, lr: 0.0000\n",
      "Epoch: 899, Training loss: 1.375320, Validation loss: 1.3721, lr: 0.0000\n",
      "Epoch: 900, Training loss: 1.371312, Validation loss: 1.3800, lr: 0.0000\n",
      "Epoch: 901, Training loss: 1.383541, Validation loss: 1.3744, lr: 0.0000\n",
      "Epoch: 902, Training loss: 1.359372, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 903, Training loss: 1.375982, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 904, Training loss: 1.382554, Validation loss: 1.4795, lr: 0.0000\n",
      "Epoch: 905, Training loss: 1.399136, Validation loss: 1.3757, lr: 0.0000\n",
      "Epoch: 906, Training loss: 1.380142, Validation loss: 1.3789, lr: 0.0000\n",
      "Epoch: 907, Training loss: 1.386203, Validation loss: 1.3876, lr: 0.0000\n",
      "Epoch: 908, Training loss: 1.365431, Validation loss: 1.3670, lr: 0.0000\n",
      "Epoch: 909, Training loss: 1.386006, Validation loss: 1.3925, lr: 0.0000\n",
      "Epoch: 910, Training loss: 1.368217, Validation loss: 1.3647, lr: 0.0000\n",
      "Epoch: 911, Training loss: 1.389850, Validation loss: 1.3887, lr: 0.0000\n",
      "Epoch: 912, Training loss: 1.379793, Validation loss: 1.3713, lr: 0.0000\n",
      "Epoch: 913, Training loss: 1.364583, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 914, Training loss: 1.404793, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 915, Training loss: 1.385677, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 916, Training loss: 1.384074, Validation loss: 1.3803, lr: 0.0000\n",
      "Epoch: 917, Training loss: 1.404867, Validation loss: 1.3750, lr: 0.0000\n",
      "Epoch: 918, Training loss: 1.379051, Validation loss: 1.3780, lr: 0.0000\n",
      "Epoch: 919, Training loss: 1.429585, Validation loss: 1.3683, lr: 0.0000\n",
      "Epoch: 920, Training loss: 1.398039, Validation loss: 1.3795, lr: 0.0000\n",
      "Epoch: 921, Training loss: 1.367390, Validation loss: 1.3886, lr: 0.0000\n",
      "Epoch: 922, Training loss: 1.369533, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 923, Training loss: 1.390592, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 924, Training loss: 1.367719, Validation loss: 1.3871, lr: 0.0000\n",
      "Epoch: 925, Training loss: 1.366734, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 926, Training loss: 1.397168, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 927, Training loss: 1.400343, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 928, Training loss: 1.384799, Validation loss: 1.3802, lr: 0.0000\n",
      "Epoch: 929, Training loss: 1.378416, Validation loss: 1.3783, lr: 0.0000\n",
      "Epoch: 930, Training loss: 1.380570, Validation loss: 1.3631, lr: 0.0000\n",
      "Epoch: 931, Training loss: 1.398444, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 932, Training loss: 1.390192, Validation loss: 1.3780, lr: 0.0000\n",
      "Epoch: 933, Training loss: 1.368092, Validation loss: 1.4046, lr: 0.0000\n",
      "Epoch: 934, Training loss: 1.380109, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 935, Training loss: 1.378927, Validation loss: 1.3938, lr: 0.0000\n",
      "Epoch: 936, Training loss: 1.390664, Validation loss: 1.4037, lr: 0.0000\n",
      "Epoch: 937, Training loss: 1.511029, Validation loss: 1.3904, lr: 0.0000\n",
      "Epoch: 938, Training loss: 1.377148, Validation loss: 1.3781, lr: 0.0000\n",
      "Epoch: 939, Training loss: 1.394456, Validation loss: 1.4060, lr: 0.0000\n",
      "Epoch: 940, Training loss: 1.372047, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 941, Training loss: 1.362633, Validation loss: 1.3731, lr: 0.0000\n",
      "Epoch: 942, Training loss: 1.375315, Validation loss: 1.3679, lr: 0.0000\n",
      "Epoch: 943, Training loss: 1.394807, Validation loss: 1.3736, lr: 0.0000\n",
      "Epoch: 944, Training loss: 1.397888, Validation loss: 1.3756, lr: 0.0000\n",
      "Epoch: 945, Training loss: 1.394442, Validation loss: 1.4510, lr: 0.0000\n",
      "Epoch: 946, Training loss: 1.378162, Validation loss: 1.3769, lr: 0.0000\n",
      "Epoch: 947, Training loss: 1.368438, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 948, Training loss: 1.392712, Validation loss: 1.3795, lr: 0.0000\n",
      "Epoch: 949, Training loss: 1.399381, Validation loss: 1.4707, lr: 0.0000\n",
      "Epoch: 950, Training loss: 1.358618, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 951, Training loss: 1.390208, Validation loss: 1.3803, lr: 0.0000\n",
      "Epoch: 952, Training loss: 1.377222, Validation loss: 1.3873, lr: 0.0000\n",
      "Epoch: 953, Training loss: 1.379630, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 954, Training loss: 1.371370, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 955, Training loss: 1.414444, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 956, Training loss: 1.401347, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 957, Training loss: 1.449165, Validation loss: 1.3517, lr: 0.0000\n",
      "Epoch: 958, Training loss: 1.356368, Validation loss: 1.3710, lr: 0.0000\n",
      "Epoch: 959, Training loss: 1.384161, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 960, Training loss: 1.371130, Validation loss: 1.3925, lr: 0.0000\n",
      "Epoch: 961, Training loss: 1.365439, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 962, Training loss: 1.385717, Validation loss: 1.4311, lr: 0.0000\n",
      "Epoch: 963, Training loss: 1.400807, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 964, Training loss: 1.364167, Validation loss: 1.3791, lr: 0.0000\n",
      "Epoch: 965, Training loss: 1.376720, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 966, Training loss: 1.482343, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 967, Training loss: 1.378407, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 968, Training loss: 1.389382, Validation loss: 1.3738, lr: 0.0000\n",
      "Epoch: 969, Training loss: 1.397673, Validation loss: 1.3809, lr: 0.0000\n",
      "Epoch: 970, Training loss: 1.383824, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 971, Training loss: 1.384109, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 972, Training loss: 1.374959, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 973, Training loss: 1.401127, Validation loss: 1.3639, lr: 0.0000\n",
      "Epoch: 974, Training loss: 1.463455, Validation loss: 1.3872, lr: 0.0000\n",
      "Epoch: 975, Training loss: 1.379154, Validation loss: 1.3603, lr: 0.0000\n",
      "Epoch: 976, Training loss: 1.384254, Validation loss: 1.3798, lr: 0.0000\n",
      "Epoch: 977, Training loss: 1.371970, Validation loss: 1.3749, lr: 0.0000\n",
      "Epoch: 978, Training loss: 1.400894, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 979, Training loss: 1.402089, Validation loss: 1.3802, lr: 0.0000\n",
      "Epoch: 980, Training loss: 1.397041, Validation loss: 1.3803, lr: 0.0000\n",
      "Epoch: 981, Training loss: 1.385680, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 982, Training loss: 1.382588, Validation loss: 1.3799, lr: 0.0000\n",
      "Epoch: 983, Training loss: 1.373046, Validation loss: 1.3791, lr: 0.0000\n",
      "Epoch: 984, Training loss: 1.374733, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 985, Training loss: 1.393639, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 986, Training loss: 1.381388, Validation loss: 1.3697, lr: 0.0000\n",
      "Epoch: 987, Training loss: 1.381914, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 988, Training loss: 1.375831, Validation loss: 1.3596, lr: 0.0000\n",
      "Epoch: 989, Training loss: 1.447476, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 990, Training loss: 1.390508, Validation loss: 1.3760, lr: 0.0000\n",
      "Epoch: 991, Training loss: 1.407154, Validation loss: 1.3636, lr: 0.0000\n",
      "Epoch: 992, Training loss: 1.376864, Validation loss: 1.3884, lr: 0.0000\n",
      "Epoch: 993, Training loss: 1.383487, Validation loss: 1.4025, lr: 0.0000\n",
      "Epoch: 994, Training loss: 1.393895, Validation loss: 1.3744, lr: 0.0000\n",
      "Epoch: 995, Training loss: 1.380333, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 996, Training loss: 1.476109, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 997, Training loss: 1.379928, Validation loss: 1.4772, lr: 0.0000\n",
      "Epoch: 998, Training loss: 1.368164, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 999, Training loss: 1.373403, Validation loss: 1.3849, lr: 0.0000\n",
      "Final test loss: 1.3846\n",
      "=== Run 07/10 ===\n",
      "\n",
      "---- Settings: \n",
      "\n",
      "epochs : 1000\n",
      "hidden_channels : [32]\n",
      "out_channels : 10\n",
      "inner_product_features : False\n",
      "batch_size : 64\n",
      "lr : 0.01\n",
      "momentum : 0.9\n",
      "dropout : 0.0\n",
      "batch_norm : batch_norm\n",
      "bias : True\n",
      "order : 2\n",
      "diffusion : True\n",
      "frac_sampled_nb : -1\n",
      "include_positions : False\n",
      "include_self : True\n",
      "vec_norm : False\n",
      "emb_norm : False\n",
      "seed : 0\n",
      "dim_signal : 100\n",
      "dim_emb : 100\n",
      "n_sampled_nb : -1\n",
      "\n",
      "---- Number of features to pass to the MLP:  1010100\n",
      "---- Total number of parameters:  32323627\n",
      "\n",
      "Using device cuda:0\n",
      "\n",
      "---- Training network ...\n",
      "\n",
      "---- Timestamp: 20250614-025115\n",
      "\n",
      " *och: 0, Training loss: 1.484308, Validation loss: 1.7569, lr: 0.0100\n",
      " *och: 1, Training loss: 1.454988, Validation loss: 1.4059, lr: 0.0100\n",
      " *och: 2, Training loss: 1.386582, Validation loss: 1.3846, lr: 0.0100\n",
      "Epoch: 3, Training loss: 1.395957, Validation loss: 1.3859, lr: 0.0100\n",
      " *och: 4, Training loss: 1.371022, Validation loss: 1.3826, lr: 0.0100\n",
      " *och: 5, Training loss: 1.429367, Validation loss: 1.3811, lr: 0.0100\n",
      " *och: 6, Training loss: 1.380195, Validation loss: 1.3734, lr: 0.0100\n",
      "Epoch: 7, Training loss: 1.409493, Validation loss: 1.3791, lr: 0.0100\n",
      " *och: 8, Training loss: 1.375924, Validation loss: 1.3579, lr: 0.0100\n",
      "Epoch: 9, Training loss: 1.392816, Validation loss: 1.3866, lr: 0.0100\n",
      "Epoch: 10, Training loss: 1.385625, Validation loss: 1.3865, lr: 0.0100\n",
      "Epoch: 11, Training loss: 1.431377, Validation loss: 1.4213, lr: 0.0100\n",
      "Epoch: 12, Training loss: 1.396224, Validation loss: 1.3890, lr: 0.0100\n",
      "Epoch: 13, Training loss: 1.380282, Validation loss: 1.3866, lr: 0.0100\n",
      "Epoch: 14, Training loss: 1.402305, Validation loss: 1.3861, lr: 0.0100\n",
      "Epoch: 15, Training loss: 1.531590, Validation loss: 1.3854, lr: 0.0010\n",
      "Epoch: 16, Training loss: 1.388032, Validation loss: 1.3854, lr: 0.0010\n",
      "Epoch: 17, Training loss: 1.372726, Validation loss: 1.3792, lr: 0.0010\n",
      "Epoch: 18, Training loss: 1.376046, Validation loss: 1.3852, lr: 0.0010\n",
      "Epoch: 19, Training loss: 1.388900, Validation loss: 1.3879, lr: 0.0010\n",
      "Epoch: 20, Training loss: 1.365498, Validation loss: 1.3877, lr: 0.0010\n",
      "Epoch: 21, Training loss: 1.381280, Validation loss: 1.3818, lr: 0.0010\n",
      "Epoch: 22, Training loss: 1.382772, Validation loss: 1.3834, lr: 0.0010\n",
      "Epoch: 23, Training loss: 1.378958, Validation loss: 1.3960, lr: 0.0010\n",
      "Epoch: 24, Training loss: 1.386773, Validation loss: 1.3841, lr: 0.0010\n",
      "Epoch: 25, Training loss: 1.435724, Validation loss: 1.3844, lr: 0.0010\n",
      "Epoch: 26, Training loss: 1.390372, Validation loss: 1.3834, lr: 0.0010\n",
      "Epoch: 27, Training loss: 1.398964, Validation loss: 1.3839, lr: 0.0010\n",
      "Epoch: 28, Training loss: 1.386250, Validation loss: 1.3799, lr: 0.0010\n",
      "Epoch: 29, Training loss: 1.374678, Validation loss: 1.3826, lr: 0.0010\n",
      "Epoch: 30, Training loss: 1.385731, Validation loss: 1.3884, lr: 0.0010\n",
      "Epoch: 31, Training loss: 1.378018, Validation loss: 1.3751, lr: 0.0001\n",
      "Epoch: 32, Training loss: 1.367882, Validation loss: 1.3777, lr: 0.0001\n",
      "Epoch: 33, Training loss: 1.373650, Validation loss: 1.3913, lr: 0.0001\n",
      "Epoch: 34, Training loss: 1.380354, Validation loss: 1.3877, lr: 0.0001\n",
      "Epoch: 35, Training loss: 1.370561, Validation loss: 1.4620, lr: 0.0001\n",
      "Epoch: 36, Training loss: 1.374815, Validation loss: 1.3875, lr: 0.0001\n",
      "Epoch: 37, Training loss: 1.385546, Validation loss: 1.3875, lr: 0.0001\n",
      "Epoch: 38, Training loss: 1.371149, Validation loss: 1.3932, lr: 0.0001\n",
      "Epoch: 39, Training loss: 1.373315, Validation loss: 1.3850, lr: 0.0001\n",
      "Epoch: 40, Training loss: 1.435564, Validation loss: 1.3843, lr: 0.0001\n",
      "Epoch: 41, Training loss: 1.384371, Validation loss: 1.3844, lr: 0.0001\n",
      "Epoch: 42, Training loss: 1.391094, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 43, Training loss: 1.374486, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 44, Training loss: 1.404118, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 45, Training loss: 1.390053, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 46, Training loss: 1.389565, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 47, Training loss: 1.368787, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 48, Training loss: 1.384101, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 49, Training loss: 1.397355, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 50, Training loss: 1.394196, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 51, Training loss: 1.378655, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 52, Training loss: 1.381360, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 53, Training loss: 1.363591, Validation loss: 1.3790, lr: 0.0000\n",
      "Epoch: 54, Training loss: 1.382166, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 55, Training loss: 1.408262, Validation loss: 1.3755, lr: 0.0000\n",
      "Epoch: 56, Training loss: 1.383604, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 57, Training loss: 1.383249, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 58, Training loss: 1.398566, Validation loss: 1.4309, lr: 0.0000\n",
      "Epoch: 59, Training loss: 1.374357, Validation loss: 1.3799, lr: 0.0000\n",
      "Epoch: 60, Training loss: 1.374816, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 61, Training loss: 1.381965, Validation loss: 1.3875, lr: 0.0000\n",
      "Epoch: 62, Training loss: 1.376503, Validation loss: 1.3803, lr: 0.0000\n",
      "Epoch: 63, Training loss: 1.382792, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 64, Training loss: 1.421594, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 65, Training loss: 1.373474, Validation loss: 1.3898, lr: 0.0000\n",
      "Epoch: 66, Training loss: 1.371788, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 67, Training loss: 1.388312, Validation loss: 1.3875, lr: 0.0000\n",
      "Epoch: 68, Training loss: 1.389426, Validation loss: 1.3943, lr: 0.0000\n",
      "Epoch: 69, Training loss: 1.384921, Validation loss: 1.3674, lr: 0.0000\n",
      "Epoch: 70, Training loss: 1.378260, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 71, Training loss: 1.482065, Validation loss: 1.3954, lr: 0.0000\n",
      "Epoch: 72, Training loss: 1.377894, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 73, Training loss: 1.380158, Validation loss: 1.3809, lr: 0.0000\n",
      "Epoch: 74, Training loss: 1.373409, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 75, Training loss: 1.412844, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 76, Training loss: 1.382917, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 77, Training loss: 1.387594, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 78, Training loss: 1.388783, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 79, Training loss: 1.387051, Validation loss: 1.3892, lr: 0.0000\n",
      "Epoch: 80, Training loss: 1.390331, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 81, Training loss: 1.370098, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 82, Training loss: 1.380338, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 83, Training loss: 1.389455, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 84, Training loss: 1.393404, Validation loss: 1.3890, lr: 0.0000\n",
      "Epoch: 85, Training loss: 1.384815, Validation loss: 1.3787, lr: 0.0000\n",
      "Epoch: 86, Training loss: 1.380145, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 87, Training loss: 1.396705, Validation loss: 1.3999, lr: 0.0000\n",
      "Epoch: 88, Training loss: 1.403979, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 89, Training loss: 1.377203, Validation loss: 1.3798, lr: 0.0000\n",
      "Epoch: 90, Training loss: 1.383444, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 91, Training loss: 1.390623, Validation loss: 1.3762, lr: 0.0000\n",
      "Epoch: 92, Training loss: 1.375930, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 93, Training loss: 1.403473, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 94, Training loss: 1.375987, Validation loss: 1.3742, lr: 0.0000\n",
      "Epoch: 95, Training loss: 1.379163, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 96, Training loss: 1.380727, Validation loss: 1.3728, lr: 0.0000\n",
      "Epoch: 97, Training loss: 1.389799, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 98, Training loss: 1.426230, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 99, Training loss: 1.390265, Validation loss: 1.3892, lr: 0.0000\n",
      "Epoch: 100, Training loss: 1.521267, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 101, Training loss: 1.407787, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 102, Training loss: 1.366069, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 103, Training loss: 1.411469, Validation loss: 1.3757, lr: 0.0000\n",
      "Epoch: 104, Training loss: 1.383034, Validation loss: 1.3904, lr: 0.0000\n",
      "Epoch: 105, Training loss: 1.376159, Validation loss: 1.3871, lr: 0.0000\n",
      "Epoch: 106, Training loss: 1.381620, Validation loss: 1.3971, lr: 0.0000\n",
      "Epoch: 107, Training loss: 1.387745, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 108, Training loss: 1.386304, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 109, Training loss: 1.394849, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 110, Training loss: 1.411517, Validation loss: 1.3929, lr: 0.0000\n",
      "Epoch: 111, Training loss: 1.372739, Validation loss: 1.3888, lr: 0.0000\n",
      "Epoch: 112, Training loss: 1.385577, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 113, Training loss: 1.427396, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 114, Training loss: 1.379314, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 115, Training loss: 1.389933, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 116, Training loss: 1.388126, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 117, Training loss: 1.387362, Validation loss: 1.3796, lr: 0.0000\n",
      "Epoch: 118, Training loss: 1.396843, Validation loss: 1.3882, lr: 0.0000\n",
      "Epoch: 119, Training loss: 1.363560, Validation loss: 1.3896, lr: 0.0000\n",
      "Epoch: 120, Training loss: 1.375530, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 121, Training loss: 1.380465, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 122, Training loss: 1.370884, Validation loss: 1.3878, lr: 0.0000\n",
      "Epoch: 123, Training loss: 1.379779, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 124, Training loss: 1.388639, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 125, Training loss: 1.380800, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 126, Training loss: 1.397927, Validation loss: 1.3872, lr: 0.0000\n",
      "Epoch: 127, Training loss: 1.368937, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 128, Training loss: 1.395811, Validation loss: 1.3874, lr: 0.0000\n",
      "Epoch: 129, Training loss: 1.377372, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 130, Training loss: 1.402217, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 131, Training loss: 1.377093, Validation loss: 1.3924, lr: 0.0000\n",
      "Epoch: 132, Training loss: 1.465288, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 133, Training loss: 1.389973, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 134, Training loss: 1.366738, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 135, Training loss: 1.380223, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 136, Training loss: 1.390178, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 137, Training loss: 1.394046, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 138, Training loss: 1.387794, Validation loss: 1.3871, lr: 0.0000\n",
      "Epoch: 139, Training loss: 1.386376, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 140, Training loss: 1.381684, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 141, Training loss: 1.369325, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 142, Training loss: 1.384986, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 143, Training loss: 1.388150, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 144, Training loss: 1.380196, Validation loss: 1.3975, lr: 0.0000\n",
      "Epoch: 145, Training loss: 1.392968, Validation loss: 1.3726, lr: 0.0000\n",
      "Epoch: 146, Training loss: 1.384916, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 147, Training loss: 1.382731, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 148, Training loss: 1.368428, Validation loss: 1.3696, lr: 0.0000\n",
      "Epoch: 149, Training loss: 1.407776, Validation loss: 1.5837, lr: 0.0000\n",
      "Epoch: 150, Training loss: 1.386770, Validation loss: 1.3763, lr: 0.0000\n",
      "Epoch: 151, Training loss: 1.379598, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 152, Training loss: 1.390207, Validation loss: 1.3780, lr: 0.0000\n",
      "Epoch: 153, Training loss: 1.377255, Validation loss: 1.3751, lr: 0.0000\n",
      "Epoch: 154, Training loss: 1.392720, Validation loss: 1.4151, lr: 0.0000\n",
      "Epoch: 155, Training loss: 1.377920, Validation loss: 1.3892, lr: 0.0000\n",
      "Epoch: 156, Training loss: 1.405508, Validation loss: 1.3740, lr: 0.0000\n",
      "Epoch: 157, Training loss: 1.441248, Validation loss: 1.3762, lr: 0.0000\n",
      "Epoch: 158, Training loss: 1.381048, Validation loss: 1.3877, lr: 0.0000\n",
      "Epoch: 159, Training loss: 1.406100, Validation loss: 1.3954, lr: 0.0000\n",
      "Epoch: 160, Training loss: 1.378223, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 161, Training loss: 1.383111, Validation loss: 1.3883, lr: 0.0000\n",
      "Epoch: 162, Training loss: 1.392191, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 163, Training loss: 1.379212, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 164, Training loss: 1.373716, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 165, Training loss: 1.390555, Validation loss: 1.3799, lr: 0.0000\n",
      "Epoch: 166, Training loss: 1.408820, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 167, Training loss: 1.385701, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 168, Training loss: 1.374197, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 169, Training loss: 1.394401, Validation loss: 1.3735, lr: 0.0000\n",
      "Epoch: 170, Training loss: 1.393324, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 171, Training loss: 1.384684, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 172, Training loss: 1.385780, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 173, Training loss: 1.399462, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 174, Training loss: 1.399424, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 175, Training loss: 1.409171, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 176, Training loss: 1.393708, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 177, Training loss: 1.383584, Validation loss: 1.3900, lr: 0.0000\n",
      "Epoch: 178, Training loss: 1.391962, Validation loss: 1.3746, lr: 0.0000\n",
      "Epoch: 179, Training loss: 1.373333, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 180, Training loss: 1.388606, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 181, Training loss: 1.379605, Validation loss: 1.3620, lr: 0.0000\n",
      "Epoch: 182, Training loss: 1.375845, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 183, Training loss: 1.376971, Validation loss: 1.3903, lr: 0.0000\n",
      "Epoch: 184, Training loss: 1.381113, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 185, Training loss: 1.381917, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 186, Training loss: 1.383399, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 187, Training loss: 1.400456, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 188, Training loss: 1.398536, Validation loss: 1.3893, lr: 0.0000\n",
      "Epoch: 189, Training loss: 1.373217, Validation loss: 1.3660, lr: 0.0000\n",
      "Epoch: 190, Training loss: 1.379665, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 191, Training loss: 1.422997, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 192, Training loss: 1.382091, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 193, Training loss: 1.367521, Validation loss: 1.3629, lr: 0.0000\n",
      "Epoch: 194, Training loss: 1.381257, Validation loss: 1.3916, lr: 0.0000\n",
      "Epoch: 195, Training loss: 1.382612, Validation loss: 1.3872, lr: 0.0000\n",
      "Epoch: 196, Training loss: 1.382234, Validation loss: 1.3975, lr: 0.0000\n",
      "Epoch: 197, Training loss: 1.378912, Validation loss: 1.3798, lr: 0.0000\n",
      "Epoch: 198, Training loss: 1.395701, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 199, Training loss: 1.393127, Validation loss: 1.3871, lr: 0.0000\n",
      "Epoch: 200, Training loss: 1.375814, Validation loss: 1.3885, lr: 0.0000\n",
      "Epoch: 201, Training loss: 1.385832, Validation loss: 1.3890, lr: 0.0000\n",
      "Epoch: 202, Training loss: 1.383780, Validation loss: 1.3873, lr: 0.0000\n",
      "Epoch: 203, Training loss: 1.395461, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 204, Training loss: 1.397486, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 205, Training loss: 1.392709, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 206, Training loss: 1.384758, Validation loss: 1.3707, lr: 0.0000\n",
      "Epoch: 207, Training loss: 1.389249, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 208, Training loss: 1.391475, Validation loss: 1.3612, lr: 0.0000\n",
      "Epoch: 209, Training loss: 1.370693, Validation loss: 1.4000, lr: 0.0000\n",
      "Epoch: 210, Training loss: 1.375817, Validation loss: 1.3760, lr: 0.0000\n",
      " *och: 211, Training loss: 1.373317, Validation loss: 1.3564, lr: 0.0000\n",
      "Epoch: 212, Training loss: 1.372809, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 213, Training loss: 1.383093, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 214, Training loss: 1.381837, Validation loss: 1.3872, lr: 0.0000\n",
      "Epoch: 215, Training loss: 1.371144, Validation loss: 1.3872, lr: 0.0000\n",
      "Epoch: 216, Training loss: 1.384570, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 217, Training loss: 1.392214, Validation loss: 1.3884, lr: 0.0000\n",
      "Epoch: 218, Training loss: 1.384884, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 219, Training loss: 1.375943, Validation loss: 1.3871, lr: 0.0000\n",
      "Epoch: 220, Training loss: 1.397214, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 221, Training loss: 1.374910, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 222, Training loss: 1.375701, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 223, Training loss: 1.383273, Validation loss: 1.3922, lr: 0.0000\n",
      "Epoch: 224, Training loss: 1.396236, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 225, Training loss: 1.375623, Validation loss: 1.3706, lr: 0.0000\n",
      "Epoch: 226, Training loss: 1.382840, Validation loss: 1.3778, lr: 0.0000\n",
      "Epoch: 227, Training loss: 1.380929, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 228, Training loss: 1.360295, Validation loss: 1.3742, lr: 0.0000\n",
      "Epoch: 229, Training loss: 1.390922, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 230, Training loss: 1.390212, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 231, Training loss: 1.384318, Validation loss: 1.3873, lr: 0.0000\n",
      "Epoch: 232, Training loss: 1.508985, Validation loss: 1.3882, lr: 0.0000\n",
      "Epoch: 233, Training loss: 1.367822, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 234, Training loss: 1.360716, Validation loss: 1.3767, lr: 0.0000\n",
      "Epoch: 235, Training loss: 1.384232, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 236, Training loss: 1.375905, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 237, Training loss: 1.374200, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 238, Training loss: 1.394037, Validation loss: 1.3906, lr: 0.0000\n",
      "Epoch: 239, Training loss: 1.356079, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 240, Training loss: 1.378721, Validation loss: 1.3885, lr: 0.0000\n",
      "Epoch: 241, Training loss: 1.393961, Validation loss: 1.3871, lr: 0.0000\n",
      "Epoch: 242, Training loss: 1.378216, Validation loss: 1.3873, lr: 0.0000\n",
      "Epoch: 243, Training loss: 1.388198, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 244, Training loss: 1.366278, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 245, Training loss: 1.391051, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 246, Training loss: 1.379191, Validation loss: 1.3711, lr: 0.0000\n",
      "Epoch: 247, Training loss: 1.385314, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 248, Training loss: 1.377663, Validation loss: 1.3877, lr: 0.0000\n",
      "Epoch: 249, Training loss: 1.444338, Validation loss: 1.3612, lr: 0.0000\n",
      "Epoch: 250, Training loss: 1.389581, Validation loss: 1.4010, lr: 0.0000\n",
      "Epoch: 251, Training loss: 1.411340, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 252, Training loss: 1.374781, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 253, Training loss: 1.363204, Validation loss: 1.3879, lr: 0.0000\n",
      "Epoch: 254, Training loss: 1.366210, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 255, Training loss: 1.384272, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 256, Training loss: 1.395718, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 257, Training loss: 1.377510, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 258, Training loss: 1.365782, Validation loss: 1.3877, lr: 0.0000\n",
      "Epoch: 259, Training loss: 1.385244, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 260, Training loss: 1.449776, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 261, Training loss: 1.386870, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 262, Training loss: 1.384222, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 263, Training loss: 1.398359, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 264, Training loss: 1.369736, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 265, Training loss: 1.402101, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 266, Training loss: 1.365804, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 267, Training loss: 1.375994, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 268, Training loss: 1.375631, Validation loss: 1.3872, lr: 0.0000\n",
      "Epoch: 269, Training loss: 1.374830, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 270, Training loss: 1.513458, Validation loss: 1.3672, lr: 0.0000\n",
      "Epoch: 271, Training loss: 1.405901, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 272, Training loss: 1.396296, Validation loss: 1.3883, lr: 0.0000\n",
      "Epoch: 273, Training loss: 1.375069, Validation loss: 1.3795, lr: 0.0000\n",
      "Epoch: 274, Training loss: 1.371089, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 275, Training loss: 1.384882, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 276, Training loss: 1.370979, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 277, Training loss: 1.373149, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 278, Training loss: 1.381413, Validation loss: 1.3929, lr: 0.0000\n",
      "Epoch: 279, Training loss: 1.363023, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 280, Training loss: 1.384840, Validation loss: 1.3800, lr: 0.0000\n",
      "Epoch: 281, Training loss: 1.378203, Validation loss: 1.3871, lr: 0.0000\n",
      "Epoch: 282, Training loss: 1.399762, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 283, Training loss: 1.385699, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 284, Training loss: 1.383307, Validation loss: 1.3800, lr: 0.0000\n",
      "Epoch: 285, Training loss: 1.383060, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 286, Training loss: 1.379680, Validation loss: 1.3887, lr: 0.0000\n",
      "Epoch: 287, Training loss: 1.383694, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 288, Training loss: 1.373213, Validation loss: 1.3797, lr: 0.0000\n",
      "Epoch: 289, Training loss: 1.391417, Validation loss: 1.4160, lr: 0.0000\n",
      "Epoch: 290, Training loss: 1.386255, Validation loss: 1.3679, lr: 0.0000\n",
      "Epoch: 291, Training loss: 1.391333, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 292, Training loss: 1.392126, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 293, Training loss: 1.374032, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 294, Training loss: 1.387516, Validation loss: 1.3756, lr: 0.0000\n",
      "Epoch: 295, Training loss: 1.384793, Validation loss: 1.3693, lr: 0.0000\n",
      "Epoch: 296, Training loss: 1.390591, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 297, Training loss: 1.375063, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 298, Training loss: 1.380369, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 299, Training loss: 1.376552, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 300, Training loss: 1.391042, Validation loss: 1.3621, lr: 0.0000\n",
      "Epoch: 301, Training loss: 1.372404, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 302, Training loss: 1.383716, Validation loss: 1.3819, lr: 0.0000\n",
      " *och: 303, Training loss: 1.383828, Validation loss: 1.3502, lr: 0.0000\n",
      "Epoch: 304, Training loss: 1.405314, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 305, Training loss: 1.385367, Validation loss: 1.3760, lr: 0.0000\n",
      "Epoch: 306, Training loss: 1.388417, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 307, Training loss: 1.383401, Validation loss: 1.3767, lr: 0.0000\n",
      "Epoch: 308, Training loss: 1.379596, Validation loss: 1.3779, lr: 0.0000\n",
      "Epoch: 309, Training loss: 1.391402, Validation loss: 1.3729, lr: 0.0000\n",
      "Epoch: 310, Training loss: 1.384372, Validation loss: 1.3793, lr: 0.0000\n",
      "Epoch: 311, Training loss: 1.384342, Validation loss: 1.3667, lr: 0.0000\n",
      "Epoch: 312, Training loss: 1.425077, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 313, Training loss: 1.374800, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 314, Training loss: 1.381339, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 315, Training loss: 1.403063, Validation loss: 1.3884, lr: 0.0000\n",
      "Epoch: 316, Training loss: 1.408754, Validation loss: 1.3902, lr: 0.0000\n",
      "Epoch: 317, Training loss: 1.384336, Validation loss: 1.3970, lr: 0.0000\n",
      "Epoch: 318, Training loss: 1.400234, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 319, Training loss: 1.378363, Validation loss: 1.3772, lr: 0.0000\n",
      "Epoch: 320, Training loss: 1.365648, Validation loss: 1.3871, lr: 0.0000\n",
      "Epoch: 321, Training loss: 1.384552, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 322, Training loss: 1.377751, Validation loss: 1.3740, lr: 0.0000\n",
      "Epoch: 323, Training loss: 1.380612, Validation loss: 1.3675, lr: 0.0000\n",
      "Epoch: 324, Training loss: 1.397114, Validation loss: 1.3886, lr: 0.0000\n",
      "Epoch: 325, Training loss: 1.392909, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 326, Training loss: 1.406104, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 327, Training loss: 1.403268, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 328, Training loss: 1.375390, Validation loss: 1.3894, lr: 0.0000\n",
      "Epoch: 329, Training loss: 1.375076, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 330, Training loss: 1.368527, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 331, Training loss: 1.382247, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 332, Training loss: 1.382159, Validation loss: 1.3875, lr: 0.0000\n",
      "Epoch: 333, Training loss: 1.387380, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 334, Training loss: 1.395585, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 335, Training loss: 1.412864, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 336, Training loss: 1.373236, Validation loss: 1.3715, lr: 0.0000\n",
      "Epoch: 337, Training loss: 1.383231, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 338, Training loss: 1.374193, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 339, Training loss: 1.394931, Validation loss: 1.3887, lr: 0.0000\n",
      "Epoch: 340, Training loss: 1.370791, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 341, Training loss: 1.392168, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 342, Training loss: 1.385287, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 343, Training loss: 1.392990, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 344, Training loss: 1.440112, Validation loss: 1.3723, lr: 0.0000\n",
      "Epoch: 345, Training loss: 1.383519, Validation loss: 1.3940, lr: 0.0000\n",
      "Epoch: 346, Training loss: 1.384159, Validation loss: 1.3874, lr: 0.0000\n",
      "Epoch: 347, Training loss: 1.364461, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 348, Training loss: 1.374802, Validation loss: 1.3871, lr: 0.0000\n",
      "Epoch: 349, Training loss: 1.381906, Validation loss: 1.3897, lr: 0.0000\n",
      "Epoch: 350, Training loss: 1.395822, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 351, Training loss: 1.381884, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 352, Training loss: 1.424572, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 353, Training loss: 1.370726, Validation loss: 1.3682, lr: 0.0000\n",
      "Epoch: 354, Training loss: 1.370562, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 355, Training loss: 1.387382, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 356, Training loss: 1.377234, Validation loss: 1.3970, lr: 0.0000\n",
      "Epoch: 357, Training loss: 1.375880, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 358, Training loss: 1.381328, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 359, Training loss: 1.384557, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 360, Training loss: 1.380827, Validation loss: 1.3748, lr: 0.0000\n",
      "Epoch: 361, Training loss: 1.381796, Validation loss: 1.3772, lr: 0.0000\n",
      "Epoch: 362, Training loss: 1.373493, Validation loss: 1.3925, lr: 0.0000\n",
      "Epoch: 363, Training loss: 1.391508, Validation loss: 1.3873, lr: 0.0000\n",
      "Epoch: 364, Training loss: 1.377489, Validation loss: 1.3981, lr: 0.0000\n",
      "Epoch: 365, Training loss: 1.397045, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 366, Training loss: 1.387358, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 367, Training loss: 1.384176, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 368, Training loss: 1.390019, Validation loss: 1.3707, lr: 0.0000\n",
      "Epoch: 369, Training loss: 1.388224, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 370, Training loss: 1.385030, Validation loss: 1.3784, lr: 0.0000\n",
      "Epoch: 371, Training loss: 1.367771, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 372, Training loss: 1.396818, Validation loss: 1.5686, lr: 0.0000\n",
      "Epoch: 373, Training loss: 1.385460, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 374, Training loss: 1.375408, Validation loss: 1.3725, lr: 0.0000\n",
      "Epoch: 375, Training loss: 1.370154, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 376, Training loss: 1.408889, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 377, Training loss: 1.385243, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 378, Training loss: 1.390890, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 379, Training loss: 1.372837, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 380, Training loss: 1.403206, Validation loss: 1.3757, lr: 0.0000\n",
      "Epoch: 381, Training loss: 1.375743, Validation loss: 1.3543, lr: 0.0000\n",
      "Epoch: 382, Training loss: 1.390236, Validation loss: 1.3632, lr: 0.0000\n",
      "Epoch: 383, Training loss: 1.381010, Validation loss: 1.4981, lr: 0.0000\n",
      "Epoch: 384, Training loss: 1.490313, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 385, Training loss: 1.390008, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 386, Training loss: 1.383953, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 387, Training loss: 1.393262, Validation loss: 1.3878, lr: 0.0000\n",
      "Epoch: 388, Training loss: 1.379601, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 389, Training loss: 1.392773, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 390, Training loss: 1.388965, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 391, Training loss: 1.407160, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 392, Training loss: 1.387041, Validation loss: 1.3769, lr: 0.0000\n",
      "Epoch: 393, Training loss: 1.378116, Validation loss: 1.3852, lr: 0.0000\n",
      " *och: 394, Training loss: 1.380174, Validation loss: 1.3502, lr: 0.0000\n",
      "Epoch: 395, Training loss: 1.375194, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 396, Training loss: 1.367090, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 397, Training loss: 1.400284, Validation loss: 1.3759, lr: 0.0000\n",
      "Epoch: 398, Training loss: 1.394745, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 399, Training loss: 1.391472, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 400, Training loss: 1.383272, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 401, Training loss: 1.392377, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 402, Training loss: 1.377891, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 403, Training loss: 1.435620, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 404, Training loss: 1.370949, Validation loss: 1.3873, lr: 0.0000\n",
      "Epoch: 405, Training loss: 1.377794, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 406, Training loss: 1.394372, Validation loss: 1.3809, lr: 0.0000\n",
      "Epoch: 407, Training loss: 1.371351, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 408, Training loss: 1.384645, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 409, Training loss: 1.425740, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 410, Training loss: 1.383616, Validation loss: 1.3886, lr: 0.0000\n",
      "Epoch: 411, Training loss: 1.386131, Validation loss: 1.3742, lr: 0.0000\n",
      "Epoch: 412, Training loss: 1.392309, Validation loss: 1.3746, lr: 0.0000\n",
      "Epoch: 413, Training loss: 1.387298, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 414, Training loss: 1.375442, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 415, Training loss: 1.379611, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 416, Training loss: 1.388191, Validation loss: 1.3737, lr: 0.0000\n",
      "Epoch: 417, Training loss: 1.379192, Validation loss: 1.3893, lr: 0.0000\n",
      "Epoch: 418, Training loss: 1.384642, Validation loss: 1.3600, lr: 0.0000\n",
      "Epoch: 419, Training loss: 1.383847, Validation loss: 1.3689, lr: 0.0000\n",
      "Epoch: 420, Training loss: 1.391695, Validation loss: 1.3876, lr: 0.0000\n",
      "Epoch: 421, Training loss: 1.380397, Validation loss: 1.3775, lr: 0.0000\n",
      "Epoch: 422, Training loss: 1.382151, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 423, Training loss: 1.433014, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 424, Training loss: 1.375021, Validation loss: 1.3956, lr: 0.0000\n",
      "Epoch: 425, Training loss: 1.394452, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 426, Training loss: 1.384290, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 427, Training loss: 1.378557, Validation loss: 1.3796, lr: 0.0000\n",
      "Epoch: 428, Training loss: 1.395543, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 429, Training loss: 1.440126, Validation loss: 1.4278, lr: 0.0000\n",
      "Epoch: 430, Training loss: 1.389089, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 431, Training loss: 1.379482, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 432, Training loss: 1.378247, Validation loss: 1.3972, lr: 0.0000\n",
      "Epoch: 433, Training loss: 1.381116, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 434, Training loss: 1.389452, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 435, Training loss: 1.377062, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 436, Training loss: 1.380744, Validation loss: 1.3875, lr: 0.0000\n",
      "Epoch: 437, Training loss: 1.388149, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 438, Training loss: 1.377743, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 439, Training loss: 1.371692, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 440, Training loss: 1.379402, Validation loss: 1.3642, lr: 0.0000\n",
      "Epoch: 441, Training loss: 1.374731, Validation loss: 1.3639, lr: 0.0000\n",
      "Epoch: 442, Training loss: 1.384074, Validation loss: 1.3695, lr: 0.0000\n",
      "Epoch: 443, Training loss: 1.375325, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 444, Training loss: 1.374904, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 445, Training loss: 1.386168, Validation loss: 1.3733, lr: 0.0000\n",
      "Epoch: 446, Training loss: 1.393510, Validation loss: 1.3704, lr: 0.0000\n",
      "Epoch: 447, Training loss: 1.380993, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 448, Training loss: 1.395114, Validation loss: 1.3888, lr: 0.0000\n",
      "Epoch: 449, Training loss: 1.394253, Validation loss: 1.3885, lr: 0.0000\n",
      "Epoch: 450, Training loss: 1.382821, Validation loss: 1.3894, lr: 0.0000\n",
      "Epoch: 451, Training loss: 1.366766, Validation loss: 1.3884, lr: 0.0000\n",
      "Epoch: 452, Training loss: 1.380591, Validation loss: 1.3879, lr: 0.0000\n",
      "Epoch: 453, Training loss: 1.377569, Validation loss: 1.3677, lr: 0.0000\n",
      "Epoch: 454, Training loss: 1.372512, Validation loss: 1.3536, lr: 0.0000\n",
      "Epoch: 455, Training loss: 1.372795, Validation loss: 1.3880, lr: 0.0000\n",
      "Epoch: 456, Training loss: 1.370817, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 457, Training loss: 1.383976, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 458, Training loss: 1.380659, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 459, Training loss: 1.433211, Validation loss: 1.3888, lr: 0.0000\n",
      "Epoch: 460, Training loss: 1.374618, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 461, Training loss: 1.377654, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 462, Training loss: 1.373907, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 463, Training loss: 1.369164, Validation loss: 1.3652, lr: 0.0000\n",
      "Epoch: 464, Training loss: 1.371543, Validation loss: 1.3716, lr: 0.0000\n",
      "Epoch: 465, Training loss: 1.369820, Validation loss: 1.3757, lr: 0.0000\n",
      "Epoch: 466, Training loss: 1.388979, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 467, Training loss: 1.400832, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 468, Training loss: 1.389339, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 469, Training loss: 1.365688, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 470, Training loss: 1.386107, Validation loss: 1.3549, lr: 0.0000\n",
      "Epoch: 471, Training loss: 1.396036, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 472, Training loss: 1.372411, Validation loss: 1.3962, lr: 0.0000\n",
      "Epoch: 473, Training loss: 1.384025, Validation loss: 1.3956, lr: 0.0000\n",
      "Epoch: 474, Training loss: 1.379054, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 475, Training loss: 1.381895, Validation loss: 1.3873, lr: 0.0000\n",
      "Epoch: 476, Training loss: 1.394707, Validation loss: 1.3871, lr: 0.0000\n",
      "Epoch: 477, Training loss: 1.379134, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 478, Training loss: 1.386441, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 479, Training loss: 1.442162, Validation loss: 1.3748, lr: 0.0000\n",
      "Epoch: 480, Training loss: 1.390332, Validation loss: 1.3715, lr: 0.0000\n",
      "Epoch: 481, Training loss: 1.376606, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 482, Training loss: 1.376405, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 483, Training loss: 1.370554, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 484, Training loss: 1.394186, Validation loss: 1.3682, lr: 0.0000\n",
      "Epoch: 485, Training loss: 1.381140, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 486, Training loss: 1.372726, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 487, Training loss: 1.380002, Validation loss: 1.3735, lr: 0.0000\n",
      "Epoch: 488, Training loss: 1.376999, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 489, Training loss: 1.378705, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 490, Training loss: 1.389472, Validation loss: 1.3742, lr: 0.0000\n",
      "Epoch: 491, Training loss: 1.386538, Validation loss: 1.3778, lr: 0.0000\n",
      "Epoch: 492, Training loss: 1.375355, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 493, Training loss: 1.378614, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 494, Training loss: 1.363211, Validation loss: 1.3945, lr: 0.0000\n",
      "Epoch: 495, Training loss: 1.393607, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 496, Training loss: 1.391909, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 497, Training loss: 1.373135, Validation loss: 1.3873, lr: 0.0000\n",
      "Epoch: 498, Training loss: 1.371659, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 499, Training loss: 1.377011, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 500, Training loss: 1.385860, Validation loss: 1.3931, lr: 0.0000\n",
      "Epoch: 501, Training loss: 1.371360, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 502, Training loss: 1.378823, Validation loss: 1.3726, lr: 0.0000\n",
      "Epoch: 503, Training loss: 1.391035, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 504, Training loss: 1.373120, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 505, Training loss: 1.382863, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 506, Training loss: 1.401918, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 507, Training loss: 1.369155, Validation loss: 1.3872, lr: 0.0000\n",
      "Epoch: 508, Training loss: 1.370299, Validation loss: 1.3763, lr: 0.0000\n",
      "Epoch: 509, Training loss: 1.383321, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 510, Training loss: 1.380424, Validation loss: 1.3908, lr: 0.0000\n",
      "Epoch: 511, Training loss: 1.376481, Validation loss: 1.3788, lr: 0.0000\n",
      "Epoch: 512, Training loss: 1.393391, Validation loss: 1.3725, lr: 0.0000\n",
      "Epoch: 513, Training loss: 1.387720, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 514, Training loss: 1.387125, Validation loss: 1.3891, lr: 0.0000\n",
      "Epoch: 515, Training loss: 1.384306, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 516, Training loss: 1.370528, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 517, Training loss: 1.396131, Validation loss: 1.3875, lr: 0.0000\n",
      "Epoch: 518, Training loss: 1.397808, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 519, Training loss: 1.387788, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 520, Training loss: 1.388944, Validation loss: 1.3876, lr: 0.0000\n",
      "Epoch: 521, Training loss: 1.397196, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 522, Training loss: 1.384594, Validation loss: 1.3875, lr: 0.0000\n",
      "Epoch: 523, Training loss: 1.389756, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 524, Training loss: 1.377790, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 525, Training loss: 1.374908, Validation loss: 1.3790, lr: 0.0000\n",
      "Epoch: 526, Training loss: 1.392064, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 527, Training loss: 1.376202, Validation loss: 1.3737, lr: 0.0000\n",
      "Epoch: 528, Training loss: 1.394607, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 529, Training loss: 1.371053, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 530, Training loss: 1.387472, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 531, Training loss: 1.410455, Validation loss: 1.3897, lr: 0.0000\n",
      "Epoch: 532, Training loss: 1.370962, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 533, Training loss: 1.376708, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 534, Training loss: 1.379783, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 535, Training loss: 1.373941, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 536, Training loss: 1.406184, Validation loss: 1.3728, lr: 0.0000\n",
      "Epoch: 537, Training loss: 1.388118, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 538, Training loss: 1.387876, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 539, Training loss: 1.371172, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 540, Training loss: 1.392237, Validation loss: 1.3941, lr: 0.0000\n",
      "Epoch: 541, Training loss: 1.401174, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 542, Training loss: 1.376070, Validation loss: 1.3889, lr: 0.0000\n",
      "Epoch: 543, Training loss: 1.370145, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 544, Training loss: 1.376653, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 545, Training loss: 1.379589, Validation loss: 1.3878, lr: 0.0000\n",
      "Epoch: 546, Training loss: 1.397203, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 547, Training loss: 1.390674, Validation loss: 1.3876, lr: 0.0000\n",
      "Epoch: 548, Training loss: 1.406136, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 549, Training loss: 1.381928, Validation loss: 1.3729, lr: 0.0000\n",
      "Epoch: 550, Training loss: 1.375644, Validation loss: 1.3607, lr: 0.0000\n",
      "Epoch: 551, Training loss: 1.373125, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 552, Training loss: 1.367918, Validation loss: 1.3847, lr: 0.0000\n",
      " *och: 553, Training loss: 1.375700, Validation loss: 1.3349, lr: 0.0000\n",
      "Epoch: 554, Training loss: 1.389145, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 555, Training loss: 1.369614, Validation loss: 1.3788, lr: 0.0000\n",
      "Epoch: 556, Training loss: 1.410227, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 557, Training loss: 1.380968, Validation loss: 1.3775, lr: 0.0000\n",
      "Epoch: 558, Training loss: 1.391463, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 559, Training loss: 1.379320, Validation loss: 1.3914, lr: 0.0000\n",
      "Epoch: 560, Training loss: 1.376692, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 561, Training loss: 1.384936, Validation loss: 1.3797, lr: 0.0000\n",
      "Epoch: 562, Training loss: 1.368743, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 563, Training loss: 1.385226, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 564, Training loss: 1.388167, Validation loss: 1.3798, lr: 0.0000\n",
      "Epoch: 565, Training loss: 1.380896, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 566, Training loss: 1.398322, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 567, Training loss: 1.383833, Validation loss: 1.3646, lr: 0.0000\n",
      "Epoch: 568, Training loss: 1.395278, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 569, Training loss: 1.376225, Validation loss: 1.3603, lr: 0.0000\n",
      "Epoch: 570, Training loss: 1.390836, Validation loss: 1.3873, lr: 0.0000\n",
      "Epoch: 571, Training loss: 1.382766, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 572, Training loss: 1.394003, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 573, Training loss: 1.385106, Validation loss: 1.3912, lr: 0.0000\n",
      "Epoch: 574, Training loss: 1.442876, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 575, Training loss: 1.371389, Validation loss: 1.3888, lr: 0.0000\n",
      "Epoch: 576, Training loss: 1.383141, Validation loss: 1.3929, lr: 0.0000\n",
      "Epoch: 577, Training loss: 1.392850, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 578, Training loss: 1.375623, Validation loss: 1.3734, lr: 0.0000\n",
      "Epoch: 579, Training loss: 1.380739, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 580, Training loss: 1.376355, Validation loss: 1.3754, lr: 0.0000\n",
      "Epoch: 581, Training loss: 1.364206, Validation loss: 1.3933, lr: 0.0000\n",
      "Epoch: 582, Training loss: 1.372088, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 583, Training loss: 1.385496, Validation loss: 1.3802, lr: 0.0000\n",
      "Epoch: 584, Training loss: 1.384765, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 585, Training loss: 1.386409, Validation loss: 1.3873, lr: 0.0000\n",
      "Epoch: 586, Training loss: 1.385560, Validation loss: 1.3749, lr: 0.0000\n",
      "Epoch: 587, Training loss: 1.384579, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 588, Training loss: 1.372333, Validation loss: 1.3920, lr: 0.0000\n",
      "Epoch: 589, Training loss: 1.382421, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 590, Training loss: 1.393663, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 591, Training loss: 1.398245, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 592, Training loss: 1.379217, Validation loss: 1.3894, lr: 0.0000\n",
      "Epoch: 593, Training loss: 1.383951, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 594, Training loss: 1.389459, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 595, Training loss: 1.392078, Validation loss: 1.3742, lr: 0.0000\n",
      "Epoch: 596, Training loss: 1.384890, Validation loss: 1.3880, lr: 0.0000\n",
      "Epoch: 597, Training loss: 1.378872, Validation loss: 1.3809, lr: 0.0000\n",
      "Epoch: 598, Training loss: 1.375534, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 599, Training loss: 1.376491, Validation loss: 1.3685, lr: 0.0000\n",
      "Epoch: 600, Training loss: 1.382525, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 601, Training loss: 1.385029, Validation loss: 1.3902, lr: 0.0000\n",
      "Epoch: 602, Training loss: 1.367427, Validation loss: 1.3800, lr: 0.0000\n",
      "Epoch: 603, Training loss: 1.386269, Validation loss: 1.3892, lr: 0.0000\n",
      "Epoch: 604, Training loss: 1.391624, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 605, Training loss: 1.386532, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 606, Training loss: 1.396237, Validation loss: 1.3775, lr: 0.0000\n",
      "Epoch: 607, Training loss: 1.403407, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 608, Training loss: 1.394797, Validation loss: 1.3774, lr: 0.0000\n",
      "Epoch: 609, Training loss: 1.371195, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 610, Training loss: 1.397358, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 611, Training loss: 1.389209, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 612, Training loss: 1.372290, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 613, Training loss: 1.372666, Validation loss: 1.3766, lr: 0.0000\n",
      "Epoch: 614, Training loss: 1.376664, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 615, Training loss: 1.372973, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 616, Training loss: 1.370985, Validation loss: 1.3724, lr: 0.0000\n",
      "Epoch: 617, Training loss: 1.402034, Validation loss: 1.3936, lr: 0.0000\n",
      "Epoch: 618, Training loss: 1.391526, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 619, Training loss: 1.379660, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 620, Training loss: 1.372333, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 621, Training loss: 1.389985, Validation loss: 1.3715, lr: 0.0000\n",
      "Epoch: 622, Training loss: 1.412012, Validation loss: 1.3745, lr: 0.0000\n",
      "Epoch: 623, Training loss: 1.400691, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 624, Training loss: 1.374373, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 625, Training loss: 1.388770, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 626, Training loss: 1.378484, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 627, Training loss: 1.387849, Validation loss: 1.3876, lr: 0.0000\n",
      "Epoch: 628, Training loss: 1.380491, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 629, Training loss: 1.381730, Validation loss: 1.3963, lr: 0.0000\n",
      "Epoch: 630, Training loss: 1.379262, Validation loss: 1.4497, lr: 0.0000\n",
      "Epoch: 631, Training loss: 1.370431, Validation loss: 1.3566, lr: 0.0000\n",
      "Epoch: 632, Training loss: 1.377192, Validation loss: 1.5992, lr: 0.0000\n",
      "Epoch: 633, Training loss: 1.376611, Validation loss: 1.3895, lr: 0.0000\n",
      "Epoch: 634, Training loss: 1.386065, Validation loss: 1.3947, lr: 0.0000\n",
      "Epoch: 635, Training loss: 1.386855, Validation loss: 1.3721, lr: 0.0000\n",
      "Epoch: 636, Training loss: 1.388090, Validation loss: 1.3905, lr: 0.0000\n",
      "Epoch: 637, Training loss: 1.398525, Validation loss: 1.3888, lr: 0.0000\n",
      "Epoch: 638, Training loss: 1.387234, Validation loss: 1.3884, lr: 0.0000\n",
      "Epoch: 639, Training loss: 1.386296, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 640, Training loss: 1.359705, Validation loss: 1.3686, lr: 0.0000\n",
      "Epoch: 641, Training loss: 1.387163, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 642, Training loss: 1.382801, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 643, Training loss: 1.373031, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 644, Training loss: 1.377466, Validation loss: 2.2805, lr: 0.0000\n",
      "Epoch: 645, Training loss: 1.384710, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 646, Training loss: 1.367523, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 647, Training loss: 1.380469, Validation loss: 1.3954, lr: 0.0000\n",
      "Epoch: 648, Training loss: 1.393280, Validation loss: 1.3784, lr: 0.0000\n",
      "Epoch: 649, Training loss: 1.371951, Validation loss: 1.3730, lr: 0.0000\n",
      "Epoch: 650, Training loss: 1.377286, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 651, Training loss: 1.383423, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 652, Training loss: 1.381803, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 653, Training loss: 1.390183, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 654, Training loss: 1.363011, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 655, Training loss: 1.375409, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 656, Training loss: 1.389204, Validation loss: 1.3455, lr: 0.0000\n",
      "Epoch: 657, Training loss: 1.379747, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 658, Training loss: 1.378888, Validation loss: 1.3784, lr: 0.0000\n",
      "Epoch: 659, Training loss: 1.394643, Validation loss: 1.3909, lr: 0.0000\n",
      "Epoch: 660, Training loss: 1.386444, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 661, Training loss: 1.380936, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 662, Training loss: 1.389239, Validation loss: 1.3872, lr: 0.0000\n",
      "Epoch: 663, Training loss: 1.377832, Validation loss: 1.3751, lr: 0.0000\n",
      "Epoch: 664, Training loss: 1.372038, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 665, Training loss: 1.376740, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 666, Training loss: 1.383081, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 667, Training loss: 1.382750, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 668, Training loss: 1.373425, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 669, Training loss: 1.371095, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 670, Training loss: 1.390699, Validation loss: 1.3898, lr: 0.0000\n",
      "Epoch: 671, Training loss: 1.372260, Validation loss: 1.3788, lr: 0.0000\n",
      "Epoch: 672, Training loss: 1.399809, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 673, Training loss: 1.423466, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 674, Training loss: 1.379966, Validation loss: 1.3882, lr: 0.0000\n",
      "Epoch: 675, Training loss: 1.401098, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 676, Training loss: 1.396107, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 677, Training loss: 1.483953, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 678, Training loss: 1.384762, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 679, Training loss: 1.400509, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 680, Training loss: 1.381491, Validation loss: 1.3733, lr: 0.0000\n",
      "Epoch: 681, Training loss: 1.378063, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 682, Training loss: 1.380559, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 683, Training loss: 1.363031, Validation loss: 1.3729, lr: 0.0000\n",
      "Epoch: 684, Training loss: 1.378793, Validation loss: 1.3713, lr: 0.0000\n",
      "Epoch: 685, Training loss: 1.385499, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 686, Training loss: 1.395179, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 687, Training loss: 1.409519, Validation loss: 1.3716, lr: 0.0000\n",
      "Epoch: 688, Training loss: 1.397374, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 689, Training loss: 1.381572, Validation loss: 1.3705, lr: 0.0000\n",
      "Epoch: 690, Training loss: 1.378049, Validation loss: 1.3871, lr: 0.0000\n",
      "Epoch: 691, Training loss: 1.432910, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 692, Training loss: 1.379482, Validation loss: 1.3904, lr: 0.0000\n",
      "Epoch: 693, Training loss: 1.380559, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 694, Training loss: 1.393355, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 695, Training loss: 1.392882, Validation loss: 1.3792, lr: 0.0000\n",
      "Epoch: 696, Training loss: 1.367472, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 697, Training loss: 1.385249, Validation loss: 1.3714, lr: 0.0000\n",
      "Epoch: 698, Training loss: 1.381684, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 699, Training loss: 1.377787, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 700, Training loss: 1.383599, Validation loss: 1.3613, lr: 0.0000\n",
      "Epoch: 701, Training loss: 1.393841, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 702, Training loss: 1.366499, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 703, Training loss: 1.381866, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 704, Training loss: 1.375970, Validation loss: 1.3795, lr: 0.0000\n",
      "Epoch: 705, Training loss: 1.374019, Validation loss: 1.3985, lr: 0.0000\n",
      "Epoch: 706, Training loss: 1.386382, Validation loss: 1.3900, lr: 0.0000\n",
      "Epoch: 707, Training loss: 1.390090, Validation loss: 1.3716, lr: 0.0000\n",
      "Epoch: 708, Training loss: 1.384166, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 709, Training loss: 1.386878, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 710, Training loss: 1.388326, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 711, Training loss: 1.397064, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 712, Training loss: 1.371353, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 713, Training loss: 1.388755, Validation loss: 1.3910, lr: 0.0000\n",
      "Epoch: 714, Training loss: 1.399777, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 715, Training loss: 1.396159, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 716, Training loss: 1.382827, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 717, Training loss: 1.390707, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 718, Training loss: 1.385566, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 719, Training loss: 1.360455, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 720, Training loss: 1.390596, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 721, Training loss: 1.410253, Validation loss: 1.3884, lr: 0.0000\n",
      "Epoch: 722, Training loss: 1.387552, Validation loss: 1.3780, lr: 0.0000\n",
      "Epoch: 723, Training loss: 1.394375, Validation loss: 1.3959, lr: 0.0000\n",
      "Epoch: 724, Training loss: 1.374981, Validation loss: 1.3873, lr: 0.0000\n",
      "Epoch: 725, Training loss: 1.386104, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 726, Training loss: 1.388227, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 727, Training loss: 1.408267, Validation loss: 1.3533, lr: 0.0000\n",
      "Epoch: 728, Training loss: 1.378952, Validation loss: 1.3745, lr: 0.0000\n",
      "Epoch: 729, Training loss: 1.409010, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 730, Training loss: 1.391269, Validation loss: 1.3895, lr: 0.0000\n",
      "Epoch: 731, Training loss: 1.369496, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 732, Training loss: 1.377277, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 733, Training loss: 1.390401, Validation loss: 1.3792, lr: 0.0000\n",
      "Epoch: 734, Training loss: 1.383073, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 735, Training loss: 1.388495, Validation loss: 1.3891, lr: 0.0000\n",
      "Epoch: 736, Training loss: 1.391182, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 737, Training loss: 1.379446, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 738, Training loss: 1.389586, Validation loss: 1.4013, lr: 0.0000\n",
      "Epoch: 739, Training loss: 1.394201, Validation loss: 1.3897, lr: 0.0000\n",
      "Epoch: 740, Training loss: 1.379653, Validation loss: 1.3966, lr: 0.0000\n",
      "Epoch: 741, Training loss: 1.375209, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 742, Training loss: 1.390352, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 743, Training loss: 1.386831, Validation loss: 1.3879, lr: 0.0000\n",
      "Epoch: 744, Training loss: 1.379032, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 745, Training loss: 1.410460, Validation loss: 1.3714, lr: 0.0000\n",
      "Epoch: 746, Training loss: 1.370315, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 747, Training loss: 1.391738, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 748, Training loss: 1.377319, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 749, Training loss: 1.382671, Validation loss: 1.3873, lr: 0.0000\n",
      "Epoch: 750, Training loss: 1.401545, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 751, Training loss: 1.380265, Validation loss: 1.3888, lr: 0.0000\n",
      "Epoch: 752, Training loss: 1.384025, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 753, Training loss: 1.385638, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 754, Training loss: 1.369507, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 755, Training loss: 1.387137, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 756, Training loss: 1.385486, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 757, Training loss: 1.374370, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 758, Training loss: 1.388111, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 759, Training loss: 1.367807, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 760, Training loss: 1.390842, Validation loss: 1.3874, lr: 0.0000\n",
      "Epoch: 761, Training loss: 1.392324, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 762, Training loss: 1.378830, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 763, Training loss: 1.373781, Validation loss: 1.3917, lr: 0.0000\n",
      "Epoch: 764, Training loss: 1.368782, Validation loss: 1.3875, lr: 0.0000\n",
      "Epoch: 765, Training loss: 1.403069, Validation loss: 1.3793, lr: 0.0000\n",
      "Epoch: 766, Training loss: 1.370175, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 767, Training loss: 1.375128, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 768, Training loss: 1.380719, Validation loss: 1.3709, lr: 0.0000\n",
      "Epoch: 769, Training loss: 1.366361, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 770, Training loss: 1.475845, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 771, Training loss: 1.392652, Validation loss: 1.3618, lr: 0.0000\n",
      "Epoch: 772, Training loss: 1.381660, Validation loss: 1.3875, lr: 0.0000\n",
      "Epoch: 773, Training loss: 1.381495, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 774, Training loss: 1.374863, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 775, Training loss: 1.391834, Validation loss: 1.4089, lr: 0.0000\n",
      "Epoch: 776, Training loss: 1.374703, Validation loss: 1.3770, lr: 0.0000\n",
      "Epoch: 777, Training loss: 1.397781, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 778, Training loss: 1.382055, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 779, Training loss: 1.384461, Validation loss: 1.3875, lr: 0.0000\n",
      "Epoch: 780, Training loss: 1.401678, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 781, Training loss: 1.383227, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 782, Training loss: 1.386120, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 783, Training loss: 1.394199, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 784, Training loss: 1.377492, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 785, Training loss: 1.374561, Validation loss: 1.3880, lr: 0.0000\n",
      "Epoch: 786, Training loss: 1.384640, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 787, Training loss: 1.381174, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 788, Training loss: 1.372109, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 789, Training loss: 1.395252, Validation loss: 1.3876, lr: 0.0000\n",
      "Epoch: 790, Training loss: 1.380297, Validation loss: 1.3922, lr: 0.0000\n",
      "Epoch: 791, Training loss: 1.390946, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 792, Training loss: 1.387945, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 793, Training loss: 1.374268, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 794, Training loss: 1.370600, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 795, Training loss: 1.394398, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 796, Training loss: 1.396998, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 797, Training loss: 1.395515, Validation loss: 1.3786, lr: 0.0000\n",
      "Epoch: 798, Training loss: 1.390762, Validation loss: 1.3555, lr: 0.0000\n",
      "Epoch: 799, Training loss: 1.396573, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 800, Training loss: 1.389547, Validation loss: 1.3946, lr: 0.0000\n",
      "Epoch: 801, Training loss: 1.365886, Validation loss: 1.3509, lr: 0.0000\n",
      "Epoch: 802, Training loss: 1.387276, Validation loss: 1.3878, lr: 0.0000\n",
      "Epoch: 803, Training loss: 1.416461, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 804, Training loss: 1.388944, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 805, Training loss: 1.400014, Validation loss: 3.1106, lr: 0.0000\n",
      "Epoch: 806, Training loss: 1.371380, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 807, Training loss: 1.389703, Validation loss: 1.3802, lr: 0.0000\n",
      "Epoch: 808, Training loss: 1.389445, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 809, Training loss: 1.378754, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 810, Training loss: 1.381830, Validation loss: 1.3884, lr: 0.0000\n",
      "Epoch: 811, Training loss: 1.375592, Validation loss: 1.3769, lr: 0.0000\n",
      "Epoch: 812, Training loss: 1.372300, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 813, Training loss: 1.373893, Validation loss: 1.3628, lr: 0.0000\n",
      "Epoch: 814, Training loss: 1.385973, Validation loss: 1.4100, lr: 0.0000\n",
      "Epoch: 815, Training loss: 1.366648, Validation loss: 1.3748, lr: 0.0000\n",
      "Epoch: 816, Training loss: 1.384193, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 817, Training loss: 1.394964, Validation loss: 1.3876, lr: 0.0000\n",
      "Epoch: 818, Training loss: 1.378556, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 819, Training loss: 1.373191, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 820, Training loss: 1.394175, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 821, Training loss: 1.383642, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 822, Training loss: 1.375164, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 823, Training loss: 1.511977, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 824, Training loss: 1.391592, Validation loss: 1.3872, lr: 0.0000\n",
      "Epoch: 825, Training loss: 1.411646, Validation loss: 1.3758, lr: 0.0000\n",
      "Epoch: 826, Training loss: 1.398085, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 827, Training loss: 1.402936, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 828, Training loss: 1.381667, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 829, Training loss: 1.376867, Validation loss: 1.3879, lr: 0.0000\n",
      "Epoch: 830, Training loss: 1.412982, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 831, Training loss: 1.381260, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 832, Training loss: 1.384213, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 833, Training loss: 1.379202, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 834, Training loss: 1.375366, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 835, Training loss: 1.374145, Validation loss: 1.3891, lr: 0.0000\n",
      "Epoch: 836, Training loss: 1.377283, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 837, Training loss: 1.396246, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 838, Training loss: 1.392242, Validation loss: 1.3888, lr: 0.0000\n",
      "Epoch: 839, Training loss: 1.380233, Validation loss: 1.3759, lr: 0.0000\n",
      "Epoch: 840, Training loss: 1.400442, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 841, Training loss: 1.378735, Validation loss: 1.3718, lr: 0.0000\n",
      "Epoch: 842, Training loss: 1.404384, Validation loss: 1.4078, lr: 0.0000\n",
      "Epoch: 843, Training loss: 1.389040, Validation loss: 1.3889, lr: 0.0000\n",
      "Epoch: 844, Training loss: 1.368613, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 845, Training loss: 1.380731, Validation loss: 1.3908, lr: 0.0000\n",
      "Epoch: 846, Training loss: 1.384365, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 847, Training loss: 1.388059, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 848, Training loss: 1.376517, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 849, Training loss: 1.371609, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 850, Training loss: 1.374908, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 851, Training loss: 1.380004, Validation loss: 1.3771, lr: 0.0000\n",
      "Epoch: 852, Training loss: 1.398213, Validation loss: 1.3383, lr: 0.0000\n",
      "Epoch: 853, Training loss: 1.381745, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 854, Training loss: 1.379480, Validation loss: 1.4936, lr: 0.0000\n",
      "Epoch: 855, Training loss: 1.370972, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 856, Training loss: 1.389122, Validation loss: 1.3578, lr: 0.0000\n",
      "Epoch: 857, Training loss: 1.384029, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 858, Training loss: 1.383225, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 859, Training loss: 1.390635, Validation loss: 1.3985, lr: 0.0000\n",
      "Epoch: 860, Training loss: 1.389282, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 861, Training loss: 1.368640, Validation loss: 1.3872, lr: 0.0000\n",
      "Epoch: 862, Training loss: 1.373450, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 863, Training loss: 1.376451, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 864, Training loss: 1.370805, Validation loss: 1.3971, lr: 0.0000\n",
      "Epoch: 865, Training loss: 1.374108, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 866, Training loss: 1.445186, Validation loss: 1.3872, lr: 0.0000\n",
      "Epoch: 867, Training loss: 1.387863, Validation loss: 1.3889, lr: 0.0000\n",
      "Epoch: 868, Training loss: 1.379525, Validation loss: 1.3791, lr: 0.0000\n",
      "Epoch: 869, Training loss: 1.388539, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 870, Training loss: 1.383619, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 871, Training loss: 1.388254, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 872, Training loss: 1.373448, Validation loss: 1.3877, lr: 0.0000\n",
      "Epoch: 873, Training loss: 1.373606, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 874, Training loss: 1.389016, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 875, Training loss: 1.382111, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 876, Training loss: 1.390357, Validation loss: 1.3888, lr: 0.0000\n",
      "Epoch: 877, Training loss: 1.384897, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 878, Training loss: 1.380400, Validation loss: 1.3877, lr: 0.0000\n",
      "Epoch: 879, Training loss: 1.364543, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 880, Training loss: 1.382417, Validation loss: 1.6625, lr: 0.0000\n",
      "Epoch: 881, Training loss: 1.386941, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 882, Training loss: 1.376002, Validation loss: 1.4012, lr: 0.0000\n",
      "Epoch: 883, Training loss: 1.384532, Validation loss: 1.3460, lr: 0.0000\n",
      "Epoch: 884, Training loss: 1.392589, Validation loss: 1.3714, lr: 0.0000\n",
      "Epoch: 885, Training loss: 1.438571, Validation loss: 1.3918, lr: 0.0000\n",
      "Epoch: 886, Training loss: 1.374773, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 887, Training loss: 1.376318, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 888, Training loss: 1.397094, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 889, Training loss: 1.375341, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 890, Training loss: 1.369937, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 891, Training loss: 1.380671, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 892, Training loss: 1.389048, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 893, Training loss: 1.373838, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 894, Training loss: 1.376818, Validation loss: 1.3873, lr: 0.0000\n",
      "Epoch: 895, Training loss: 1.386467, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 896, Training loss: 1.374282, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 897, Training loss: 1.387185, Validation loss: 1.3779, lr: 0.0000\n",
      "Epoch: 898, Training loss: 1.383093, Validation loss: 1.3877, lr: 0.0000\n",
      "Epoch: 899, Training loss: 1.365072, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 900, Training loss: 1.400496, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 901, Training loss: 1.380835, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 902, Training loss: 1.375526, Validation loss: 1.3736, lr: 0.0000\n",
      "Epoch: 903, Training loss: 1.408130, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 904, Training loss: 1.388491, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 905, Training loss: 1.412553, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 906, Training loss: 1.387819, Validation loss: 1.3875, lr: 0.0000\n",
      "Epoch: 907, Training loss: 1.383316, Validation loss: 1.3751, lr: 0.0000\n",
      "Epoch: 908, Training loss: 1.385181, Validation loss: 1.3693, lr: 0.0000\n",
      "Epoch: 909, Training loss: 1.379319, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 910, Training loss: 1.374792, Validation loss: 1.3892, lr: 0.0000\n",
      "Epoch: 911, Training loss: 1.394012, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 912, Training loss: 1.379068, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 913, Training loss: 1.381859, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 914, Training loss: 1.379383, Validation loss: 1.3739, lr: 0.0000\n",
      "Epoch: 915, Training loss: 1.377919, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 916, Training loss: 1.372226, Validation loss: 1.3784, lr: 0.0000\n",
      "Epoch: 917, Training loss: 1.382020, Validation loss: 1.3891, lr: 0.0000\n",
      "Epoch: 918, Training loss: 1.382447, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 919, Training loss: 1.382058, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 920, Training loss: 1.382757, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 921, Training loss: 1.387808, Validation loss: 1.3696, lr: 0.0000\n",
      "Epoch: 922, Training loss: 1.398472, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 923, Training loss: 1.387263, Validation loss: 1.3757, lr: 0.0000\n",
      "Epoch: 924, Training loss: 1.390349, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 925, Training loss: 1.476648, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 926, Training loss: 1.454348, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 927, Training loss: 1.399029, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 928, Training loss: 1.415689, Validation loss: 1.4026, lr: 0.0000\n",
      "Epoch: 929, Training loss: 1.371448, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 930, Training loss: 1.392739, Validation loss: 1.3945, lr: 0.0000\n",
      "Epoch: 931, Training loss: 1.383117, Validation loss: 1.3871, lr: 0.0000\n",
      "Epoch: 932, Training loss: 1.381871, Validation loss: 1.3795, lr: 0.0000\n",
      "Epoch: 933, Training loss: 1.387651, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 934, Training loss: 1.376395, Validation loss: 1.3884, lr: 0.0000\n",
      "Epoch: 935, Training loss: 1.380146, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 936, Training loss: 1.496450, Validation loss: 1.5709, lr: 0.0000\n",
      "Epoch: 937, Training loss: 1.385022, Validation loss: 1.3885, lr: 0.0000\n",
      "Epoch: 938, Training loss: 1.387706, Validation loss: 1.3873, lr: 0.0000\n",
      "Epoch: 939, Training loss: 1.375502, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 940, Training loss: 1.383184, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 941, Training loss: 1.384437, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 942, Training loss: 1.367394, Validation loss: 1.3872, lr: 0.0000\n",
      "Epoch: 943, Training loss: 1.380383, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 944, Training loss: 1.381540, Validation loss: 1.3892, lr: 0.0000\n",
      "Epoch: 945, Training loss: 1.389477, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 946, Training loss: 1.384068, Validation loss: 1.3873, lr: 0.0000\n",
      "Epoch: 947, Training loss: 1.369025, Validation loss: 1.3713, lr: 0.0000\n",
      "Epoch: 948, Training loss: 1.389556, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 949, Training loss: 1.375171, Validation loss: 1.3691, lr: 0.0000\n",
      "Epoch: 950, Training loss: 1.371434, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 951, Training loss: 1.380725, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 952, Training loss: 1.373423, Validation loss: 1.3963, lr: 0.0000\n",
      "Epoch: 953, Training loss: 1.416052, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 954, Training loss: 1.380535, Validation loss: 1.3872, lr: 0.0000\n",
      "Epoch: 955, Training loss: 1.382166, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 956, Training loss: 1.386354, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 957, Training loss: 1.382899, Validation loss: 1.3873, lr: 0.0000\n",
      "Epoch: 958, Training loss: 1.396699, Validation loss: 1.3710, lr: 0.0000\n",
      "Epoch: 959, Training loss: 1.423811, Validation loss: 1.3901, lr: 0.0000\n",
      "Epoch: 960, Training loss: 1.376772, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 961, Training loss: 1.395217, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 962, Training loss: 1.406998, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 963, Training loss: 1.374986, Validation loss: 1.3768, lr: 0.0000\n",
      "Epoch: 964, Training loss: 1.380569, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 965, Training loss: 1.379080, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 966, Training loss: 1.377216, Validation loss: 1.3749, lr: 0.0000\n",
      "Epoch: 967, Training loss: 1.378996, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 968, Training loss: 1.382716, Validation loss: 1.3741, lr: 0.0000\n",
      "Epoch: 969, Training loss: 1.439420, Validation loss: 1.3908, lr: 0.0000\n",
      "Epoch: 970, Training loss: 1.382250, Validation loss: 1.4134, lr: 0.0000\n",
      "Epoch: 971, Training loss: 1.401491, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 972, Training loss: 1.380640, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 973, Training loss: 1.379997, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 974, Training loss: 1.387255, Validation loss: 1.3802, lr: 0.0000\n",
      "Epoch: 975, Training loss: 1.394512, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 976, Training loss: 1.383825, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 977, Training loss: 1.436917, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 978, Training loss: 1.372689, Validation loss: 1.3733, lr: 0.0000\n",
      "Epoch: 979, Training loss: 1.382297, Validation loss: 1.4032, lr: 0.0000\n",
      "Epoch: 980, Training loss: 1.403628, Validation loss: 1.3698, lr: 0.0000\n",
      "Epoch: 981, Training loss: 1.373180, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 982, Training loss: 1.384539, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 983, Training loss: 1.388687, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 984, Training loss: 1.404341, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 985, Training loss: 1.378541, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 986, Training loss: 1.381710, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 987, Training loss: 1.386995, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 988, Training loss: 1.392790, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 989, Training loss: 1.389715, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 990, Training loss: 1.412266, Validation loss: 1.3871, lr: 0.0000\n",
      "Epoch: 991, Training loss: 1.364322, Validation loss: 1.3878, lr: 0.0000\n",
      "Epoch: 992, Training loss: 1.378026, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 993, Training loss: 1.388207, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 994, Training loss: 1.385008, Validation loss: 1.3874, lr: 0.0000\n",
      "Epoch: 995, Training loss: 1.385296, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 996, Training loss: 1.397646, Validation loss: 1.3928, lr: 0.0000\n",
      "Epoch: 997, Training loss: 1.387994, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 998, Training loss: 1.415161, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 999, Training loss: 1.385651, Validation loss: 1.4274, lr: 0.0000\n",
      "Final test loss: 1.3651\n",
      "=== Run 08/10 ===\n",
      "\n",
      "---- Settings: \n",
      "\n",
      "epochs : 1000\n",
      "hidden_channels : [32]\n",
      "out_channels : 10\n",
      "inner_product_features : False\n",
      "batch_size : 64\n",
      "lr : 0.01\n",
      "momentum : 0.9\n",
      "dropout : 0.0\n",
      "batch_norm : batch_norm\n",
      "bias : True\n",
      "order : 2\n",
      "diffusion : True\n",
      "frac_sampled_nb : -1\n",
      "include_positions : False\n",
      "include_self : True\n",
      "vec_norm : False\n",
      "emb_norm : False\n",
      "seed : 0\n",
      "dim_signal : 100\n",
      "dim_emb : 100\n",
      "n_sampled_nb : -1\n",
      "\n",
      "---- Number of features to pass to the MLP:  1010100\n",
      "---- Total number of parameters:  32323627\n",
      "\n",
      "Using device cuda:0\n",
      "\n",
      "---- Training network ...\n",
      "\n",
      "---- Timestamp: 20250614-040321\n",
      "\n",
      " *och: 0, Training loss: 1.490096, Validation loss: 1.3573, lr: 0.0100\n",
      "Epoch: 1, Training loss: 1.612461, Validation loss: 1.3862, lr: 0.0100\n",
      "Epoch: 2, Training loss: 1.396354, Validation loss: 1.3796, lr: 0.0100\n",
      "Epoch: 3, Training loss: 1.400526, Validation loss: 1.4017, lr: 0.0100\n",
      "Epoch: 4, Training loss: 1.379512, Validation loss: 1.3893, lr: 0.0100\n",
      "Epoch: 5, Training loss: 1.382531, Validation loss: 1.3889, lr: 0.0100\n",
      "Epoch: 6, Training loss: 1.394003, Validation loss: 1.3738, lr: 0.0100\n",
      "Epoch: 7, Training loss: 1.377582, Validation loss: 1.3764, lr: 0.0100\n",
      "Epoch: 8, Training loss: 1.398335, Validation loss: 1.3799, lr: 0.0100\n",
      "Epoch: 9, Training loss: 1.391772, Validation loss: 1.3843, lr: 0.0100\n",
      "Epoch: 10, Training loss: 1.378838, Validation loss: 1.3722, lr: 0.0100\n",
      "Epoch: 11, Training loss: 1.418926, Validation loss: 1.3669, lr: 0.0100\n",
      "Epoch: 12, Training loss: 1.371335, Validation loss: 1.3943, lr: 0.0100\n",
      "Epoch: 13, Training loss: 1.381397, Validation loss: 1.3808, lr: 0.0100\n",
      "Epoch: 14, Training loss: 1.384844, Validation loss: 1.3876, lr: 0.0100\n",
      "Epoch: 15, Training loss: 1.385894, Validation loss: 1.3847, lr: 0.0100\n",
      "Epoch: 16, Training loss: 1.384220, Validation loss: 1.3845, lr: 0.0100\n",
      " *och: 17, Training loss: 1.375424, Validation loss: 1.3535, lr: 0.0100\n",
      "Epoch: 18, Training loss: 1.381826, Validation loss: 1.3818, lr: 0.0100\n",
      "Epoch: 19, Training loss: 1.387237, Validation loss: 1.3831, lr: 0.0100\n",
      "Epoch: 20, Training loss: 1.382220, Validation loss: 1.3858, lr: 0.0100\n",
      "Epoch: 21, Training loss: 1.438831, Validation loss: 1.3947, lr: 0.0100\n",
      "Epoch: 22, Training loss: 1.393994, Validation loss: 1.3856, lr: 0.0100\n",
      "Epoch: 23, Training loss: 1.357144, Validation loss: 1.3872, lr: 0.0100\n",
      "Epoch: 24, Training loss: 1.379774, Validation loss: 1.3790, lr: 0.0100\n",
      "Epoch: 25, Training loss: 1.367056, Validation loss: 1.3773, lr: 0.0100\n",
      "Epoch: 26, Training loss: 1.367078, Validation loss: 1.3822, lr: 0.0100\n",
      "Epoch: 27, Training loss: 1.378405, Validation loss: 1.3922, lr: 0.0100\n",
      "Epoch: 28, Training loss: 1.375388, Validation loss: 1.3874, lr: 0.0100\n",
      "Epoch: 29, Training loss: 1.373466, Validation loss: 1.3872, lr: 0.0100\n",
      "Epoch: 30, Training loss: 1.395644, Validation loss: 1.3863, lr: 0.0100\n",
      "Epoch: 31, Training loss: 1.383802, Validation loss: 1.3842, lr: 0.0100\n",
      "Epoch: 32, Training loss: 1.391705, Validation loss: 1.3882, lr: 0.0100\n",
      "Epoch: 33, Training loss: 1.381655, Validation loss: 1.3836, lr: 0.0100\n",
      " *och: 34, Training loss: 1.365579, Validation loss: 1.3504, lr: 0.0010\n",
      "Epoch: 35, Training loss: 1.417911, Validation loss: 1.3855, lr: 0.0010\n",
      "Epoch: 36, Training loss: 1.384120, Validation loss: 1.3769, lr: 0.0010\n",
      "Epoch: 37, Training loss: 1.364886, Validation loss: 1.3842, lr: 0.0010\n",
      "Epoch: 38, Training loss: 1.384205, Validation loss: 1.3870, lr: 0.0010\n",
      "Epoch: 39, Training loss: 1.390725, Validation loss: 1.3874, lr: 0.0010\n",
      "Epoch: 40, Training loss: 1.412996, Validation loss: 1.3862, lr: 0.0010\n",
      "Epoch: 41, Training loss: 1.370912, Validation loss: 1.3884, lr: 0.0010\n",
      "Epoch: 42, Training loss: 1.373877, Validation loss: 1.3849, lr: 0.0010\n",
      "Epoch: 43, Training loss: 1.377640, Validation loss: 1.3853, lr: 0.0010\n",
      "Epoch: 44, Training loss: 1.372473, Validation loss: 1.3794, lr: 0.0010\n",
      "Epoch: 45, Training loss: 1.392689, Validation loss: 1.3838, lr: 0.0001\n",
      "Epoch: 46, Training loss: 1.375434, Validation loss: 1.3859, lr: 0.0001\n",
      "Epoch: 47, Training loss: 1.378354, Validation loss: 1.3871, lr: 0.0001\n",
      "Epoch: 48, Training loss: 1.379228, Validation loss: 1.3819, lr: 0.0001\n",
      "Epoch: 49, Training loss: 1.382048, Validation loss: 1.3873, lr: 0.0001\n",
      "Epoch: 50, Training loss: 1.377414, Validation loss: 1.3828, lr: 0.0001\n",
      "Epoch: 51, Training loss: 1.374425, Validation loss: 1.3818, lr: 0.0001\n",
      "Epoch: 52, Training loss: 1.382979, Validation loss: 1.3855, lr: 0.0001\n",
      "Epoch: 53, Training loss: 1.368867, Validation loss: 1.3872, lr: 0.0001\n",
      "Epoch: 54, Training loss: 1.368418, Validation loss: 1.3681, lr: 0.0001\n",
      "Epoch: 55, Training loss: 1.374594, Validation loss: 1.3842, lr: 0.0001\n",
      "Epoch: 56, Training loss: 1.383174, Validation loss: 1.3733, lr: 0.0000\n",
      "Epoch: 57, Training loss: 1.358624, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 58, Training loss: 1.380379, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 59, Training loss: 1.382666, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 60, Training loss: 1.368607, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 61, Training loss: 1.468310, Validation loss: 1.3885, lr: 0.0000\n",
      "Epoch: 62, Training loss: 1.376708, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 63, Training loss: 1.392713, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 64, Training loss: 1.372434, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 65, Training loss: 1.374466, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 66, Training loss: 1.391525, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 67, Training loss: 1.391302, Validation loss: 1.3892, lr: 0.0000\n",
      "Epoch: 68, Training loss: 1.383412, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 69, Training loss: 1.373628, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 70, Training loss: 1.394090, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 71, Training loss: 1.373926, Validation loss: 1.3707, lr: 0.0000\n",
      "Epoch: 72, Training loss: 1.371872, Validation loss: 1.3735, lr: 0.0000\n",
      "Epoch: 73, Training loss: 1.360291, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 74, Training loss: 1.376886, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 75, Training loss: 1.373556, Validation loss: 1.3890, lr: 0.0000\n",
      "Epoch: 76, Training loss: 1.380680, Validation loss: 1.3771, lr: 0.0000\n",
      "Epoch: 77, Training loss: 1.379589, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 78, Training loss: 1.374995, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 79, Training loss: 1.374524, Validation loss: 1.3776, lr: 0.0000\n",
      "Epoch: 80, Training loss: 1.379293, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 81, Training loss: 1.385443, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 82, Training loss: 1.382756, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 83, Training loss: 1.382077, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 84, Training loss: 1.374077, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 85, Training loss: 1.469645, Validation loss: 1.3888, lr: 0.0000\n",
      "Epoch: 86, Training loss: 1.358728, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 87, Training loss: 1.437131, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 88, Training loss: 1.378908, Validation loss: 1.3937, lr: 0.0000\n",
      "Epoch: 89, Training loss: 1.374183, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 90, Training loss: 1.369799, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 91, Training loss: 1.387742, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 92, Training loss: 1.390352, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 93, Training loss: 1.383818, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 94, Training loss: 1.397251, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 95, Training loss: 1.381058, Validation loss: 1.3896, lr: 0.0000\n",
      "Epoch: 96, Training loss: 1.382692, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 97, Training loss: 1.384244, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 98, Training loss: 1.378504, Validation loss: 1.3769, lr: 0.0000\n",
      "Epoch: 99, Training loss: 1.376938, Validation loss: 1.3874, lr: 0.0000\n",
      "Epoch: 100, Training loss: 1.366449, Validation loss: 1.3765, lr: 0.0000\n",
      "Epoch: 101, Training loss: 1.371056, Validation loss: 1.3890, lr: 0.0000\n",
      "Epoch: 102, Training loss: 1.374684, Validation loss: 1.3788, lr: 0.0000\n",
      "Epoch: 103, Training loss: 1.375962, Validation loss: 1.3883, lr: 0.0000\n",
      "Epoch: 104, Training loss: 1.387703, Validation loss: 1.3633, lr: 0.0000\n",
      "Epoch: 105, Training loss: 1.377733, Validation loss: 1.3787, lr: 0.0000\n",
      "Epoch: 106, Training loss: 1.387609, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 107, Training loss: 1.422119, Validation loss: 1.3634, lr: 0.0000\n",
      "Epoch: 108, Training loss: 1.391372, Validation loss: 1.3759, lr: 0.0000\n",
      "Epoch: 109, Training loss: 1.371029, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 110, Training loss: 1.389715, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 111, Training loss: 1.401230, Validation loss: 1.3754, lr: 0.0000\n",
      "Epoch: 112, Training loss: 1.399282, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 113, Training loss: 1.359151, Validation loss: 1.3900, lr: 0.0000\n",
      "Epoch: 114, Training loss: 1.369819, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 115, Training loss: 1.392159, Validation loss: 1.3993, lr: 0.0000\n",
      "Epoch: 116, Training loss: 1.405103, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 117, Training loss: 1.385712, Validation loss: 1.3737, lr: 0.0000\n",
      "Epoch: 118, Training loss: 1.429271, Validation loss: 1.3761, lr: 0.0000\n",
      "Epoch: 119, Training loss: 1.375599, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 120, Training loss: 1.390804, Validation loss: 1.3785, lr: 0.0000\n",
      "Epoch: 121, Training loss: 1.375686, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 122, Training loss: 1.375652, Validation loss: 1.3772, lr: 0.0000\n",
      "Epoch: 123, Training loss: 1.386410, Validation loss: 1.3668, lr: 0.0000\n",
      "Epoch: 124, Training loss: 1.376223, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 125, Training loss: 1.389550, Validation loss: 1.3909, lr: 0.0000\n",
      "Epoch: 126, Training loss: 1.380683, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 127, Training loss: 1.382687, Validation loss: 1.3951, lr: 0.0000\n",
      "Epoch: 128, Training loss: 1.362909, Validation loss: 1.3687, lr: 0.0000\n",
      "Epoch: 129, Training loss: 1.385045, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 130, Training loss: 1.388004, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 131, Training loss: 1.381292, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 132, Training loss: 1.376807, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 133, Training loss: 1.364034, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 134, Training loss: 1.363449, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 135, Training loss: 1.385980, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 136, Training loss: 1.386160, Validation loss: 1.3909, lr: 0.0000\n",
      "Epoch: 137, Training loss: 1.380044, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 138, Training loss: 1.375196, Validation loss: 1.3875, lr: 0.0000\n",
      "Epoch: 139, Training loss: 1.430537, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 140, Training loss: 1.361703, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 141, Training loss: 1.351468, Validation loss: 1.3886, lr: 0.0000\n",
      "Epoch: 142, Training loss: 1.378563, Validation loss: 1.3872, lr: 0.0000\n",
      "Epoch: 143, Training loss: 1.375476, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 144, Training loss: 1.379253, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 145, Training loss: 1.363428, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 146, Training loss: 1.372763, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 147, Training loss: 1.369925, Validation loss: 1.3774, lr: 0.0000\n",
      "Epoch: 148, Training loss: 1.368372, Validation loss: 1.3772, lr: 0.0000\n",
      "Epoch: 149, Training loss: 1.359578, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 150, Training loss: 1.457439, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 151, Training loss: 1.368015, Validation loss: 1.3776, lr: 0.0000\n",
      "Epoch: 152, Training loss: 1.379841, Validation loss: 1.3685, lr: 0.0000\n",
      "Epoch: 153, Training loss: 1.375718, Validation loss: 1.3891, lr: 0.0000\n",
      "Epoch: 154, Training loss: 1.443118, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 155, Training loss: 1.418409, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 156, Training loss: 1.383485, Validation loss: 1.3792, lr: 0.0000\n",
      "Epoch: 157, Training loss: 1.378795, Validation loss: 1.3607, lr: 0.0000\n",
      "Epoch: 158, Training loss: 1.379956, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 159, Training loss: 1.379110, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 160, Training loss: 1.367953, Validation loss: 1.3764, lr: 0.0000\n",
      "Epoch: 161, Training loss: 1.370681, Validation loss: 1.3656, lr: 0.0000\n",
      "Epoch: 162, Training loss: 1.395438, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 163, Training loss: 1.371213, Validation loss: 1.3778, lr: 0.0000\n",
      "Epoch: 164, Training loss: 1.378426, Validation loss: 1.5990, lr: 0.0000\n",
      "Epoch: 165, Training loss: 1.380462, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 166, Training loss: 1.347160, Validation loss: 1.3688, lr: 0.0000\n",
      "Epoch: 167, Training loss: 1.390095, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 168, Training loss: 1.367623, Validation loss: 1.3782, lr: 0.0000\n",
      "Epoch: 169, Training loss: 1.372504, Validation loss: 1.3908, lr: 0.0000\n",
      "Epoch: 170, Training loss: 1.375354, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 171, Training loss: 1.380691, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 172, Training loss: 1.376628, Validation loss: 1.3875, lr: 0.0000\n",
      "Epoch: 173, Training loss: 1.409137, Validation loss: 1.3982, lr: 0.0000\n",
      "Epoch: 174, Training loss: 1.378593, Validation loss: 1.3879, lr: 0.0000\n",
      "Epoch: 175, Training loss: 1.383231, Validation loss: 1.3760, lr: 0.0000\n",
      "Epoch: 176, Training loss: 1.380659, Validation loss: 1.3692, lr: 0.0000\n",
      "Epoch: 177, Training loss: 1.389754, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 178, Training loss: 1.388191, Validation loss: 1.3879, lr: 0.0000\n",
      "Epoch: 179, Training loss: 1.376922, Validation loss: 1.3885, lr: 0.0000\n",
      "Epoch: 180, Training loss: 1.466212, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 181, Training loss: 1.381912, Validation loss: 1.3940, lr: 0.0000\n",
      "Epoch: 182, Training loss: 1.364719, Validation loss: 1.3875, lr: 0.0000\n",
      "Epoch: 183, Training loss: 1.402715, Validation loss: 1.3889, lr: 0.0000\n",
      "Epoch: 184, Training loss: 1.392306, Validation loss: 1.3785, lr: 0.0000\n",
      "Epoch: 185, Training loss: 1.367495, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 186, Training loss: 1.375175, Validation loss: 1.3776, lr: 0.0000\n",
      "Epoch: 187, Training loss: 1.380515, Validation loss: 1.3893, lr: 0.0000\n",
      "Epoch: 188, Training loss: 1.409959, Validation loss: 1.3898, lr: 0.0000\n",
      "Epoch: 189, Training loss: 1.385693, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 190, Training loss: 1.376855, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 191, Training loss: 1.379437, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 192, Training loss: 1.368605, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 193, Training loss: 1.380601, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 194, Training loss: 1.374460, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 195, Training loss: 1.383369, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 196, Training loss: 1.356500, Validation loss: 1.3772, lr: 0.0000\n",
      "Epoch: 197, Training loss: 1.380333, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 198, Training loss: 1.356372, Validation loss: 1.3909, lr: 0.0000\n",
      "Epoch: 199, Training loss: 1.373415, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 200, Training loss: 1.381099, Validation loss: 1.3795, lr: 0.0000\n",
      "Epoch: 201, Training loss: 1.380470, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 202, Training loss: 1.371730, Validation loss: 1.3651, lr: 0.0000\n",
      "Epoch: 203, Training loss: 1.371556, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 204, Training loss: 1.392438, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 205, Training loss: 1.367010, Validation loss: 1.4077, lr: 0.0000\n",
      "Epoch: 206, Training loss: 1.379984, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 207, Training loss: 1.378704, Validation loss: 1.3768, lr: 0.0000\n",
      "Epoch: 208, Training loss: 1.381558, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 209, Training loss: 1.393784, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 210, Training loss: 1.383315, Validation loss: 1.3951, lr: 0.0000\n",
      "Epoch: 211, Training loss: 1.381172, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 212, Training loss: 1.379573, Validation loss: 1.3973, lr: 0.0000\n",
      "Epoch: 213, Training loss: 1.382239, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 214, Training loss: 1.380030, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 215, Training loss: 1.390247, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 216, Training loss: 1.364694, Validation loss: 1.3800, lr: 0.0000\n",
      "Epoch: 217, Training loss: 1.378504, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 218, Training loss: 1.388534, Validation loss: 1.3693, lr: 0.0000\n",
      "Epoch: 219, Training loss: 1.369435, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 220, Training loss: 1.364106, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 221, Training loss: 1.377235, Validation loss: 1.3913, lr: 0.0000\n",
      "Epoch: 222, Training loss: 1.393684, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 223, Training loss: 1.380340, Validation loss: 1.3644, lr: 0.0000\n",
      "Epoch: 224, Training loss: 1.377287, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 225, Training loss: 1.396525, Validation loss: 1.3741, lr: 0.0000\n",
      "Epoch: 226, Training loss: 1.370572, Validation loss: 1.3885, lr: 0.0000\n",
      "Epoch: 227, Training loss: 1.378733, Validation loss: 1.3907, lr: 0.0000\n",
      "Epoch: 228, Training loss: 1.388583, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 229, Training loss: 1.362129, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 230, Training loss: 1.374339, Validation loss: 1.3878, lr: 0.0000\n",
      "Epoch: 231, Training loss: 1.370681, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 232, Training loss: 1.385387, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 233, Training loss: 1.369183, Validation loss: 1.3742, lr: 0.0000\n",
      "Epoch: 234, Training loss: 1.368795, Validation loss: 1.3871, lr: 0.0000\n",
      "Epoch: 235, Training loss: 1.364196, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 236, Training loss: 1.372336, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 237, Training loss: 1.378633, Validation loss: 1.3998, lr: 0.0000\n",
      "Epoch: 238, Training loss: 1.391917, Validation loss: 1.3894, lr: 0.0000\n",
      "Epoch: 239, Training loss: 1.397211, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 240, Training loss: 1.370971, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 241, Training loss: 1.383659, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 242, Training loss: 1.400251, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 243, Training loss: 1.393227, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 244, Training loss: 1.389570, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 245, Training loss: 1.409374, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 246, Training loss: 1.405158, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 247, Training loss: 1.383397, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 248, Training loss: 1.376403, Validation loss: 1.3871, lr: 0.0000\n",
      "Epoch: 249, Training loss: 1.374663, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 250, Training loss: 1.387231, Validation loss: 1.3790, lr: 0.0000\n",
      "Epoch: 251, Training loss: 1.363273, Validation loss: 1.3893, lr: 0.0000\n",
      "Epoch: 252, Training loss: 1.407495, Validation loss: 1.3576, lr: 0.0000\n",
      "Epoch: 253, Training loss: 1.366791, Validation loss: 1.3704, lr: 0.0000\n",
      "Epoch: 254, Training loss: 1.355396, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 255, Training loss: 1.386307, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 256, Training loss: 1.386499, Validation loss: 1.3874, lr: 0.0000\n",
      "Epoch: 257, Training loss: 1.367366, Validation loss: 1.4104, lr: 0.0000\n",
      "Epoch: 258, Training loss: 1.390485, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 259, Training loss: 1.382194, Validation loss: 1.3883, lr: 0.0000\n",
      "Epoch: 260, Training loss: 1.359475, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 261, Training loss: 1.375256, Validation loss: 1.3725, lr: 0.0000\n",
      "Epoch: 262, Training loss: 1.367386, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 263, Training loss: 1.493181, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 264, Training loss: 1.363587, Validation loss: 1.3790, lr: 0.0000\n",
      "Epoch: 265, Training loss: 1.386996, Validation loss: 1.3912, lr: 0.0000\n",
      "Epoch: 266, Training loss: 1.417372, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 267, Training loss: 1.362369, Validation loss: 1.3778, lr: 0.0000\n",
      "Epoch: 268, Training loss: 1.377229, Validation loss: 1.3874, lr: 0.0000\n",
      "Epoch: 269, Training loss: 1.395639, Validation loss: 1.3902, lr: 0.0000\n",
      "Epoch: 270, Training loss: 1.373927, Validation loss: 1.3772, lr: 0.0000\n",
      "Epoch: 271, Training loss: 1.387145, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 272, Training loss: 1.374504, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 273, Training loss: 1.378627, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 274, Training loss: 1.373760, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 275, Training loss: 1.374119, Validation loss: 1.3778, lr: 0.0000\n",
      "Epoch: 276, Training loss: 1.411457, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 277, Training loss: 1.380590, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 278, Training loss: 1.404536, Validation loss: 1.3885, lr: 0.0000\n",
      "Epoch: 279, Training loss: 1.378688, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 280, Training loss: 1.375465, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 281, Training loss: 1.381825, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 282, Training loss: 1.405369, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 283, Training loss: 1.386567, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 284, Training loss: 1.378992, Validation loss: 1.3721, lr: 0.0000\n",
      "Epoch: 285, Training loss: 1.406343, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 286, Training loss: 1.359810, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 287, Training loss: 1.384198, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 288, Training loss: 1.373719, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 289, Training loss: 1.368252, Validation loss: 1.3698, lr: 0.0000\n",
      "Epoch: 290, Training loss: 1.390034, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 291, Training loss: 1.383603, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 292, Training loss: 1.377194, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 293, Training loss: 1.365742, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 294, Training loss: 1.374981, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 295, Training loss: 1.363199, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 296, Training loss: 1.396385, Validation loss: 1.3687, lr: 0.0000\n",
      "Epoch: 297, Training loss: 1.369044, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 298, Training loss: 1.389227, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 299, Training loss: 1.382599, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 300, Training loss: 1.358820, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 301, Training loss: 1.368885, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 302, Training loss: 1.455427, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 303, Training loss: 1.388612, Validation loss: 1.3998, lr: 0.0000\n",
      "Epoch: 304, Training loss: 1.378889, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 305, Training loss: 1.397366, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 306, Training loss: 1.382466, Validation loss: 1.3758, lr: 0.0000\n",
      "Epoch: 307, Training loss: 1.412619, Validation loss: 1.3881, lr: 0.0000\n",
      "Epoch: 308, Training loss: 1.399792, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 309, Training loss: 1.389574, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 310, Training loss: 1.380005, Validation loss: 1.3876, lr: 0.0000\n",
      "Epoch: 311, Training loss: 1.443103, Validation loss: 1.3781, lr: 0.0000\n",
      "Epoch: 312, Training loss: 1.390138, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 313, Training loss: 1.367874, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 314, Training loss: 1.378381, Validation loss: 1.3876, lr: 0.0000\n",
      "Epoch: 315, Training loss: 1.396543, Validation loss: 1.4062, lr: 0.0000\n",
      "Epoch: 316, Training loss: 1.385628, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 317, Training loss: 1.385145, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 318, Training loss: 1.374537, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 319, Training loss: 1.396828, Validation loss: 1.3743, lr: 0.0000\n",
      "Epoch: 320, Training loss: 1.379413, Validation loss: 1.3895, lr: 0.0000\n",
      "Epoch: 321, Training loss: 1.364509, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 322, Training loss: 1.386189, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 323, Training loss: 1.382072, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 324, Training loss: 1.374999, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 325, Training loss: 1.363453, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 326, Training loss: 1.375958, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 327, Training loss: 1.382988, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 328, Training loss: 1.360084, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 329, Training loss: 1.394393, Validation loss: 1.3783, lr: 0.0000\n",
      "Epoch: 330, Training loss: 1.415833, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 331, Training loss: 1.375971, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 332, Training loss: 1.373302, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 333, Training loss: 1.385735, Validation loss: 1.3771, lr: 0.0000\n",
      "Epoch: 334, Training loss: 1.385130, Validation loss: 1.3800, lr: 0.0000\n",
      "Epoch: 335, Training loss: 1.379087, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 336, Training loss: 1.378112, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 337, Training loss: 1.384078, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 338, Training loss: 1.376990, Validation loss: 1.3877, lr: 0.0000\n",
      "Epoch: 339, Training loss: 1.377720, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 340, Training loss: 1.384700, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 341, Training loss: 1.381551, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 342, Training loss: 1.378982, Validation loss: 1.3742, lr: 0.0000\n",
      "Epoch: 343, Training loss: 1.386561, Validation loss: 1.3634, lr: 0.0000\n",
      "Epoch: 344, Training loss: 1.375275, Validation loss: 1.3744, lr: 0.0000\n",
      "Epoch: 345, Training loss: 1.364496, Validation loss: 1.3872, lr: 0.0000\n",
      "Epoch: 346, Training loss: 1.396051, Validation loss: 1.3593, lr: 0.0000\n",
      "Epoch: 347, Training loss: 1.359396, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 348, Training loss: 1.419577, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 349, Training loss: 1.370521, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 350, Training loss: 1.380248, Validation loss: 1.3721, lr: 0.0000\n",
      "Epoch: 351, Training loss: 1.389100, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 352, Training loss: 1.384126, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 353, Training loss: 1.375358, Validation loss: 1.3797, lr: 0.0000\n",
      "Epoch: 354, Training loss: 1.376079, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 355, Training loss: 1.372901, Validation loss: 1.3785, lr: 0.0000\n",
      "Epoch: 356, Training loss: 1.371015, Validation loss: 1.3795, lr: 0.0000\n",
      "Epoch: 357, Training loss: 1.378014, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 358, Training loss: 1.401243, Validation loss: 1.3874, lr: 0.0000\n",
      "Epoch: 359, Training loss: 1.429440, Validation loss: 1.3596, lr: 0.0000\n",
      "Epoch: 360, Training loss: 1.375201, Validation loss: 1.3906, lr: 0.0000\n",
      "Epoch: 361, Training loss: 1.392177, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 362, Training loss: 1.381808, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 363, Training loss: 1.429152, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 364, Training loss: 1.383104, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 365, Training loss: 1.380631, Validation loss: 1.3735, lr: 0.0000\n",
      "Epoch: 366, Training loss: 1.377876, Validation loss: 1.3668, lr: 0.0000\n",
      "Epoch: 367, Training loss: 1.412965, Validation loss: 1.3896, lr: 0.0000\n",
      "Epoch: 368, Training loss: 1.369885, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 369, Training loss: 1.394485, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 370, Training loss: 1.415667, Validation loss: 1.3878, lr: 0.0000\n",
      "Epoch: 371, Training loss: 1.382817, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 372, Training loss: 1.374964, Validation loss: 1.3792, lr: 0.0000\n",
      "Epoch: 373, Training loss: 1.389226, Validation loss: 1.3743, lr: 0.0000\n",
      "Epoch: 374, Training loss: 1.376687, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 375, Training loss: 1.375066, Validation loss: 1.3798, lr: 0.0000\n",
      "Epoch: 376, Training loss: 1.384140, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 377, Training loss: 1.392370, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 378, Training loss: 1.367566, Validation loss: 1.3880, lr: 0.0000\n",
      "Epoch: 379, Training loss: 1.426619, Validation loss: 1.3877, lr: 0.0000\n",
      "Epoch: 380, Training loss: 1.370616, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 381, Training loss: 1.377327, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 382, Training loss: 1.371102, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 383, Training loss: 1.370185, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 384, Training loss: 1.372651, Validation loss: 1.3794, lr: 0.0000\n",
      "Epoch: 385, Training loss: 1.383061, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 386, Training loss: 1.374157, Validation loss: 1.3797, lr: 0.0000\n",
      "Epoch: 387, Training loss: 1.372087, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 388, Training loss: 1.368853, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 389, Training loss: 1.390927, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 390, Training loss: 1.347734, Validation loss: 1.3694, lr: 0.0000\n",
      "Epoch: 391, Training loss: 1.396685, Validation loss: 1.3872, lr: 0.0000\n",
      "Epoch: 392, Training loss: 1.394787, Validation loss: 1.3724, lr: 0.0000\n",
      "Epoch: 393, Training loss: 1.382823, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 394, Training loss: 1.385020, Validation loss: 1.3719, lr: 0.0000\n",
      "Epoch: 395, Training loss: 1.374576, Validation loss: 1.3734, lr: 0.0000\n",
      "Epoch: 396, Training loss: 1.376716, Validation loss: 1.5905, lr: 0.0000\n",
      "Epoch: 397, Training loss: 1.413965, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 398, Training loss: 1.406176, Validation loss: 1.3882, lr: 0.0000\n",
      "Epoch: 399, Training loss: 1.400195, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 400, Training loss: 1.380161, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 401, Training loss: 1.401098, Validation loss: 1.3900, lr: 0.0000\n",
      "Epoch: 402, Training loss: 1.379930, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 403, Training loss: 1.375275, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 404, Training loss: 1.395184, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 405, Training loss: 1.396320, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 406, Training loss: 1.386443, Validation loss: 1.3716, lr: 0.0000\n",
      " *och: 407, Training loss: 1.378659, Validation loss: 1.3465, lr: 0.0000\n",
      "Epoch: 408, Training loss: 1.394283, Validation loss: 1.3869, lr: 0.0000\n",
      " *och: 409, Training loss: 1.362605, Validation loss: 1.3419, lr: 0.0000\n",
      "Epoch: 410, Training loss: 1.375245, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 411, Training loss: 1.374239, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 412, Training loss: 1.375418, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 413, Training loss: 1.366095, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 414, Training loss: 1.388443, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 415, Training loss: 1.386696, Validation loss: 1.4970, lr: 0.0000\n",
      "Epoch: 416, Training loss: 1.375267, Validation loss: 2.2391, lr: 0.0000\n",
      "Epoch: 417, Training loss: 1.382059, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 418, Training loss: 1.375730, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 419, Training loss: 1.392194, Validation loss: 1.3786, lr: 0.0000\n",
      "Epoch: 420, Training loss: 1.362666, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 421, Training loss: 1.387607, Validation loss: 1.3776, lr: 0.0000\n",
      "Epoch: 422, Training loss: 1.408649, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 423, Training loss: 1.384514, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 424, Training loss: 1.376751, Validation loss: 1.3621, lr: 0.0000\n",
      "Epoch: 425, Training loss: 1.372990, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 426, Training loss: 1.373148, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 427, Training loss: 1.407167, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 428, Training loss: 1.383121, Validation loss: 1.3798, lr: 0.0000\n",
      "Epoch: 429, Training loss: 1.374397, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 430, Training loss: 1.381904, Validation loss: 1.3791, lr: 0.0000\n",
      "Epoch: 431, Training loss: 1.379782, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 432, Training loss: 1.445914, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 433, Training loss: 1.356300, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 434, Training loss: 1.382908, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 435, Training loss: 1.366740, Validation loss: 1.3779, lr: 0.0000\n",
      "Epoch: 436, Training loss: 1.387188, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 437, Training loss: 1.372595, Validation loss: 1.3972, lr: 0.0000\n",
      "Epoch: 438, Training loss: 1.374728, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 439, Training loss: 1.363018, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 440, Training loss: 1.381311, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 441, Training loss: 1.392914, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 442, Training loss: 1.371972, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 443, Training loss: 1.377271, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 444, Training loss: 1.362827, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 445, Training loss: 1.377668, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 446, Training loss: 1.367355, Validation loss: 1.3666, lr: 0.0000\n",
      "Epoch: 447, Training loss: 1.385609, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 448, Training loss: 1.378595, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 449, Training loss: 1.386079, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 450, Training loss: 1.394909, Validation loss: 1.3681, lr: 0.0000\n",
      "Epoch: 451, Training loss: 1.377576, Validation loss: 1.3572, lr: 0.0000\n",
      "Epoch: 452, Training loss: 1.403378, Validation loss: 1.3666, lr: 0.0000\n",
      "Epoch: 453, Training loss: 1.372428, Validation loss: 1.3699, lr: 0.0000\n",
      "Epoch: 454, Training loss: 1.373844, Validation loss: 1.3637, lr: 0.0000\n",
      "Epoch: 455, Training loss: 1.388399, Validation loss: 1.3658, lr: 0.0000\n",
      "Epoch: 456, Training loss: 1.390101, Validation loss: 1.3809, lr: 0.0000\n",
      "Epoch: 457, Training loss: 1.416685, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 458, Training loss: 1.369259, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 459, Training loss: 1.377690, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 460, Training loss: 1.413104, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 461, Training loss: 1.379851, Validation loss: 1.3797, lr: 0.0000\n",
      "Epoch: 462, Training loss: 1.382049, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 463, Training loss: 1.381858, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 464, Training loss: 1.368810, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 465, Training loss: 1.466756, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 466, Training loss: 1.382935, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 467, Training loss: 1.370433, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 468, Training loss: 1.372300, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 469, Training loss: 1.376574, Validation loss: 1.3663, lr: 0.0000\n",
      "Epoch: 470, Training loss: 1.373123, Validation loss: 1.3899, lr: 0.0000\n",
      "Epoch: 471, Training loss: 1.377516, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 472, Training loss: 1.370935, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 473, Training loss: 1.380565, Validation loss: 1.3792, lr: 0.0000\n",
      "Epoch: 474, Training loss: 1.387591, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 475, Training loss: 1.369205, Validation loss: 1.3887, lr: 0.0000\n",
      "Epoch: 476, Training loss: 1.407115, Validation loss: 1.3875, lr: 0.0000\n",
      "Epoch: 477, Training loss: 1.401332, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 478, Training loss: 1.387473, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 479, Training loss: 1.371629, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 480, Training loss: 1.400088, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 481, Training loss: 1.376771, Validation loss: 1.3912, lr: 0.0000\n",
      "Epoch: 482, Training loss: 1.384472, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 483, Training loss: 1.380494, Validation loss: 1.3800, lr: 0.0000\n",
      "Epoch: 484, Training loss: 1.372869, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 485, Training loss: 1.392422, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 486, Training loss: 1.361673, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 487, Training loss: 1.381944, Validation loss: 1.3746, lr: 0.0000\n",
      "Epoch: 488, Training loss: 1.405342, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 489, Training loss: 1.372046, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 490, Training loss: 1.372243, Validation loss: 1.3670, lr: 0.0000\n",
      "Epoch: 491, Training loss: 1.367765, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 492, Training loss: 1.423942, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 493, Training loss: 1.391066, Validation loss: 1.3770, lr: 0.0000\n",
      "Epoch: 494, Training loss: 1.378113, Validation loss: 1.3913, lr: 0.0000\n",
      "Epoch: 495, Training loss: 1.369729, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 496, Training loss: 1.380135, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 497, Training loss: 1.382401, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 498, Training loss: 1.379455, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 499, Training loss: 1.387185, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 500, Training loss: 1.373437, Validation loss: 1.3774, lr: 0.0000\n",
      "Epoch: 501, Training loss: 1.376941, Validation loss: 1.3906, lr: 0.0000\n",
      "Epoch: 502, Training loss: 1.378545, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 503, Training loss: 1.366356, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 504, Training loss: 1.382815, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 505, Training loss: 1.392569, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 506, Training loss: 1.376445, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 507, Training loss: 1.366305, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 508, Training loss: 1.394904, Validation loss: 1.3714, lr: 0.0000\n",
      "Epoch: 509, Training loss: 1.370377, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 510, Training loss: 1.384238, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 511, Training loss: 1.386765, Validation loss: 1.3706, lr: 0.0000\n",
      "Epoch: 512, Training loss: 1.384426, Validation loss: 1.3907, lr: 0.0000\n",
      "Epoch: 513, Training loss: 1.381252, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 514, Training loss: 1.376991, Validation loss: 1.3798, lr: 0.0000\n",
      "Epoch: 515, Training loss: 1.383413, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 516, Training loss: 1.421451, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 517, Training loss: 1.397138, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 518, Training loss: 1.369814, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 519, Training loss: 1.374373, Validation loss: 1.3674, lr: 0.0000\n",
      "Epoch: 520, Training loss: 1.412061, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 521, Training loss: 1.383408, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 522, Training loss: 1.368802, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 523, Training loss: 1.374855, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 524, Training loss: 1.371335, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 525, Training loss: 1.366141, Validation loss: 1.3886, lr: 0.0000\n",
      "Epoch: 526, Training loss: 1.371876, Validation loss: 1.3879, lr: 0.0000\n",
      "Epoch: 527, Training loss: 1.375774, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 528, Training loss: 1.386018, Validation loss: 1.3649, lr: 0.0000\n",
      "Epoch: 529, Training loss: 1.389520, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 530, Training loss: 1.383857, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 531, Training loss: 1.379545, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 532, Training loss: 1.355267, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 533, Training loss: 1.388761, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 534, Training loss: 1.382095, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 535, Training loss: 1.376772, Validation loss: 1.3899, lr: 0.0000\n",
      "Epoch: 536, Training loss: 1.374628, Validation loss: 1.3875, lr: 0.0000\n",
      "Epoch: 537, Training loss: 1.372902, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 538, Training loss: 1.384034, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 539, Training loss: 1.366795, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 540, Training loss: 1.361788, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 541, Training loss: 1.386577, Validation loss: 1.3619, lr: 0.0000\n",
      "Epoch: 542, Training loss: 1.402369, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 543, Training loss: 1.383447, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 544, Training loss: 1.374975, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 545, Training loss: 1.350910, Validation loss: 1.3734, lr: 0.0000\n",
      "Epoch: 546, Training loss: 1.379305, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 547, Training loss: 1.387645, Validation loss: 1.3889, lr: 0.0000\n",
      "Epoch: 548, Training loss: 1.362534, Validation loss: 2.5455, lr: 0.0000\n",
      "Epoch: 549, Training loss: 1.369843, Validation loss: 1.5807, lr: 0.0000\n",
      "Epoch: 550, Training loss: 1.389431, Validation loss: 1.3899, lr: 0.0000\n",
      "Epoch: 551, Training loss: 1.361257, Validation loss: 1.3762, lr: 0.0000\n",
      "Epoch: 552, Training loss: 1.382982, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 553, Training loss: 1.375666, Validation loss: 1.3885, lr: 0.0000\n",
      "Epoch: 554, Training loss: 1.388103, Validation loss: 1.3802, lr: 0.0000\n",
      "Epoch: 555, Training loss: 1.364568, Validation loss: 1.3893, lr: 0.0000\n",
      "Epoch: 556, Training loss: 1.381172, Validation loss: 1.4121, lr: 0.0000\n",
      "Epoch: 557, Training loss: 1.371396, Validation loss: 1.3667, lr: 0.0000\n",
      "Epoch: 558, Training loss: 1.384175, Validation loss: 1.3773, lr: 0.0000\n",
      "Epoch: 559, Training loss: 1.370003, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 560, Training loss: 1.349422, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 561, Training loss: 1.371453, Validation loss: 1.3787, lr: 0.0000\n",
      "Epoch: 562, Training loss: 1.394160, Validation loss: 1.3876, lr: 0.0000\n",
      "Epoch: 563, Training loss: 1.381457, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 564, Training loss: 1.377727, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 565, Training loss: 1.374109, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 566, Training loss: 1.374136, Validation loss: 1.3720, lr: 0.0000\n",
      "Epoch: 567, Training loss: 1.362561, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 568, Training loss: 1.379892, Validation loss: 1.3788, lr: 0.0000\n",
      "Epoch: 569, Training loss: 1.406721, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 570, Training loss: 1.370296, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 571, Training loss: 1.371343, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 572, Training loss: 1.369885, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 573, Training loss: 1.370799, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 574, Training loss: 1.378114, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 575, Training loss: 1.395666, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 576, Training loss: 1.498959, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 577, Training loss: 1.387238, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 578, Training loss: 1.378922, Validation loss: 1.3754, lr: 0.0000\n",
      "Epoch: 579, Training loss: 1.406002, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 580, Training loss: 1.368317, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 581, Training loss: 1.373915, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 582, Training loss: 1.370994, Validation loss: 1.3874, lr: 0.0000\n",
      "Epoch: 583, Training loss: 1.378935, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 584, Training loss: 1.382508, Validation loss: 1.3880, lr: 0.0000\n",
      "Epoch: 585, Training loss: 1.387701, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 586, Training loss: 1.392051, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 587, Training loss: 1.384185, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 588, Training loss: 1.354618, Validation loss: 1.3881, lr: 0.0000\n",
      "Epoch: 589, Training loss: 1.364367, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 590, Training loss: 1.386985, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 591, Training loss: 1.396066, Validation loss: 1.3797, lr: 0.0000\n",
      "Epoch: 592, Training loss: 1.367061, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 593, Training loss: 1.370186, Validation loss: 1.3579, lr: 0.0000\n",
      "Epoch: 594, Training loss: 1.387103, Validation loss: 1.3882, lr: 0.0000\n",
      "Epoch: 595, Training loss: 1.375486, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 596, Training loss: 1.380320, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 597, Training loss: 1.380586, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 598, Training loss: 1.379580, Validation loss: 1.3709, lr: 0.0000\n",
      "Epoch: 599, Training loss: 1.373536, Validation loss: 1.3945, lr: 0.0000\n",
      "Epoch: 600, Training loss: 1.380918, Validation loss: 1.3674, lr: 0.0000\n",
      "Epoch: 601, Training loss: 1.380501, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 602, Training loss: 1.373247, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 603, Training loss: 1.383448, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 604, Training loss: 1.385185, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 605, Training loss: 1.389188, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 606, Training loss: 1.382077, Validation loss: 1.4001, lr: 0.0000\n",
      "Epoch: 607, Training loss: 1.377243, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 608, Training loss: 1.376412, Validation loss: 1.3717, lr: 0.0000\n",
      "Epoch: 609, Training loss: 1.389892, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 610, Training loss: 1.398492, Validation loss: 1.3883, lr: 0.0000\n",
      "Epoch: 611, Training loss: 1.394897, Validation loss: 1.3770, lr: 0.0000\n",
      "Epoch: 612, Training loss: 1.369922, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 613, Training loss: 1.355500, Validation loss: 1.3986, lr: 0.0000\n",
      "Epoch: 614, Training loss: 1.381941, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 615, Training loss: 1.387019, Validation loss: 1.3877, lr: 0.0000\n",
      "Epoch: 616, Training loss: 1.356844, Validation loss: 1.3792, lr: 0.0000\n",
      "Epoch: 617, Training loss: 1.360374, Validation loss: 1.3898, lr: 0.0000\n",
      "Epoch: 618, Training loss: 1.371381, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 619, Training loss: 1.374690, Validation loss: 1.3776, lr: 0.0000\n",
      "Epoch: 620, Training loss: 1.391600, Validation loss: 1.3619, lr: 0.0000\n",
      "Epoch: 621, Training loss: 1.370839, Validation loss: 1.3673, lr: 0.0000\n",
      "Epoch: 622, Training loss: 1.357099, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 623, Training loss: 1.369394, Validation loss: 1.3786, lr: 0.0000\n",
      "Epoch: 624, Training loss: 1.374507, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 625, Training loss: 1.417445, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 626, Training loss: 1.369799, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 627, Training loss: 1.441099, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 628, Training loss: 1.380249, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 629, Training loss: 1.364971, Validation loss: 1.3792, lr: 0.0000\n",
      "Epoch: 630, Training loss: 1.371439, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 631, Training loss: 1.376424, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 632, Training loss: 1.377749, Validation loss: 1.3897, lr: 0.0000\n",
      "Epoch: 633, Training loss: 1.488732, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 634, Training loss: 1.428482, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 635, Training loss: 1.374517, Validation loss: 1.4475, lr: 0.0000\n",
      "Epoch: 636, Training loss: 1.373281, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 637, Training loss: 1.383124, Validation loss: 1.4445, lr: 0.0000\n",
      "Epoch: 638, Training loss: 1.375209, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 639, Training loss: 1.365973, Validation loss: 1.3902, lr: 0.0000\n",
      "Epoch: 640, Training loss: 1.381968, Validation loss: 1.4077, lr: 0.0000\n",
      "Epoch: 641, Training loss: 1.378368, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 642, Training loss: 1.372289, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 643, Training loss: 1.402470, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 644, Training loss: 1.369373, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 645, Training loss: 1.381925, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 646, Training loss: 1.387239, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 647, Training loss: 1.362180, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 648, Training loss: 1.399310, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 649, Training loss: 1.397422, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 650, Training loss: 1.380406, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 651, Training loss: 1.378278, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 652, Training loss: 1.388466, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 653, Training loss: 1.394703, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 654, Training loss: 1.391295, Validation loss: 1.3753, lr: 0.0000\n",
      "Epoch: 655, Training loss: 1.383686, Validation loss: 1.3880, lr: 0.0000\n",
      "Epoch: 656, Training loss: 1.384932, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 657, Training loss: 1.377849, Validation loss: 1.3879, lr: 0.0000\n",
      "Epoch: 658, Training loss: 1.368840, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 659, Training loss: 1.371138, Validation loss: 1.3871, lr: 0.0000\n",
      "Epoch: 660, Training loss: 1.375665, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 661, Training loss: 1.379061, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 662, Training loss: 1.378179, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 663, Training loss: 1.376347, Validation loss: 1.3796, lr: 0.0000\n",
      "Epoch: 664, Training loss: 1.377353, Validation loss: 1.3725, lr: 0.0000\n",
      "Epoch: 665, Training loss: 1.380958, Validation loss: 1.3748, lr: 0.0000\n",
      "Epoch: 666, Training loss: 1.373649, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 667, Training loss: 1.383978, Validation loss: 1.3802, lr: 0.0000\n",
      "Epoch: 668, Training loss: 1.380690, Validation loss: 1.3716, lr: 0.0000\n",
      "Epoch: 669, Training loss: 1.392222, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 670, Training loss: 1.385504, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 671, Training loss: 1.377351, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 672, Training loss: 1.373325, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 673, Training loss: 1.375241, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 674, Training loss: 1.376290, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 675, Training loss: 1.375708, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 676, Training loss: 1.374264, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 677, Training loss: 1.360197, Validation loss: 1.3731, lr: 0.0000\n",
      "Epoch: 678, Training loss: 1.388601, Validation loss: 1.3468, lr: 0.0000\n",
      "Epoch: 679, Training loss: 1.371004, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 680, Training loss: 1.390800, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 681, Training loss: 1.394882, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 682, Training loss: 1.371690, Validation loss: 1.3753, lr: 0.0000\n",
      "Epoch: 683, Training loss: 1.394801, Validation loss: 1.3902, lr: 0.0000\n",
      "Epoch: 684, Training loss: 1.369744, Validation loss: 1.3797, lr: 0.0000\n",
      "Epoch: 685, Training loss: 1.377065, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 686, Training loss: 1.371575, Validation loss: 1.3886, lr: 0.0000\n",
      "Epoch: 687, Training loss: 1.392641, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 688, Training loss: 1.377369, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 689, Training loss: 1.375269, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 690, Training loss: 1.407216, Validation loss: 1.4630, lr: 0.0000\n",
      "Epoch: 691, Training loss: 1.364132, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 692, Training loss: 1.384129, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 693, Training loss: 1.406519, Validation loss: 1.3797, lr: 0.0000\n",
      "Epoch: 694, Training loss: 1.382895, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 695, Training loss: 1.377469, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 696, Training loss: 1.366861, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 697, Training loss: 1.392316, Validation loss: 1.3420, lr: 0.0000\n",
      "Epoch: 698, Training loss: 1.375746, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 699, Training loss: 1.373684, Validation loss: 1.3887, lr: 0.0000\n",
      "Epoch: 700, Training loss: 1.384472, Validation loss: 1.3670, lr: 0.0000\n",
      "Epoch: 701, Training loss: 1.380269, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 702, Training loss: 1.366335, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 703, Training loss: 1.389496, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 704, Training loss: 1.384135, Validation loss: 1.3802, lr: 0.0000\n",
      "Epoch: 705, Training loss: 1.390521, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 706, Training loss: 1.380267, Validation loss: 1.3777, lr: 0.0000\n",
      "Epoch: 707, Training loss: 1.382745, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 708, Training loss: 1.410724, Validation loss: 1.3676, lr: 0.0000\n",
      "Epoch: 709, Training loss: 1.377959, Validation loss: 1.3557, lr: 0.0000\n",
      "Epoch: 710, Training loss: 1.375852, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 711, Training loss: 1.369749, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 712, Training loss: 1.383486, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 713, Training loss: 1.373434, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 714, Training loss: 1.385866, Validation loss: 1.3916, lr: 0.0000\n",
      "Epoch: 715, Training loss: 1.384908, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 716, Training loss: 1.370705, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 717, Training loss: 1.409428, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 718, Training loss: 1.362883, Validation loss: 1.3731, lr: 0.0000\n",
      "Epoch: 719, Training loss: 1.395016, Validation loss: 1.3794, lr: 0.0000\n",
      "Epoch: 720, Training loss: 1.363486, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 721, Training loss: 1.391311, Validation loss: 1.3771, lr: 0.0000\n",
      "Epoch: 722, Training loss: 1.381001, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 723, Training loss: 1.381330, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 724, Training loss: 1.393346, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 725, Training loss: 1.385366, Validation loss: 1.3752, lr: 0.0000\n",
      "Epoch: 726, Training loss: 1.367478, Validation loss: 1.3809, lr: 0.0000\n",
      "Epoch: 727, Training loss: 1.366760, Validation loss: 1.3888, lr: 0.0000\n",
      "Epoch: 728, Training loss: 1.377156, Validation loss: 1.3924, lr: 0.0000\n",
      "Epoch: 729, Training loss: 1.376530, Validation loss: 1.3925, lr: 0.0000\n",
      "Epoch: 730, Training loss: 1.366433, Validation loss: 1.4038, lr: 0.0000\n",
      "Epoch: 731, Training loss: 1.365451, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 732, Training loss: 1.371539, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 733, Training loss: 1.381114, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 734, Training loss: 1.378344, Validation loss: 1.3746, lr: 0.0000\n",
      "Epoch: 735, Training loss: 1.379910, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 736, Training loss: 1.381240, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 737, Training loss: 1.375000, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 738, Training loss: 1.387941, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 739, Training loss: 1.382215, Validation loss: 1.3896, lr: 0.0000\n",
      "Epoch: 740, Training loss: 1.360807, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 741, Training loss: 1.374889, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 742, Training loss: 1.379462, Validation loss: 1.4004, lr: 0.0000\n",
      "Epoch: 743, Training loss: 1.391436, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 744, Training loss: 1.378023, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 745, Training loss: 1.372409, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 746, Training loss: 1.370652, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 747, Training loss: 1.374928, Validation loss: 1.3920, lr: 0.0000\n",
      "Epoch: 748, Training loss: 1.454645, Validation loss: 1.3939, lr: 0.0000\n",
      "Epoch: 749, Training loss: 1.379737, Validation loss: 1.3909, lr: 0.0000\n",
      "Epoch: 750, Training loss: 1.374699, Validation loss: 1.3876, lr: 0.0000\n",
      "Epoch: 751, Training loss: 1.380347, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 752, Training loss: 1.375622, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 753, Training loss: 1.379629, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 754, Training loss: 1.371425, Validation loss: 1.3890, lr: 0.0000\n",
      "Epoch: 755, Training loss: 1.417198, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 756, Training loss: 1.377328, Validation loss: 1.3884, lr: 0.0000\n",
      "Epoch: 757, Training loss: 1.379853, Validation loss: 1.3689, lr: 0.0000\n",
      "Epoch: 758, Training loss: 1.363660, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 759, Training loss: 1.364812, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 760, Training loss: 1.384240, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 761, Training loss: 1.383968, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 762, Training loss: 1.375864, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 763, Training loss: 1.372567, Validation loss: 1.3922, lr: 0.0000\n",
      "Epoch: 764, Training loss: 1.364226, Validation loss: 1.3809, lr: 0.0000\n",
      "Epoch: 765, Training loss: 1.383735, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 766, Training loss: 1.379366, Validation loss: 1.3680, lr: 0.0000\n",
      "Epoch: 767, Training loss: 1.393476, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 768, Training loss: 1.393921, Validation loss: 1.3880, lr: 0.0000\n",
      "Epoch: 769, Training loss: 1.384071, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 770, Training loss: 1.378593, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 771, Training loss: 1.384667, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 772, Training loss: 1.360342, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 773, Training loss: 1.391852, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 774, Training loss: 1.375846, Validation loss: 1.3653, lr: 0.0000\n",
      "Epoch: 775, Training loss: 1.383853, Validation loss: 1.5323, lr: 0.0000\n",
      "Epoch: 776, Training loss: 1.389030, Validation loss: 1.3606, lr: 0.0000\n",
      "Epoch: 777, Training loss: 1.378239, Validation loss: 1.3736, lr: 0.0000\n",
      "Epoch: 778, Training loss: 1.380785, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 779, Training loss: 1.389085, Validation loss: 1.3886, lr: 0.0000\n",
      "Epoch: 780, Training loss: 1.385009, Validation loss: 1.3941, lr: 0.0000\n",
      "Epoch: 781, Training loss: 1.382464, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 782, Training loss: 1.384108, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 783, Training loss: 1.386327, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 784, Training loss: 1.370255, Validation loss: 1.3873, lr: 0.0000\n",
      "Epoch: 785, Training loss: 1.387580, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 786, Training loss: 1.374017, Validation loss: 1.3686, lr: 0.0000\n",
      "Epoch: 787, Training loss: 1.374248, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 788, Training loss: 1.372658, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 789, Training loss: 1.375437, Validation loss: 1.3789, lr: 0.0000\n",
      "Epoch: 790, Training loss: 1.366588, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 791, Training loss: 1.383914, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 792, Training loss: 1.368950, Validation loss: 1.3673, lr: 0.0000\n",
      "Epoch: 793, Training loss: 1.373249, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 794, Training loss: 1.376044, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 795, Training loss: 1.372414, Validation loss: 1.3877, lr: 0.0000\n",
      "Epoch: 796, Training loss: 1.390451, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 797, Training loss: 1.374467, Validation loss: 1.3781, lr: 0.0000\n",
      "Epoch: 798, Training loss: 1.375840, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 799, Training loss: 1.374955, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 800, Training loss: 1.378822, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 801, Training loss: 1.369192, Validation loss: 1.3879, lr: 0.0000\n",
      "Epoch: 802, Training loss: 1.366015, Validation loss: 1.3799, lr: 0.0000\n",
      "Epoch: 803, Training loss: 1.371039, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 804, Training loss: 1.376071, Validation loss: 1.3800, lr: 0.0000\n",
      "Epoch: 805, Training loss: 1.371803, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 806, Training loss: 1.367082, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 807, Training loss: 1.392942, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 808, Training loss: 1.370095, Validation loss: 1.3717, lr: 0.0000\n",
      "Epoch: 809, Training loss: 1.393914, Validation loss: 1.3625, lr: 0.0000\n",
      "Epoch: 810, Training loss: 1.364390, Validation loss: 1.3662, lr: 0.0000\n",
      "Epoch: 811, Training loss: 1.371845, Validation loss: 1.3764, lr: 0.0000\n",
      "Epoch: 812, Training loss: 1.363755, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 813, Training loss: 1.362334, Validation loss: 1.3871, lr: 0.0000\n",
      "Epoch: 814, Training loss: 1.373758, Validation loss: 1.3775, lr: 0.0000\n",
      "Epoch: 815, Training loss: 1.379481, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 816, Training loss: 1.384099, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 817, Training loss: 1.372689, Validation loss: 1.3783, lr: 0.0000\n",
      "Epoch: 818, Training loss: 1.381875, Validation loss: 1.3798, lr: 0.0000\n",
      "Epoch: 819, Training loss: 1.375394, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 820, Training loss: 1.378095, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 821, Training loss: 1.391970, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 822, Training loss: 1.390957, Validation loss: 1.3917, lr: 0.0000\n",
      "Epoch: 823, Training loss: 1.383580, Validation loss: 1.3790, lr: 0.0000\n",
      "Epoch: 824, Training loss: 1.398852, Validation loss: 1.3780, lr: 0.0000\n",
      "Epoch: 825, Training loss: 1.370769, Validation loss: 1.3872, lr: 0.0000\n",
      "Epoch: 826, Training loss: 1.377396, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 827, Training loss: 1.371756, Validation loss: 1.3536, lr: 0.0000\n",
      "Epoch: 828, Training loss: 1.378971, Validation loss: 1.3938, lr: 0.0000\n",
      "Epoch: 829, Training loss: 1.400554, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 830, Training loss: 1.407593, Validation loss: 1.3768, lr: 0.0000\n",
      "Epoch: 831, Training loss: 1.389174, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 832, Training loss: 1.394710, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 833, Training loss: 1.378394, Validation loss: 1.3872, lr: 0.0000\n",
      "Epoch: 834, Training loss: 1.382411, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 835, Training loss: 1.409175, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 836, Training loss: 1.361069, Validation loss: 1.3891, lr: 0.0000\n",
      "Epoch: 837, Training loss: 1.386147, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 838, Training loss: 1.410462, Validation loss: 1.3944, lr: 0.0000\n",
      "Epoch: 839, Training loss: 1.374753, Validation loss: 1.3731, lr: 0.0000\n",
      "Epoch: 840, Training loss: 1.371345, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 841, Training loss: 1.387076, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 842, Training loss: 1.369929, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 843, Training loss: 1.399649, Validation loss: 1.3650, lr: 0.0000\n",
      "Epoch: 844, Training loss: 1.382760, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 845, Training loss: 1.379619, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 846, Training loss: 1.377286, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 847, Training loss: 1.369931, Validation loss: 1.3676, lr: 0.0000\n",
      "Epoch: 848, Training loss: 1.395154, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 849, Training loss: 1.394242, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 850, Training loss: 1.361987, Validation loss: 1.3793, lr: 0.0000\n",
      "Epoch: 851, Training loss: 1.389885, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 852, Training loss: 1.377884, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 853, Training loss: 1.374511, Validation loss: 1.3698, lr: 0.0000\n",
      "Epoch: 854, Training loss: 1.373647, Validation loss: 1.3794, lr: 0.0000\n",
      "Epoch: 855, Training loss: 1.383640, Validation loss: 1.3891, lr: 0.0000\n",
      "Epoch: 856, Training loss: 1.373857, Validation loss: 1.3946, lr: 0.0000\n",
      "Epoch: 857, Training loss: 1.372031, Validation loss: 1.4607, lr: 0.0000\n",
      "Epoch: 858, Training loss: 1.380578, Validation loss: 1.3650, lr: 0.0000\n",
      "Epoch: 859, Training loss: 1.372540, Validation loss: 1.3875, lr: 0.0000\n",
      "Epoch: 860, Training loss: 1.381272, Validation loss: 1.3793, lr: 0.0000\n",
      "Epoch: 861, Training loss: 1.379333, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 862, Training loss: 1.438791, Validation loss: 1.3797, lr: 0.0000\n",
      "Epoch: 863, Training loss: 1.380408, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 864, Training loss: 1.370097, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 865, Training loss: 1.382172, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 866, Training loss: 1.378041, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 867, Training loss: 1.401710, Validation loss: 1.3872, lr: 0.0000\n",
      "Epoch: 868, Training loss: 1.382586, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 869, Training loss: 1.389042, Validation loss: 1.3771, lr: 0.0000\n",
      "Epoch: 870, Training loss: 1.379324, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 871, Training loss: 1.408613, Validation loss: 1.3749, lr: 0.0000\n",
      "Epoch: 872, Training loss: 1.376875, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 873, Training loss: 1.367344, Validation loss: 1.3885, lr: 0.0000\n",
      "Epoch: 874, Training loss: 1.373993, Validation loss: 1.3881, lr: 0.0000\n",
      "Epoch: 875, Training loss: 1.368911, Validation loss: 1.3744, lr: 0.0000\n",
      "Epoch: 876, Training loss: 1.372491, Validation loss: 1.3786, lr: 0.0000\n",
      "Epoch: 877, Training loss: 1.367016, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 878, Training loss: 1.375387, Validation loss: 1.3926, lr: 0.0000\n",
      "Epoch: 879, Training loss: 1.379355, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 880, Training loss: 1.382696, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 881, Training loss: 1.378766, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 882, Training loss: 1.366524, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 883, Training loss: 1.380447, Validation loss: 1.3469, lr: 0.0000\n",
      "Epoch: 884, Training loss: 1.385942, Validation loss: 1.3901, lr: 0.0000\n",
      "Epoch: 885, Training loss: 1.368946, Validation loss: 1.3886, lr: 0.0000\n",
      "Epoch: 886, Training loss: 1.382557, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 887, Training loss: 1.383823, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 888, Training loss: 1.376899, Validation loss: 1.3877, lr: 0.0000\n",
      "Epoch: 889, Training loss: 1.476335, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 890, Training loss: 1.367737, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 891, Training loss: 1.397105, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 892, Training loss: 1.461534, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 893, Training loss: 1.378155, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 894, Training loss: 1.380316, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 895, Training loss: 1.376060, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 896, Training loss: 1.381821, Validation loss: 1.3773, lr: 0.0000\n",
      "Epoch: 897, Training loss: 1.374664, Validation loss: 1.3876, lr: 0.0000\n",
      "Epoch: 898, Training loss: 1.385194, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 899, Training loss: 1.369563, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 900, Training loss: 1.374777, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 901, Training loss: 1.444644, Validation loss: 1.3749, lr: 0.0000\n",
      "Epoch: 902, Training loss: 1.375536, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 903, Training loss: 1.378477, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 904, Training loss: 1.393003, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 905, Training loss: 1.375756, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 906, Training loss: 1.367104, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 907, Training loss: 1.379939, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 908, Training loss: 1.369596, Validation loss: 1.3792, lr: 0.0000\n",
      "Epoch: 909, Training loss: 1.371364, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 910, Training loss: 1.396782, Validation loss: 1.4024, lr: 0.0000\n",
      "Epoch: 911, Training loss: 1.375534, Validation loss: 1.3897, lr: 0.0000\n",
      "Epoch: 912, Training loss: 1.372262, Validation loss: 1.4030, lr: 0.0000\n",
      "Epoch: 913, Training loss: 1.397121, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 914, Training loss: 1.369396, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 915, Training loss: 1.400446, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 916, Training loss: 1.366451, Validation loss: 1.3877, lr: 0.0000\n",
      "Epoch: 917, Training loss: 1.374820, Validation loss: 1.3758, lr: 0.0000\n",
      "Epoch: 918, Training loss: 1.380450, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 919, Training loss: 1.363013, Validation loss: 1.3871, lr: 0.0000\n",
      "Epoch: 920, Training loss: 1.372792, Validation loss: 1.3737, lr: 0.0000\n",
      "Epoch: 921, Training loss: 1.367576, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 922, Training loss: 1.381940, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 923, Training loss: 1.382951, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 924, Training loss: 1.369857, Validation loss: 1.3800, lr: 0.0000\n",
      "Epoch: 925, Training loss: 1.365299, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 926, Training loss: 1.392193, Validation loss: 1.3931, lr: 0.0000\n",
      "Epoch: 927, Training loss: 1.369464, Validation loss: 1.3694, lr: 0.0000\n",
      "Epoch: 928, Training loss: 1.365282, Validation loss: 1.3624, lr: 0.0000\n",
      "Epoch: 929, Training loss: 1.385824, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 930, Training loss: 1.394781, Validation loss: 1.3758, lr: 0.0000\n",
      "Epoch: 931, Training loss: 1.367989, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 932, Training loss: 1.368664, Validation loss: 1.3715, lr: 0.0000\n",
      "Epoch: 933, Training loss: 1.368227, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 934, Training loss: 1.376053, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 935, Training loss: 1.378025, Validation loss: 1.3771, lr: 0.0000\n",
      "Epoch: 936, Training loss: 1.382700, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 937, Training loss: 1.371975, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 938, Training loss: 1.366164, Validation loss: 1.3712, lr: 0.0000\n",
      "Epoch: 939, Training loss: 1.379238, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 940, Training loss: 1.376621, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 941, Training loss: 1.396330, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 942, Training loss: 1.377360, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 943, Training loss: 1.372270, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 944, Training loss: 1.373952, Validation loss: 1.3794, lr: 0.0000\n",
      "Epoch: 945, Training loss: 1.367982, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 946, Training loss: 1.376416, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 947, Training loss: 1.359818, Validation loss: 1.3881, lr: 0.0000\n",
      "Epoch: 948, Training loss: 1.381703, Validation loss: 1.3880, lr: 0.0000\n",
      "Epoch: 949, Training loss: 1.355285, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 950, Training loss: 1.370359, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 951, Training loss: 1.410128, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 952, Training loss: 1.381202, Validation loss: 1.3781, lr: 0.0000\n",
      "Epoch: 953, Training loss: 1.384239, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 954, Training loss: 1.382249, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 955, Training loss: 1.376868, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 956, Training loss: 1.383711, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 957, Training loss: 1.387006, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 958, Training loss: 1.386634, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 959, Training loss: 1.391359, Validation loss: 1.3799, lr: 0.0000\n",
      "Epoch: 960, Training loss: 1.367519, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 961, Training loss: 1.372705, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 962, Training loss: 1.379155, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 963, Training loss: 1.381178, Validation loss: 1.3907, lr: 0.0000\n",
      "Epoch: 964, Training loss: 1.379563, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 965, Training loss: 1.387003, Validation loss: 1.3773, lr: 0.0000\n",
      "Epoch: 966, Training loss: 1.368680, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 967, Training loss: 1.368300, Validation loss: 1.3743, lr: 0.0000\n",
      "Epoch: 968, Training loss: 1.365474, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 969, Training loss: 1.364948, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 970, Training loss: 1.375193, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 971, Training loss: 1.380676, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 972, Training loss: 1.387285, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 973, Training loss: 1.365481, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 974, Training loss: 1.378686, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 975, Training loss: 1.373536, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 976, Training loss: 1.370948, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 977, Training loss: 1.376138, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 978, Training loss: 1.384059, Validation loss: 1.3704, lr: 0.0000\n",
      "Epoch: 979, Training loss: 1.380775, Validation loss: 1.3773, lr: 0.0000\n",
      "Epoch: 980, Training loss: 1.376185, Validation loss: 1.3678, lr: 0.0000\n",
      "Epoch: 981, Training loss: 1.383648, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 982, Training loss: 1.376009, Validation loss: 1.3876, lr: 0.0000\n",
      "Epoch: 983, Training loss: 1.381035, Validation loss: 1.3799, lr: 0.0000\n",
      "Epoch: 984, Training loss: 1.392676, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 985, Training loss: 1.377325, Validation loss: 1.3879, lr: 0.0000\n",
      "Epoch: 986, Training loss: 1.365179, Validation loss: 1.3802, lr: 0.0000\n",
      "Epoch: 987, Training loss: 1.408114, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 988, Training loss: 1.355227, Validation loss: 1.3736, lr: 0.0000\n",
      "Epoch: 989, Training loss: 1.380280, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 990, Training loss: 1.383254, Validation loss: 1.3872, lr: 0.0000\n",
      "Epoch: 991, Training loss: 1.379949, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 992, Training loss: 1.369196, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 993, Training loss: 1.367678, Validation loss: 1.3710, lr: 0.0000\n",
      "Epoch: 994, Training loss: 1.381566, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 995, Training loss: 1.378044, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 996, Training loss: 1.368740, Validation loss: 1.3715, lr: 0.0000\n",
      "Epoch: 997, Training loss: 1.389136, Validation loss: 1.3746, lr: 0.0000\n",
      "Epoch: 998, Training loss: 1.386425, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 999, Training loss: 1.376354, Validation loss: 1.3799, lr: 0.0000\n",
      "Final test loss: 1.3852\n",
      "=== Run 09/10 ===\n",
      "\n",
      "---- Settings: \n",
      "\n",
      "epochs : 1000\n",
      "hidden_channels : [32]\n",
      "out_channels : 10\n",
      "inner_product_features : False\n",
      "batch_size : 64\n",
      "lr : 0.01\n",
      "momentum : 0.9\n",
      "dropout : 0.0\n",
      "batch_norm : batch_norm\n",
      "bias : True\n",
      "order : 2\n",
      "diffusion : True\n",
      "frac_sampled_nb : -1\n",
      "include_positions : False\n",
      "include_self : True\n",
      "vec_norm : False\n",
      "emb_norm : False\n",
      "seed : 0\n",
      "dim_signal : 100\n",
      "dim_emb : 100\n",
      "n_sampled_nb : -1\n",
      "\n",
      "---- Number of features to pass to the MLP:  1010100\n",
      "---- Total number of parameters:  32323627\n",
      "\n",
      "Using device cuda:0\n",
      "\n",
      "---- Training network ...\n",
      "\n",
      "---- Timestamp: 20250614-051512\n",
      "\n",
      " *och: 0, Training loss: 1.418804, Validation loss: 1.4048, lr: 0.0100\n",
      " *och: 1, Training loss: 1.534019, Validation loss: 1.3984, lr: 0.0100\n",
      " *och: 2, Training loss: 1.426216, Validation loss: 1.3705, lr: 0.0100\n",
      "Epoch: 3, Training loss: 1.412174, Validation loss: 1.3855, lr: 0.0100\n",
      "Epoch: 4, Training loss: 1.386856, Validation loss: 1.3798, lr: 0.0100\n",
      "Epoch: 5, Training loss: 1.383239, Validation loss: 1.3791, lr: 0.0100\n",
      "Epoch: 6, Training loss: 1.425187, Validation loss: 1.3868, lr: 0.0100\n",
      "Epoch: 7, Training loss: 1.366973, Validation loss: 1.3891, lr: 0.0100\n",
      "Epoch: 8, Training loss: 1.408421, Validation loss: 1.3852, lr: 0.0100\n",
      "Epoch: 9, Training loss: 1.381216, Validation loss: 1.3846, lr: 0.0100\n",
      "Epoch: 10, Training loss: 1.390043, Validation loss: 1.3832, lr: 0.0100\n",
      "Epoch: 11, Training loss: 1.378768, Validation loss: 1.3865, lr: 0.0100\n",
      " *och: 12, Training loss: 1.419049, Validation loss: 1.3505, lr: 0.0100\n",
      "Epoch: 13, Training loss: 1.371763, Validation loss: 1.3851, lr: 0.0100\n",
      "Epoch: 14, Training loss: 1.370500, Validation loss: 1.3858, lr: 0.0100\n",
      "Epoch: 15, Training loss: 1.384617, Validation loss: 1.3836, lr: 0.0100\n",
      "Epoch: 16, Training loss: 1.369995, Validation loss: 1.3840, lr: 0.0100\n",
      "Epoch: 17, Training loss: 1.364077, Validation loss: 1.3847, lr: 0.0100\n",
      "Epoch: 18, Training loss: 1.380110, Validation loss: 1.3881, lr: 0.0100\n",
      "Epoch: 19, Training loss: 1.396159, Validation loss: 1.3837, lr: 0.0100\n",
      "Epoch: 20, Training loss: 1.370232, Validation loss: 1.3788, lr: 0.0100\n",
      "Epoch: 21, Training loss: 1.372704, Validation loss: 1.3749, lr: 0.0100\n",
      "Epoch: 22, Training loss: 1.382188, Validation loss: 1.3844, lr: 0.0100\n",
      "Epoch: 23, Training loss: 1.394066, Validation loss: 1.3834, lr: 0.0100\n",
      "Epoch: 24, Training loss: 1.361226, Validation loss: 1.3737, lr: 0.0100\n",
      "Epoch: 25, Training loss: 1.388101, Validation loss: 1.3813, lr: 0.0100\n",
      "Epoch: 26, Training loss: 1.401199, Validation loss: 1.3767, lr: 0.0100\n",
      "Epoch: 27, Training loss: 1.364697, Validation loss: 1.3856, lr: 0.0100\n",
      "Epoch: 28, Training loss: 1.380671, Validation loss: 1.3809, lr: 0.0100\n",
      "Epoch: 29, Training loss: 1.365642, Validation loss: 1.3770, lr: 0.0100\n",
      "Epoch: 30, Training loss: 1.382644, Validation loss: 1.3776, lr: 0.0100\n",
      "Epoch: 31, Training loss: 1.366477, Validation loss: 1.3741, lr: 0.0100\n",
      "Epoch: 32, Training loss: 1.382543, Validation loss: 1.3820, lr: 0.0100\n",
      "Epoch: 33, Training loss: 1.388851, Validation loss: 1.3831, lr: 0.0100\n",
      "Epoch: 34, Training loss: 1.377063, Validation loss: 1.3850, lr: 0.0100\n",
      "Epoch: 35, Training loss: 1.370279, Validation loss: 1.3809, lr: 0.0010\n",
      "Epoch: 36, Training loss: 1.365060, Validation loss: 1.4943, lr: 0.0010\n",
      "Epoch: 37, Training loss: 1.369194, Validation loss: 1.3837, lr: 0.0010\n",
      "Epoch: 38, Training loss: 1.386459, Validation loss: 1.3847, lr: 0.0010\n",
      "Epoch: 39, Training loss: 1.366019, Validation loss: 1.3832, lr: 0.0010\n",
      "Epoch: 40, Training loss: 1.390552, Validation loss: 1.3862, lr: 0.0010\n",
      "Epoch: 41, Training loss: 1.375326, Validation loss: 1.3832, lr: 0.0010\n",
      "Epoch: 42, Training loss: 1.388534, Validation loss: 1.3719, lr: 0.0010\n",
      "Epoch: 43, Training loss: 1.373267, Validation loss: 1.3829, lr: 0.0010\n",
      "Epoch: 44, Training loss: 1.370869, Validation loss: 1.3812, lr: 0.0010\n",
      "Epoch: 45, Training loss: 1.378623, Validation loss: 1.3834, lr: 0.0010\n",
      "Epoch: 46, Training loss: 1.405525, Validation loss: 1.3698, lr: 0.0001\n",
      "Epoch: 47, Training loss: 1.377407, Validation loss: 1.3838, lr: 0.0001\n",
      "Epoch: 48, Training loss: 1.362567, Validation loss: 1.3823, lr: 0.0001\n",
      "Epoch: 49, Training loss: 1.359484, Validation loss: 1.3791, lr: 0.0001\n",
      "Epoch: 50, Training loss: 1.400597, Validation loss: 1.3734, lr: 0.0001\n",
      " *och: 51, Training loss: 1.362745, Validation loss: 1.3484, lr: 0.0001\n",
      "Epoch: 52, Training loss: 1.362323, Validation loss: 1.3776, lr: 0.0001\n",
      "Epoch: 53, Training loss: 1.431133, Validation loss: 1.3806, lr: 0.0001\n",
      "Epoch: 54, Training loss: 1.432009, Validation loss: 1.3905, lr: 0.0001\n",
      "Epoch: 55, Training loss: 1.385024, Validation loss: 1.3844, lr: 0.0001\n",
      "Epoch: 56, Training loss: 1.371176, Validation loss: 1.3808, lr: 0.0001\n",
      "Epoch: 57, Training loss: 1.396379, Validation loss: 1.3841, lr: 0.0001\n",
      "Epoch: 58, Training loss: 1.377536, Validation loss: 1.3781, lr: 0.0001\n",
      "Epoch: 59, Training loss: 1.362455, Validation loss: 1.3866, lr: 0.0001\n",
      "Epoch: 60, Training loss: 1.381781, Validation loss: 1.3800, lr: 0.0000\n",
      "Epoch: 61, Training loss: 1.370760, Validation loss: 1.3759, lr: 0.0000\n",
      "Epoch: 62, Training loss: 1.383573, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 63, Training loss: 1.364776, Validation loss: 1.3919, lr: 0.0000\n",
      "Epoch: 64, Training loss: 1.383598, Validation loss: 1.3675, lr: 0.0000\n",
      "Epoch: 65, Training loss: 1.400935, Validation loss: 1.3558, lr: 0.0000\n",
      "Epoch: 66, Training loss: 1.373942, Validation loss: 1.3669, lr: 0.0000\n",
      "Epoch: 67, Training loss: 1.363016, Validation loss: 1.3826, lr: 0.0000\n",
      " *och: 68, Training loss: 1.376900, Validation loss: 1.3405, lr: 0.0000\n",
      "Epoch: 69, Training loss: 1.391137, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 70, Training loss: 1.361950, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 71, Training loss: 1.381292, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 72, Training loss: 1.377676, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 73, Training loss: 1.365833, Validation loss: 1.3528, lr: 0.0000\n",
      "Epoch: 74, Training loss: 1.400316, Validation loss: 1.3733, lr: 0.0000\n",
      "Epoch: 75, Training loss: 1.374004, Validation loss: 1.3931, lr: 0.0000\n",
      "Epoch: 76, Training loss: 1.357787, Validation loss: 1.3773, lr: 0.0000\n",
      "Epoch: 77, Training loss: 1.366429, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 78, Training loss: 1.390667, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 79, Training loss: 1.357836, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 80, Training loss: 1.361661, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 81, Training loss: 1.380159, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 82, Training loss: 1.373086, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 83, Training loss: 1.360937, Validation loss: 1.3792, lr: 0.0000\n",
      "Epoch: 84, Training loss: 1.404664, Validation loss: 1.3784, lr: 0.0000\n",
      "Epoch: 85, Training loss: 1.376353, Validation loss: 1.3787, lr: 0.0000\n",
      "Epoch: 86, Training loss: 1.376981, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 87, Training loss: 1.368386, Validation loss: 1.3782, lr: 0.0000\n",
      "Epoch: 88, Training loss: 1.365714, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 89, Training loss: 1.366027, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 90, Training loss: 1.359470, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 91, Training loss: 1.359021, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 92, Training loss: 1.363043, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 93, Training loss: 1.374080, Validation loss: 1.3790, lr: 0.0000\n",
      "Epoch: 94, Training loss: 1.374590, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 95, Training loss: 1.379914, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 96, Training loss: 1.371357, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 97, Training loss: 1.366208, Validation loss: 1.3775, lr: 0.0000\n",
      "Epoch: 98, Training loss: 1.418002, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 99, Training loss: 1.372497, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 100, Training loss: 1.382365, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 101, Training loss: 1.380579, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 102, Training loss: 1.372731, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 103, Training loss: 1.364041, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 104, Training loss: 1.367900, Validation loss: 1.3903, lr: 0.0000\n",
      "Epoch: 105, Training loss: 1.377717, Validation loss: 1.3710, lr: 0.0000\n",
      "Epoch: 106, Training loss: 1.371434, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 107, Training loss: 1.396418, Validation loss: 1.3893, lr: 0.0000\n",
      "Epoch: 108, Training loss: 1.371040, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 109, Training loss: 1.339384, Validation loss: 1.3800, lr: 0.0000\n",
      "Epoch: 110, Training loss: 1.364999, Validation loss: 1.3766, lr: 0.0000\n",
      "Epoch: 111, Training loss: 1.375522, Validation loss: 1.3679, lr: 0.0000\n",
      "Epoch: 112, Training loss: 1.370162, Validation loss: 1.3782, lr: 0.0000\n",
      "Epoch: 113, Training loss: 1.387871, Validation loss: 1.3594, lr: 0.0000\n",
      "Epoch: 114, Training loss: 1.378270, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 115, Training loss: 1.382119, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 116, Training loss: 1.346692, Validation loss: 1.3799, lr: 0.0000\n",
      "Epoch: 117, Training loss: 1.359307, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 118, Training loss: 1.392331, Validation loss: 1.3789, lr: 0.0000\n",
      "Epoch: 119, Training loss: 1.366725, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 120, Training loss: 1.370672, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 121, Training loss: 1.398792, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 122, Training loss: 1.379984, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 123, Training loss: 1.372911, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 124, Training loss: 1.382913, Validation loss: 1.3957, lr: 0.0000\n",
      "Epoch: 125, Training loss: 1.366862, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 126, Training loss: 1.357775, Validation loss: 1.3725, lr: 0.0000\n",
      "Epoch: 127, Training loss: 1.402397, Validation loss: 1.3989, lr: 0.0000\n",
      "Epoch: 128, Training loss: 1.395908, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 129, Training loss: 1.386158, Validation loss: 1.3880, lr: 0.0000\n",
      "Epoch: 130, Training loss: 1.370342, Validation loss: 1.3794, lr: 0.0000\n",
      "Epoch: 131, Training loss: 1.364773, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 132, Training loss: 1.375787, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 133, Training loss: 1.397272, Validation loss: 1.3795, lr: 0.0000\n",
      "Epoch: 134, Training loss: 1.374396, Validation loss: 1.3707, lr: 0.0000\n",
      "Epoch: 135, Training loss: 1.361148, Validation loss: 1.3636, lr: 0.0000\n",
      "Epoch: 136, Training loss: 1.367011, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 137, Training loss: 1.385168, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 138, Training loss: 1.373358, Validation loss: 1.3775, lr: 0.0000\n",
      "Epoch: 139, Training loss: 1.481119, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 140, Training loss: 1.371314, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 141, Training loss: 1.406564, Validation loss: 1.3745, lr: 0.0000\n",
      "Epoch: 142, Training loss: 1.384180, Validation loss: 1.3728, lr: 0.0000\n",
      "Epoch: 143, Training loss: 1.358110, Validation loss: 1.3785, lr: 0.0000\n",
      "Epoch: 144, Training loss: 1.377950, Validation loss: 1.3711, lr: 0.0000\n",
      "Epoch: 145, Training loss: 1.377239, Validation loss: 1.3753, lr: 0.0000\n",
      "Epoch: 146, Training loss: 1.360871, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 147, Training loss: 1.370408, Validation loss: 1.3751, lr: 0.0000\n",
      "Epoch: 148, Training loss: 1.377513, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 149, Training loss: 1.384103, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 150, Training loss: 1.399197, Validation loss: 1.3791, lr: 0.0000\n",
      "Epoch: 151, Training loss: 1.367960, Validation loss: 1.3909, lr: 0.0000\n",
      "Epoch: 152, Training loss: 1.377335, Validation loss: 1.4258, lr: 0.0000\n",
      "Epoch: 153, Training loss: 1.377833, Validation loss: 1.4794, lr: 0.0000\n",
      "Epoch: 154, Training loss: 1.365797, Validation loss: 1.3925, lr: 0.0000\n",
      "Epoch: 155, Training loss: 1.364597, Validation loss: 1.3731, lr: 0.0000\n",
      "Epoch: 156, Training loss: 1.378602, Validation loss: 1.3885, lr: 0.0000\n",
      "Epoch: 157, Training loss: 1.374767, Validation loss: 1.3622, lr: 0.0000\n",
      "Epoch: 158, Training loss: 1.369247, Validation loss: 1.3734, lr: 0.0000\n",
      "Epoch: 159, Training loss: 1.384933, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 160, Training loss: 1.379422, Validation loss: 1.3761, lr: 0.0000\n",
      "Epoch: 161, Training loss: 1.380550, Validation loss: 1.3784, lr: 0.0000\n",
      "Epoch: 162, Training loss: 1.376034, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 163, Training loss: 1.359653, Validation loss: 1.3872, lr: 0.0000\n",
      "Epoch: 164, Training loss: 1.362618, Validation loss: 1.3699, lr: 0.0000\n",
      "Epoch: 165, Training loss: 1.356996, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 166, Training loss: 1.394677, Validation loss: 1.3803, lr: 0.0000\n",
      "Epoch: 167, Training loss: 1.360336, Validation loss: 1.3686, lr: 0.0000\n",
      "Epoch: 168, Training loss: 1.365644, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 169, Training loss: 1.371810, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 170, Training loss: 1.380335, Validation loss: 1.3663, lr: 0.0000\n",
      "Epoch: 171, Training loss: 1.366791, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 172, Training loss: 1.385419, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 173, Training loss: 1.385438, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 174, Training loss: 1.366170, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 175, Training loss: 1.380761, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 176, Training loss: 1.372763, Validation loss: 1.3794, lr: 0.0000\n",
      "Epoch: 177, Training loss: 1.376239, Validation loss: 1.3795, lr: 0.0000\n",
      "Epoch: 178, Training loss: 1.365173, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 179, Training loss: 1.379390, Validation loss: 1.3785, lr: 0.0000\n",
      "Epoch: 180, Training loss: 1.399162, Validation loss: 1.3761, lr: 0.0000\n",
      "Epoch: 181, Training loss: 1.363293, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 182, Training loss: 1.382277, Validation loss: 1.3670, lr: 0.0000\n",
      "Epoch: 183, Training loss: 1.383665, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 184, Training loss: 1.390269, Validation loss: 1.3758, lr: 0.0000\n",
      "Epoch: 185, Training loss: 1.385110, Validation loss: 1.3877, lr: 0.0000\n",
      "Epoch: 186, Training loss: 1.379321, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 187, Training loss: 1.363394, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 188, Training loss: 1.370276, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 189, Training loss: 1.370052, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 190, Training loss: 1.369987, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 191, Training loss: 1.378118, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 192, Training loss: 1.349831, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 193, Training loss: 1.368096, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 194, Training loss: 1.358702, Validation loss: 1.3451, lr: 0.0000\n",
      "Epoch: 195, Training loss: 1.358086, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 196, Training loss: 1.382770, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 197, Training loss: 1.399072, Validation loss: 1.3735, lr: 0.0000\n",
      "Epoch: 198, Training loss: 1.371587, Validation loss: 1.3799, lr: 0.0000\n",
      "Epoch: 199, Training loss: 1.379534, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 200, Training loss: 1.364565, Validation loss: 1.3676, lr: 0.0000\n",
      "Epoch: 201, Training loss: 1.370681, Validation loss: 1.3576, lr: 0.0000\n",
      "Epoch: 202, Training loss: 1.351906, Validation loss: 1.3761, lr: 0.0000\n",
      "Epoch: 203, Training loss: 1.408559, Validation loss: 1.3789, lr: 0.0000\n",
      "Epoch: 204, Training loss: 1.364775, Validation loss: 1.3803, lr: 0.0000\n",
      "Epoch: 205, Training loss: 1.380858, Validation loss: 1.3957, lr: 0.0000\n",
      "Epoch: 206, Training loss: 1.344441, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 207, Training loss: 1.357443, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 208, Training loss: 1.412548, Validation loss: 1.3713, lr: 0.0000\n",
      "Epoch: 209, Training loss: 1.377008, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 210, Training loss: 1.383968, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 211, Training loss: 1.366144, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 212, Training loss: 1.367023, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 213, Training loss: 1.354174, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 214, Training loss: 1.381880, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 215, Training loss: 1.372445, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 216, Training loss: 1.401710, Validation loss: 1.3797, lr: 0.0000\n",
      "Epoch: 217, Training loss: 1.358724, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 218, Training loss: 1.377635, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 219, Training loss: 1.382277, Validation loss: 1.3871, lr: 0.0000\n",
      "Epoch: 220, Training loss: 1.400553, Validation loss: 1.3765, lr: 0.0000\n",
      "Epoch: 221, Training loss: 1.375982, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 222, Training loss: 1.376331, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 223, Training loss: 1.368302, Validation loss: 1.3796, lr: 0.0000\n",
      "Epoch: 224, Training loss: 1.376840, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 225, Training loss: 1.362667, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 226, Training loss: 1.354364, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 227, Training loss: 1.367583, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 228, Training loss: 1.381431, Validation loss: 1.3907, lr: 0.0000\n",
      "Epoch: 229, Training loss: 1.389960, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 230, Training loss: 1.358030, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 231, Training loss: 1.418585, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 232, Training loss: 1.373809, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 233, Training loss: 1.383473, Validation loss: 1.3877, lr: 0.0000\n",
      "Epoch: 234, Training loss: 1.484452, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 235, Training loss: 1.383927, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 236, Training loss: 1.377963, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 237, Training loss: 1.371232, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 238, Training loss: 1.378898, Validation loss: 1.3785, lr: 0.0000\n",
      "Epoch: 239, Training loss: 1.383249, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 240, Training loss: 1.375145, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 241, Training loss: 1.382188, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 242, Training loss: 1.363673, Validation loss: 1.3760, lr: 0.0000\n",
      "Epoch: 243, Training loss: 1.368264, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 244, Training loss: 1.363103, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 245, Training loss: 1.369131, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 246, Training loss: 1.350343, Validation loss: 1.3647, lr: 0.0000\n",
      "Epoch: 247, Training loss: 1.383848, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 248, Training loss: 1.367190, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 249, Training loss: 1.363811, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 250, Training loss: 1.373522, Validation loss: 1.3745, lr: 0.0000\n",
      "Epoch: 251, Training loss: 1.363606, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 252, Training loss: 1.379762, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 253, Training loss: 1.374896, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 254, Training loss: 1.381244, Validation loss: 1.3737, lr: 0.0000\n",
      "Epoch: 255, Training loss: 1.372404, Validation loss: 1.3796, lr: 0.0000\n",
      "Epoch: 256, Training loss: 1.367486, Validation loss: 1.3776, lr: 0.0000\n",
      "Epoch: 257, Training loss: 1.375495, Validation loss: 1.3874, lr: 0.0000\n",
      "Epoch: 258, Training loss: 1.361036, Validation loss: 1.3736, lr: 0.0000\n",
      "Epoch: 259, Training loss: 1.377192, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 260, Training loss: 1.366918, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 261, Training loss: 1.371462, Validation loss: 1.3797, lr: 0.0000\n",
      "Epoch: 262, Training loss: 1.395634, Validation loss: 1.3730, lr: 0.0000\n",
      "Epoch: 263, Training loss: 1.371490, Validation loss: 1.3708, lr: 0.0000\n",
      "Epoch: 264, Training loss: 1.377361, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 265, Training loss: 1.369874, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 266, Training loss: 1.371292, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 267, Training loss: 1.395999, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 268, Training loss: 1.375272, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 269, Training loss: 1.358319, Validation loss: 1.3738, lr: 0.0000\n",
      "Epoch: 270, Training loss: 1.436117, Validation loss: 1.3798, lr: 0.0000\n",
      "Epoch: 271, Training loss: 1.357932, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 272, Training loss: 1.378294, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 273, Training loss: 1.361119, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 274, Training loss: 1.375291, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 275, Training loss: 1.374567, Validation loss: 1.3772, lr: 0.0000\n",
      "Epoch: 276, Training loss: 1.383004, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 277, Training loss: 1.387573, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 278, Training loss: 1.374590, Validation loss: 1.3770, lr: 0.0000\n",
      "Epoch: 279, Training loss: 1.353455, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 280, Training loss: 1.372175, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 281, Training loss: 1.376156, Validation loss: 1.4000, lr: 0.0000\n",
      "Epoch: 282, Training loss: 1.399858, Validation loss: 1.3621, lr: 0.0000\n",
      "Epoch: 283, Training loss: 1.372753, Validation loss: 1.3800, lr: 0.0000\n",
      "Epoch: 284, Training loss: 1.375785, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 285, Training loss: 1.392878, Validation loss: 1.3750, lr: 0.0000\n",
      "Epoch: 286, Training loss: 1.374348, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 287, Training loss: 1.368940, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 288, Training loss: 1.384943, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 289, Training loss: 1.366333, Validation loss: 1.3773, lr: 0.0000\n",
      "Epoch: 290, Training loss: 1.379242, Validation loss: 1.3902, lr: 0.0000\n",
      "Epoch: 291, Training loss: 1.376820, Validation loss: 1.3706, lr: 0.0000\n",
      "Epoch: 292, Training loss: 1.359550, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 293, Training loss: 1.374210, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 294, Training loss: 1.371385, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 295, Training loss: 1.385254, Validation loss: 1.3793, lr: 0.0000\n",
      "Epoch: 296, Training loss: 1.352822, Validation loss: 1.3891, lr: 0.0000\n",
      "Epoch: 297, Training loss: 1.392755, Validation loss: 1.3950, lr: 0.0000\n",
      "Epoch: 298, Training loss: 1.376543, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 299, Training loss: 1.383476, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 300, Training loss: 1.360098, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 301, Training loss: 1.390703, Validation loss: 1.3736, lr: 0.0000\n",
      "Epoch: 302, Training loss: 1.375094, Validation loss: 1.3692, lr: 0.0000\n",
      "Epoch: 303, Training loss: 1.361413, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 304, Training loss: 1.367361, Validation loss: 1.3766, lr: 0.0000\n",
      "Epoch: 305, Training loss: 1.387065, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 306, Training loss: 1.370888, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 307, Training loss: 1.388340, Validation loss: 1.3886, lr: 0.0000\n",
      "Epoch: 308, Training loss: 1.370345, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 309, Training loss: 1.368096, Validation loss: 1.3891, lr: 0.0000\n",
      "Epoch: 310, Training loss: 1.375361, Validation loss: 1.3751, lr: 0.0000\n",
      "Epoch: 311, Training loss: 1.365792, Validation loss: 1.3800, lr: 0.0000\n",
      "Epoch: 312, Training loss: 1.364506, Validation loss: 1.3803, lr: 0.0000\n",
      "Epoch: 313, Training loss: 1.361391, Validation loss: 1.3786, lr: 0.0000\n",
      "Epoch: 314, Training loss: 1.407467, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 315, Training loss: 1.391114, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 316, Training loss: 1.371354, Validation loss: 1.4122, lr: 0.0000\n",
      "Epoch: 317, Training loss: 1.362961, Validation loss: 1.3872, lr: 0.0000\n",
      "Epoch: 318, Training loss: 1.359544, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 319, Training loss: 1.400809, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 320, Training loss: 1.364397, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 321, Training loss: 1.375480, Validation loss: 1.3721, lr: 0.0000\n",
      "Epoch: 322, Training loss: 1.377818, Validation loss: 1.3771, lr: 0.0000\n",
      "Epoch: 323, Training loss: 1.386610, Validation loss: 1.3796, lr: 0.0000\n",
      "Epoch: 324, Training loss: 1.373709, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 325, Training loss: 1.381310, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 326, Training loss: 1.398584, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 327, Training loss: 1.401013, Validation loss: 1.3746, lr: 0.0000\n",
      "Epoch: 328, Training loss: 1.367099, Validation loss: 1.3787, lr: 0.0000\n",
      "Epoch: 329, Training loss: 1.382035, Validation loss: 1.3668, lr: 0.0000\n",
      "Epoch: 330, Training loss: 1.361667, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 331, Training loss: 1.369025, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 332, Training loss: 1.382372, Validation loss: 1.3882, lr: 0.0000\n",
      "Epoch: 333, Training loss: 1.371834, Validation loss: 1.3717, lr: 0.0000\n",
      "Epoch: 334, Training loss: 1.381578, Validation loss: 1.3756, lr: 0.0000\n",
      "Epoch: 335, Training loss: 1.371672, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 336, Training loss: 1.379182, Validation loss: 1.3779, lr: 0.0000\n",
      "Epoch: 337, Training loss: 1.370850, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 338, Training loss: 1.372368, Validation loss: 1.3690, lr: 0.0000\n",
      "Epoch: 339, Training loss: 1.369548, Validation loss: 1.3876, lr: 0.0000\n",
      "Epoch: 340, Training loss: 1.356076, Validation loss: 1.3776, lr: 0.0000\n",
      "Epoch: 341, Training loss: 1.360205, Validation loss: 1.3702, lr: 0.0000\n",
      "Epoch: 342, Training loss: 1.370078, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 343, Training loss: 1.376877, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 344, Training loss: 1.385326, Validation loss: 1.3802, lr: 0.0000\n",
      "Epoch: 345, Training loss: 1.353186, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 346, Training loss: 1.395501, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 347, Training loss: 1.374552, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 348, Training loss: 1.372668, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 349, Training loss: 1.367856, Validation loss: 1.3737, lr: 0.0000\n",
      "Epoch: 350, Training loss: 1.357589, Validation loss: 1.3902, lr: 0.0000\n",
      "Epoch: 351, Training loss: 1.371965, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 352, Training loss: 1.389412, Validation loss: 1.3875, lr: 0.0000\n",
      "Epoch: 353, Training loss: 1.368608, Validation loss: 1.3482, lr: 0.0000\n",
      "Epoch: 354, Training loss: 1.369097, Validation loss: 1.3797, lr: 0.0000\n",
      "Epoch: 355, Training loss: 1.377776, Validation loss: 1.3726, lr: 0.0000\n",
      "Epoch: 356, Training loss: 1.347159, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 357, Training loss: 1.381607, Validation loss: 1.3704, lr: 0.0000\n",
      "Epoch: 358, Training loss: 1.380972, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 359, Training loss: 1.369065, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 360, Training loss: 1.379854, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 361, Training loss: 1.356688, Validation loss: 1.3750, lr: 0.0000\n",
      "Epoch: 362, Training loss: 1.372113, Validation loss: 1.3767, lr: 0.0000\n",
      "Epoch: 363, Training loss: 1.368417, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 364, Training loss: 1.375511, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 365, Training loss: 1.377713, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 366, Training loss: 1.370296, Validation loss: 1.3707, lr: 0.0000\n",
      "Epoch: 367, Training loss: 1.412266, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 368, Training loss: 1.380964, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 369, Training loss: 1.374172, Validation loss: 1.3758, lr: 0.0000\n",
      "Epoch: 370, Training loss: 1.391533, Validation loss: 1.3727, lr: 0.0000\n",
      "Epoch: 371, Training loss: 1.377116, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 372, Training loss: 1.379746, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 373, Training loss: 1.368076, Validation loss: 1.3578, lr: 0.0000\n",
      "Epoch: 374, Training loss: 1.371864, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 375, Training loss: 1.389758, Validation loss: 1.3718, lr: 0.0000\n",
      "Epoch: 376, Training loss: 1.376627, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 377, Training loss: 1.362527, Validation loss: 1.3802, lr: 0.0000\n",
      "Epoch: 378, Training loss: 1.373836, Validation loss: 1.3809, lr: 0.0000\n",
      "Epoch: 379, Training loss: 1.352722, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 380, Training loss: 1.386686, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 381, Training loss: 1.372940, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 382, Training loss: 1.372183, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 383, Training loss: 1.388512, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 384, Training loss: 1.344437, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 385, Training loss: 1.368620, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 386, Training loss: 1.381072, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 387, Training loss: 1.348451, Validation loss: 1.3795, lr: 0.0000\n",
      "Epoch: 388, Training loss: 1.374739, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 389, Training loss: 1.366645, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 390, Training loss: 1.435188, Validation loss: 1.3744, lr: 0.0000\n",
      "Epoch: 391, Training loss: 1.384216, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 392, Training loss: 1.377523, Validation loss: 1.3876, lr: 0.0000\n",
      "Epoch: 393, Training loss: 1.362094, Validation loss: 1.3749, lr: 0.0000\n",
      "Epoch: 394, Training loss: 1.372818, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 395, Training loss: 1.369798, Validation loss: 1.3798, lr: 0.0000\n",
      "Epoch: 396, Training loss: 1.361880, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 397, Training loss: 1.360217, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 398, Training loss: 1.379498, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 399, Training loss: 1.379757, Validation loss: 1.3626, lr: 0.0000\n",
      "Epoch: 400, Training loss: 1.358061, Validation loss: 1.3768, lr: 0.0000\n",
      "Epoch: 401, Training loss: 1.357979, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 402, Training loss: 1.380746, Validation loss: 1.3713, lr: 0.0000\n",
      "Epoch: 403, Training loss: 1.374534, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 404, Training loss: 1.379749, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 405, Training loss: 1.378580, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 406, Training loss: 1.363943, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 407, Training loss: 1.363140, Validation loss: 1.3898, lr: 0.0000\n",
      "Epoch: 408, Training loss: 1.384239, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 409, Training loss: 1.367496, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 410, Training loss: 1.369546, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 411, Training loss: 1.383275, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 412, Training loss: 1.365116, Validation loss: 1.3784, lr: 0.0000\n",
      "Epoch: 413, Training loss: 1.360607, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 414, Training loss: 1.379484, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 415, Training loss: 1.371871, Validation loss: 1.3750, lr: 0.0000\n",
      "Epoch: 416, Training loss: 1.371777, Validation loss: 1.3942, lr: 0.0000\n",
      "Epoch: 417, Training loss: 1.367646, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 418, Training loss: 1.417527, Validation loss: 1.3983, lr: 0.0000\n",
      "Epoch: 419, Training loss: 1.393396, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 420, Training loss: 1.376396, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 421, Training loss: 1.377354, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 422, Training loss: 1.424000, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 423, Training loss: 1.412291, Validation loss: 1.3765, lr: 0.0000\n",
      "Epoch: 424, Training loss: 1.379775, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 425, Training loss: 1.320437, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 426, Training loss: 1.376420, Validation loss: 1.3787, lr: 0.0000\n",
      "Epoch: 427, Training loss: 1.364560, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 428, Training loss: 1.382560, Validation loss: 1.3756, lr: 0.0000\n",
      "Epoch: 429, Training loss: 1.355706, Validation loss: 1.3762, lr: 0.0000\n",
      "Epoch: 430, Training loss: 1.364561, Validation loss: 1.3783, lr: 0.0000\n",
      "Epoch: 431, Training loss: 1.339398, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 432, Training loss: 1.359371, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 433, Training loss: 1.383213, Validation loss: 1.3447, lr: 0.0000\n",
      "Epoch: 434, Training loss: 1.380087, Validation loss: 1.3797, lr: 0.0000\n",
      "Epoch: 435, Training loss: 1.371735, Validation loss: 1.3734, lr: 0.0000\n",
      "Epoch: 436, Training loss: 1.356846, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 437, Training loss: 1.382976, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 438, Training loss: 1.388110, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 439, Training loss: 1.370656, Validation loss: 1.3797, lr: 0.0000\n",
      "Epoch: 440, Training loss: 1.377431, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 441, Training loss: 1.382040, Validation loss: 1.3755, lr: 0.0000\n",
      "Epoch: 442, Training loss: 1.370572, Validation loss: 1.3937, lr: 0.0000\n",
      "Epoch: 443, Training loss: 1.353988, Validation loss: 1.3739, lr: 0.0000\n",
      "Epoch: 444, Training loss: 1.369447, Validation loss: 1.3799, lr: 0.0000\n",
      "Epoch: 445, Training loss: 1.392276, Validation loss: 1.3797, lr: 0.0000\n",
      "Epoch: 446, Training loss: 1.377020, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 447, Training loss: 1.357538, Validation loss: 1.3795, lr: 0.0000\n",
      "Epoch: 448, Training loss: 1.348857, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 449, Training loss: 1.370292, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 450, Training loss: 1.390179, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 451, Training loss: 1.375949, Validation loss: 1.3741, lr: 0.0000\n",
      "Epoch: 452, Training loss: 1.381440, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 453, Training loss: 1.360240, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 454, Training loss: 1.372052, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 455, Training loss: 1.402131, Validation loss: 1.3613, lr: 0.0000\n",
      "Epoch: 456, Training loss: 1.380259, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 457, Training loss: 1.379844, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 458, Training loss: 1.370017, Validation loss: 1.3893, lr: 0.0000\n",
      "Epoch: 459, Training loss: 1.372502, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 460, Training loss: 1.386250, Validation loss: 1.3778, lr: 0.0000\n",
      "Epoch: 461, Training loss: 1.372134, Validation loss: 1.3792, lr: 0.0000\n",
      "Epoch: 462, Training loss: 1.379423, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 463, Training loss: 1.363371, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 464, Training loss: 1.372643, Validation loss: 1.3755, lr: 0.0000\n",
      "Epoch: 465, Training loss: 1.376427, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 466, Training loss: 1.407283, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 467, Training loss: 1.369369, Validation loss: 1.3798, lr: 0.0000\n",
      "Epoch: 468, Training loss: 1.371491, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 469, Training loss: 1.367661, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 470, Training loss: 1.381666, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 471, Training loss: 1.383352, Validation loss: 1.3749, lr: 0.0000\n",
      "Epoch: 472, Training loss: 1.385086, Validation loss: 1.3657, lr: 0.0000\n",
      "Epoch: 473, Training loss: 1.375015, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 474, Training loss: 1.360469, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 475, Training loss: 1.376813, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 476, Training loss: 1.388669, Validation loss: 1.4249, lr: 0.0000\n",
      "Epoch: 477, Training loss: 1.364424, Validation loss: 1.3871, lr: 0.0000\n",
      "Epoch: 478, Training loss: 1.369327, Validation loss: 1.3710, lr: 0.0000\n",
      "Epoch: 479, Training loss: 1.371852, Validation loss: 1.3710, lr: 0.0000\n",
      "Epoch: 480, Training loss: 1.365875, Validation loss: 1.3710, lr: 0.0000\n",
      "Epoch: 481, Training loss: 1.394864, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 482, Training loss: 1.372777, Validation loss: 1.3788, lr: 0.0000\n",
      "Epoch: 483, Training loss: 1.368141, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 484, Training loss: 1.373762, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 485, Training loss: 1.374275, Validation loss: 1.3878, lr: 0.0000\n",
      "Epoch: 486, Training loss: 1.390050, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 487, Training loss: 1.363599, Validation loss: 1.3760, lr: 0.0000\n",
      "Epoch: 488, Training loss: 1.364786, Validation loss: 1.3786, lr: 0.0000\n",
      "Epoch: 489, Training loss: 1.361190, Validation loss: 1.3736, lr: 0.0000\n",
      "Epoch: 490, Training loss: 1.353721, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 491, Training loss: 1.360415, Validation loss: 1.3570, lr: 0.0000\n",
      "Epoch: 492, Training loss: 1.365745, Validation loss: 1.3884, lr: 0.0000\n",
      "Epoch: 493, Training loss: 1.341433, Validation loss: 1.3662, lr: 0.0000\n",
      "Epoch: 494, Training loss: 1.395977, Validation loss: 1.3768, lr: 0.0000\n",
      "Epoch: 495, Training loss: 1.360829, Validation loss: 1.3798, lr: 0.0000\n",
      "Epoch: 496, Training loss: 1.372507, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 497, Training loss: 1.368411, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 498, Training loss: 1.375320, Validation loss: 1.3670, lr: 0.0000\n",
      "Epoch: 499, Training loss: 1.386215, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 500, Training loss: 1.381182, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 501, Training loss: 1.350016, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 502, Training loss: 1.355073, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 503, Training loss: 1.385744, Validation loss: 1.3789, lr: 0.0000\n",
      "Epoch: 504, Training loss: 1.342374, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 505, Training loss: 1.382106, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 506, Training loss: 1.375532, Validation loss: 1.3774, lr: 0.0000\n",
      "Epoch: 507, Training loss: 1.373696, Validation loss: 1.3796, lr: 0.0000\n",
      "Epoch: 508, Training loss: 1.387652, Validation loss: 1.3698, lr: 0.0000\n",
      "Epoch: 509, Training loss: 1.362881, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 510, Training loss: 1.366804, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 511, Training loss: 1.359281, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 512, Training loss: 1.390947, Validation loss: 1.3759, lr: 0.0000\n",
      "Epoch: 513, Training loss: 1.386716, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 514, Training loss: 1.363790, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 515, Training loss: 1.375315, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 516, Training loss: 1.385017, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 517, Training loss: 1.369476, Validation loss: 1.3743, lr: 0.0000\n",
      "Epoch: 518, Training loss: 1.396095, Validation loss: 1.3775, lr: 0.0000\n",
      "Epoch: 519, Training loss: 1.402380, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 520, Training loss: 1.360886, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 521, Training loss: 1.434411, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 522, Training loss: 1.365385, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 523, Training loss: 1.371730, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 524, Training loss: 1.353342, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 525, Training loss: 1.401377, Validation loss: 1.3750, lr: 0.0000\n",
      "Epoch: 526, Training loss: 1.371423, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 527, Training loss: 1.359399, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 528, Training loss: 1.382402, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 529, Training loss: 1.390634, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 530, Training loss: 1.360120, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 531, Training loss: 1.379555, Validation loss: 1.3738, lr: 0.0000\n",
      "Epoch: 532, Training loss: 1.352121, Validation loss: 1.3648, lr: 0.0000\n",
      "Epoch: 533, Training loss: 1.374042, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 534, Training loss: 1.358301, Validation loss: 1.3711, lr: 0.0000\n",
      "Epoch: 535, Training loss: 1.404220, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 536, Training loss: 1.364803, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 537, Training loss: 1.364425, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 538, Training loss: 1.369886, Validation loss: 1.3809, lr: 0.0000\n",
      "Epoch: 539, Training loss: 1.374161, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 540, Training loss: 1.392198, Validation loss: 1.3764, lr: 0.0000\n",
      "Epoch: 541, Training loss: 1.366246, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 542, Training loss: 1.362330, Validation loss: 1.3677, lr: 0.0000\n",
      "Epoch: 543, Training loss: 1.419405, Validation loss: 1.3874, lr: 0.0000\n",
      "Epoch: 544, Training loss: 1.372433, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 545, Training loss: 1.367208, Validation loss: 1.3696, lr: 0.0000\n",
      "Epoch: 546, Training loss: 1.364248, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 547, Training loss: 1.380698, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 548, Training loss: 1.363647, Validation loss: 1.3750, lr: 0.0000\n",
      "Epoch: 549, Training loss: 1.373847, Validation loss: 1.3727, lr: 0.0000\n",
      "Epoch: 550, Training loss: 1.348818, Validation loss: 1.3708, lr: 0.0000\n",
      "Epoch: 551, Training loss: 1.381811, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 552, Training loss: 1.356479, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 553, Training loss: 1.359802, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 554, Training loss: 1.367217, Validation loss: 1.4014, lr: 0.0000\n",
      "Epoch: 555, Training loss: 1.371714, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 556, Training loss: 1.418693, Validation loss: 1.3795, lr: 0.0000\n",
      "Epoch: 557, Training loss: 1.359316, Validation loss: 1.3675, lr: 0.0000\n",
      "Epoch: 558, Training loss: 1.372500, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 559, Training loss: 1.361162, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 560, Training loss: 1.393025, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 561, Training loss: 1.385483, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 562, Training loss: 1.359467, Validation loss: 1.3877, lr: 0.0000\n",
      "Epoch: 563, Training loss: 1.373418, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 564, Training loss: 1.379923, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 565, Training loss: 1.362384, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 566, Training loss: 1.410791, Validation loss: 1.3744, lr: 0.0000\n",
      "Epoch: 567, Training loss: 1.384642, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 568, Training loss: 1.356042, Validation loss: 1.3890, lr: 0.0000\n",
      "Epoch: 569, Training loss: 1.350374, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 570, Training loss: 1.410297, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 571, Training loss: 1.405125, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 572, Training loss: 1.389197, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 573, Training loss: 1.384601, Validation loss: 1.3802, lr: 0.0000\n",
      "Epoch: 574, Training loss: 1.383910, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 575, Training loss: 1.387115, Validation loss: 1.3741, lr: 0.0000\n",
      "Epoch: 576, Training loss: 1.380851, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 577, Training loss: 1.382921, Validation loss: 1.3903, lr: 0.0000\n",
      "Epoch: 578, Training loss: 1.366610, Validation loss: 1.3676, lr: 0.0000\n",
      "Epoch: 579, Training loss: 1.373937, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 580, Training loss: 1.364253, Validation loss: 1.3522, lr: 0.0000\n",
      "Epoch: 581, Training loss: 1.367357, Validation loss: 1.3798, lr: 0.0000\n",
      "Epoch: 582, Training loss: 1.379982, Validation loss: 1.3742, lr: 0.0000\n",
      "Epoch: 583, Training loss: 1.373458, Validation loss: 1.3802, lr: 0.0000\n",
      "Epoch: 584, Training loss: 1.372523, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 585, Training loss: 1.359654, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 586, Training loss: 1.364363, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 587, Training loss: 1.363960, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 588, Training loss: 1.372586, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 589, Training loss: 1.358027, Validation loss: 1.4066, lr: 0.0000\n",
      "Epoch: 590, Training loss: 1.362807, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 591, Training loss: 1.395058, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 592, Training loss: 1.435786, Validation loss: 1.3660, lr: 0.0000\n",
      "Epoch: 593, Training loss: 1.376417, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 594, Training loss: 1.357301, Validation loss: 1.3786, lr: 0.0000\n",
      "Epoch: 595, Training loss: 1.374350, Validation loss: 1.3762, lr: 0.0000\n",
      "Epoch: 596, Training loss: 1.402344, Validation loss: 1.3746, lr: 0.0000\n",
      "Epoch: 597, Training loss: 1.377804, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 598, Training loss: 1.361896, Validation loss: 1.4227, lr: 0.0000\n",
      "Epoch: 599, Training loss: 1.370610, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 600, Training loss: 1.361395, Validation loss: 1.3755, lr: 0.0000\n",
      "Epoch: 601, Training loss: 1.363927, Validation loss: 1.3794, lr: 0.0000\n",
      "Epoch: 602, Training loss: 1.368495, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 603, Training loss: 1.376029, Validation loss: 1.3792, lr: 0.0000\n",
      "Epoch: 604, Training loss: 1.371012, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 605, Training loss: 1.371677, Validation loss: 1.3885, lr: 0.0000\n",
      "Epoch: 606, Training loss: 1.372013, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 607, Training loss: 1.368021, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 608, Training loss: 1.403597, Validation loss: 1.3724, lr: 0.0000\n",
      "Epoch: 609, Training loss: 1.375938, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 610, Training loss: 1.373442, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 611, Training loss: 1.394253, Validation loss: 1.3721, lr: 0.0000\n",
      "Epoch: 612, Training loss: 1.374657, Validation loss: 1.3728, lr: 0.0000\n",
      "Epoch: 613, Training loss: 1.375293, Validation loss: 1.4570, lr: 0.0000\n",
      "Epoch: 614, Training loss: 1.372204, Validation loss: 1.3802, lr: 0.0000\n",
      "Epoch: 615, Training loss: 1.374278, Validation loss: 1.3783, lr: 0.0000\n",
      "Epoch: 616, Training loss: 1.367008, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 617, Training loss: 1.362521, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 618, Training loss: 1.368411, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 619, Training loss: 1.354787, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 620, Training loss: 1.383979, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 621, Training loss: 1.355763, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 622, Training loss: 1.381804, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 623, Training loss: 1.447067, Validation loss: 1.3711, lr: 0.0000\n",
      "Epoch: 624, Training loss: 1.376778, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 625, Training loss: 1.369822, Validation loss: 1.3789, lr: 0.0000\n",
      "Epoch: 626, Training loss: 1.360574, Validation loss: 1.3578, lr: 0.0000\n",
      "Epoch: 627, Training loss: 1.404487, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 628, Training loss: 1.360494, Validation loss: 1.3783, lr: 0.0000\n",
      "Epoch: 629, Training loss: 1.360417, Validation loss: 1.3776, lr: 0.0000\n",
      "Epoch: 630, Training loss: 1.367645, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 631, Training loss: 1.376868, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 632, Training loss: 1.373892, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 633, Training loss: 1.367718, Validation loss: 1.3982, lr: 0.0000\n",
      "Epoch: 634, Training loss: 1.363975, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 635, Training loss: 1.368715, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 636, Training loss: 1.371808, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 637, Training loss: 1.366989, Validation loss: 1.3799, lr: 0.0000\n",
      "Epoch: 638, Training loss: 1.372499, Validation loss: 1.3740, lr: 0.0000\n",
      "Epoch: 639, Training loss: 1.374997, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 640, Training loss: 1.380256, Validation loss: 1.3894, lr: 0.0000\n",
      "Epoch: 641, Training loss: 1.359607, Validation loss: 1.3740, lr: 0.0000\n",
      "Epoch: 642, Training loss: 1.409820, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 643, Training loss: 1.394699, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 644, Training loss: 1.427540, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 645, Training loss: 1.387541, Validation loss: 1.3802, lr: 0.0000\n",
      "Epoch: 646, Training loss: 1.376855, Validation loss: 1.3602, lr: 0.0000\n",
      "Epoch: 647, Training loss: 1.378783, Validation loss: 1.3777, lr: 0.0000\n",
      "Epoch: 648, Training loss: 1.363523, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 649, Training loss: 1.373026, Validation loss: 1.3538, lr: 0.0000\n",
      "Epoch: 650, Training loss: 1.359614, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 651, Training loss: 1.376034, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 652, Training loss: 1.360563, Validation loss: 1.4012, lr: 0.0000\n",
      "Epoch: 653, Training loss: 1.350587, Validation loss: 1.3733, lr: 0.0000\n",
      "Epoch: 654, Training loss: 1.355012, Validation loss: 1.3769, lr: 0.0000\n",
      "Epoch: 655, Training loss: 1.364791, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 656, Training loss: 1.369944, Validation loss: 1.3795, lr: 0.0000\n",
      "Epoch: 657, Training loss: 1.396892, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 658, Training loss: 1.368406, Validation loss: 1.3872, lr: 0.0000\n",
      "Epoch: 659, Training loss: 1.372223, Validation loss: 1.3557, lr: 0.0000\n",
      "Epoch: 660, Training loss: 1.381560, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 661, Training loss: 1.383087, Validation loss: 1.3786, lr: 0.0000\n",
      "Epoch: 662, Training loss: 1.376692, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 663, Training loss: 1.402248, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 664, Training loss: 1.361402, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 665, Training loss: 1.346316, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 666, Training loss: 1.359660, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 667, Training loss: 1.386056, Validation loss: 1.3778, lr: 0.0000\n",
      "Epoch: 668, Training loss: 1.370377, Validation loss: 1.3882, lr: 0.0000\n",
      "Epoch: 669, Training loss: 1.369863, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 670, Training loss: 1.369359, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 671, Training loss: 1.380748, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 672, Training loss: 1.365256, Validation loss: 1.3791, lr: 0.0000\n",
      "Epoch: 673, Training loss: 1.399994, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 674, Training loss: 1.369305, Validation loss: 1.3776, lr: 0.0000\n",
      "Epoch: 675, Training loss: 1.365216, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 676, Training loss: 1.375226, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 677, Training loss: 1.364137, Validation loss: 1.3875, lr: 0.0000\n",
      "Epoch: 678, Training loss: 1.347290, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 679, Training loss: 1.381906, Validation loss: 1.3775, lr: 0.0000\n",
      "Epoch: 680, Training loss: 1.372454, Validation loss: 1.3792, lr: 0.0000\n",
      "Epoch: 681, Training loss: 1.379602, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 682, Training loss: 1.370619, Validation loss: 1.3765, lr: 0.0000\n",
      "Epoch: 683, Training loss: 1.381423, Validation loss: 1.3881, lr: 0.0000\n",
      "Epoch: 684, Training loss: 1.366913, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 685, Training loss: 1.359016, Validation loss: 1.3849, lr: 0.0000\n",
      " *och: 686, Training loss: 1.389508, Validation loss: 1.3404, lr: 0.0000\n",
      "Epoch: 687, Training loss: 1.376870, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 688, Training loss: 1.380418, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 689, Training loss: 1.375281, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 690, Training loss: 1.362005, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 691, Training loss: 1.374308, Validation loss: 1.3787, lr: 0.0000\n",
      "Epoch: 692, Training loss: 1.370444, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 693, Training loss: 1.391599, Validation loss: 1.3786, lr: 0.0000\n",
      "Epoch: 694, Training loss: 1.359964, Validation loss: 1.3751, lr: 0.0000\n",
      "Epoch: 695, Training loss: 1.379078, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 696, Training loss: 1.366850, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 697, Training loss: 1.365651, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 698, Training loss: 1.369688, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 699, Training loss: 1.369664, Validation loss: 1.3888, lr: 0.0000\n",
      "Epoch: 700, Training loss: 1.383950, Validation loss: 1.3916, lr: 0.0000\n",
      "Epoch: 701, Training loss: 1.375115, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 702, Training loss: 1.385682, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 703, Training loss: 1.406070, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 704, Training loss: 1.375368, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 705, Training loss: 1.357309, Validation loss: 1.3737, lr: 0.0000\n",
      "Epoch: 706, Training loss: 1.446572, Validation loss: 1.3758, lr: 0.0000\n",
      "Epoch: 707, Training loss: 1.380858, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 708, Training loss: 1.374941, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 709, Training loss: 1.365020, Validation loss: 1.3688, lr: 0.0000\n",
      "Epoch: 710, Training loss: 1.355062, Validation loss: 1.3783, lr: 0.0000\n",
      "Epoch: 711, Training loss: 1.429574, Validation loss: 1.3795, lr: 0.0000\n",
      "Epoch: 712, Training loss: 1.383070, Validation loss: 1.3680, lr: 0.0000\n",
      "Epoch: 713, Training loss: 1.378604, Validation loss: 1.3771, lr: 0.0000\n",
      "Epoch: 714, Training loss: 1.375474, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 715, Training loss: 1.395296, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 716, Training loss: 1.348681, Validation loss: 1.3749, lr: 0.0000\n",
      "Epoch: 717, Training loss: 1.380973, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 718, Training loss: 1.359577, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 719, Training loss: 1.369785, Validation loss: 1.3724, lr: 0.0000\n",
      "Epoch: 720, Training loss: 1.383044, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 721, Training loss: 1.374173, Validation loss: 1.3971, lr: 0.0000\n",
      "Epoch: 722, Training loss: 1.361296, Validation loss: 1.3710, lr: 0.0000\n",
      "Epoch: 723, Training loss: 1.372340, Validation loss: 1.3745, lr: 0.0000\n",
      "Epoch: 724, Training loss: 1.363653, Validation loss: 1.3794, lr: 0.0000\n",
      "Epoch: 725, Training loss: 1.389519, Validation loss: 1.3596, lr: 0.0000\n",
      "Epoch: 726, Training loss: 1.408371, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 727, Training loss: 1.366391, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 728, Training loss: 1.381492, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 729, Training loss: 1.370955, Validation loss: 1.3720, lr: 0.0000\n",
      "Epoch: 730, Training loss: 1.356123, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 731, Training loss: 1.374288, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 732, Training loss: 1.370364, Validation loss: 1.3908, lr: 0.0000\n",
      "Epoch: 733, Training loss: 1.375030, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 734, Training loss: 1.386900, Validation loss: 1.3749, lr: 0.0000\n",
      "Epoch: 735, Training loss: 1.365277, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 736, Training loss: 1.369002, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 737, Training loss: 1.371334, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 738, Training loss: 1.380729, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 739, Training loss: 1.367585, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 740, Training loss: 1.394858, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 741, Training loss: 1.366937, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 742, Training loss: 1.382189, Validation loss: 1.3768, lr: 0.0000\n",
      "Epoch: 743, Training loss: 1.382814, Validation loss: 1.3733, lr: 0.0000\n",
      "Epoch: 744, Training loss: 1.388503, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 745, Training loss: 1.396035, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 746, Training loss: 1.383645, Validation loss: 1.3754, lr: 0.0000\n",
      "Epoch: 747, Training loss: 1.374979, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 748, Training loss: 1.366445, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 749, Training loss: 1.366034, Validation loss: 1.3914, lr: 0.0000\n",
      "Epoch: 750, Training loss: 1.375209, Validation loss: 1.3876, lr: 0.0000\n",
      "Epoch: 751, Training loss: 1.391613, Validation loss: 1.3877, lr: 0.0000\n",
      "Epoch: 752, Training loss: 1.387381, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 753, Training loss: 1.380902, Validation loss: 1.3651, lr: 0.0000\n",
      "Epoch: 754, Training loss: 1.382472, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 755, Training loss: 1.372196, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 756, Training loss: 1.365002, Validation loss: 1.3731, lr: 0.0000\n",
      "Epoch: 757, Training loss: 1.383972, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 758, Training loss: 1.373751, Validation loss: 1.3961, lr: 0.0000\n",
      "Epoch: 759, Training loss: 1.384488, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 760, Training loss: 1.379796, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 761, Training loss: 1.362051, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 762, Training loss: 1.383748, Validation loss: 1.3459, lr: 0.0000\n",
      "Epoch: 763, Training loss: 1.399148, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 764, Training loss: 1.368020, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 765, Training loss: 1.383000, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 766, Training loss: 1.374124, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 767, Training loss: 1.376344, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 768, Training loss: 1.357602, Validation loss: 1.3672, lr: 0.0000\n",
      "Epoch: 769, Training loss: 1.374652, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 770, Training loss: 1.386801, Validation loss: 1.3611, lr: 0.0000\n",
      "Epoch: 771, Training loss: 1.358740, Validation loss: 1.3684, lr: 0.0000\n",
      "Epoch: 772, Training loss: 1.367285, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 773, Training loss: 1.375721, Validation loss: 1.3753, lr: 0.0000\n",
      "Epoch: 774, Training loss: 1.367615, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 775, Training loss: 1.382406, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 776, Training loss: 1.363094, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 777, Training loss: 1.372553, Validation loss: 1.3798, lr: 0.0000\n",
      "Epoch: 778, Training loss: 1.386570, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 779, Training loss: 1.342596, Validation loss: 1.3657, lr: 0.0000\n",
      "Epoch: 780, Training loss: 1.367810, Validation loss: 1.3748, lr: 0.0000\n",
      "Epoch: 781, Training loss: 1.367536, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 782, Training loss: 1.372542, Validation loss: 1.3786, lr: 0.0000\n",
      "Epoch: 783, Training loss: 1.384189, Validation loss: 1.3744, lr: 0.0000\n",
      "Epoch: 784, Training loss: 1.386273, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 785, Training loss: 1.363540, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 786, Training loss: 1.374876, Validation loss: 1.3872, lr: 0.0000\n",
      "Epoch: 787, Training loss: 1.402068, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 788, Training loss: 1.372516, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 789, Training loss: 1.379683, Validation loss: 1.3800, lr: 0.0000\n",
      "Epoch: 790, Training loss: 1.369000, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 791, Training loss: 1.369875, Validation loss: 1.3946, lr: 0.0000\n",
      "Epoch: 792, Training loss: 1.376062, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 793, Training loss: 1.363990, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 794, Training loss: 1.378284, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 795, Training loss: 1.361679, Validation loss: 1.3790, lr: 0.0000\n",
      "Epoch: 796, Training loss: 1.364156, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 797, Training loss: 1.367330, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 798, Training loss: 1.370989, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 799, Training loss: 1.370971, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 800, Training loss: 1.381520, Validation loss: 1.3664, lr: 0.0000\n",
      "Epoch: 801, Training loss: 1.378278, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 802, Training loss: 1.413163, Validation loss: 1.3781, lr: 0.0000\n",
      "Epoch: 803, Training loss: 1.374049, Validation loss: 1.3771, lr: 0.0000\n",
      "Epoch: 804, Training loss: 1.377304, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 805, Training loss: 1.369792, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 806, Training loss: 1.373150, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 807, Training loss: 1.368947, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 808, Training loss: 1.389209, Validation loss: 1.3585, lr: 0.0000\n",
      "Epoch: 809, Training loss: 1.377919, Validation loss: 1.3799, lr: 0.0000\n",
      "Epoch: 810, Training loss: 1.376928, Validation loss: 1.3597, lr: 0.0000\n",
      "Epoch: 811, Training loss: 1.382224, Validation loss: 1.3876, lr: 0.0000\n",
      "Epoch: 812, Training loss: 1.390803, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 813, Training loss: 1.363388, Validation loss: 1.3796, lr: 0.0000\n",
      "Epoch: 814, Training loss: 1.367946, Validation loss: 1.3735, lr: 0.0000\n",
      "Epoch: 815, Training loss: 1.379460, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 816, Training loss: 1.366057, Validation loss: 1.3803, lr: 0.0000\n",
      "Epoch: 817, Training loss: 1.372332, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 818, Training loss: 1.366494, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 819, Training loss: 1.382124, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 820, Training loss: 1.459785, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 821, Training loss: 1.376964, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 822, Training loss: 1.390928, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 823, Training loss: 1.368346, Validation loss: 1.3785, lr: 0.0000\n",
      "Epoch: 824, Training loss: 1.380506, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 825, Training loss: 1.385989, Validation loss: 1.3850, lr: 0.0000\n",
      " *och: 826, Training loss: 1.373165, Validation loss: 1.3194, lr: 0.0000\n",
      "Epoch: 827, Training loss: 1.359147, Validation loss: 1.3797, lr: 0.0000\n",
      "Epoch: 828, Training loss: 1.346183, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 829, Training loss: 1.363347, Validation loss: 1.3799, lr: 0.0000\n",
      "Epoch: 830, Training loss: 1.372333, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 831, Training loss: 1.387366, Validation loss: 1.3784, lr: 0.0000\n",
      "Epoch: 832, Training loss: 1.372302, Validation loss: 1.3730, lr: 0.0000\n",
      "Epoch: 833, Training loss: 1.364146, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 834, Training loss: 1.370669, Validation loss: 1.3649, lr: 0.0000\n",
      "Epoch: 835, Training loss: 1.398915, Validation loss: 1.3871, lr: 0.0000\n",
      "Epoch: 836, Training loss: 1.363420, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 837, Training loss: 1.371760, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 838, Training loss: 1.374928, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 839, Training loss: 1.368115, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 840, Training loss: 1.373854, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 841, Training loss: 1.380432, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 842, Training loss: 1.393662, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 843, Training loss: 1.363605, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 844, Training loss: 1.373374, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 845, Training loss: 1.382045, Validation loss: 1.3738, lr: 0.0000\n",
      "Epoch: 846, Training loss: 1.364011, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 847, Training loss: 1.372648, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 848, Training loss: 1.363168, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 849, Training loss: 1.365701, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 850, Training loss: 1.371726, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 851, Training loss: 1.406693, Validation loss: 1.3882, lr: 0.0000\n",
      "Epoch: 852, Training loss: 1.397263, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 853, Training loss: 1.375357, Validation loss: 1.3766, lr: 0.0000\n",
      "Epoch: 854, Training loss: 1.388107, Validation loss: 1.3757, lr: 0.0000\n",
      "Epoch: 855, Training loss: 1.369029, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 856, Training loss: 1.369809, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 857, Training loss: 1.359167, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 858, Training loss: 1.361790, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 859, Training loss: 1.348244, Validation loss: 1.3880, lr: 0.0000\n",
      "Epoch: 860, Training loss: 1.362466, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 861, Training loss: 1.379053, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 862, Training loss: 1.377839, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 863, Training loss: 1.435220, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 864, Training loss: 1.351255, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 865, Training loss: 1.358181, Validation loss: 1.3722, lr: 0.0000\n",
      "Epoch: 866, Training loss: 1.358661, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 867, Training loss: 1.375538, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 868, Training loss: 1.379475, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 869, Training loss: 1.373277, Validation loss: 1.3382, lr: 0.0000\n",
      "Epoch: 870, Training loss: 1.343683, Validation loss: 1.3730, lr: 0.0000\n",
      "Epoch: 871, Training loss: 1.385359, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 872, Training loss: 1.377605, Validation loss: 1.3781, lr: 0.0000\n",
      "Epoch: 873, Training loss: 1.444012, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 874, Training loss: 1.380975, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 875, Training loss: 1.373049, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 876, Training loss: 1.396178, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 877, Training loss: 1.364710, Validation loss: 1.3796, lr: 0.0000\n",
      "Epoch: 878, Training loss: 1.370184, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 879, Training loss: 1.372986, Validation loss: 1.3781, lr: 0.0000\n",
      "Epoch: 880, Training loss: 1.381765, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 881, Training loss: 1.391977, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 882, Training loss: 1.386078, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 883, Training loss: 1.364145, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 884, Training loss: 1.369900, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 885, Training loss: 1.368677, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 886, Training loss: 1.379160, Validation loss: 1.3793, lr: 0.0000\n",
      "Epoch: 887, Training loss: 1.376758, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 888, Training loss: 1.407186, Validation loss: 1.3789, lr: 0.0000\n",
      "Epoch: 889, Training loss: 1.367826, Validation loss: 1.3637, lr: 0.0000\n",
      "Epoch: 890, Training loss: 1.374877, Validation loss: 1.3918, lr: 0.0000\n",
      "Epoch: 891, Training loss: 1.371497, Validation loss: 1.3888, lr: 0.0000\n",
      "Epoch: 892, Training loss: 1.360735, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 893, Training loss: 1.378797, Validation loss: 1.3771, lr: 0.0000\n",
      "Epoch: 894, Training loss: 1.368512, Validation loss: 1.3705, lr: 0.0000\n",
      "Epoch: 895, Training loss: 1.365740, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 896, Training loss: 1.392267, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 897, Training loss: 1.381789, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 898, Training loss: 1.366645, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 899, Training loss: 1.374851, Validation loss: 1.3783, lr: 0.0000\n",
      "Epoch: 900, Training loss: 1.389043, Validation loss: 1.3745, lr: 0.0000\n",
      "Epoch: 901, Training loss: 1.367751, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 902, Training loss: 1.378036, Validation loss: 1.3794, lr: 0.0000\n",
      "Epoch: 903, Training loss: 1.393913, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 904, Training loss: 1.389689, Validation loss: 1.3697, lr: 0.0000\n",
      "Epoch: 905, Training loss: 1.375846, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 906, Training loss: 1.385937, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 907, Training loss: 1.389678, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 908, Training loss: 1.366347, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 909, Training loss: 1.364341, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 910, Training loss: 1.366925, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 911, Training loss: 1.514980, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 912, Training loss: 1.374636, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 913, Training loss: 1.374740, Validation loss: 1.3629, lr: 0.0000\n",
      "Epoch: 914, Training loss: 1.381059, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 915, Training loss: 1.376245, Validation loss: 1.3650, lr: 0.0000\n",
      "Epoch: 916, Training loss: 1.370418, Validation loss: 1.3688, lr: 0.0000\n",
      "Epoch: 917, Training loss: 1.368522, Validation loss: 1.3949, lr: 0.0000\n",
      "Epoch: 918, Training loss: 1.379694, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 919, Training loss: 1.372293, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 920, Training loss: 1.378028, Validation loss: 1.4142, lr: 0.0000\n",
      "Epoch: 921, Training loss: 1.371271, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 922, Training loss: 1.375062, Validation loss: 1.3468, lr: 0.0000\n",
      "Epoch: 923, Training loss: 1.362549, Validation loss: 1.3713, lr: 0.0000\n",
      "Epoch: 924, Training loss: 1.391486, Validation loss: 1.3744, lr: 0.0000\n",
      "Epoch: 925, Training loss: 1.384962, Validation loss: 1.3767, lr: 0.0000\n",
      "Epoch: 926, Training loss: 1.389003, Validation loss: 1.4038, lr: 0.0000\n",
      "Epoch: 927, Training loss: 1.369760, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 928, Training loss: 1.392398, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 929, Training loss: 1.371285, Validation loss: 1.3722, lr: 0.0000\n",
      "Epoch: 930, Training loss: 1.383579, Validation loss: 1.3725, lr: 0.0000\n",
      "Epoch: 931, Training loss: 1.354542, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 932, Training loss: 1.370458, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 933, Training loss: 1.380338, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 934, Training loss: 1.360937, Validation loss: 1.3793, lr: 0.0000\n",
      "Epoch: 935, Training loss: 1.361559, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 936, Training loss: 1.370529, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 937, Training loss: 1.367504, Validation loss: 1.3791, lr: 0.0000\n",
      "Epoch: 938, Training loss: 1.387248, Validation loss: 1.3729, lr: 0.0000\n",
      "Epoch: 939, Training loss: 1.385728, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 940, Training loss: 1.398892, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 941, Training loss: 1.367171, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 942, Training loss: 1.377798, Validation loss: 1.3879, lr: 0.0000\n",
      "Epoch: 943, Training loss: 1.368972, Validation loss: 1.3727, lr: 0.0000\n",
      "Epoch: 944, Training loss: 1.375779, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 945, Training loss: 1.366576, Validation loss: 1.3724, lr: 0.0000\n",
      "Epoch: 946, Training loss: 1.392556, Validation loss: 1.3733, lr: 0.0000\n",
      "Epoch: 947, Training loss: 1.373155, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 948, Training loss: 1.369169, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 949, Training loss: 1.367195, Validation loss: 1.3706, lr: 0.0000\n",
      "Epoch: 950, Training loss: 1.373142, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 951, Training loss: 1.367508, Validation loss: 1.3769, lr: 0.0000\n",
      "Epoch: 952, Training loss: 1.367498, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 953, Training loss: 1.355809, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 954, Training loss: 1.388156, Validation loss: 1.3793, lr: 0.0000\n",
      "Epoch: 955, Training loss: 1.372801, Validation loss: 1.3660, lr: 0.0000\n",
      "Epoch: 956, Training loss: 1.369524, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 957, Training loss: 1.382425, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 958, Training loss: 1.367228, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 959, Training loss: 1.378072, Validation loss: 1.3766, lr: 0.0000\n",
      "Epoch: 960, Training loss: 1.356021, Validation loss: 1.3750, lr: 0.0000\n",
      "Epoch: 961, Training loss: 1.386036, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 962, Training loss: 1.372448, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 963, Training loss: 1.377085, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 964, Training loss: 1.350238, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 965, Training loss: 1.399723, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 966, Training loss: 1.376388, Validation loss: 1.4276, lr: 0.0000\n",
      "Epoch: 967, Training loss: 1.387355, Validation loss: 1.3754, lr: 0.0000\n",
      "Epoch: 968, Training loss: 1.359798, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 969, Training loss: 1.371784, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 970, Training loss: 1.365985, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 971, Training loss: 1.374127, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 972, Training loss: 1.370886, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 973, Training loss: 1.362292, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 974, Training loss: 1.371229, Validation loss: 1.3871, lr: 0.0000\n",
      "Epoch: 975, Training loss: 1.372134, Validation loss: 1.3878, lr: 0.0000\n",
      "Epoch: 976, Training loss: 1.354240, Validation loss: 1.3788, lr: 0.0000\n",
      "Epoch: 977, Training loss: 1.365615, Validation loss: 1.3776, lr: 0.0000\n",
      "Epoch: 978, Training loss: 1.387545, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 979, Training loss: 1.364334, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 980, Training loss: 1.370149, Validation loss: 1.3663, lr: 0.0000\n",
      "Epoch: 981, Training loss: 1.363462, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 982, Training loss: 1.364048, Validation loss: 1.3764, lr: 0.0000\n",
      "Epoch: 983, Training loss: 1.362731, Validation loss: 1.3677, lr: 0.0000\n",
      "Epoch: 984, Training loss: 1.358266, Validation loss: 1.3776, lr: 0.0000\n",
      "Epoch: 985, Training loss: 1.368270, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 986, Training loss: 1.386412, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 987, Training loss: 1.365095, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 988, Training loss: 1.381486, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 989, Training loss: 1.360263, Validation loss: 1.3656, lr: 0.0000\n",
      "Epoch: 990, Training loss: 1.389142, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 991, Training loss: 1.382457, Validation loss: 1.3534, lr: 0.0000\n",
      "Epoch: 992, Training loss: 1.364824, Validation loss: 1.3802, lr: 0.0000\n",
      "Epoch: 993, Training loss: 1.366399, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 994, Training loss: 1.370607, Validation loss: 1.3919, lr: 0.0000\n",
      "Epoch: 995, Training loss: 1.408487, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 996, Training loss: 1.364312, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 997, Training loss: 1.385811, Validation loss: 1.3666, lr: 0.0000\n",
      "Epoch: 998, Training loss: 1.385270, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 999, Training loss: 1.378760, Validation loss: 1.3858, lr: 0.0000\n",
      "Final test loss: 1.3823\n",
      "=== Run 10/10 ===\n",
      "\n",
      "---- Settings: \n",
      "\n",
      "epochs : 1000\n",
      "hidden_channels : [32]\n",
      "out_channels : 10\n",
      "inner_product_features : False\n",
      "batch_size : 64\n",
      "lr : 0.01\n",
      "momentum : 0.9\n",
      "dropout : 0.0\n",
      "batch_norm : batch_norm\n",
      "bias : True\n",
      "order : 2\n",
      "diffusion : True\n",
      "frac_sampled_nb : -1\n",
      "include_positions : False\n",
      "include_self : True\n",
      "vec_norm : False\n",
      "emb_norm : False\n",
      "seed : 0\n",
      "dim_signal : 100\n",
      "dim_emb : 100\n",
      "n_sampled_nb : -1\n",
      "\n",
      "---- Number of features to pass to the MLP:  1010100\n",
      "---- Total number of parameters:  32323627\n",
      "\n",
      "Using device cuda:0\n",
      "\n",
      "---- Training network ...\n",
      "\n",
      "---- Timestamp: 20250614-062710\n",
      "\n",
      " *och: 0, Training loss: 1.548922, Validation loss: 1.3718, lr: 0.0100\n",
      "Epoch: 1, Training loss: 1.456529, Validation loss: 1.4750, lr: 0.0100\n",
      "Epoch: 2, Training loss: 1.399469, Validation loss: 1.3754, lr: 0.0100\n",
      "Epoch: 3, Training loss: 1.371312, Validation loss: 1.3800, lr: 0.0100\n",
      "Epoch: 4, Training loss: 1.425058, Validation loss: 1.3833, lr: 0.0100\n",
      "Epoch: 5, Training loss: 1.417268, Validation loss: 1.3832, lr: 0.0100\n",
      " *och: 6, Training loss: 1.379886, Validation loss: 1.3475, lr: 0.0100\n",
      "Epoch: 7, Training loss: 1.371875, Validation loss: 1.3909, lr: 0.0100\n",
      "Epoch: 8, Training loss: 1.416763, Validation loss: 1.3890, lr: 0.0100\n",
      "Epoch: 9, Training loss: 1.387341, Validation loss: 1.3831, lr: 0.0100\n",
      "Epoch: 10, Training loss: 1.393672, Validation loss: 1.3833, lr: 0.0100\n",
      "Epoch: 11, Training loss: 1.388547, Validation loss: 1.4516, lr: 0.0100\n",
      "Epoch: 12, Training loss: 1.400479, Validation loss: 1.3826, lr: 0.0100\n",
      "Epoch: 13, Training loss: 1.394990, Validation loss: 1.3780, lr: 0.0100\n",
      "Epoch: 14, Training loss: 1.383298, Validation loss: 1.3987, lr: 0.0010\n",
      "Epoch: 15, Training loss: 1.385538, Validation loss: 1.3564, lr: 0.0010\n",
      "Epoch: 16, Training loss: 1.390033, Validation loss: 1.3761, lr: 0.0010\n",
      "Epoch: 17, Training loss: 1.379898, Validation loss: 1.3816, lr: 0.0010\n",
      "Epoch: 18, Training loss: 1.369901, Validation loss: 1.3901, lr: 0.0010\n",
      "Epoch: 19, Training loss: 1.412358, Validation loss: 1.3869, lr: 0.0010\n",
      "Epoch: 20, Training loss: 1.384178, Validation loss: 1.3889, lr: 0.0010\n",
      "Epoch: 21, Training loss: 1.377405, Validation loss: 1.3865, lr: 0.0010\n",
      "Epoch: 22, Training loss: 1.396910, Validation loss: 1.4071, lr: 0.0010\n",
      "Epoch: 23, Training loss: 1.380170, Validation loss: 1.3848, lr: 0.0010\n",
      "Epoch: 24, Training loss: 1.380516, Validation loss: 1.3862, lr: 0.0010\n",
      "Epoch: 25, Training loss: 1.372542, Validation loss: 1.3826, lr: 0.0010\n",
      "Epoch: 26, Training loss: 1.400576, Validation loss: 1.3863, lr: 0.0010\n",
      "Epoch: 27, Training loss: 1.363409, Validation loss: 1.3840, lr: 0.0010\n",
      "Epoch: 28, Training loss: 1.393445, Validation loss: 1.3857, lr: 0.0010\n",
      "Epoch: 29, Training loss: 1.378117, Validation loss: 1.3840, lr: 0.0010\n",
      "Epoch: 30, Training loss: 1.376253, Validation loss: 1.3830, lr: 0.0010\n",
      "Epoch: 31, Training loss: 1.370905, Validation loss: 1.3877, lr: 0.0010\n",
      "Epoch: 32, Training loss: 1.357690, Validation loss: 1.3871, lr: 0.0010\n",
      "Epoch: 33, Training loss: 1.397525, Validation loss: 1.3754, lr: 0.0010\n",
      "Epoch: 34, Training loss: 1.396177, Validation loss: 1.3797, lr: 0.0010\n",
      "Epoch: 35, Training loss: 1.379813, Validation loss: 1.3835, lr: 0.0010\n",
      "Epoch: 36, Training loss: 1.378501, Validation loss: 1.3860, lr: 0.0010\n",
      "Epoch: 37, Training loss: 1.373626, Validation loss: 1.3820, lr: 0.0010\n",
      "Epoch: 38, Training loss: 1.396853, Validation loss: 1.3763, lr: 0.0010\n",
      "Epoch: 39, Training loss: 1.379578, Validation loss: 1.3735, lr: 0.0010\n",
      "Epoch: 40, Training loss: 1.383208, Validation loss: 1.3856, lr: 0.0010\n",
      "Epoch: 41, Training loss: 1.393242, Validation loss: 1.3837, lr: 0.0010\n",
      "Epoch: 42, Training loss: 1.374175, Validation loss: 1.3749, lr: 0.0010\n",
      "Epoch: 43, Training loss: 1.370777, Validation loss: 1.3826, lr: 0.0001\n",
      "Epoch: 44, Training loss: 1.386364, Validation loss: 1.3804, lr: 0.0001\n",
      "Epoch: 45, Training loss: 1.380817, Validation loss: 1.3802, lr: 0.0001\n",
      "Epoch: 46, Training loss: 1.391697, Validation loss: 1.3696, lr: 0.0001\n",
      " *och: 47, Training loss: 1.403939, Validation loss: 1.3395, lr: 0.0001\n",
      "Epoch: 48, Training loss: 1.384209, Validation loss: 1.3877, lr: 0.0001\n",
      "Epoch: 49, Training loss: 1.391375, Validation loss: 1.3863, lr: 0.0001\n",
      "Epoch: 50, Training loss: 1.364592, Validation loss: 1.3842, lr: 0.0001\n",
      "Epoch: 51, Training loss: 1.379573, Validation loss: 1.3860, lr: 0.0001\n",
      "Epoch: 52, Training loss: 1.383976, Validation loss: 1.3851, lr: 0.0001\n",
      "Epoch: 53, Training loss: 1.388221, Validation loss: 1.3850, lr: 0.0001\n",
      "Epoch: 54, Training loss: 1.378140, Validation loss: 1.3772, lr: 0.0000\n",
      "Epoch: 55, Training loss: 1.362991, Validation loss: 1.5249, lr: 0.0000\n",
      "Epoch: 56, Training loss: 1.391080, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 57, Training loss: 1.375276, Validation loss: 1.3733, lr: 0.0000\n",
      "Epoch: 58, Training loss: 1.425976, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 59, Training loss: 1.383140, Validation loss: 1.3650, lr: 0.0000\n",
      "Epoch: 60, Training loss: 1.369767, Validation loss: 1.3882, lr: 0.0000\n",
      "Epoch: 61, Training loss: 1.365421, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 62, Training loss: 1.384023, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 63, Training loss: 1.385617, Validation loss: 1.3872, lr: 0.0000\n",
      "Epoch: 64, Training loss: 1.382577, Validation loss: 1.3888, lr: 0.0000\n",
      "Epoch: 65, Training loss: 1.389693, Validation loss: 1.3908, lr: 0.0000\n",
      "Epoch: 66, Training loss: 1.380223, Validation loss: 1.3749, lr: 0.0000\n",
      "Epoch: 67, Training loss: 1.376653, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 68, Training loss: 1.375094, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 69, Training loss: 1.381527, Validation loss: 1.3871, lr: 0.0000\n",
      "Epoch: 70, Training loss: 1.397722, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 71, Training loss: 1.397628, Validation loss: 1.3750, lr: 0.0000\n",
      "Epoch: 72, Training loss: 1.369319, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 73, Training loss: 1.372390, Validation loss: 1.3875, lr: 0.0000\n",
      "Epoch: 74, Training loss: 1.385442, Validation loss: 1.3957, lr: 0.0000\n",
      "Epoch: 75, Training loss: 1.376557, Validation loss: 1.3797, lr: 0.0000\n",
      "Epoch: 76, Training loss: 1.388779, Validation loss: 1.5139, lr: 0.0000\n",
      "Epoch: 77, Training loss: 1.477256, Validation loss: 1.3960, lr: 0.0000\n",
      "Epoch: 78, Training loss: 1.384047, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 79, Training loss: 1.370098, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 80, Training loss: 1.382639, Validation loss: 1.3778, lr: 0.0000\n",
      "Epoch: 81, Training loss: 1.384618, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 82, Training loss: 1.388705, Validation loss: 1.3628, lr: 0.0000\n",
      "Epoch: 83, Training loss: 1.388747, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 84, Training loss: 1.405152, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 85, Training loss: 1.387447, Validation loss: 1.3791, lr: 0.0000\n",
      "Epoch: 86, Training loss: 1.376725, Validation loss: 1.3734, lr: 0.0000\n",
      "Epoch: 87, Training loss: 1.390596, Validation loss: 1.3889, lr: 0.0000\n",
      "Epoch: 88, Training loss: 1.404452, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 89, Training loss: 1.380162, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 90, Training loss: 1.392180, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 91, Training loss: 1.377035, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 92, Training loss: 1.408348, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 93, Training loss: 1.405385, Validation loss: 1.3667, lr: 0.0000\n",
      "Epoch: 94, Training loss: 1.375345, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 95, Training loss: 1.370354, Validation loss: 1.3875, lr: 0.0000\n",
      "Epoch: 96, Training loss: 1.387906, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 97, Training loss: 1.379365, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 98, Training loss: 1.381384, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 99, Training loss: 1.384951, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 100, Training loss: 1.379562, Validation loss: 1.3727, lr: 0.0000\n",
      "Epoch: 101, Training loss: 1.450535, Validation loss: 1.3871, lr: 0.0000\n",
      "Epoch: 102, Training loss: 1.403598, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 103, Training loss: 1.392024, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 104, Training loss: 1.390033, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 105, Training loss: 1.371434, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 106, Training loss: 1.380301, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 107, Training loss: 1.381868, Validation loss: 1.3744, lr: 0.0000\n",
      "Epoch: 108, Training loss: 1.372139, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 109, Training loss: 1.385275, Validation loss: 1.3875, lr: 0.0000\n",
      "Epoch: 110, Training loss: 1.374557, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 111, Training loss: 1.378602, Validation loss: 1.3756, lr: 0.0000\n",
      "Epoch: 112, Training loss: 1.403393, Validation loss: 1.3873, lr: 0.0000\n",
      "Epoch: 113, Training loss: 1.400428, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 114, Training loss: 1.442868, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 115, Training loss: 1.388498, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 116, Training loss: 1.383108, Validation loss: 1.3666, lr: 0.0000\n",
      "Epoch: 117, Training loss: 1.372391, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 118, Training loss: 1.386962, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 119, Training loss: 1.378823, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 120, Training loss: 1.377443, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 121, Training loss: 1.377009, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 122, Training loss: 1.394008, Validation loss: 1.3960, lr: 0.0000\n",
      "Epoch: 123, Training loss: 1.373261, Validation loss: 1.3637, lr: 0.0000\n",
      "Epoch: 124, Training loss: 1.364554, Validation loss: 1.3792, lr: 0.0000\n",
      "Epoch: 125, Training loss: 1.380227, Validation loss: 1.3877, lr: 0.0000\n",
      "Epoch: 126, Training loss: 1.369914, Validation loss: 1.3771, lr: 0.0000\n",
      "Epoch: 127, Training loss: 1.386269, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 128, Training loss: 1.374024, Validation loss: 1.3893, lr: 0.0000\n",
      "Epoch: 129, Training loss: 1.376986, Validation loss: 1.3908, lr: 0.0000\n",
      "Epoch: 130, Training loss: 1.361672, Validation loss: 1.3833, lr: 0.0000\n",
      " *och: 131, Training loss: 1.381440, Validation loss: 1.3374, lr: 0.0000\n",
      "Epoch: 132, Training loss: 1.379880, Validation loss: 1.3733, lr: 0.0000\n",
      "Epoch: 133, Training loss: 1.372174, Validation loss: 1.3902, lr: 0.0000\n",
      "Epoch: 134, Training loss: 1.369767, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 135, Training loss: 1.375863, Validation loss: 1.3880, lr: 0.0000\n",
      "Epoch: 136, Training loss: 1.392630, Validation loss: 1.3879, lr: 0.0000\n",
      "Epoch: 137, Training loss: 1.376466, Validation loss: 1.3715, lr: 0.0000\n",
      "Epoch: 138, Training loss: 1.383362, Validation loss: 1.3703, lr: 0.0000\n",
      "Epoch: 139, Training loss: 1.405868, Validation loss: 1.3785, lr: 0.0000\n",
      "Epoch: 140, Training loss: 1.429419, Validation loss: 1.3886, lr: 0.0000\n",
      "Epoch: 141, Training loss: 1.370746, Validation loss: 1.3799, lr: 0.0000\n",
      "Epoch: 142, Training loss: 1.377004, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 143, Training loss: 1.381106, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 144, Training loss: 1.379530, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 145, Training loss: 1.396472, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 146, Training loss: 1.376577, Validation loss: 1.3895, lr: 0.0000\n",
      "Epoch: 147, Training loss: 1.395179, Validation loss: 1.3882, lr: 0.0000\n",
      "Epoch: 148, Training loss: 1.379211, Validation loss: 1.3767, lr: 0.0000\n",
      "Epoch: 149, Training loss: 1.375949, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 150, Training loss: 1.399488, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 151, Training loss: 1.365297, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 152, Training loss: 1.397058, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 153, Training loss: 1.375844, Validation loss: 1.3784, lr: 0.0000\n",
      "Epoch: 154, Training loss: 1.389965, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 155, Training loss: 1.383237, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 156, Training loss: 1.398265, Validation loss: 1.3794, lr: 0.0000\n",
      "Epoch: 157, Training loss: 1.387834, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 158, Training loss: 1.376889, Validation loss: 1.3874, lr: 0.0000\n",
      "Epoch: 159, Training loss: 1.369313, Validation loss: 1.3797, lr: 0.0000\n",
      "Epoch: 160, Training loss: 1.401531, Validation loss: 1.3795, lr: 0.0000\n",
      "Epoch: 161, Training loss: 1.365148, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 162, Training loss: 1.385039, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 163, Training loss: 1.376697, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 164, Training loss: 1.386091, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 165, Training loss: 1.400533, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 166, Training loss: 1.387151, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 167, Training loss: 1.399680, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 168, Training loss: 1.385082, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 169, Training loss: 1.379558, Validation loss: 1.3793, lr: 0.0000\n",
      "Epoch: 170, Training loss: 1.390221, Validation loss: 4.0137, lr: 0.0000\n",
      "Epoch: 171, Training loss: 1.381957, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 172, Training loss: 1.378970, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 173, Training loss: 1.371889, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 174, Training loss: 1.378845, Validation loss: 1.3885, lr: 0.0000\n",
      "Epoch: 175, Training loss: 1.421221, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 176, Training loss: 1.391221, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 177, Training loss: 1.385075, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 178, Training loss: 1.393103, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 179, Training loss: 1.381486, Validation loss: 1.3747, lr: 0.0000\n",
      "Epoch: 180, Training loss: 1.367489, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 181, Training loss: 1.388964, Validation loss: 1.3793, lr: 0.0000\n",
      "Epoch: 182, Training loss: 1.496903, Validation loss: 1.3684, lr: 0.0000\n",
      "Epoch: 183, Training loss: 1.401267, Validation loss: 1.3682, lr: 0.0000\n",
      "Epoch: 184, Training loss: 1.380293, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 185, Training loss: 1.412626, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 186, Training loss: 1.379849, Validation loss: 1.3950, lr: 0.0000\n",
      "Epoch: 187, Training loss: 1.389922, Validation loss: 1.3672, lr: 0.0000\n",
      "Epoch: 188, Training loss: 1.404923, Validation loss: 1.3657, lr: 0.0000\n",
      "Epoch: 189, Training loss: 1.392513, Validation loss: 1.3746, lr: 0.0000\n",
      "Epoch: 190, Training loss: 1.383646, Validation loss: 1.3593, lr: 0.0000\n",
      "Epoch: 191, Training loss: 1.384027, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 192, Training loss: 1.371686, Validation loss: 1.3901, lr: 0.0000\n",
      "Epoch: 193, Training loss: 1.373111, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 194, Training loss: 1.385317, Validation loss: 1.3874, lr: 0.0000\n",
      "Epoch: 195, Training loss: 1.387240, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 196, Training loss: 1.385485, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 197, Training loss: 1.378961, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 198, Training loss: 1.383760, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 199, Training loss: 1.359314, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 200, Training loss: 1.374030, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 201, Training loss: 1.371297, Validation loss: 1.3888, lr: 0.0000\n",
      "Epoch: 202, Training loss: 1.383534, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 203, Training loss: 1.379435, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 204, Training loss: 1.378175, Validation loss: 1.3878, lr: 0.0000\n",
      "Epoch: 205, Training loss: 1.387167, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 206, Training loss: 1.380313, Validation loss: 1.3742, lr: 0.0000\n",
      "Epoch: 207, Training loss: 1.389385, Validation loss: 1.3494, lr: 0.0000\n",
      "Epoch: 208, Training loss: 1.368391, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 209, Training loss: 1.380948, Validation loss: 1.3691, lr: 0.0000\n",
      "Epoch: 210, Training loss: 1.383506, Validation loss: 1.3763, lr: 0.0000\n",
      "Epoch: 211, Training loss: 1.384713, Validation loss: 1.3758, lr: 0.0000\n",
      "Epoch: 212, Training loss: 1.383364, Validation loss: 1.4130, lr: 0.0000\n",
      "Epoch: 213, Training loss: 1.399905, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 214, Training loss: 1.385482, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 215, Training loss: 1.373061, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 216, Training loss: 1.387818, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 217, Training loss: 1.373313, Validation loss: 1.3679, lr: 0.0000\n",
      "Epoch: 218, Training loss: 1.373261, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 219, Training loss: 1.390719, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 220, Training loss: 1.400816, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 221, Training loss: 1.381092, Validation loss: 1.3872, lr: 0.0000\n",
      "Epoch: 222, Training loss: 1.376561, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 223, Training loss: 1.383588, Validation loss: 1.4007, lr: 0.0000\n",
      "Epoch: 224, Training loss: 1.377416, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 225, Training loss: 1.380640, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 226, Training loss: 1.373262, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 227, Training loss: 1.367441, Validation loss: 1.4327, lr: 0.0000\n",
      "Epoch: 228, Training loss: 1.375222, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 229, Training loss: 1.383488, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 230, Training loss: 1.376166, Validation loss: 1.3719, lr: 0.0000\n",
      "Epoch: 231, Training loss: 1.369493, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 232, Training loss: 1.370245, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 233, Training loss: 1.436718, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 234, Training loss: 1.388567, Validation loss: 1.3703, lr: 0.0000\n",
      "Epoch: 235, Training loss: 1.385031, Validation loss: 1.3740, lr: 0.0000\n",
      "Epoch: 236, Training loss: 1.383304, Validation loss: 1.4531, lr: 0.0000\n",
      "Epoch: 237, Training loss: 1.384173, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 238, Training loss: 1.393076, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 239, Training loss: 1.385718, Validation loss: 1.3910, lr: 0.0000\n",
      "Epoch: 240, Training loss: 1.391021, Validation loss: 1.3883, lr: 0.0000\n",
      "Epoch: 241, Training loss: 1.366527, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 242, Training loss: 1.377332, Validation loss: 1.3605, lr: 0.0000\n",
      "Epoch: 243, Training loss: 1.376136, Validation loss: 1.3934, lr: 0.0000\n",
      "Epoch: 244, Training loss: 1.388897, Validation loss: 1.3809, lr: 0.0000\n",
      "Epoch: 245, Training loss: 1.383273, Validation loss: 1.3894, lr: 0.0000\n",
      "Epoch: 246, Training loss: 1.377237, Validation loss: 1.3871, lr: 0.0000\n",
      "Epoch: 247, Training loss: 1.374540, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 248, Training loss: 1.382795, Validation loss: 1.3707, lr: 0.0000\n",
      "Epoch: 249, Training loss: 1.361724, Validation loss: 1.3871, lr: 0.0000\n",
      "Epoch: 250, Training loss: 1.378283, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 251, Training loss: 1.387956, Validation loss: 1.3680, lr: 0.0000\n",
      "Epoch: 252, Training loss: 1.384103, Validation loss: 1.3699, lr: 0.0000\n",
      "Epoch: 253, Training loss: 1.372141, Validation loss: 1.3624, lr: 0.0000\n",
      "Epoch: 254, Training loss: 1.377403, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 255, Training loss: 1.385564, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 256, Training loss: 1.379896, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 257, Training loss: 1.365232, Validation loss: 1.3679, lr: 0.0000\n",
      "Epoch: 258, Training loss: 1.392324, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 259, Training loss: 1.365273, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 260, Training loss: 1.381755, Validation loss: 1.3873, lr: 0.0000\n",
      "Epoch: 261, Training loss: 1.373740, Validation loss: 1.3876, lr: 0.0000\n",
      "Epoch: 262, Training loss: 1.403562, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 263, Training loss: 1.371809, Validation loss: 1.3880, lr: 0.0000\n",
      "Epoch: 264, Training loss: 1.377762, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 265, Training loss: 1.373854, Validation loss: 1.3747, lr: 0.0000\n",
      "Epoch: 266, Training loss: 1.395577, Validation loss: 1.3762, lr: 0.0000\n",
      "Epoch: 267, Training loss: 1.371988, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 268, Training loss: 1.382606, Validation loss: 1.3940, lr: 0.0000\n",
      "Epoch: 269, Training loss: 1.381483, Validation loss: 1.3976, lr: 0.0000\n",
      "Epoch: 270, Training loss: 1.389880, Validation loss: 2.1325, lr: 0.0000\n",
      "Epoch: 271, Training loss: 1.379112, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 272, Training loss: 1.371925, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 273, Training loss: 1.420724, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 274, Training loss: 1.383921, Validation loss: 1.3871, lr: 0.0000\n",
      "Epoch: 275, Training loss: 1.389722, Validation loss: 1.3875, lr: 0.0000\n",
      "Epoch: 276, Training loss: 1.385883, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 277, Training loss: 1.372705, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 278, Training loss: 1.386808, Validation loss: 1.3681, lr: 0.0000\n",
      "Epoch: 279, Training loss: 1.383612, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 280, Training loss: 1.359075, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 281, Training loss: 1.394735, Validation loss: 1.3686, lr: 0.0000\n",
      "Epoch: 282, Training loss: 1.375471, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 283, Training loss: 1.382291, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 284, Training loss: 1.374155, Validation loss: 1.3926, lr: 0.0000\n",
      "Epoch: 285, Training loss: 1.375658, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 286, Training loss: 1.377556, Validation loss: 1.3799, lr: 0.0000\n",
      "Epoch: 287, Training loss: 1.389799, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 288, Training loss: 1.374373, Validation loss: 1.3769, lr: 0.0000\n",
      "Epoch: 289, Training loss: 1.380613, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 290, Training loss: 1.373766, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 291, Training loss: 1.371530, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 292, Training loss: 1.400641, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 293, Training loss: 1.379086, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 294, Training loss: 1.383475, Validation loss: 1.3688, lr: 0.0000\n",
      "Epoch: 295, Training loss: 1.373071, Validation loss: 1.3585, lr: 0.0000\n",
      "Epoch: 296, Training loss: 1.388680, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 297, Training loss: 1.382240, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 298, Training loss: 1.382483, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 299, Training loss: 1.383735, Validation loss: 1.3775, lr: 0.0000\n",
      "Epoch: 300, Training loss: 1.386246, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 301, Training loss: 1.482208, Validation loss: 1.3871, lr: 0.0000\n",
      "Epoch: 302, Training loss: 1.372896, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 303, Training loss: 1.365063, Validation loss: 1.3524, lr: 0.0000\n",
      "Epoch: 304, Training loss: 1.383688, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 305, Training loss: 1.377924, Validation loss: 1.3790, lr: 0.0000\n",
      "Epoch: 306, Training loss: 1.374198, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 307, Training loss: 1.372642, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 308, Training loss: 1.413243, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 309, Training loss: 1.385472, Validation loss: 1.3752, lr: 0.0000\n",
      "Epoch: 310, Training loss: 1.391519, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 311, Training loss: 1.377502, Validation loss: 1.3772, lr: 0.0000\n",
      "Epoch: 312, Training loss: 1.373238, Validation loss: 1.3872, lr: 0.0000\n",
      "Epoch: 313, Training loss: 1.389150, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 314, Training loss: 1.385050, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 315, Training loss: 1.387934, Validation loss: 1.3755, lr: 0.0000\n",
      "Epoch: 316, Training loss: 1.370553, Validation loss: 1.3560, lr: 0.0000\n",
      "Epoch: 317, Training loss: 1.385963, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 318, Training loss: 1.379522, Validation loss: 1.3637, lr: 0.0000\n",
      "Epoch: 319, Training loss: 1.387619, Validation loss: 1.3879, lr: 0.0000\n",
      "Epoch: 320, Training loss: 1.381994, Validation loss: 1.3707, lr: 0.0000\n",
      "Epoch: 321, Training loss: 1.389026, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 322, Training loss: 1.384208, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 323, Training loss: 1.374289, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 324, Training loss: 1.391712, Validation loss: 1.3669, lr: 0.0000\n",
      "Epoch: 325, Training loss: 1.374209, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 326, Training loss: 1.392541, Validation loss: 1.3882, lr: 0.0000\n",
      "Epoch: 327, Training loss: 1.380564, Validation loss: 1.4031, lr: 0.0000\n",
      "Epoch: 328, Training loss: 1.381677, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 329, Training loss: 1.377599, Validation loss: 1.3898, lr: 0.0000\n",
      "Epoch: 330, Training loss: 1.390321, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 331, Training loss: 1.374683, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 332, Training loss: 1.389992, Validation loss: 1.3791, lr: 0.0000\n",
      "Epoch: 333, Training loss: 1.403636, Validation loss: 1.3886, lr: 0.0000\n",
      "Epoch: 334, Training loss: 1.377692, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 335, Training loss: 1.389682, Validation loss: 1.3878, lr: 0.0000\n",
      "Epoch: 336, Training loss: 1.373362, Validation loss: 1.3879, lr: 0.0000\n",
      "Epoch: 337, Training loss: 1.382967, Validation loss: 1.3910, lr: 0.0000\n",
      "Epoch: 338, Training loss: 1.398498, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 339, Training loss: 1.378059, Validation loss: 1.3756, lr: 0.0000\n",
      "Epoch: 340, Training loss: 1.386028, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 341, Training loss: 1.365808, Validation loss: 1.3886, lr: 0.0000\n",
      "Epoch: 342, Training loss: 1.399036, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 343, Training loss: 1.372402, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 344, Training loss: 1.370148, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 345, Training loss: 1.393497, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 346, Training loss: 1.380541, Validation loss: 1.3900, lr: 0.0000\n",
      "Epoch: 347, Training loss: 1.384825, Validation loss: 1.3872, lr: 0.0000\n",
      "Epoch: 348, Training loss: 1.361954, Validation loss: 1.3843, lr: 0.0000\n",
      " *och: 349, Training loss: 1.365463, Validation loss: 1.3307, lr: 0.0000\n",
      "Epoch: 350, Training loss: 1.379077, Validation loss: 1.3715, lr: 0.0000\n",
      "Epoch: 351, Training loss: 1.377387, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 352, Training loss: 1.395472, Validation loss: 1.3723, lr: 0.0000\n",
      "Epoch: 353, Training loss: 1.402059, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 354, Training loss: 1.378372, Validation loss: 1.3873, lr: 0.0000\n",
      "Epoch: 355, Training loss: 1.391797, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 356, Training loss: 1.418877, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 357, Training loss: 1.427152, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 358, Training loss: 1.394008, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 359, Training loss: 1.380910, Validation loss: 1.3948, lr: 0.0000\n",
      "Epoch: 360, Training loss: 1.378291, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 361, Training loss: 1.385310, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 362, Training loss: 1.373760, Validation loss: 1.4042, lr: 0.0000\n",
      "Epoch: 363, Training loss: 1.374142, Validation loss: 1.3800, lr: 0.0000\n",
      "Epoch: 364, Training loss: 1.381385, Validation loss: 1.3783, lr: 0.0000\n",
      "Epoch: 365, Training loss: 1.368567, Validation loss: 1.3788, lr: 0.0000\n",
      "Epoch: 366, Training loss: 1.381376, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 367, Training loss: 1.383477, Validation loss: 1.3705, lr: 0.0000\n",
      "Epoch: 368, Training loss: 1.385482, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 369, Training loss: 1.391633, Validation loss: 1.3658, lr: 0.0000\n",
      "Epoch: 370, Training loss: 1.373916, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 371, Training loss: 1.393866, Validation loss: 1.3654, lr: 0.0000\n",
      "Epoch: 372, Training loss: 1.383098, Validation loss: 1.3874, lr: 0.0000\n",
      "Epoch: 373, Training loss: 1.390175, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 374, Training loss: 1.381093, Validation loss: 1.3796, lr: 0.0000\n",
      "Epoch: 375, Training loss: 1.379503, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 376, Training loss: 1.378710, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 377, Training loss: 1.371330, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 378, Training loss: 1.371045, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 379, Training loss: 1.415212, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 380, Training loss: 1.368498, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 381, Training loss: 1.389032, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 382, Training loss: 1.401849, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 383, Training loss: 1.378994, Validation loss: 1.3772, lr: 0.0000\n",
      "Epoch: 384, Training loss: 1.374129, Validation loss: 1.3621, lr: 0.0000\n",
      "Epoch: 385, Training loss: 1.369583, Validation loss: 1.3789, lr: 0.0000\n",
      "Epoch: 386, Training loss: 1.375211, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 387, Training loss: 1.373160, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 388, Training loss: 1.378251, Validation loss: 1.3879, lr: 0.0000\n",
      "Epoch: 389, Training loss: 1.395837, Validation loss: 1.3900, lr: 0.0000\n",
      "Epoch: 390, Training loss: 1.382296, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 391, Training loss: 1.389814, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 392, Training loss: 1.369642, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 393, Training loss: 1.365760, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 394, Training loss: 1.368736, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 395, Training loss: 1.367524, Validation loss: 1.3597, lr: 0.0000\n",
      "Epoch: 396, Training loss: 1.382779, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 397, Training loss: 1.431613, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 398, Training loss: 1.385937, Validation loss: 1.3672, lr: 0.0000\n",
      "Epoch: 399, Training loss: 1.382791, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 400, Training loss: 1.376030, Validation loss: 1.3796, lr: 0.0000\n",
      "Epoch: 401, Training loss: 1.393447, Validation loss: 1.3781, lr: 0.0000\n",
      "Epoch: 402, Training loss: 1.392005, Validation loss: 1.3879, lr: 0.0000\n",
      "Epoch: 403, Training loss: 1.411000, Validation loss: 1.3775, lr: 0.0000\n",
      "Epoch: 404, Training loss: 1.404824, Validation loss: 1.3711, lr: 0.0000\n",
      "Epoch: 405, Training loss: 1.381429, Validation loss: 1.3882, lr: 0.0000\n",
      "Epoch: 406, Training loss: 1.391419, Validation loss: 1.3512, lr: 0.0000\n",
      "Epoch: 407, Training loss: 1.371884, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 408, Training loss: 1.378927, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 409, Training loss: 1.388341, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 410, Training loss: 1.397739, Validation loss: 1.3769, lr: 0.0000\n",
      "Epoch: 411, Training loss: 1.386024, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 412, Training loss: 1.376416, Validation loss: 1.3956, lr: 0.0000\n",
      "Epoch: 413, Training loss: 1.384339, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 414, Training loss: 1.387973, Validation loss: 1.4124, lr: 0.0000\n",
      "Epoch: 415, Training loss: 1.414307, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 416, Training loss: 1.386502, Validation loss: 1.3672, lr: 0.0000\n",
      "Epoch: 417, Training loss: 1.382796, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 418, Training loss: 1.376505, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 419, Training loss: 1.381480, Validation loss: 1.3886, lr: 0.0000\n",
      "Epoch: 420, Training loss: 1.374742, Validation loss: 1.3798, lr: 0.0000\n",
      "Epoch: 421, Training loss: 1.381588, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 422, Training loss: 1.386417, Validation loss: 1.3583, lr: 0.0000\n",
      "Epoch: 423, Training loss: 1.365551, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 424, Training loss: 1.393945, Validation loss: 1.3740, lr: 0.0000\n",
      "Epoch: 425, Training loss: 1.377204, Validation loss: 1.3545, lr: 0.0000\n",
      "Epoch: 426, Training loss: 1.385992, Validation loss: 1.3923, lr: 0.0000\n",
      "Epoch: 427, Training loss: 1.384826, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 428, Training loss: 1.379181, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 429, Training loss: 1.389090, Validation loss: 1.3879, lr: 0.0000\n",
      "Epoch: 430, Training loss: 1.385349, Validation loss: 1.3935, lr: 0.0000\n",
      "Epoch: 431, Training loss: 1.373156, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 432, Training loss: 1.392837, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 433, Training loss: 1.382574, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 434, Training loss: 1.398161, Validation loss: 1.3451, lr: 0.0000\n",
      "Epoch: 435, Training loss: 1.373831, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 436, Training loss: 1.385001, Validation loss: 1.3731, lr: 0.0000\n",
      "Epoch: 437, Training loss: 1.375583, Validation loss: 1.3609, lr: 0.0000\n",
      "Epoch: 438, Training loss: 1.374810, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 439, Training loss: 1.404785, Validation loss: 1.3599, lr: 0.0000\n",
      "Epoch: 440, Training loss: 1.390540, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 441, Training loss: 1.368676, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 442, Training loss: 1.380954, Validation loss: 1.3668, lr: 0.0000\n",
      "Epoch: 443, Training loss: 1.400336, Validation loss: 1.3735, lr: 0.0000\n",
      "Epoch: 444, Training loss: 1.377130, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 445, Training loss: 1.450705, Validation loss: 1.3886, lr: 0.0000\n",
      "Epoch: 446, Training loss: 1.411046, Validation loss: 1.3882, lr: 0.0000\n",
      "Epoch: 447, Training loss: 1.394589, Validation loss: 1.3873, lr: 0.0000\n",
      "Epoch: 448, Training loss: 1.379334, Validation loss: 1.3559, lr: 0.0000\n",
      "Epoch: 449, Training loss: 1.368778, Validation loss: 1.3680, lr: 0.0000\n",
      "Epoch: 450, Training loss: 1.367718, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 451, Training loss: 1.380312, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 452, Training loss: 1.374487, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 453, Training loss: 1.402544, Validation loss: 1.4178, lr: 0.0000\n",
      "Epoch: 454, Training loss: 1.366596, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 455, Training loss: 1.380380, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 456, Training loss: 1.383959, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 457, Training loss: 1.378236, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 458, Training loss: 1.388431, Validation loss: 1.3792, lr: 0.0000\n",
      "Epoch: 459, Training loss: 1.374292, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 460, Training loss: 1.386900, Validation loss: 1.3875, lr: 0.0000\n",
      "Epoch: 461, Training loss: 1.370414, Validation loss: 1.3886, lr: 0.0000\n",
      "Epoch: 462, Training loss: 1.393071, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 463, Training loss: 1.379503, Validation loss: 1.3899, lr: 0.0000\n",
      "Epoch: 464, Training loss: 1.393347, Validation loss: 1.3727, lr: 0.0000\n",
      "Epoch: 465, Training loss: 1.369956, Validation loss: 1.3726, lr: 0.0000\n",
      "Epoch: 466, Training loss: 1.371146, Validation loss: 1.3969, lr: 0.0000\n",
      "Epoch: 467, Training loss: 1.394171, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 468, Training loss: 1.380051, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 469, Training loss: 1.383195, Validation loss: 1.3636, lr: 0.0000\n",
      "Epoch: 470, Training loss: 1.374827, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 471, Training loss: 1.384364, Validation loss: 1.3926, lr: 0.0000\n",
      "Epoch: 472, Training loss: 1.371065, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 473, Training loss: 1.379909, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 474, Training loss: 1.374002, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 475, Training loss: 1.396347, Validation loss: 1.3608, lr: 0.0000\n",
      "Epoch: 476, Training loss: 1.383399, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 477, Training loss: 1.371917, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 478, Training loss: 1.378749, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 479, Training loss: 1.381642, Validation loss: 1.3770, lr: 0.0000\n",
      "Epoch: 480, Training loss: 1.369705, Validation loss: 1.3789, lr: 0.0000\n",
      "Epoch: 481, Training loss: 1.385411, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 482, Training loss: 1.379328, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 483, Training loss: 1.402421, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 484, Training loss: 1.381601, Validation loss: 1.3875, lr: 0.0000\n",
      "Epoch: 485, Training loss: 1.369455, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 486, Training loss: 1.384390, Validation loss: 1.3761, lr: 0.0000\n",
      "Epoch: 487, Training loss: 1.397703, Validation loss: 1.3939, lr: 0.0000\n",
      "Epoch: 488, Training loss: 1.367297, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 489, Training loss: 1.380027, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 490, Training loss: 1.382776, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 491, Training loss: 1.390959, Validation loss: 1.3725, lr: 0.0000\n",
      "Epoch: 492, Training loss: 1.395466, Validation loss: 1.3783, lr: 0.0000\n",
      "Epoch: 493, Training loss: 1.368500, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 494, Training loss: 1.392374, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 495, Training loss: 1.393942, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 496, Training loss: 1.384510, Validation loss: 1.3917, lr: 0.0000\n",
      "Epoch: 497, Training loss: 1.384898, Validation loss: 1.3708, lr: 0.0000\n",
      "Epoch: 498, Training loss: 1.385317, Validation loss: 1.3944, lr: 0.0000\n",
      "Epoch: 499, Training loss: 1.380573, Validation loss: 1.3896, lr: 0.0000\n",
      "Epoch: 500, Training loss: 1.392064, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 501, Training loss: 1.390049, Validation loss: 1.3764, lr: 0.0000\n",
      "Epoch: 502, Training loss: 1.372127, Validation loss: 1.3754, lr: 0.0000\n",
      "Epoch: 503, Training loss: 1.375709, Validation loss: 1.3944, lr: 0.0000\n",
      "Epoch: 504, Training loss: 1.376687, Validation loss: 1.3928, lr: 0.0000\n",
      "Epoch: 505, Training loss: 1.389057, Validation loss: 1.3923, lr: 0.0000\n",
      "Epoch: 506, Training loss: 1.417619, Validation loss: 1.3737, lr: 0.0000\n",
      "Epoch: 507, Training loss: 1.374065, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 508, Training loss: 1.452724, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 509, Training loss: 1.371454, Validation loss: 1.3795, lr: 0.0000\n",
      "Epoch: 510, Training loss: 1.424160, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 511, Training loss: 1.507576, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 512, Training loss: 1.382758, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 513, Training loss: 1.380341, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 514, Training loss: 1.397224, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 515, Training loss: 1.371613, Validation loss: 1.3758, lr: 0.0000\n",
      "Epoch: 516, Training loss: 1.374136, Validation loss: 1.3912, lr: 0.0000\n",
      "Epoch: 517, Training loss: 1.389655, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 518, Training loss: 1.386285, Validation loss: 1.3790, lr: 0.0000\n",
      "Epoch: 519, Training loss: 1.376150, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 520, Training loss: 1.399468, Validation loss: 1.3873, lr: 0.0000\n",
      "Epoch: 521, Training loss: 1.379588, Validation loss: 1.4786, lr: 0.0000\n",
      "Epoch: 522, Training loss: 1.379382, Validation loss: 1.3750, lr: 0.0000\n",
      "Epoch: 523, Training loss: 1.377324, Validation loss: 1.4069, lr: 0.0000\n",
      "Epoch: 524, Training loss: 1.395931, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 525, Training loss: 1.383139, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 526, Training loss: 1.389018, Validation loss: 1.3879, lr: 0.0000\n",
      "Epoch: 527, Training loss: 1.380008, Validation loss: 1.3872, lr: 0.0000\n",
      "Epoch: 528, Training loss: 1.419386, Validation loss: 1.4428, lr: 0.0000\n",
      "Epoch: 529, Training loss: 1.370370, Validation loss: 1.3741, lr: 0.0000\n",
      "Epoch: 530, Training loss: 1.371931, Validation loss: 1.3559, lr: 0.0000\n",
      "Epoch: 531, Training loss: 1.373465, Validation loss: 1.3726, lr: 0.0000\n",
      "Epoch: 532, Training loss: 1.380224, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 533, Training loss: 1.386947, Validation loss: 1.3879, lr: 0.0000\n",
      "Epoch: 534, Training loss: 1.386368, Validation loss: 1.3722, lr: 0.0000\n",
      "Epoch: 535, Training loss: 1.373095, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 536, Training loss: 1.365623, Validation loss: 1.3565, lr: 0.0000\n",
      "Epoch: 537, Training loss: 1.395667, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 538, Training loss: 1.397436, Validation loss: 1.3435, lr: 0.0000\n",
      "Epoch: 539, Training loss: 1.376283, Validation loss: 1.3875, lr: 0.0000\n",
      "Epoch: 540, Training loss: 1.371073, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 541, Training loss: 1.366283, Validation loss: 1.3723, lr: 0.0000\n",
      "Epoch: 542, Training loss: 1.364201, Validation loss: 1.3882, lr: 0.0000\n",
      "Epoch: 543, Training loss: 1.392359, Validation loss: 1.3707, lr: 0.0000\n",
      "Epoch: 544, Training loss: 1.363370, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 545, Training loss: 1.385803, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 546, Training loss: 1.368060, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 547, Training loss: 1.367007, Validation loss: 1.3884, lr: 0.0000\n",
      "Epoch: 548, Training loss: 1.387935, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 549, Training loss: 1.376754, Validation loss: 1.3884, lr: 0.0000\n",
      "Epoch: 550, Training loss: 1.371810, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 551, Training loss: 1.374590, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 552, Training loss: 1.381777, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 553, Training loss: 1.383018, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 554, Training loss: 1.377254, Validation loss: 1.3936, lr: 0.0000\n",
      "Epoch: 555, Training loss: 1.385152, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 556, Training loss: 1.369294, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 557, Training loss: 1.380330, Validation loss: 1.3880, lr: 0.0000\n",
      "Epoch: 558, Training loss: 1.401955, Validation loss: 1.3797, lr: 0.0000\n",
      "Epoch: 559, Training loss: 1.371297, Validation loss: 1.3916, lr: 0.0000\n",
      "Epoch: 560, Training loss: 1.410968, Validation loss: 1.3691, lr: 0.0000\n",
      "Epoch: 561, Training loss: 1.393148, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 562, Training loss: 1.374608, Validation loss: 1.3730, lr: 0.0000\n",
      "Epoch: 563, Training loss: 1.385576, Validation loss: 1.3793, lr: 0.0000\n",
      "Epoch: 564, Training loss: 1.386477, Validation loss: 1.3883, lr: 0.0000\n",
      "Epoch: 565, Training loss: 1.370497, Validation loss: 1.3802, lr: 0.0000\n",
      "Epoch: 566, Training loss: 1.379137, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 567, Training loss: 1.394465, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 568, Training loss: 1.367163, Validation loss: 1.3789, lr: 0.0000\n",
      "Epoch: 569, Training loss: 1.383958, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 570, Training loss: 1.426139, Validation loss: 1.3876, lr: 0.0000\n",
      "Epoch: 571, Training loss: 1.371284, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 572, Training loss: 1.379914, Validation loss: 1.3630, lr: 0.0000\n",
      "Epoch: 573, Training loss: 1.370064, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 574, Training loss: 1.372934, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 575, Training loss: 1.381705, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 576, Training loss: 1.367935, Validation loss: 1.3793, lr: 0.0000\n",
      "Epoch: 577, Training loss: 1.369474, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 578, Training loss: 1.365822, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 579, Training loss: 1.388867, Validation loss: 1.3879, lr: 0.0000\n",
      "Epoch: 580, Training loss: 1.374419, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 581, Training loss: 1.376483, Validation loss: 1.3756, lr: 0.0000\n",
      "Epoch: 582, Training loss: 1.373995, Validation loss: 1.3884, lr: 0.0000\n",
      "Epoch: 583, Training loss: 1.371516, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 584, Training loss: 1.387786, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 585, Training loss: 1.380459, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 586, Training loss: 1.382341, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 587, Training loss: 1.398238, Validation loss: 1.3774, lr: 0.0000\n",
      "Epoch: 588, Training loss: 1.391155, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 589, Training loss: 1.390133, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 590, Training loss: 1.369887, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 591, Training loss: 1.382992, Validation loss: 1.3719, lr: 0.0000\n",
      "Epoch: 592, Training loss: 1.385583, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 593, Training loss: 1.391687, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 594, Training loss: 1.382577, Validation loss: 1.3721, lr: 0.0000\n",
      "Epoch: 595, Training loss: 1.386668, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 596, Training loss: 1.368403, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 597, Training loss: 1.376086, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 598, Training loss: 1.377063, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 599, Training loss: 1.377356, Validation loss: 1.3789, lr: 0.0000\n",
      "Epoch: 600, Training loss: 1.378547, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 601, Training loss: 1.384992, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 602, Training loss: 1.363819, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 603, Training loss: 1.375891, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 604, Training loss: 1.381409, Validation loss: 1.3765, lr: 0.0000\n",
      "Epoch: 605, Training loss: 1.371512, Validation loss: 1.3872, lr: 0.0000\n",
      "Epoch: 606, Training loss: 1.376832, Validation loss: 1.3681, lr: 0.0000\n",
      "Epoch: 607, Training loss: 1.377866, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 608, Training loss: 1.364629, Validation loss: 1.3786, lr: 0.0000\n",
      "Epoch: 609, Training loss: 1.372777, Validation loss: 1.3883, lr: 0.0000\n",
      "Epoch: 610, Training loss: 1.399370, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 611, Training loss: 1.387804, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 612, Training loss: 1.382083, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 613, Training loss: 1.388162, Validation loss: 1.3721, lr: 0.0000\n",
      "Epoch: 614, Training loss: 1.378380, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 615, Training loss: 1.372772, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 616, Training loss: 1.369844, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 617, Training loss: 1.392832, Validation loss: 1.3763, lr: 0.0000\n",
      "Epoch: 618, Training loss: 1.404844, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 619, Training loss: 1.383787, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 620, Training loss: 1.375172, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 621, Training loss: 1.373248, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 622, Training loss: 1.396972, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 623, Training loss: 1.406006, Validation loss: 1.3793, lr: 0.0000\n",
      "Epoch: 624, Training loss: 1.379895, Validation loss: 1.3712, lr: 0.0000\n",
      "Epoch: 625, Training loss: 1.380449, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 626, Training loss: 1.370406, Validation loss: 1.3586, lr: 0.0000\n",
      "Epoch: 627, Training loss: 1.380012, Validation loss: 1.3939, lr: 0.0000\n",
      "Epoch: 628, Training loss: 1.380302, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 629, Training loss: 1.373879, Validation loss: 1.3753, lr: 0.0000\n",
      "Epoch: 630, Training loss: 1.379324, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 631, Training loss: 1.393771, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 632, Training loss: 1.387320, Validation loss: 1.3690, lr: 0.0000\n",
      "Epoch: 633, Training loss: 1.364672, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 634, Training loss: 1.363636, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 635, Training loss: 1.379896, Validation loss: 1.3906, lr: 0.0000\n",
      "Epoch: 636, Training loss: 1.377731, Validation loss: 1.3901, lr: 0.0000\n",
      "Epoch: 637, Training loss: 1.400599, Validation loss: 1.3809, lr: 0.0000\n",
      "Epoch: 638, Training loss: 1.384912, Validation loss: 1.3732, lr: 0.0000\n",
      "Epoch: 639, Training loss: 1.416275, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 640, Training loss: 1.372809, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 641, Training loss: 1.380048, Validation loss: 1.3974, lr: 0.0000\n",
      "Epoch: 642, Training loss: 1.369732, Validation loss: 1.3884, lr: 0.0000\n",
      "Epoch: 643, Training loss: 1.371368, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 644, Training loss: 1.355069, Validation loss: 1.3872, lr: 0.0000\n",
      "Epoch: 645, Training loss: 1.382245, Validation loss: 1.3879, lr: 0.0000\n",
      "Epoch: 646, Training loss: 1.403690, Validation loss: 1.4654, lr: 0.0000\n",
      "Epoch: 647, Training loss: 1.370232, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 648, Training loss: 1.384518, Validation loss: 1.4080, lr: 0.0000\n",
      "Epoch: 649, Training loss: 1.371605, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 650, Training loss: 1.386503, Validation loss: 1.3786, lr: 0.0000\n",
      "Epoch: 651, Training loss: 1.382297, Validation loss: 1.3785, lr: 0.0000\n",
      "Epoch: 652, Training loss: 1.382537, Validation loss: 1.3882, lr: 0.0000\n",
      "Epoch: 653, Training loss: 1.391103, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 654, Training loss: 1.371673, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 655, Training loss: 1.370679, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 656, Training loss: 1.380574, Validation loss: 1.3726, lr: 0.0000\n",
      "Epoch: 657, Training loss: 1.382284, Validation loss: 1.3784, lr: 0.0000\n",
      "Epoch: 658, Training loss: 1.379615, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 659, Training loss: 1.408380, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 660, Training loss: 1.429711, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 661, Training loss: 1.402810, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 662, Training loss: 1.395469, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 663, Training loss: 1.377938, Validation loss: 1.3772, lr: 0.0000\n",
      "Epoch: 664, Training loss: 1.395781, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 665, Training loss: 1.377301, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 666, Training loss: 1.375124, Validation loss: 1.3702, lr: 0.0000\n",
      "Epoch: 667, Training loss: 1.366026, Validation loss: 1.3799, lr: 0.0000\n",
      "Epoch: 668, Training loss: 1.387942, Validation loss: 1.3929, lr: 0.0000\n",
      "Epoch: 669, Training loss: 1.374773, Validation loss: 1.3765, lr: 0.0000\n",
      "Epoch: 670, Training loss: 1.412771, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 671, Training loss: 1.372507, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 672, Training loss: 1.389538, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 673, Training loss: 1.371370, Validation loss: 1.3879, lr: 0.0000\n",
      "Epoch: 674, Training loss: 1.425377, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 675, Training loss: 1.377585, Validation loss: 1.3873, lr: 0.0000\n",
      "Epoch: 676, Training loss: 1.395245, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 677, Training loss: 1.376931, Validation loss: 1.3872, lr: 0.0000\n",
      "Epoch: 678, Training loss: 1.384066, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 679, Training loss: 1.382438, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 680, Training loss: 1.372596, Validation loss: 1.3750, lr: 0.0000\n",
      "Epoch: 681, Training loss: 1.370624, Validation loss: 1.3573, lr: 0.0000\n",
      "Epoch: 682, Training loss: 1.406916, Validation loss: 1.4096, lr: 0.0000\n",
      "Epoch: 683, Training loss: 1.384771, Validation loss: 1.3900, lr: 0.0000\n",
      "Epoch: 684, Training loss: 1.424547, Validation loss: 1.4527, lr: 0.0000\n",
      "Epoch: 685, Training loss: 1.403032, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 686, Training loss: 1.390755, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 687, Training loss: 1.387686, Validation loss: 1.4093, lr: 0.0000\n",
      "Epoch: 688, Training loss: 1.380147, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 689, Training loss: 1.380472, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 690, Training loss: 1.384411, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 691, Training loss: 1.393680, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 692, Training loss: 1.374168, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 693, Training loss: 1.401505, Validation loss: 1.3708, lr: 0.0000\n",
      "Epoch: 694, Training loss: 1.377378, Validation loss: 1.3736, lr: 0.0000\n",
      "Epoch: 695, Training loss: 1.386000, Validation loss: 1.3451, lr: 0.0000\n",
      "Epoch: 696, Training loss: 1.387555, Validation loss: 1.4010, lr: 0.0000\n",
      "Epoch: 697, Training loss: 1.381328, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 698, Training loss: 1.387040, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 699, Training loss: 1.386055, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 700, Training loss: 1.375919, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 701, Training loss: 1.378722, Validation loss: 1.3765, lr: 0.0000\n",
      "Epoch: 702, Training loss: 1.380395, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 703, Training loss: 1.394448, Validation loss: 1.3746, lr: 0.0000\n",
      "Epoch: 704, Training loss: 1.387718, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 705, Training loss: 1.359886, Validation loss: 1.3900, lr: 0.0000\n",
      "Epoch: 706, Training loss: 1.391446, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 707, Training loss: 1.375423, Validation loss: 1.3341, lr: 0.0000\n",
      "Epoch: 708, Training loss: 1.381806, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 709, Training loss: 1.362088, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 710, Training loss: 1.389894, Validation loss: 1.3911, lr: 0.0000\n",
      "Epoch: 711, Training loss: 1.380604, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 712, Training loss: 1.375813, Validation loss: 1.5263, lr: 0.0000\n",
      "Epoch: 713, Training loss: 1.382370, Validation loss: 1.3721, lr: 0.0000\n",
      "Epoch: 714, Training loss: 1.371525, Validation loss: 1.3725, lr: 0.0000\n",
      "Epoch: 715, Training loss: 1.371470, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 716, Training loss: 1.422524, Validation loss: 1.3774, lr: 0.0000\n",
      "Epoch: 717, Training loss: 1.386396, Validation loss: 1.3653, lr: 0.0000\n",
      "Epoch: 718, Training loss: 1.376289, Validation loss: 1.3632, lr: 0.0000\n",
      "Epoch: 719, Training loss: 1.391671, Validation loss: 1.3901, lr: 0.0000\n",
      "Epoch: 720, Training loss: 1.373045, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 721, Training loss: 1.370714, Validation loss: 1.3794, lr: 0.0000\n",
      "Epoch: 722, Training loss: 1.380078, Validation loss: 1.3576, lr: 0.0000\n",
      "Epoch: 723, Training loss: 1.384131, Validation loss: 1.3760, lr: 0.0000\n",
      "Epoch: 724, Training loss: 1.383962, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 725, Training loss: 1.376665, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 726, Training loss: 1.369732, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 727, Training loss: 1.404057, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 728, Training loss: 1.387049, Validation loss: 1.4269, lr: 0.0000\n",
      "Epoch: 729, Training loss: 1.376356, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 730, Training loss: 1.378568, Validation loss: 1.3798, lr: 0.0000\n",
      "Epoch: 731, Training loss: 1.371253, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 732, Training loss: 1.383030, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 733, Training loss: 1.378718, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 734, Training loss: 1.391205, Validation loss: 1.3419, lr: 0.0000\n",
      "Epoch: 735, Training loss: 1.375005, Validation loss: 1.3606, lr: 0.0000\n",
      "Epoch: 736, Training loss: 1.366420, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 737, Training loss: 1.395307, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 738, Training loss: 1.394616, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 739, Training loss: 1.413160, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 740, Training loss: 1.381054, Validation loss: 1.3887, lr: 0.0000\n",
      "Epoch: 741, Training loss: 1.373195, Validation loss: 1.3756, lr: 0.0000\n",
      "Epoch: 742, Training loss: 1.392879, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 743, Training loss: 1.380402, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 744, Training loss: 1.406424, Validation loss: 1.3789, lr: 0.0000\n",
      "Epoch: 745, Training loss: 1.377014, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 746, Training loss: 1.379628, Validation loss: 1.3757, lr: 0.0000\n",
      "Epoch: 747, Training loss: 1.381531, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 748, Training loss: 1.388160, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 749, Training loss: 1.386137, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 750, Training loss: 1.379998, Validation loss: 1.3680, lr: 0.0000\n",
      "Epoch: 751, Training loss: 1.379671, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 752, Training loss: 1.384125, Validation loss: 1.3716, lr: 0.0000\n",
      "Epoch: 753, Training loss: 1.365499, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 754, Training loss: 1.378410, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 755, Training loss: 1.392670, Validation loss: 1.3877, lr: 0.0000\n",
      "Epoch: 756, Training loss: 1.375190, Validation loss: 1.3889, lr: 0.0000\n",
      "Epoch: 757, Training loss: 1.392785, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 758, Training loss: 1.393308, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 759, Training loss: 1.400975, Validation loss: 1.3478, lr: 0.0000\n",
      "Epoch: 760, Training loss: 1.383351, Validation loss: 1.3784, lr: 0.0000\n",
      "Epoch: 761, Training loss: 1.388124, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 762, Training loss: 1.386394, Validation loss: 1.3657, lr: 0.0000\n",
      "Epoch: 763, Training loss: 1.383404, Validation loss: 1.3876, lr: 0.0000\n",
      "Epoch: 764, Training loss: 1.369836, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 765, Training loss: 1.395195, Validation loss: 1.3909, lr: 0.0000\n",
      "Epoch: 766, Training loss: 1.368401, Validation loss: 1.3591, lr: 0.0000\n",
      "Epoch: 767, Training loss: 1.395740, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 768, Training loss: 1.387044, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 769, Training loss: 1.383696, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 770, Training loss: 1.384601, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 771, Training loss: 1.379679, Validation loss: 1.3703, lr: 0.0000\n",
      "Epoch: 772, Training loss: 1.450533, Validation loss: 1.3773, lr: 0.0000\n",
      "Epoch: 773, Training loss: 1.379178, Validation loss: 1.3905, lr: 0.0000\n",
      "Epoch: 774, Training loss: 1.411752, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 775, Training loss: 1.400429, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 776, Training loss: 1.399853, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 777, Training loss: 1.401668, Validation loss: 1.3665, lr: 0.0000\n",
      "Epoch: 778, Training loss: 1.379157, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 779, Training loss: 1.375793, Validation loss: 1.3767, lr: 0.0000\n",
      "Epoch: 780, Training loss: 1.383677, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 781, Training loss: 1.389802, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 782, Training loss: 1.454328, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 783, Training loss: 1.390744, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 784, Training loss: 1.379655, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 785, Training loss: 1.375407, Validation loss: 1.3887, lr: 0.0000\n",
      "Epoch: 786, Training loss: 1.442525, Validation loss: 1.3726, lr: 0.0000\n",
      "Epoch: 787, Training loss: 1.372235, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 788, Training loss: 1.369237, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 789, Training loss: 1.357809, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 790, Training loss: 1.363428, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 791, Training loss: 1.366821, Validation loss: 1.3884, lr: 0.0000\n",
      "Epoch: 792, Training loss: 1.358561, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 793, Training loss: 1.380818, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 794, Training loss: 1.368063, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 795, Training loss: 1.382375, Validation loss: 1.3750, lr: 0.0000\n",
      "Epoch: 796, Training loss: 1.371762, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 797, Training loss: 1.382133, Validation loss: 1.3419, lr: 0.0000\n",
      "Epoch: 798, Training loss: 1.368652, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 799, Training loss: 1.377982, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 800, Training loss: 1.377396, Validation loss: 1.3651, lr: 0.0000\n",
      "Epoch: 801, Training loss: 1.375572, Validation loss: 1.3664, lr: 0.0000\n",
      "Epoch: 802, Training loss: 1.407309, Validation loss: 1.3722, lr: 0.0000\n",
      "Epoch: 803, Training loss: 1.389184, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 804, Training loss: 1.376359, Validation loss: 1.3770, lr: 0.0000\n",
      "Epoch: 805, Training loss: 1.386332, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 806, Training loss: 1.371361, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 807, Training loss: 1.376788, Validation loss: 1.3974, lr: 0.0000\n",
      "Epoch: 808, Training loss: 1.393264, Validation loss: 1.3720, lr: 0.0000\n",
      "Epoch: 809, Training loss: 1.373859, Validation loss: 1.3760, lr: 0.0000\n",
      "Epoch: 810, Training loss: 1.376940, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 811, Training loss: 1.367936, Validation loss: 1.3904, lr: 0.0000\n",
      "Epoch: 812, Training loss: 1.382711, Validation loss: 1.4114, lr: 0.0000\n",
      "Epoch: 813, Training loss: 1.379169, Validation loss: 1.3789, lr: 0.0000\n",
      "Epoch: 814, Training loss: 1.369824, Validation loss: 1.4344, lr: 0.0000\n",
      "Epoch: 815, Training loss: 1.387908, Validation loss: 1.4044, lr: 0.0000\n",
      "Epoch: 816, Training loss: 1.374024, Validation loss: 1.3384, lr: 0.0000\n",
      "Epoch: 817, Training loss: 1.378495, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 818, Training loss: 1.393846, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 819, Training loss: 1.365715, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 820, Training loss: 1.370321, Validation loss: 1.3787, lr: 0.0000\n",
      "Epoch: 821, Training loss: 1.370278, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 822, Training loss: 1.389067, Validation loss: 1.3900, lr: 0.0000\n",
      "Epoch: 823, Training loss: 1.374484, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 824, Training loss: 1.399476, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 825, Training loss: 1.377152, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 826, Training loss: 1.373492, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 827, Training loss: 1.385520, Validation loss: 1.3901, lr: 0.0000\n",
      "Epoch: 828, Training loss: 1.422340, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 829, Training loss: 1.381762, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 830, Training loss: 1.376912, Validation loss: 1.3651, lr: 0.0000\n",
      "Epoch: 831, Training loss: 1.378994, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 832, Training loss: 1.372150, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 833, Training loss: 1.354050, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 834, Training loss: 1.388216, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 835, Training loss: 1.380491, Validation loss: 1.3761, lr: 0.0000\n",
      "Epoch: 836, Training loss: 1.385384, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 837, Training loss: 1.386961, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 838, Training loss: 1.373836, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 839, Training loss: 1.401232, Validation loss: 1.3888, lr: 0.0000\n",
      "Epoch: 840, Training loss: 1.381471, Validation loss: 3.5046, lr: 0.0000\n",
      "Epoch: 841, Training loss: 1.397287, Validation loss: 1.3728, lr: 0.0000\n",
      "Epoch: 842, Training loss: 1.377502, Validation loss: 1.3587, lr: 0.0000\n",
      "Epoch: 843, Training loss: 1.392856, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 844, Training loss: 1.384393, Validation loss: 1.3787, lr: 0.0000\n",
      "Epoch: 845, Training loss: 1.383645, Validation loss: 1.3604, lr: 0.0000\n",
      "Epoch: 846, Training loss: 1.395103, Validation loss: 1.3774, lr: 0.0000\n",
      "Epoch: 847, Training loss: 1.355139, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 848, Training loss: 1.372612, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 849, Training loss: 1.375078, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 850, Training loss: 1.394245, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 851, Training loss: 1.386013, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 852, Training loss: 1.405968, Validation loss: 1.3877, lr: 0.0000\n",
      "Epoch: 853, Training loss: 1.371344, Validation loss: 1.3760, lr: 0.0000\n",
      "Epoch: 854, Training loss: 1.380758, Validation loss: 1.3926, lr: 0.0000\n",
      "Epoch: 855, Training loss: 1.385604, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 856, Training loss: 1.360189, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 857, Training loss: 1.381466, Validation loss: 1.3689, lr: 0.0000\n",
      "Epoch: 858, Training loss: 1.383351, Validation loss: 1.3676, lr: 0.0000\n",
      "Epoch: 859, Training loss: 1.369914, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 860, Training loss: 1.379540, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 861, Training loss: 1.559231, Validation loss: 1.3737, lr: 0.0000\n",
      "Epoch: 862, Training loss: 1.367032, Validation loss: 1.3588, lr: 0.0000\n",
      "Epoch: 863, Training loss: 1.369821, Validation loss: 1.4212, lr: 0.0000\n",
      "Epoch: 864, Training loss: 1.414366, Validation loss: 1.4102, lr: 0.0000\n",
      "Epoch: 865, Training loss: 1.385746, Validation loss: 1.4684, lr: 0.0000\n",
      "Epoch: 866, Training loss: 1.364437, Validation loss: 1.3378, lr: 0.0000\n",
      "Epoch: 867, Training loss: 1.378108, Validation loss: 1.3800, lr: 0.0000\n",
      "Epoch: 868, Training loss: 1.373776, Validation loss: 1.3797, lr: 0.0000\n",
      "Epoch: 869, Training loss: 1.374825, Validation loss: 1.3878, lr: 0.0000\n",
      "Epoch: 870, Training loss: 1.385969, Validation loss: 1.3907, lr: 0.0000\n",
      "Epoch: 871, Training loss: 1.382960, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 872, Training loss: 1.368469, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 873, Training loss: 1.381197, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 874, Training loss: 1.390088, Validation loss: 1.3747, lr: 0.0000\n",
      "Epoch: 875, Training loss: 1.375882, Validation loss: 1.3980, lr: 0.0000\n",
      "Epoch: 876, Training loss: 1.401696, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 877, Training loss: 1.394721, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 878, Training loss: 1.376196, Validation loss: 1.3721, lr: 0.0000\n",
      "Epoch: 879, Training loss: 1.370670, Validation loss: 1.3871, lr: 0.0000\n",
      "Epoch: 880, Training loss: 1.370757, Validation loss: 1.3882, lr: 0.0000\n",
      "Epoch: 881, Training loss: 1.380131, Validation loss: 1.3794, lr: 0.0000\n",
      "Epoch: 882, Training loss: 1.381121, Validation loss: 1.3570, lr: 0.0000\n",
      "Epoch: 883, Training loss: 1.438626, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 884, Training loss: 1.380220, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 885, Training loss: 1.367050, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 886, Training loss: 1.376073, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 887, Training loss: 1.376792, Validation loss: 1.3721, lr: 0.0000\n",
      "Epoch: 888, Training loss: 1.378301, Validation loss: 1.3477, lr: 0.0000\n",
      "Epoch: 889, Training loss: 1.374493, Validation loss: 1.3877, lr: 0.0000\n",
      "Epoch: 890, Training loss: 1.359344, Validation loss: 1.3794, lr: 0.0000\n",
      "Epoch: 891, Training loss: 1.367417, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 892, Training loss: 1.373602, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 893, Training loss: 1.382211, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 894, Training loss: 1.387603, Validation loss: 1.3740, lr: 0.0000\n",
      "Epoch: 895, Training loss: 1.383509, Validation loss: 1.3592, lr: 0.0000\n",
      "Epoch: 896, Training loss: 1.377229, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 897, Training loss: 1.398320, Validation loss: 1.3878, lr: 0.0000\n",
      "Epoch: 898, Training loss: 1.384509, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 899, Training loss: 1.375502, Validation loss: 1.3879, lr: 0.0000\n",
      "Epoch: 900, Training loss: 1.368052, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 901, Training loss: 1.377613, Validation loss: 1.3711, lr: 0.0000\n",
      "Epoch: 902, Training loss: 1.379988, Validation loss: 1.4058, lr: 0.0000\n",
      "Epoch: 903, Training loss: 1.369556, Validation loss: 1.3879, lr: 0.0000\n",
      "Epoch: 904, Training loss: 1.368194, Validation loss: 1.3896, lr: 0.0000\n",
      "Epoch: 905, Training loss: 1.356861, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 906, Training loss: 1.374400, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 907, Training loss: 1.388159, Validation loss: 1.3900, lr: 0.0000\n",
      "Epoch: 908, Training loss: 1.390134, Validation loss: 1.4026, lr: 0.0000\n",
      "Epoch: 909, Training loss: 1.380995, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 910, Training loss: 1.361394, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 911, Training loss: 1.380589, Validation loss: 1.4632, lr: 0.0000\n",
      "Epoch: 912, Training loss: 1.395271, Validation loss: 1.3875, lr: 0.0000\n",
      "Epoch: 913, Training loss: 1.382484, Validation loss: 1.3664, lr: 0.0000\n",
      "Epoch: 914, Training loss: 1.361153, Validation loss: 1.3914, lr: 0.0000\n",
      "Epoch: 915, Training loss: 1.382570, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 916, Training loss: 1.368061, Validation loss: 1.3615, lr: 0.0000\n",
      "Epoch: 917, Training loss: 1.370069, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 918, Training loss: 1.399921, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 919, Training loss: 1.394948, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 920, Training loss: 1.398655, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 921, Training loss: 1.372556, Validation loss: 1.3445, lr: 0.0000\n",
      "Epoch: 922, Training loss: 1.392604, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 923, Training loss: 1.379493, Validation loss: 1.3671, lr: 0.0000\n",
      "Epoch: 924, Training loss: 1.384355, Validation loss: 1.3874, lr: 0.0000\n",
      "Epoch: 925, Training loss: 1.378965, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 926, Training loss: 1.394312, Validation loss: 1.3682, lr: 0.0000\n",
      "Epoch: 927, Training loss: 1.361889, Validation loss: 1.3757, lr: 0.0000\n",
      "Epoch: 928, Training loss: 1.396599, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 929, Training loss: 1.387306, Validation loss: 1.3881, lr: 0.0000\n",
      "Epoch: 930, Training loss: 1.371949, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 931, Training loss: 1.397257, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 932, Training loss: 1.362567, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 933, Training loss: 1.408459, Validation loss: 1.3574, lr: 0.0000\n",
      "Epoch: 934, Training loss: 1.394051, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 935, Training loss: 1.383776, Validation loss: 1.3726, lr: 0.0000\n",
      "Epoch: 936, Training loss: 1.398876, Validation loss: 1.3895, lr: 0.0000\n",
      "Epoch: 937, Training loss: 1.385641, Validation loss: 1.8325, lr: 0.0000\n",
      "Epoch: 938, Training loss: 1.375881, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 939, Training loss: 1.384047, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 940, Training loss: 1.387668, Validation loss: 1.3574, lr: 0.0000\n",
      "Epoch: 941, Training loss: 1.386229, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 942, Training loss: 1.385918, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 943, Training loss: 1.399741, Validation loss: 1.3735, lr: 0.0000\n",
      "Epoch: 944, Training loss: 1.363761, Validation loss: 1.3736, lr: 0.0000\n",
      "Epoch: 945, Training loss: 1.398030, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 946, Training loss: 1.413255, Validation loss: 1.3691, lr: 0.0000\n",
      "Epoch: 947, Training loss: 1.394976, Validation loss: 1.3715, lr: 0.0000\n",
      "Epoch: 948, Training loss: 1.365800, Validation loss: 1.3926, lr: 0.0000\n",
      "Epoch: 949, Training loss: 1.380070, Validation loss: 1.3875, lr: 0.0000\n",
      "Epoch: 950, Training loss: 1.392213, Validation loss: 1.3628, lr: 0.0000\n",
      "Epoch: 951, Training loss: 1.384847, Validation loss: 1.3878, lr: 0.0000\n",
      "Epoch: 952, Training loss: 1.394144, Validation loss: 1.3891, lr: 0.0000\n",
      "Epoch: 953, Training loss: 1.375189, Validation loss: 1.3902, lr: 0.0000\n",
      "Epoch: 954, Training loss: 1.392232, Validation loss: 1.3886, lr: 0.0000\n",
      "Epoch: 955, Training loss: 1.379826, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 956, Training loss: 1.434048, Validation loss: 1.3799, lr: 0.0000\n",
      "Epoch: 957, Training loss: 1.373116, Validation loss: 1.4048, lr: 0.0000\n",
      "Epoch: 958, Training loss: 1.417015, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 959, Training loss: 1.391868, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 960, Training loss: 1.368840, Validation loss: 1.3890, lr: 0.0000\n",
      "Epoch: 961, Training loss: 1.372399, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 962, Training loss: 1.378234, Validation loss: 1.3875, lr: 0.0000\n",
      "Epoch: 963, Training loss: 1.406033, Validation loss: 1.3688, lr: 0.0000\n",
      "Epoch: 964, Training loss: 1.379708, Validation loss: 1.4656, lr: 0.0000\n",
      "Epoch: 965, Training loss: 1.388608, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 966, Training loss: 1.375281, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 967, Training loss: 1.370309, Validation loss: 1.3762, lr: 0.0000\n",
      "Epoch: 968, Training loss: 1.413549, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 969, Training loss: 1.380202, Validation loss: 1.3791, lr: 0.0000\n",
      "Epoch: 970, Training loss: 1.389130, Validation loss: 1.3903, lr: 0.0000\n",
      "Epoch: 971, Training loss: 1.408884, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 972, Training loss: 1.390827, Validation loss: 1.3884, lr: 0.0000\n",
      "Epoch: 973, Training loss: 1.380881, Validation loss: 1.3724, lr: 0.0000\n",
      "Epoch: 974, Training loss: 1.385520, Validation loss: 1.3689, lr: 0.0000\n",
      "Epoch: 975, Training loss: 1.389416, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 976, Training loss: 1.376453, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 977, Training loss: 1.375482, Validation loss: 1.3892, lr: 0.0000\n",
      "Epoch: 978, Training loss: 1.375967, Validation loss: 1.3637, lr: 0.0000\n",
      "Epoch: 979, Training loss: 1.377191, Validation loss: 1.3658, lr: 0.0000\n",
      "Epoch: 980, Training loss: 1.377968, Validation loss: 1.3881, lr: 0.0000\n",
      "Epoch: 981, Training loss: 1.397109, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 982, Training loss: 1.380337, Validation loss: 1.3769, lr: 0.0000\n",
      "Epoch: 983, Training loss: 1.375777, Validation loss: 1.3876, lr: 0.0000\n",
      "Epoch: 984, Training loss: 1.379671, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 985, Training loss: 1.402126, Validation loss: 1.3871, lr: 0.0000\n",
      "Epoch: 986, Training loss: 1.374813, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 987, Training loss: 1.374321, Validation loss: 1.3678, lr: 0.0000\n",
      "Epoch: 988, Training loss: 1.386548, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 989, Training loss: 1.389536, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 990, Training loss: 1.383494, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 991, Training loss: 1.382553, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 992, Training loss: 1.383255, Validation loss: 1.3674, lr: 0.0000\n",
      "Epoch: 993, Training loss: 1.403982, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 994, Training loss: 1.374856, Validation loss: 1.3590, lr: 0.0000\n",
      "Epoch: 995, Training loss: 1.371075, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 996, Training loss: 1.373388, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 997, Training loss: 1.385945, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 998, Training loss: 1.375990, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 999, Training loss: 1.373694, Validation loss: 1.3868, lr: 0.0000\n",
      "Final test loss: 1.3857\n",
      "\n",
      "---- Embedding dimension: 100\n",
      "---- Signal dimension: 100\n",
      "---- Computing kernels ... \n",
      "---- Computing full spectrum ...\n",
      "              (if this takes too long, then run construct_dataset()\n",
      "              with number_of_eigenvectors specified) \n",
      "---- Embedding dimension: 100\n",
      "---- Signal dimension: 100\n",
      "---- Computing kernels ... \n",
      "---- Computing full spectrum ...\n",
      "              (if this takes too long, then run construct_dataset()\n",
      "=== Run 01/10 ===h number_of_eigenvectors specified) \n",
      "\n",
      "---- Settings: \n",
      "\n",
      "epochs : 1000\n",
      "hidden_channels : [32]\n",
      "out_channels : 10\n",
      "inner_product_features : False\n",
      "batch_size : 64\n",
      "lr : 0.01\n",
      "momentum : 0.9\n",
      "dropout : 0.0\n",
      "batch_norm : batch_norm\n",
      "bias : True\n",
      "order : 2\n",
      "diffusion : True\n",
      "frac_sampled_nb : -1\n",
      "include_positions : False\n",
      "include_self : True\n",
      "vec_norm : False\n",
      "emb_norm : False\n",
      "seed : 0\n",
      "dim_signal : 100\n",
      "dim_emb : 100\n",
      "n_sampled_nb : -1\n",
      "\n",
      "---- Number of features to pass to the MLP:  1010100\n",
      "---- Total number of parameters:  32323627\n",
      "\n",
      "Using device cuda:0\n",
      "\n",
      "---- Training network ...\n",
      "\n",
      "---- Timestamp: 20250614-073902\n",
      "\n",
      " *och: 0, Training loss: 1.403350, Validation loss: 1.3908, lr: 0.0100\n",
      " *och: 1, Training loss: 1.434615, Validation loss: 1.3614, lr: 0.0100\n",
      "Epoch: 2, Training loss: 1.391060, Validation loss: 1.4740, lr: 0.0100\n",
      " *och: 3, Training loss: 1.389170, Validation loss: 1.3517, lr: 0.0100\n",
      "Epoch: 4, Training loss: 1.418705, Validation loss: 1.3713, lr: 0.0100\n",
      "Epoch: 5, Training loss: 1.373242, Validation loss: 1.3680, lr: 0.0100\n",
      "Epoch: 6, Training loss: 1.387133, Validation loss: 1.3786, lr: 0.0100\n",
      "Epoch: 7, Training loss: 1.449633, Validation loss: 1.3767, lr: 0.0100\n",
      "Epoch: 8, Training loss: 1.375653, Validation loss: 1.3791, lr: 0.0100\n",
      "Epoch: 9, Training loss: 1.381048, Validation loss: 1.3966, lr: 0.0100\n",
      "Epoch: 10, Training loss: 1.406185, Validation loss: 1.3880, lr: 0.0100\n",
      "Epoch: 11, Training loss: 1.384329, Validation loss: 1.5351, lr: 0.0100\n",
      "Epoch: 12, Training loss: 1.370469, Validation loss: 1.3855, lr: 0.0100\n",
      "Epoch: 13, Training loss: 1.385797, Validation loss: 1.3813, lr: 0.0100\n",
      "Epoch: 14, Training loss: 1.371078, Validation loss: 1.3819, lr: 0.0100\n",
      "Epoch: 15, Training loss: 1.332566, Validation loss: 1.3797, lr: 0.0100\n",
      "Epoch: 16, Training loss: 1.386238, Validation loss: 1.3787, lr: 0.0100\n",
      "Epoch: 17, Training loss: 1.383956, Validation loss: 1.3792, lr: 0.0100\n",
      "Epoch: 18, Training loss: 1.393785, Validation loss: 1.3881, lr: 0.0100\n",
      "Epoch: 19, Training loss: 1.419896, Validation loss: 1.3798, lr: 0.0100\n",
      "Epoch: 20, Training loss: 1.358652, Validation loss: 1.3668, lr: 0.0100\n",
      "Epoch: 21, Training loss: 1.393850, Validation loss: 1.3792, lr: 0.0100\n",
      "Epoch: 22, Training loss: 1.382894, Validation loss: 1.3804, lr: 0.0100\n",
      "Epoch: 23, Training loss: 1.381013, Validation loss: 1.3809, lr: 0.0100\n",
      "Epoch: 24, Training loss: 1.367095, Validation loss: 1.3798, lr: 0.0100\n",
      "Epoch: 25, Training loss: 1.371999, Validation loss: 1.3854, lr: 0.0100\n",
      "Epoch: 26, Training loss: 1.349677, Validation loss: 1.3767, lr: 0.0010\n",
      "Epoch: 27, Training loss: 1.350228, Validation loss: 1.4024, lr: 0.0010\n",
      "Epoch: 28, Training loss: 1.398970, Validation loss: 1.3803, lr: 0.0010\n",
      "Epoch: 29, Training loss: 1.377362, Validation loss: 1.3832, lr: 0.0010\n",
      "Epoch: 30, Training loss: 1.364667, Validation loss: 1.3868, lr: 0.0010\n",
      "Epoch: 31, Training loss: 1.394072, Validation loss: 1.3974, lr: 0.0010\n",
      " *och: 32, Training loss: 1.357935, Validation loss: 1.3516, lr: 0.0010\n",
      "Epoch: 33, Training loss: 1.466539, Validation loss: 1.3860, lr: 0.0010\n",
      "Epoch: 34, Training loss: 1.413466, Validation loss: 1.3724, lr: 0.0010\n",
      "Epoch: 35, Training loss: 1.342004, Validation loss: 1.3759, lr: 0.0010\n",
      "Epoch: 36, Training loss: 1.362748, Validation loss: 1.3856, lr: 0.0010\n",
      "Epoch: 37, Training loss: 1.361765, Validation loss: 1.3925, lr: 0.0001\n",
      "Epoch: 38, Training loss: 1.357158, Validation loss: 1.3535, lr: 0.0001\n",
      "Epoch: 39, Training loss: 1.380555, Validation loss: 1.3938, lr: 0.0001\n",
      "Epoch: 40, Training loss: 1.356908, Validation loss: 1.3741, lr: 0.0001\n",
      "Epoch: 41, Training loss: 1.374554, Validation loss: 1.3769, lr: 0.0001\n",
      "Epoch: 42, Training loss: 1.344365, Validation loss: 1.3724, lr: 0.0001\n",
      "Epoch: 43, Training loss: 1.377377, Validation loss: 1.3553, lr: 0.0001\n",
      "Epoch: 44, Training loss: 1.364650, Validation loss: 1.4360, lr: 0.0001\n",
      "Epoch: 45, Training loss: 1.359095, Validation loss: 1.3532, lr: 0.0001\n",
      "Epoch: 46, Training loss: 1.338364, Validation loss: 1.3533, lr: 0.0001\n",
      "Epoch: 47, Training loss: 1.366852, Validation loss: 1.3606, lr: 0.0001\n",
      "Epoch: 48, Training loss: 1.381969, Validation loss: 1.3729, lr: 0.0000\n",
      "Epoch: 49, Training loss: 1.367399, Validation loss: 1.3750, lr: 0.0000\n",
      "Epoch: 50, Training loss: 1.361630, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 51, Training loss: 1.372230, Validation loss: 1.3790, lr: 0.0000\n",
      "Epoch: 52, Training loss: 1.369705, Validation loss: 1.3723, lr: 0.0000\n",
      "Epoch: 53, Training loss: 1.393418, Validation loss: 1.3784, lr: 0.0000\n",
      "Epoch: 54, Training loss: 1.398838, Validation loss: 1.3803, lr: 0.0000\n",
      "Epoch: 55, Training loss: 1.385775, Validation loss: 1.3944, lr: 0.0000\n",
      "Epoch: 56, Training loss: 1.334378, Validation loss: 1.3750, lr: 0.0000\n",
      "Epoch: 57, Training loss: 1.345488, Validation loss: 1.3547, lr: 0.0000\n",
      "Epoch: 58, Training loss: 1.351432, Validation loss: 1.3753, lr: 0.0000\n",
      "Epoch: 59, Training loss: 1.354156, Validation loss: 1.3775, lr: 0.0000\n",
      "Epoch: 60, Training loss: 1.360770, Validation loss: 1.3636, lr: 0.0000\n",
      "Epoch: 61, Training loss: 1.361007, Validation loss: 1.3662, lr: 0.0000\n",
      "Epoch: 62, Training loss: 1.363759, Validation loss: 1.3803, lr: 0.0000\n",
      "Epoch: 63, Training loss: 1.365085, Validation loss: 1.3675, lr: 0.0000\n",
      "Epoch: 64, Training loss: 1.325492, Validation loss: 1.3788, lr: 0.0000\n",
      "Epoch: 65, Training loss: 1.359271, Validation loss: 1.3900, lr: 0.0000\n",
      "Epoch: 66, Training loss: 1.340932, Validation loss: 1.3719, lr: 0.0000\n",
      "Epoch: 67, Training loss: 1.339240, Validation loss: 1.3763, lr: 0.0000\n",
      "Epoch: 68, Training loss: 1.368612, Validation loss: 1.3800, lr: 0.0000\n",
      "Epoch: 69, Training loss: 1.375537, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 70, Training loss: 1.352920, Validation loss: 1.3882, lr: 0.0000\n",
      "Epoch: 71, Training loss: 1.345568, Validation loss: 1.3726, lr: 0.0000\n",
      "Epoch: 72, Training loss: 1.358011, Validation loss: 1.3798, lr: 0.0000\n",
      " *och: 73, Training loss: 1.332892, Validation loss: 1.3418, lr: 0.0000\n",
      "Epoch: 74, Training loss: 1.420586, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 75, Training loss: 1.366594, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 76, Training loss: 1.364446, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 77, Training loss: 1.339951, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 78, Training loss: 1.387973, Validation loss: 1.3766, lr: 0.0000\n",
      "Epoch: 79, Training loss: 1.371952, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 80, Training loss: 1.358558, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 81, Training loss: 1.352965, Validation loss: 1.3796, lr: 0.0000\n",
      "Epoch: 82, Training loss: 1.352855, Validation loss: 1.3612, lr: 0.0000\n",
      "Epoch: 83, Training loss: 1.349729, Validation loss: 1.3737, lr: 0.0000\n",
      "Epoch: 84, Training loss: 1.486260, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 85, Training loss: 1.369730, Validation loss: 1.3743, lr: 0.0000\n",
      "Epoch: 86, Training loss: 1.373888, Validation loss: 1.3694, lr: 0.0000\n",
      "Epoch: 87, Training loss: 1.357697, Validation loss: 1.3768, lr: 0.0000\n",
      "Epoch: 88, Training loss: 1.365328, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 89, Training loss: 1.354333, Validation loss: 1.3678, lr: 0.0000\n",
      "Epoch: 90, Training loss: 1.366078, Validation loss: 1.3780, lr: 0.0000\n",
      "Epoch: 91, Training loss: 1.349944, Validation loss: 1.3740, lr: 0.0000\n",
      "Epoch: 92, Training loss: 1.360177, Validation loss: 1.3762, lr: 0.0000\n",
      "Epoch: 93, Training loss: 1.378585, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 94, Training loss: 1.363517, Validation loss: 1.3641, lr: 0.0000\n",
      "Epoch: 95, Training loss: 1.327608, Validation loss: 1.3551, lr: 0.0000\n",
      "Epoch: 96, Training loss: 1.374628, Validation loss: 1.3781, lr: 0.0000\n",
      "Epoch: 97, Training loss: 1.359205, Validation loss: 1.3541, lr: 0.0000\n",
      "Epoch: 98, Training loss: 1.388023, Validation loss: 1.3721, lr: 0.0000\n",
      "Epoch: 99, Training loss: 1.350327, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 100, Training loss: 1.353904, Validation loss: 1.3735, lr: 0.0000\n",
      "Epoch: 101, Training loss: 1.355525, Validation loss: 1.3634, lr: 0.0000\n",
      "Epoch: 102, Training loss: 1.377239, Validation loss: 1.3739, lr: 0.0000\n",
      "Epoch: 103, Training loss: 1.369539, Validation loss: 1.4448, lr: 0.0000\n",
      "Epoch: 104, Training loss: 1.364528, Validation loss: 1.3767, lr: 0.0000\n",
      "Epoch: 105, Training loss: 1.355285, Validation loss: 1.3793, lr: 0.0000\n",
      "Epoch: 106, Training loss: 1.357700, Validation loss: 1.3666, lr: 0.0000\n",
      "Epoch: 107, Training loss: 1.369452, Validation loss: 1.3795, lr: 0.0000\n",
      "Epoch: 108, Training loss: 1.346245, Validation loss: 1.3535, lr: 0.0000\n",
      "Epoch: 109, Training loss: 1.351771, Validation loss: 1.3789, lr: 0.0000\n",
      "Epoch: 110, Training loss: 1.366931, Validation loss: 1.3739, lr: 0.0000\n",
      "Epoch: 111, Training loss: 1.363883, Validation loss: 1.3684, lr: 0.0000\n",
      "Epoch: 112, Training loss: 1.358528, Validation loss: 1.3571, lr: 0.0000\n",
      "Epoch: 113, Training loss: 1.363115, Validation loss: 1.3741, lr: 0.0000\n",
      "Epoch: 114, Training loss: 1.381026, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 115, Training loss: 1.362106, Validation loss: 1.3948, lr: 0.0000\n",
      "Epoch: 116, Training loss: 1.356454, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 117, Training loss: 1.335183, Validation loss: 1.3788, lr: 0.0000\n",
      "Epoch: 118, Training loss: 1.371939, Validation loss: 1.4815, lr: 0.0000\n",
      "Epoch: 119, Training loss: 1.347719, Validation loss: 1.3722, lr: 0.0000\n",
      "Epoch: 120, Training loss: 1.368697, Validation loss: 1.3655, lr: 0.0000\n",
      "Epoch: 121, Training loss: 1.359197, Validation loss: 1.3788, lr: 0.0000\n",
      "Epoch: 122, Training loss: 1.362581, Validation loss: 1.3763, lr: 0.0000\n",
      "Epoch: 123, Training loss: 1.329474, Validation loss: 1.3745, lr: 0.0000\n",
      "Epoch: 124, Training loss: 1.358632, Validation loss: 1.3795, lr: 0.0000\n",
      "Epoch: 125, Training loss: 1.367307, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 126, Training loss: 1.343063, Validation loss: 1.3778, lr: 0.0000\n",
      "Epoch: 127, Training loss: 1.370899, Validation loss: 1.6840, lr: 0.0000\n",
      "Epoch: 128, Training loss: 1.351806, Validation loss: 1.3803, lr: 0.0000\n",
      "Epoch: 129, Training loss: 1.356541, Validation loss: 1.3615, lr: 0.0000\n",
      "Epoch: 130, Training loss: 1.367502, Validation loss: 1.3773, lr: 0.0000\n",
      "Epoch: 131, Training loss: 1.375814, Validation loss: 1.3889, lr: 0.0000\n",
      "Epoch: 132, Training loss: 1.352330, Validation loss: 1.3876, lr: 0.0000\n",
      "Epoch: 133, Training loss: 1.374048, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 134, Training loss: 1.429745, Validation loss: 1.3462, lr: 0.0000\n",
      "Epoch: 135, Training loss: 1.363488, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 136, Training loss: 1.330768, Validation loss: 1.3430, lr: 0.0000\n",
      "Epoch: 137, Training loss: 1.356568, Validation loss: 1.3718, lr: 0.0000\n",
      "Epoch: 138, Training loss: 1.372193, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 139, Training loss: 1.341954, Validation loss: 1.3773, lr: 0.0000\n",
      "Epoch: 140, Training loss: 1.382723, Validation loss: 1.3799, lr: 0.0000\n",
      "Epoch: 141, Training loss: 1.348886, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 142, Training loss: 1.360854, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 143, Training loss: 1.391539, Validation loss: 1.3703, lr: 0.0000\n",
      "Epoch: 144, Training loss: 1.331814, Validation loss: 1.3707, lr: 0.0000\n",
      "Epoch: 145, Training loss: 1.382463, Validation loss: 1.3688, lr: 0.0000\n",
      "Epoch: 146, Training loss: 1.428923, Validation loss: 1.3621, lr: 0.0000\n",
      "Epoch: 147, Training loss: 1.396113, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 148, Training loss: 1.372571, Validation loss: 1.3795, lr: 0.0000\n",
      "Epoch: 149, Training loss: 1.379144, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 150, Training loss: 1.351644, Validation loss: 1.3775, lr: 0.0000\n",
      "Epoch: 151, Training loss: 1.362674, Validation loss: 1.3672, lr: 0.0000\n",
      "Epoch: 152, Training loss: 1.350326, Validation loss: 1.3681, lr: 0.0000\n",
      "Epoch: 153, Training loss: 1.380978, Validation loss: 1.3794, lr: 0.0000\n",
      "Epoch: 154, Training loss: 1.356804, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 155, Training loss: 1.349780, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 156, Training loss: 1.350117, Validation loss: 1.3888, lr: 0.0000\n",
      "Epoch: 157, Training loss: 1.371138, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 158, Training loss: 1.386948, Validation loss: 1.4301, lr: 0.0000\n",
      "Epoch: 159, Training loss: 1.399487, Validation loss: 1.3741, lr: 0.0000\n",
      "Epoch: 160, Training loss: 1.350296, Validation loss: 1.3727, lr: 0.0000\n",
      "Epoch: 161, Training loss: 1.398514, Validation loss: 1.3634, lr: 0.0000\n",
      "Epoch: 162, Training loss: 1.355637, Validation loss: 1.3802, lr: 0.0000\n",
      "Epoch: 163, Training loss: 1.357319, Validation loss: 1.3779, lr: 0.0000\n",
      "Epoch: 164, Training loss: 1.385887, Validation loss: 1.8447, lr: 0.0000\n",
      "Epoch: 165, Training loss: 1.350522, Validation loss: 1.3742, lr: 0.0000\n",
      "Epoch: 166, Training loss: 1.343031, Validation loss: 1.3724, lr: 0.0000\n",
      "Epoch: 167, Training loss: 1.380868, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 168, Training loss: 1.376237, Validation loss: 1.3735, lr: 0.0000\n",
      "Epoch: 169, Training loss: 1.370202, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 170, Training loss: 1.364773, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 171, Training loss: 1.366944, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 172, Training loss: 1.392390, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 173, Training loss: 1.382553, Validation loss: 1.3640, lr: 0.0000\n",
      "Epoch: 174, Training loss: 1.357891, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 175, Training loss: 1.381319, Validation loss: 1.3779, lr: 0.0000\n",
      "Epoch: 176, Training loss: 1.338984, Validation loss: 1.3779, lr: 0.0000\n",
      "Epoch: 177, Training loss: 1.357079, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 178, Training loss: 1.412433, Validation loss: 1.3666, lr: 0.0000\n",
      "Epoch: 179, Training loss: 1.372056, Validation loss: 1.3665, lr: 0.0000\n",
      "Epoch: 180, Training loss: 1.394969, Validation loss: 1.3772, lr: 0.0000\n",
      "Epoch: 181, Training loss: 1.350062, Validation loss: 1.3642, lr: 0.0000\n",
      "Epoch: 182, Training loss: 1.324901, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 183, Training loss: 1.367073, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 184, Training loss: 1.352957, Validation loss: 1.3562, lr: 0.0000\n",
      "Epoch: 185, Training loss: 1.386195, Validation loss: 1.3913, lr: 0.0000\n",
      "Epoch: 186, Training loss: 1.345588, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 187, Training loss: 1.344288, Validation loss: 1.3782, lr: 0.0000\n",
      "Epoch: 188, Training loss: 1.380472, Validation loss: 1.3797, lr: 0.0000\n",
      "Epoch: 189, Training loss: 1.363425, Validation loss: 1.3590, lr: 0.0000\n",
      "Epoch: 190, Training loss: 1.340439, Validation loss: 1.3911, lr: 0.0000\n",
      "Epoch: 191, Training loss: 1.345762, Validation loss: 1.3633, lr: 0.0000\n",
      "Epoch: 192, Training loss: 1.346802, Validation loss: 1.3612, lr: 0.0000\n",
      "Epoch: 193, Training loss: 1.353165, Validation loss: 1.3727, lr: 0.0000\n",
      "Epoch: 194, Training loss: 1.373514, Validation loss: 1.3765, lr: 0.0000\n",
      "Epoch: 195, Training loss: 1.372036, Validation loss: 1.3674, lr: 0.0000\n",
      "Epoch: 196, Training loss: 1.363565, Validation loss: 1.3613, lr: 0.0000\n",
      "Epoch: 197, Training loss: 1.336760, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 198, Training loss: 1.353920, Validation loss: 1.3476, lr: 0.0000\n",
      "Epoch: 199, Training loss: 1.352149, Validation loss: 1.3683, lr: 0.0000\n",
      "Epoch: 200, Training loss: 1.374659, Validation loss: 1.3797, lr: 0.0000\n",
      "Epoch: 201, Training loss: 1.346775, Validation loss: 1.3786, lr: 0.0000\n",
      "Epoch: 202, Training loss: 1.363787, Validation loss: 1.3503, lr: 0.0000\n",
      "Epoch: 203, Training loss: 1.458576, Validation loss: 1.3749, lr: 0.0000\n",
      "Epoch: 204, Training loss: 1.353371, Validation loss: 1.3722, lr: 0.0000\n",
      "Epoch: 205, Training loss: 1.402335, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 206, Training loss: 1.378122, Validation loss: 1.3685, lr: 0.0000\n",
      "Epoch: 207, Training loss: 1.384637, Validation loss: 1.3887, lr: 0.0000\n",
      "Epoch: 208, Training loss: 1.357032, Validation loss: 1.4702, lr: 0.0000\n",
      "Epoch: 209, Training loss: 1.351841, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 210, Training loss: 1.409677, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 211, Training loss: 1.359473, Validation loss: 1.3653, lr: 0.0000\n",
      "Epoch: 212, Training loss: 1.419633, Validation loss: 1.3590, lr: 0.0000\n",
      "Epoch: 213, Training loss: 1.360737, Validation loss: 1.3729, lr: 0.0000\n",
      "Epoch: 214, Training loss: 1.355107, Validation loss: 1.3720, lr: 0.0000\n",
      "Epoch: 215, Training loss: 1.357710, Validation loss: 1.3777, lr: 0.0000\n",
      "Epoch: 216, Training loss: 1.384083, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 217, Training loss: 1.377156, Validation loss: 1.3763, lr: 0.0000\n",
      "Epoch: 218, Training loss: 1.383139, Validation loss: 1.3795, lr: 0.0000\n",
      "Epoch: 219, Training loss: 1.379564, Validation loss: 1.3800, lr: 0.0000\n",
      "Epoch: 220, Training loss: 1.353355, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 221, Training loss: 1.326494, Validation loss: 1.3779, lr: 0.0000\n",
      "Epoch: 222, Training loss: 1.338903, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 223, Training loss: 1.347742, Validation loss: 1.3793, lr: 0.0000\n",
      "Epoch: 224, Training loss: 1.354649, Validation loss: 1.3775, lr: 0.0000\n",
      "Epoch: 225, Training loss: 1.378854, Validation loss: 1.3757, lr: 0.0000\n",
      "Epoch: 226, Training loss: 1.361994, Validation loss: 1.3737, lr: 0.0000\n",
      "Epoch: 227, Training loss: 1.357700, Validation loss: 1.3747, lr: 0.0000\n",
      "Epoch: 228, Training loss: 1.359597, Validation loss: 1.3637, lr: 0.0000\n",
      "Epoch: 229, Training loss: 1.362606, Validation loss: 1.3803, lr: 0.0000\n",
      "Epoch: 230, Training loss: 1.363497, Validation loss: 1.3762, lr: 0.0000\n",
      "Epoch: 231, Training loss: 1.405403, Validation loss: 1.3746, lr: 0.0000\n",
      "Epoch: 232, Training loss: 1.375056, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 233, Training loss: 1.372908, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 234, Training loss: 1.348780, Validation loss: 1.3794, lr: 0.0000\n",
      "Epoch: 235, Training loss: 1.364671, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 236, Training loss: 1.337244, Validation loss: 1.3876, lr: 0.0000\n",
      "Epoch: 237, Training loss: 1.343561, Validation loss: 1.3762, lr: 0.0000\n",
      "Epoch: 238, Training loss: 1.379395, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 239, Training loss: 1.368546, Validation loss: 1.3923, lr: 0.0000\n",
      "Epoch: 240, Training loss: 1.374611, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 241, Training loss: 1.443332, Validation loss: 1.3967, lr: 0.0000\n",
      "Epoch: 242, Training loss: 1.374804, Validation loss: 1.3639, lr: 0.0000\n",
      "Epoch: 243, Training loss: 1.349701, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 244, Training loss: 1.347779, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 245, Training loss: 1.375189, Validation loss: 1.3778, lr: 0.0000\n",
      "Epoch: 246, Training loss: 1.372038, Validation loss: 1.3672, lr: 0.0000\n",
      "Epoch: 247, Training loss: 1.375623, Validation loss: 1.3772, lr: 0.0000\n",
      "Epoch: 248, Training loss: 1.330316, Validation loss: 1.3770, lr: 0.0000\n",
      "Epoch: 249, Training loss: 1.421966, Validation loss: 1.3752, lr: 0.0000\n",
      "Epoch: 250, Training loss: 1.364182, Validation loss: 1.3743, lr: 0.0000\n",
      "Epoch: 251, Training loss: 1.372700, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 252, Training loss: 1.353863, Validation loss: 1.3730, lr: 0.0000\n",
      "Epoch: 253, Training loss: 1.358675, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 254, Training loss: 1.335666, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 255, Training loss: 1.391970, Validation loss: 1.4122, lr: 0.0000\n",
      "Epoch: 256, Training loss: 1.367287, Validation loss: 1.3727, lr: 0.0000\n",
      "Epoch: 257, Training loss: 1.358267, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 258, Training loss: 1.362971, Validation loss: 1.3758, lr: 0.0000\n",
      "Epoch: 259, Training loss: 1.361652, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 260, Training loss: 1.369757, Validation loss: 1.3797, lr: 0.0000\n",
      "Epoch: 261, Training loss: 1.352475, Validation loss: 1.4357, lr: 0.0000\n",
      "Epoch: 262, Training loss: 1.377528, Validation loss: 1.3662, lr: 0.0000\n",
      "Epoch: 263, Training loss: 1.370619, Validation loss: 1.3785, lr: 0.0000\n",
      "Epoch: 264, Training loss: 1.360729, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 265, Training loss: 1.361068, Validation loss: 1.3775, lr: 0.0000\n",
      "Epoch: 266, Training loss: 1.354322, Validation loss: 1.3761, lr: 0.0000\n",
      "Epoch: 267, Training loss: 1.367192, Validation loss: 1.3877, lr: 0.0000\n",
      "Epoch: 268, Training loss: 1.386485, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 269, Training loss: 1.355845, Validation loss: 1.3883, lr: 0.0000\n",
      "Epoch: 270, Training loss: 1.349729, Validation loss: 1.3772, lr: 0.0000\n",
      "Epoch: 271, Training loss: 1.364138, Validation loss: 1.3659, lr: 0.0000\n",
      "Epoch: 272, Training loss: 1.356484, Validation loss: 1.3731, lr: 0.0000\n",
      "Epoch: 273, Training loss: 1.359679, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 274, Training loss: 1.366709, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 275, Training loss: 1.344094, Validation loss: 1.3880, lr: 0.0000\n",
      "Epoch: 276, Training loss: 1.367824, Validation loss: 1.3793, lr: 0.0000\n",
      "Epoch: 277, Training loss: 1.380302, Validation loss: 1.3779, lr: 0.0000\n",
      "Epoch: 278, Training loss: 1.388013, Validation loss: 1.3690, lr: 0.0000\n",
      "Epoch: 279, Training loss: 1.354877, Validation loss: 1.3736, lr: 0.0000\n",
      "Epoch: 280, Training loss: 1.354852, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 281, Training loss: 1.366840, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 282, Training loss: 1.344822, Validation loss: 1.3919, lr: 0.0000\n",
      "Epoch: 283, Training loss: 1.341391, Validation loss: 1.3742, lr: 0.0000\n",
      "Epoch: 284, Training loss: 1.334619, Validation loss: 1.3722, lr: 0.0000\n",
      "Epoch: 285, Training loss: 1.346111, Validation loss: 1.3707, lr: 0.0000\n",
      "Epoch: 286, Training loss: 1.367226, Validation loss: 1.3717, lr: 0.0000\n",
      "Epoch: 287, Training loss: 1.370201, Validation loss: 1.3655, lr: 0.0000\n",
      "Epoch: 288, Training loss: 1.355001, Validation loss: 1.3646, lr: 0.0000\n",
      "Epoch: 289, Training loss: 1.334106, Validation loss: 1.3595, lr: 0.0000\n",
      "Epoch: 290, Training loss: 1.378818, Validation loss: 1.3554, lr: 0.0000\n",
      "Epoch: 291, Training loss: 1.365594, Validation loss: 1.3729, lr: 0.0000\n",
      "Epoch: 292, Training loss: 1.348499, Validation loss: 1.4190, lr: 0.0000\n",
      "Epoch: 293, Training loss: 1.390722, Validation loss: 1.3657, lr: 0.0000\n",
      "Epoch: 294, Training loss: 1.386409, Validation loss: 1.3930, lr: 0.0000\n",
      "Epoch: 295, Training loss: 1.350152, Validation loss: 1.3721, lr: 0.0000\n",
      "Epoch: 296, Training loss: 1.351724, Validation loss: 1.3670, lr: 0.0000\n",
      "Epoch: 297, Training loss: 1.358729, Validation loss: 1.3893, lr: 0.0000\n",
      "Epoch: 298, Training loss: 1.382864, Validation loss: 1.3771, lr: 0.0000\n",
      "Epoch: 299, Training loss: 1.389499, Validation loss: 1.4110, lr: 0.0000\n",
      "Epoch: 300, Training loss: 1.352941, Validation loss: 1.3493, lr: 0.0000\n",
      "Epoch: 301, Training loss: 1.358409, Validation loss: 1.3693, lr: 0.0000\n",
      "Epoch: 302, Training loss: 1.376380, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 303, Training loss: 1.381906, Validation loss: 1.3764, lr: 0.0000\n",
      "Epoch: 304, Training loss: 1.360721, Validation loss: 1.3749, lr: 0.0000\n",
      "Epoch: 305, Training loss: 1.337304, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 306, Training loss: 1.391490, Validation loss: 1.3877, lr: 0.0000\n",
      "Epoch: 307, Training loss: 1.361083, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 308, Training loss: 1.375686, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 309, Training loss: 1.366330, Validation loss: 1.3752, lr: 0.0000\n",
      "Epoch: 310, Training loss: 1.360446, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 311, Training loss: 1.366762, Validation loss: 1.3771, lr: 0.0000\n",
      "Epoch: 312, Training loss: 1.346515, Validation loss: 1.3771, lr: 0.0000\n",
      "Epoch: 313, Training loss: 1.405463, Validation loss: 1.3743, lr: 0.0000\n",
      "Epoch: 314, Training loss: 1.428696, Validation loss: 1.3746, lr: 0.0000\n",
      "Epoch: 315, Training loss: 1.363413, Validation loss: 1.3750, lr: 0.0000\n",
      "Epoch: 316, Training loss: 1.345371, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 317, Training loss: 1.349933, Validation loss: 1.3739, lr: 0.0000\n",
      "Epoch: 318, Training loss: 1.396000, Validation loss: 1.3735, lr: 0.0000\n",
      "Epoch: 319, Training loss: 1.369529, Validation loss: 1.3782, lr: 0.0000\n",
      "Epoch: 320, Training loss: 1.344176, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 321, Training loss: 1.417011, Validation loss: 1.3726, lr: 0.0000\n",
      "Epoch: 322, Training loss: 1.356366, Validation loss: 1.3748, lr: 0.0000\n",
      "Epoch: 323, Training loss: 1.360289, Validation loss: 1.3748, lr: 0.0000\n",
      "Epoch: 324, Training loss: 1.347923, Validation loss: 1.3664, lr: 0.0000\n",
      "Epoch: 325, Training loss: 1.359600, Validation loss: 1.3532, lr: 0.0000\n",
      "Epoch: 326, Training loss: 1.338866, Validation loss: 1.3894, lr: 0.0000\n",
      "Epoch: 327, Training loss: 1.349892, Validation loss: 1.3784, lr: 0.0000\n",
      "Epoch: 328, Training loss: 1.355417, Validation loss: 1.3597, lr: 0.0000\n",
      "Epoch: 329, Training loss: 1.376791, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 330, Training loss: 1.358493, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 331, Training loss: 1.376622, Validation loss: 1.3773, lr: 0.0000\n",
      "Epoch: 332, Training loss: 1.370920, Validation loss: 1.3572, lr: 0.0000\n",
      "Epoch: 333, Training loss: 1.361047, Validation loss: 1.3797, lr: 0.0000\n",
      "Epoch: 334, Training loss: 1.344787, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 335, Training loss: 1.343993, Validation loss: 1.3686, lr: 0.0000\n",
      "Epoch: 336, Training loss: 1.379689, Validation loss: 1.3775, lr: 0.0000\n",
      "Epoch: 337, Training loss: 1.429960, Validation loss: 1.3735, lr: 0.0000\n",
      "Epoch: 338, Training loss: 1.345454, Validation loss: 1.3764, lr: 0.0000\n",
      "Epoch: 339, Training loss: 1.373593, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 340, Training loss: 1.345303, Validation loss: 1.3796, lr: 0.0000\n",
      "Epoch: 341, Training loss: 1.356160, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 342, Training loss: 1.352720, Validation loss: 1.3745, lr: 0.0000\n",
      "Epoch: 343, Training loss: 1.434297, Validation loss: 1.3785, lr: 0.0000\n",
      "Epoch: 344, Training loss: 1.361118, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 345, Training loss: 1.355789, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 346, Training loss: 1.366136, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 347, Training loss: 1.365882, Validation loss: 1.3754, lr: 0.0000\n",
      "Epoch: 348, Training loss: 1.358824, Validation loss: 1.3767, lr: 0.0000\n",
      " *och: 349, Training loss: 1.335247, Validation loss: 1.3298, lr: 0.0000\n",
      "Epoch: 350, Training loss: 1.361648, Validation loss: 1.3771, lr: 0.0000\n",
      "Epoch: 351, Training loss: 1.346499, Validation loss: 1.3683, lr: 0.0000\n",
      "Epoch: 352, Training loss: 1.378886, Validation loss: 1.3716, lr: 0.0000\n",
      "Epoch: 353, Training loss: 1.335408, Validation loss: 1.3711, lr: 0.0000\n",
      "Epoch: 354, Training loss: 1.371678, Validation loss: 1.3654, lr: 0.0000\n",
      "Epoch: 355, Training loss: 1.352141, Validation loss: 1.3769, lr: 0.0000\n",
      "Epoch: 356, Training loss: 1.362829, Validation loss: 1.3471, lr: 0.0000\n",
      "Epoch: 357, Training loss: 1.355578, Validation loss: 1.3700, lr: 0.0000\n",
      "Epoch: 358, Training loss: 1.373769, Validation loss: 1.3888, lr: 0.0000\n",
      "Epoch: 359, Training loss: 1.342348, Validation loss: 1.3633, lr: 0.0000\n",
      "Epoch: 360, Training loss: 1.397540, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 361, Training loss: 1.384772, Validation loss: 1.3736, lr: 0.0000\n",
      "Epoch: 362, Training loss: 1.355591, Validation loss: 1.3755, lr: 0.0000\n",
      "Epoch: 363, Training loss: 1.360857, Validation loss: 1.3795, lr: 0.0000\n",
      "Epoch: 364, Training loss: 1.422807, Validation loss: 1.3598, lr: 0.0000\n",
      "Epoch: 365, Training loss: 1.349502, Validation loss: 1.3725, lr: 0.0000\n",
      "Epoch: 366, Training loss: 1.364651, Validation loss: 1.3667, lr: 0.0000\n",
      "Epoch: 367, Training loss: 1.363868, Validation loss: 1.3767, lr: 0.0000\n",
      "Epoch: 368, Training loss: 1.353310, Validation loss: 1.3607, lr: 0.0000\n",
      "Epoch: 369, Training loss: 1.354904, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 370, Training loss: 1.378453, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 371, Training loss: 1.376386, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 372, Training loss: 1.360812, Validation loss: 1.3754, lr: 0.0000\n",
      "Epoch: 373, Training loss: 1.336832, Validation loss: 1.3780, lr: 0.0000\n",
      "Epoch: 374, Training loss: 1.354379, Validation loss: 1.3758, lr: 0.0000\n",
      "Epoch: 375, Training loss: 1.366751, Validation loss: 1.3761, lr: 0.0000\n",
      "Epoch: 376, Training loss: 1.387914, Validation loss: 1.3631, lr: 0.0000\n",
      "Epoch: 377, Training loss: 1.360582, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 378, Training loss: 1.371232, Validation loss: 1.3802, lr: 0.0000\n",
      "Epoch: 379, Training loss: 1.379162, Validation loss: 1.3751, lr: 0.0000\n",
      "Epoch: 380, Training loss: 1.343724, Validation loss: 1.3771, lr: 0.0000\n",
      "Epoch: 381, Training loss: 1.345908, Validation loss: 1.3800, lr: 0.0000\n",
      "Epoch: 382, Training loss: 1.356811, Validation loss: 1.3597, lr: 0.0000\n",
      "Epoch: 383, Training loss: 1.367847, Validation loss: 1.3799, lr: 0.0000\n",
      "Epoch: 384, Training loss: 1.342781, Validation loss: 1.3743, lr: 0.0000\n",
      "Epoch: 385, Training loss: 1.354748, Validation loss: 1.3725, lr: 0.0000\n",
      "Epoch: 386, Training loss: 1.382988, Validation loss: 1.3771, lr: 0.0000\n",
      "Epoch: 387, Training loss: 1.363859, Validation loss: 1.3578, lr: 0.0000\n",
      "Epoch: 388, Training loss: 1.330009, Validation loss: 1.3771, lr: 0.0000\n",
      "Epoch: 389, Training loss: 1.362586, Validation loss: 1.3703, lr: 0.0000\n",
      "Epoch: 390, Training loss: 1.348710, Validation loss: 1.3728, lr: 0.0000\n",
      "Epoch: 391, Training loss: 1.344441, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 392, Training loss: 1.347166, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 393, Training loss: 1.356984, Validation loss: 1.3701, lr: 0.0000\n",
      "Epoch: 394, Training loss: 1.342684, Validation loss: 1.3488, lr: 0.0000\n",
      "Epoch: 395, Training loss: 1.388084, Validation loss: 1.3772, lr: 0.0000\n",
      "Epoch: 396, Training loss: 1.361842, Validation loss: 1.3788, lr: 0.0000\n",
      "Epoch: 397, Training loss: 1.342859, Validation loss: 1.3769, lr: 0.0000\n",
      "Epoch: 398, Training loss: 1.351938, Validation loss: 1.3592, lr: 0.0000\n",
      "Epoch: 399, Training loss: 1.383919, Validation loss: 1.4117, lr: 0.0000\n",
      "Epoch: 400, Training loss: 1.353213, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 401, Training loss: 1.338396, Validation loss: 1.3745, lr: 0.0000\n",
      "Epoch: 402, Training loss: 1.400180, Validation loss: 1.4194, lr: 0.0000\n",
      "Epoch: 403, Training loss: 1.360254, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 404, Training loss: 1.342092, Validation loss: 1.3774, lr: 0.0000\n",
      "Epoch: 405, Training loss: 1.343686, Validation loss: 1.3381, lr: 0.0000\n",
      "Epoch: 406, Training loss: 1.366588, Validation loss: 1.3783, lr: 0.0000\n",
      "Epoch: 407, Training loss: 1.352509, Validation loss: 1.3790, lr: 0.0000\n",
      "Epoch: 408, Training loss: 1.336704, Validation loss: 1.3650, lr: 0.0000\n",
      "Epoch: 409, Training loss: 1.347517, Validation loss: 1.3682, lr: 0.0000\n",
      "Epoch: 410, Training loss: 1.387158, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 411, Training loss: 1.346839, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 412, Training loss: 1.365438, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 413, Training loss: 1.362796, Validation loss: 1.3784, lr: 0.0000\n",
      "Epoch: 414, Training loss: 1.376995, Validation loss: 1.3762, lr: 0.0000\n",
      "Epoch: 415, Training loss: 1.350682, Validation loss: 1.3786, lr: 0.0000\n",
      "Epoch: 416, Training loss: 1.357803, Validation loss: 1.4007, lr: 0.0000\n",
      "Epoch: 417, Training loss: 1.354473, Validation loss: 1.3585, lr: 0.0000\n",
      "Epoch: 418, Training loss: 1.419583, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 419, Training loss: 1.364165, Validation loss: 1.3879, lr: 0.0000\n",
      "Epoch: 420, Training loss: 1.364827, Validation loss: 1.3762, lr: 0.0000\n",
      "Epoch: 421, Training loss: 1.362749, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 422, Training loss: 1.345320, Validation loss: 1.3762, lr: 0.0000\n",
      "Epoch: 423, Training loss: 1.376536, Validation loss: 1.3729, lr: 0.0000\n",
      "Epoch: 424, Training loss: 1.371051, Validation loss: 1.3686, lr: 0.0000\n",
      "Epoch: 425, Training loss: 1.371728, Validation loss: 1.3788, lr: 0.0000\n",
      "Epoch: 426, Training loss: 1.376454, Validation loss: 1.3799, lr: 0.0000\n",
      "Epoch: 427, Training loss: 1.383673, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 428, Training loss: 1.378394, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 429, Training loss: 1.363887, Validation loss: 1.3785, lr: 0.0000\n",
      "Epoch: 430, Training loss: 1.353915, Validation loss: 1.4500, lr: 0.0000\n",
      "Epoch: 431, Training loss: 1.351928, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 432, Training loss: 1.356947, Validation loss: 1.3692, lr: 0.0000\n",
      "Epoch: 433, Training loss: 1.338327, Validation loss: 1.3791, lr: 0.0000\n",
      "Epoch: 434, Training loss: 1.422358, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 435, Training loss: 1.352483, Validation loss: 1.3685, lr: 0.0000\n",
      "Epoch: 436, Training loss: 1.373863, Validation loss: 1.3704, lr: 0.0000\n",
      "Epoch: 437, Training loss: 1.347753, Validation loss: 1.3783, lr: 0.0000\n",
      "Epoch: 438, Training loss: 1.367681, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 439, Training loss: 1.339685, Validation loss: 1.3719, lr: 0.0000\n",
      "Epoch: 440, Training loss: 1.353889, Validation loss: 1.3697, lr: 0.0000\n",
      "Epoch: 441, Training loss: 1.338853, Validation loss: 1.3688, lr: 0.0000\n",
      "Epoch: 442, Training loss: 1.369663, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 443, Training loss: 1.395216, Validation loss: 1.3789, lr: 0.0000\n",
      "Epoch: 444, Training loss: 1.364787, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 445, Training loss: 1.374058, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 446, Training loss: 1.334970, Validation loss: 1.3730, lr: 0.0000\n",
      "Epoch: 447, Training loss: 1.347796, Validation loss: 1.3743, lr: 0.0000\n",
      "Epoch: 448, Training loss: 1.346854, Validation loss: 1.3762, lr: 0.0000\n",
      "Epoch: 449, Training loss: 1.381588, Validation loss: 1.3752, lr: 0.0000\n",
      "Epoch: 450, Training loss: 1.463300, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 451, Training loss: 1.395662, Validation loss: 1.3733, lr: 0.0000\n",
      "Epoch: 452, Training loss: 1.371801, Validation loss: 1.3729, lr: 0.0000\n",
      "Epoch: 453, Training loss: 1.379241, Validation loss: 1.3875, lr: 0.0000\n",
      "Epoch: 454, Training loss: 1.381248, Validation loss: 1.3748, lr: 0.0000\n",
      "Epoch: 455, Training loss: 1.356495, Validation loss: 1.3771, lr: 0.0000\n",
      "Epoch: 456, Training loss: 1.351758, Validation loss: 1.3714, lr: 0.0000\n",
      "Epoch: 457, Training loss: 1.366126, Validation loss: 1.3671, lr: 0.0000\n",
      "Epoch: 458, Training loss: 1.368938, Validation loss: 1.3681, lr: 0.0000\n",
      "Epoch: 459, Training loss: 1.338601, Validation loss: 1.3770, lr: 0.0000\n",
      "Epoch: 460, Training loss: 1.361609, Validation loss: 1.3782, lr: 0.0000\n",
      "Epoch: 461, Training loss: 1.349718, Validation loss: 1.3782, lr: 0.0000\n",
      "Epoch: 462, Training loss: 1.345627, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 463, Training loss: 1.371311, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 464, Training loss: 1.364131, Validation loss: 1.3791, lr: 0.0000\n",
      "Epoch: 465, Training loss: 1.384563, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 466, Training loss: 1.362922, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 467, Training loss: 1.359162, Validation loss: 1.3791, lr: 0.0000\n",
      "Epoch: 468, Training loss: 1.381609, Validation loss: 1.4063, lr: 0.0000\n",
      "Epoch: 469, Training loss: 1.322065, Validation loss: 1.3762, lr: 0.0000\n",
      "Epoch: 470, Training loss: 1.455920, Validation loss: 1.3662, lr: 0.0000\n",
      "Epoch: 471, Training loss: 1.367512, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 472, Training loss: 1.336970, Validation loss: 1.3723, lr: 0.0000\n",
      "Epoch: 473, Training loss: 1.363520, Validation loss: 1.3896, lr: 0.0000\n",
      "Epoch: 474, Training loss: 1.359158, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 475, Training loss: 1.376874, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 476, Training loss: 1.342655, Validation loss: 1.3682, lr: 0.0000\n",
      "Epoch: 477, Training loss: 1.348085, Validation loss: 1.3793, lr: 0.0000\n",
      "Epoch: 478, Training loss: 1.371878, Validation loss: 1.3796, lr: 0.0000\n",
      "Epoch: 479, Training loss: 1.420506, Validation loss: 1.3775, lr: 0.0000\n",
      "Epoch: 480, Training loss: 1.347148, Validation loss: 1.3785, lr: 0.0000\n",
      "Epoch: 481, Training loss: 1.398315, Validation loss: 1.3915, lr: 0.0000\n",
      "Epoch: 482, Training loss: 1.368304, Validation loss: 1.3760, lr: 0.0000\n",
      "Epoch: 483, Training loss: 1.354667, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 484, Training loss: 1.352169, Validation loss: 1.3790, lr: 0.0000\n",
      "Epoch: 485, Training loss: 1.353411, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 486, Training loss: 1.393963, Validation loss: 1.3746, lr: 0.0000\n",
      "Epoch: 487, Training loss: 1.339243, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 488, Training loss: 1.358992, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 489, Training loss: 1.375055, Validation loss: 1.3657, lr: 0.0000\n",
      "Epoch: 490, Training loss: 1.355311, Validation loss: 1.3757, lr: 0.0000\n",
      "Epoch: 491, Training loss: 1.359805, Validation loss: 1.3744, lr: 0.0000\n",
      "Epoch: 492, Training loss: 1.348856, Validation loss: 1.3550, lr: 0.0000\n",
      "Epoch: 493, Training loss: 1.372174, Validation loss: 1.3564, lr: 0.0000\n",
      "Epoch: 494, Training loss: 1.362729, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 495, Training loss: 1.356021, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 496, Training loss: 1.377951, Validation loss: 1.3766, lr: 0.0000\n",
      "Epoch: 497, Training loss: 1.382212, Validation loss: 1.3874, lr: 0.0000\n",
      "Epoch: 498, Training loss: 1.349336, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 499, Training loss: 1.363000, Validation loss: 1.3788, lr: 0.0000\n",
      "Epoch: 500, Training loss: 1.394413, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 501, Training loss: 1.370714, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 502, Training loss: 1.375731, Validation loss: 1.3713, lr: 0.0000\n",
      "Epoch: 503, Training loss: 1.374350, Validation loss: 1.3562, lr: 0.0000\n",
      "Epoch: 504, Training loss: 1.329699, Validation loss: 1.3759, lr: 0.0000\n",
      "Epoch: 505, Training loss: 1.388280, Validation loss: 1.3738, lr: 0.0000\n",
      "Epoch: 506, Training loss: 1.366177, Validation loss: 1.3673, lr: 0.0000\n",
      "Epoch: 507, Training loss: 1.363560, Validation loss: 1.3790, lr: 0.0000\n",
      "Epoch: 508, Training loss: 1.358554, Validation loss: 1.3783, lr: 0.0000\n",
      "Epoch: 509, Training loss: 1.352703, Validation loss: 1.3782, lr: 0.0000\n",
      "Epoch: 510, Training loss: 1.329691, Validation loss: 1.3792, lr: 0.0000\n",
      "Epoch: 511, Training loss: 1.356267, Validation loss: 1.3712, lr: 0.0000\n",
      "Epoch: 512, Training loss: 1.339827, Validation loss: 1.3554, lr: 0.0000\n",
      "Epoch: 513, Training loss: 1.356323, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 514, Training loss: 1.367068, Validation loss: 1.3767, lr: 0.0000\n",
      "Epoch: 515, Training loss: 1.346666, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 516, Training loss: 1.358690, Validation loss: 1.3796, lr: 0.0000\n",
      "Epoch: 517, Training loss: 1.370856, Validation loss: 1.3767, lr: 0.0000\n",
      "Epoch: 518, Training loss: 1.362819, Validation loss: 1.3739, lr: 0.0000\n",
      "Epoch: 519, Training loss: 1.343957, Validation loss: 1.3777, lr: 0.0000\n",
      "Epoch: 520, Training loss: 1.347448, Validation loss: 1.3770, lr: 0.0000\n",
      "Epoch: 521, Training loss: 1.344381, Validation loss: 1.3723, lr: 0.0000\n",
      "Epoch: 522, Training loss: 1.381333, Validation loss: 1.4805, lr: 0.0000\n",
      "Epoch: 523, Training loss: 1.366683, Validation loss: 1.3809, lr: 0.0000\n",
      "Epoch: 524, Training loss: 1.391452, Validation loss: 1.3720, lr: 0.0000\n",
      "Epoch: 525, Training loss: 1.344675, Validation loss: 1.3731, lr: 0.0000\n",
      "Epoch: 526, Training loss: 1.374560, Validation loss: 1.3464, lr: 0.0000\n",
      "Epoch: 527, Training loss: 1.367875, Validation loss: 1.3643, lr: 0.0000\n",
      "Epoch: 528, Training loss: 1.362960, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 529, Training loss: 1.360533, Validation loss: 1.3720, lr: 0.0000\n",
      "Epoch: 530, Training loss: 1.347106, Validation loss: 1.3777, lr: 0.0000\n",
      "Epoch: 531, Training loss: 1.348842, Validation loss: 1.3742, lr: 0.0000\n",
      "Epoch: 532, Training loss: 1.353464, Validation loss: 1.3794, lr: 0.0000\n",
      "Epoch: 533, Training loss: 1.378719, Validation loss: 1.3771, lr: 0.0000\n",
      "Epoch: 534, Training loss: 1.380138, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 535, Training loss: 1.372417, Validation loss: 1.3727, lr: 0.0000\n",
      "Epoch: 536, Training loss: 1.372247, Validation loss: 1.3685, lr: 0.0000\n",
      "Epoch: 537, Training loss: 1.381875, Validation loss: 1.3742, lr: 0.0000\n",
      "Epoch: 538, Training loss: 1.339182, Validation loss: 1.3696, lr: 0.0000\n",
      "Epoch: 539, Training loss: 1.378037, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 540, Training loss: 1.335290, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 541, Training loss: 1.332833, Validation loss: 1.3780, lr: 0.0000\n",
      "Epoch: 542, Training loss: 1.352612, Validation loss: 1.3672, lr: 0.0000\n",
      "Epoch: 543, Training loss: 1.358373, Validation loss: 1.3665, lr: 0.0000\n",
      "Epoch: 544, Training loss: 1.360400, Validation loss: 1.3592, lr: 0.0000\n",
      "Epoch: 545, Training loss: 1.361846, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 546, Training loss: 1.368227, Validation loss: 1.3878, lr: 0.0000\n",
      "Epoch: 547, Training loss: 1.366463, Validation loss: 1.3710, lr: 0.0000\n",
      "Epoch: 548, Training loss: 1.372465, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 549, Training loss: 1.375103, Validation loss: 1.4056, lr: 0.0000\n",
      "Epoch: 550, Training loss: 1.349936, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 551, Training loss: 1.425970, Validation loss: 1.3778, lr: 0.0000\n",
      "Epoch: 552, Training loss: 1.382592, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 553, Training loss: 1.372857, Validation loss: 1.3735, lr: 0.0000\n",
      "Epoch: 554, Training loss: 1.328912, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 555, Training loss: 1.351800, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 556, Training loss: 1.366521, Validation loss: 1.3514, lr: 0.0000\n",
      "Epoch: 557, Training loss: 1.376116, Validation loss: 1.3641, lr: 0.0000\n",
      "Epoch: 558, Training loss: 1.349027, Validation loss: 1.3784, lr: 0.0000\n",
      "Epoch: 559, Training loss: 1.359942, Validation loss: 1.3654, lr: 0.0000\n",
      "Epoch: 560, Training loss: 1.349557, Validation loss: 1.3699, lr: 0.0000\n",
      "Epoch: 561, Training loss: 1.367083, Validation loss: 1.3704, lr: 0.0000\n",
      "Epoch: 562, Training loss: 1.376079, Validation loss: 1.3746, lr: 0.0000\n",
      "Epoch: 563, Training loss: 1.322196, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 564, Training loss: 1.380444, Validation loss: 1.3726, lr: 0.0000\n",
      "Epoch: 565, Training loss: 1.332922, Validation loss: 1.3795, lr: 0.0000\n",
      "Epoch: 566, Training loss: 1.365454, Validation loss: 1.3775, lr: 0.0000\n",
      "Epoch: 567, Training loss: 1.365337, Validation loss: 1.3803, lr: 0.0000\n",
      "Epoch: 568, Training loss: 1.371464, Validation loss: 1.3789, lr: 0.0000\n",
      "Epoch: 569, Training loss: 1.362279, Validation loss: 1.3614, lr: 0.0000\n",
      "Epoch: 570, Training loss: 1.358282, Validation loss: 1.3733, lr: 0.0000\n",
      "Epoch: 571, Training loss: 1.379493, Validation loss: 1.3713, lr: 0.0000\n",
      "Epoch: 572, Training loss: 1.359802, Validation loss: 1.3771, lr: 0.0000\n",
      "Epoch: 573, Training loss: 1.355105, Validation loss: 1.3670, lr: 0.0000\n",
      "Epoch: 574, Training loss: 1.357169, Validation loss: 1.3788, lr: 0.0000\n",
      "Epoch: 575, Training loss: 1.348848, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 576, Training loss: 1.349253, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 577, Training loss: 1.341577, Validation loss: 1.3631, lr: 0.0000\n",
      "Epoch: 578, Training loss: 1.386863, Validation loss: 1.3771, lr: 0.0000\n",
      "Epoch: 579, Training loss: 1.382121, Validation loss: 1.3743, lr: 0.0000\n",
      "Epoch: 580, Training loss: 1.361533, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 581, Training loss: 1.394977, Validation loss: 1.4122, lr: 0.0000\n",
      "Epoch: 582, Training loss: 1.351426, Validation loss: 1.3372, lr: 0.0000\n",
      "Epoch: 583, Training loss: 1.345659, Validation loss: 1.3595, lr: 0.0000\n",
      "Epoch: 584, Training loss: 1.361032, Validation loss: 1.3746, lr: 0.0000\n",
      "Epoch: 585, Training loss: 1.367437, Validation loss: 1.3728, lr: 0.0000\n",
      "Epoch: 586, Training loss: 1.345521, Validation loss: 1.3677, lr: 0.0000\n",
      "Epoch: 587, Training loss: 1.383836, Validation loss: 1.3920, lr: 0.0000\n",
      "Epoch: 588, Training loss: 1.339213, Validation loss: 1.3800, lr: 0.0000\n",
      "Epoch: 589, Training loss: 1.378745, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 590, Training loss: 1.334698, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 591, Training loss: 1.381835, Validation loss: 1.3786, lr: 0.0000\n",
      "Epoch: 592, Training loss: 1.361036, Validation loss: 1.3792, lr: 0.0000\n",
      "Epoch: 593, Training loss: 1.363438, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 594, Training loss: 1.347420, Validation loss: 1.4347, lr: 0.0000\n",
      "Epoch: 595, Training loss: 1.369724, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 596, Training loss: 1.356282, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 597, Training loss: 1.352655, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 598, Training loss: 1.366053, Validation loss: 1.3785, lr: 0.0000\n",
      "Epoch: 599, Training loss: 1.370768, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 600, Training loss: 1.400741, Validation loss: 1.3699, lr: 0.0000\n",
      "Epoch: 601, Training loss: 1.396581, Validation loss: 1.3769, lr: 0.0000\n",
      "Epoch: 602, Training loss: 1.346399, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 603, Training loss: 1.363019, Validation loss: 1.3802, lr: 0.0000\n",
      "Epoch: 604, Training loss: 1.363065, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 605, Training loss: 1.363332, Validation loss: 1.4173, lr: 0.0000\n",
      "Epoch: 606, Training loss: 1.396031, Validation loss: 1.3797, lr: 0.0000\n",
      "Epoch: 607, Training loss: 1.387350, Validation loss: 1.3798, lr: 0.0000\n",
      "Epoch: 608, Training loss: 1.375017, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 609, Training loss: 1.394398, Validation loss: 1.3792, lr: 0.0000\n",
      "Epoch: 610, Training loss: 1.354642, Validation loss: 1.3568, lr: 0.0000\n",
      "Epoch: 611, Training loss: 1.352078, Validation loss: 1.3780, lr: 0.0000\n",
      "Epoch: 612, Training loss: 1.395499, Validation loss: 1.3602, lr: 0.0000\n",
      "Epoch: 613, Training loss: 1.355328, Validation loss: 1.3791, lr: 0.0000\n",
      "Epoch: 614, Training loss: 1.347249, Validation loss: 1.3629, lr: 0.0000\n",
      "Epoch: 615, Training loss: 1.361674, Validation loss: 1.3773, lr: 0.0000\n",
      "Epoch: 616, Training loss: 1.384869, Validation loss: 1.3726, lr: 0.0000\n",
      "Epoch: 617, Training loss: 1.391882, Validation loss: 1.3730, lr: 0.0000\n",
      "Epoch: 618, Training loss: 1.370144, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 619, Training loss: 1.359468, Validation loss: 1.3792, lr: 0.0000\n",
      "Epoch: 620, Training loss: 1.366749, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 621, Training loss: 1.363642, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 622, Training loss: 1.390686, Validation loss: 1.3800, lr: 0.0000\n",
      "Epoch: 623, Training loss: 1.329811, Validation loss: 1.3732, lr: 0.0000\n",
      "Epoch: 624, Training loss: 1.377184, Validation loss: 1.3655, lr: 0.0000\n",
      "Epoch: 625, Training loss: 1.362952, Validation loss: 1.3696, lr: 0.0000\n",
      "Epoch: 626, Training loss: 1.345423, Validation loss: 1.3711, lr: 0.0000\n",
      "Epoch: 627, Training loss: 1.351919, Validation loss: 1.3721, lr: 0.0000\n",
      "Epoch: 628, Training loss: 1.346503, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 629, Training loss: 1.383556, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 630, Training loss: 1.355580, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 631, Training loss: 1.361841, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 632, Training loss: 1.341913, Validation loss: 1.3760, lr: 0.0000\n",
      "Epoch: 633, Training loss: 1.403075, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 634, Training loss: 1.341883, Validation loss: 1.3779, lr: 0.0000\n",
      "Epoch: 635, Training loss: 1.351175, Validation loss: 1.3878, lr: 0.0000\n",
      "Epoch: 636, Training loss: 1.346789, Validation loss: 1.3778, lr: 0.0000\n",
      "Epoch: 637, Training loss: 1.405958, Validation loss: 1.3757, lr: 0.0000\n",
      "Epoch: 638, Training loss: 1.366959, Validation loss: 1.3789, lr: 0.0000\n",
      "Epoch: 639, Training loss: 1.370982, Validation loss: 1.3766, lr: 0.0000\n",
      "Epoch: 640, Training loss: 1.355775, Validation loss: 1.3809, lr: 0.0000\n",
      "Epoch: 641, Training loss: 1.354982, Validation loss: 1.3792, lr: 0.0000\n",
      "Epoch: 642, Training loss: 1.349240, Validation loss: 1.3717, lr: 0.0000\n",
      "Epoch: 643, Training loss: 1.350245, Validation loss: 1.3691, lr: 0.0000\n",
      "Epoch: 644, Training loss: 1.346860, Validation loss: 1.3724, lr: 0.0000\n",
      "Epoch: 645, Training loss: 1.371401, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 646, Training loss: 1.364163, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 647, Training loss: 1.347095, Validation loss: 1.3761, lr: 0.0000\n",
      "Epoch: 648, Training loss: 1.330693, Validation loss: 1.3779, lr: 0.0000\n",
      "Epoch: 649, Training loss: 1.353629, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 650, Training loss: 1.318632, Validation loss: 1.3741, lr: 0.0000\n",
      "Epoch: 651, Training loss: 1.338656, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 652, Training loss: 1.354949, Validation loss: 1.3703, lr: 0.0000\n",
      "Epoch: 653, Training loss: 1.358011, Validation loss: 1.3795, lr: 0.0000\n",
      "Epoch: 654, Training loss: 1.394243, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 655, Training loss: 1.366448, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 656, Training loss: 1.376388, Validation loss: 1.3470, lr: 0.0000\n",
      "Epoch: 657, Training loss: 1.337639, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 658, Training loss: 1.340998, Validation loss: 1.3712, lr: 0.0000\n",
      "Epoch: 659, Training loss: 1.326277, Validation loss: 1.3988, lr: 0.0000\n",
      "Epoch: 660, Training loss: 1.362470, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 661, Training loss: 1.352817, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 662, Training loss: 1.352396, Validation loss: 1.3760, lr: 0.0000\n",
      "Epoch: 663, Training loss: 1.354880, Validation loss: 1.4153, lr: 0.0000\n",
      "Epoch: 664, Training loss: 1.353954, Validation loss: 1.3771, lr: 0.0000\n",
      "Epoch: 665, Training loss: 1.346645, Validation loss: 1.3789, lr: 0.0000\n",
      "Epoch: 666, Training loss: 1.354765, Validation loss: 1.3890, lr: 0.0000\n",
      "Epoch: 667, Training loss: 1.362868, Validation loss: 1.3714, lr: 0.0000\n",
      "Epoch: 668, Training loss: 1.353594, Validation loss: 1.3760, lr: 0.0000\n",
      "Epoch: 669, Training loss: 1.347753, Validation loss: 1.4438, lr: 0.0000\n",
      "Epoch: 670, Training loss: 1.368301, Validation loss: 1.3701, lr: 0.0000\n",
      "Epoch: 671, Training loss: 1.359770, Validation loss: 1.3577, lr: 0.0000\n",
      "Epoch: 672, Training loss: 1.343499, Validation loss: 1.3761, lr: 0.0000\n",
      "Epoch: 673, Training loss: 1.372420, Validation loss: 1.3782, lr: 0.0000\n",
      "Epoch: 674, Training loss: 1.369340, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 675, Training loss: 1.332194, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 676, Training loss: 1.372962, Validation loss: 1.3951, lr: 0.0000\n",
      "Epoch: 677, Training loss: 1.348356, Validation loss: 1.3721, lr: 0.0000\n",
      "Epoch: 678, Training loss: 1.382018, Validation loss: 1.3594, lr: 0.0000\n",
      "Epoch: 679, Training loss: 1.363919, Validation loss: 1.3771, lr: 0.0000\n",
      "Epoch: 680, Training loss: 1.358751, Validation loss: 1.3795, lr: 0.0000\n",
      "Epoch: 681, Training loss: 1.371459, Validation loss: 1.3555, lr: 0.0000\n",
      "Epoch: 682, Training loss: 1.384637, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 683, Training loss: 1.378011, Validation loss: 1.3729, lr: 0.0000\n",
      "Epoch: 684, Training loss: 1.354190, Validation loss: 1.3748, lr: 0.0000\n",
      "Epoch: 685, Training loss: 1.372556, Validation loss: 1.3797, lr: 0.0000\n",
      "Epoch: 686, Training loss: 1.376905, Validation loss: 1.3761, lr: 0.0000\n",
      "Epoch: 687, Training loss: 1.345429, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 688, Training loss: 1.362918, Validation loss: 1.3946, lr: 0.0000\n",
      "Epoch: 689, Training loss: 1.343147, Validation loss: 1.3688, lr: 0.0000\n",
      "Epoch: 690, Training loss: 1.354842, Validation loss: 1.3450, lr: 0.0000\n",
      "Epoch: 691, Training loss: 1.397967, Validation loss: 1.3724, lr: 0.0000\n",
      "Epoch: 692, Training loss: 1.373974, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 693, Training loss: 1.344071, Validation loss: 1.3466, lr: 0.0000\n",
      "Epoch: 694, Training loss: 1.364039, Validation loss: 1.3999, lr: 0.0000\n",
      "Epoch: 695, Training loss: 1.343293, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 696, Training loss: 1.390885, Validation loss: 1.3600, lr: 0.0000\n",
      "Epoch: 697, Training loss: 1.389465, Validation loss: 1.3661, lr: 0.0000\n",
      "Epoch: 698, Training loss: 1.378793, Validation loss: 1.3748, lr: 0.0000\n",
      "Epoch: 699, Training loss: 1.372468, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 700, Training loss: 1.363488, Validation loss: 1.3769, lr: 0.0000\n",
      "Epoch: 701, Training loss: 1.353467, Validation loss: 1.3771, lr: 0.0000\n",
      "Epoch: 702, Training loss: 1.364518, Validation loss: 1.3649, lr: 0.0000\n",
      "Epoch: 703, Training loss: 1.346669, Validation loss: 1.3678, lr: 0.0000\n",
      "Epoch: 704, Training loss: 1.369156, Validation loss: 1.3752, lr: 0.0000\n",
      "Epoch: 705, Training loss: 1.359451, Validation loss: 1.3962, lr: 0.0000\n",
      "Epoch: 706, Training loss: 1.364827, Validation loss: 1.3700, lr: 0.0000\n",
      "Epoch: 707, Training loss: 1.360917, Validation loss: 1.3748, lr: 0.0000\n",
      "Epoch: 708, Training loss: 1.353940, Validation loss: 1.3672, lr: 0.0000\n",
      "Epoch: 709, Training loss: 1.386463, Validation loss: 1.3779, lr: 0.0000\n",
      "Epoch: 710, Training loss: 1.364364, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 711, Training loss: 1.355151, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 712, Training loss: 1.353013, Validation loss: 1.3756, lr: 0.0000\n",
      "Epoch: 713, Training loss: 1.340877, Validation loss: 1.3666, lr: 0.0000\n",
      "Epoch: 714, Training loss: 1.363950, Validation loss: 1.3580, lr: 0.0000\n",
      "Epoch: 715, Training loss: 1.375406, Validation loss: 1.3786, lr: 0.0000\n",
      "Epoch: 716, Training loss: 1.348953, Validation loss: 1.3718, lr: 0.0000\n",
      "Epoch: 717, Training loss: 1.351898, Validation loss: 1.3692, lr: 0.0000\n",
      "Epoch: 718, Training loss: 1.363381, Validation loss: 1.3767, lr: 0.0000\n",
      "Epoch: 719, Training loss: 1.370656, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 720, Training loss: 1.359168, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 721, Training loss: 1.373213, Validation loss: 1.3713, lr: 0.0000\n",
      "Epoch: 722, Training loss: 1.400922, Validation loss: 1.3721, lr: 0.0000\n",
      "Epoch: 723, Training loss: 1.373507, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 724, Training loss: 1.356767, Validation loss: 1.3721, lr: 0.0000\n",
      "Epoch: 725, Training loss: 1.367844, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 726, Training loss: 1.368958, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 727, Training loss: 1.365879, Validation loss: 1.3798, lr: 0.0000\n",
      "Epoch: 728, Training loss: 1.391327, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 729, Training loss: 1.341898, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 730, Training loss: 1.326394, Validation loss: 1.3767, lr: 0.0000\n",
      "Epoch: 731, Training loss: 1.352307, Validation loss: 1.3878, lr: 0.0000\n",
      "Epoch: 732, Training loss: 1.371312, Validation loss: 1.3779, lr: 0.0000\n",
      "Epoch: 733, Training loss: 1.328431, Validation loss: 1.3785, lr: 0.0000\n",
      "Epoch: 734, Training loss: 1.359329, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 735, Training loss: 1.368919, Validation loss: 1.3727, lr: 0.0000\n",
      "Epoch: 736, Training loss: 1.347525, Validation loss: 1.3758, lr: 0.0000\n",
      "Epoch: 737, Training loss: 1.364490, Validation loss: 1.3784, lr: 0.0000\n",
      "Epoch: 738, Training loss: 1.343101, Validation loss: 1.3782, lr: 0.0000\n",
      "Epoch: 739, Training loss: 1.348623, Validation loss: 1.3670, lr: 0.0000\n",
      "Epoch: 740, Training loss: 1.384209, Validation loss: 1.3896, lr: 0.0000\n",
      "Epoch: 741, Training loss: 1.355127, Validation loss: 1.3600, lr: 0.0000\n",
      "Epoch: 742, Training loss: 1.361648, Validation loss: 1.3349, lr: 0.0000\n",
      "Epoch: 743, Training loss: 1.473624, Validation loss: 1.3780, lr: 0.0000\n",
      "Epoch: 744, Training loss: 1.382104, Validation loss: 1.3579, lr: 0.0000\n",
      "Epoch: 745, Training loss: 1.370754, Validation loss: 1.3671, lr: 0.0000\n",
      "Epoch: 746, Training loss: 1.383677, Validation loss: 1.3720, lr: 0.0000\n",
      "Epoch: 747, Training loss: 1.363637, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 748, Training loss: 1.375503, Validation loss: 1.3703, lr: 0.0000\n",
      "Epoch: 749, Training loss: 1.379556, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 750, Training loss: 1.356408, Validation loss: 1.3746, lr: 0.0000\n",
      "Epoch: 751, Training loss: 1.341203, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 752, Training loss: 1.362733, Validation loss: 1.3748, lr: 0.0000\n",
      "Epoch: 753, Training loss: 1.346958, Validation loss: 1.3922, lr: 0.0000\n",
      "Epoch: 754, Training loss: 1.339248, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 755, Training loss: 1.361819, Validation loss: 1.3796, lr: 0.0000\n",
      "Epoch: 756, Training loss: 1.359729, Validation loss: 1.3874, lr: 0.0000\n",
      "Epoch: 757, Training loss: 1.373352, Validation loss: 1.3745, lr: 0.0000\n",
      "Epoch: 758, Training loss: 1.348736, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 759, Training loss: 1.326102, Validation loss: 1.3677, lr: 0.0000\n",
      "Epoch: 760, Training loss: 1.370323, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 761, Training loss: 1.353594, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 762, Training loss: 1.342082, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 763, Training loss: 1.348677, Validation loss: 1.3635, lr: 0.0000\n",
      "Epoch: 764, Training loss: 1.364396, Validation loss: 1.3893, lr: 0.0000\n",
      "Epoch: 765, Training loss: 1.360873, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 766, Training loss: 1.354065, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 767, Training loss: 1.359287, Validation loss: 1.3784, lr: 0.0000\n",
      "Epoch: 768, Training loss: 1.341857, Validation loss: 1.3768, lr: 0.0000\n",
      "Epoch: 769, Training loss: 1.347938, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 770, Training loss: 1.355138, Validation loss: 1.3792, lr: 0.0000\n",
      "Epoch: 771, Training loss: 1.375730, Validation loss: 1.3740, lr: 0.0000\n",
      "Epoch: 772, Training loss: 1.360585, Validation loss: 1.3762, lr: 0.0000\n",
      "Epoch: 773, Training loss: 1.384793, Validation loss: 1.3704, lr: 0.0000\n",
      "Epoch: 774, Training loss: 1.344797, Validation loss: 1.3582, lr: 0.0000\n",
      "Epoch: 775, Training loss: 1.358721, Validation loss: 1.3584, lr: 0.0000\n",
      "Epoch: 776, Training loss: 1.361534, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 777, Training loss: 1.359090, Validation loss: 1.3775, lr: 0.0000\n",
      "Epoch: 778, Training loss: 1.340096, Validation loss: 1.3749, lr: 0.0000\n",
      "Epoch: 779, Training loss: 1.378914, Validation loss: 1.3639, lr: 0.0000\n",
      "Epoch: 780, Training loss: 1.354207, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 781, Training loss: 1.347984, Validation loss: 1.3397, lr: 0.0000\n",
      "Epoch: 782, Training loss: 1.356430, Validation loss: 1.3795, lr: 0.0000\n",
      "Epoch: 783, Training loss: 1.335047, Validation loss: 1.3642, lr: 0.0000\n",
      "Epoch: 784, Training loss: 1.365030, Validation loss: 1.3769, lr: 0.0000\n",
      "Epoch: 785, Training loss: 1.363079, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 786, Training loss: 1.361269, Validation loss: 1.3788, lr: 0.0000\n",
      "Epoch: 787, Training loss: 1.386791, Validation loss: 1.3708, lr: 0.0000\n",
      "Epoch: 788, Training loss: 1.338302, Validation loss: 1.3685, lr: 0.0000\n",
      "Epoch: 789, Training loss: 1.362112, Validation loss: 1.3753, lr: 0.0000\n",
      "Epoch: 790, Training loss: 1.377487, Validation loss: 1.3726, lr: 0.0000\n",
      "Epoch: 791, Training loss: 1.372627, Validation loss: 1.3683, lr: 0.0000\n",
      "Epoch: 792, Training loss: 1.356941, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 793, Training loss: 1.372487, Validation loss: 1.3725, lr: 0.0000\n",
      "Epoch: 794, Training loss: 1.366890, Validation loss: 1.3709, lr: 0.0000\n",
      "Epoch: 795, Training loss: 1.393524, Validation loss: 1.3767, lr: 0.0000\n",
      "Epoch: 796, Training loss: 1.364649, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 797, Training loss: 1.348466, Validation loss: 1.3691, lr: 0.0000\n",
      "Epoch: 798, Training loss: 1.361430, Validation loss: 1.3678, lr: 0.0000\n",
      "Epoch: 799, Training loss: 1.387807, Validation loss: 1.3726, lr: 0.0000\n",
      "Epoch: 800, Training loss: 1.390045, Validation loss: 1.3607, lr: 0.0000\n",
      "Epoch: 801, Training loss: 1.371803, Validation loss: 1.3753, lr: 0.0000\n",
      "Epoch: 802, Training loss: 1.406231, Validation loss: 1.3769, lr: 0.0000\n",
      "Epoch: 803, Training loss: 1.368743, Validation loss: 1.3717, lr: 0.0000\n",
      "Epoch: 804, Training loss: 1.374951, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 805, Training loss: 1.356157, Validation loss: 1.3798, lr: 0.0000\n",
      "Epoch: 806, Training loss: 1.357827, Validation loss: 1.3803, lr: 0.0000\n",
      "Epoch: 807, Training loss: 1.382739, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 808, Training loss: 1.372242, Validation loss: 1.3697, lr: 0.0000\n",
      "Epoch: 809, Training loss: 1.358506, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 810, Training loss: 1.367994, Validation loss: 1.3917, lr: 0.0000\n",
      "Epoch: 811, Training loss: 1.371051, Validation loss: 1.3751, lr: 0.0000\n",
      "Epoch: 812, Training loss: 1.338185, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 813, Training loss: 1.370584, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 814, Training loss: 1.343364, Validation loss: 1.3785, lr: 0.0000\n",
      "Epoch: 815, Training loss: 1.361906, Validation loss: 1.3727, lr: 0.0000\n",
      "Epoch: 816, Training loss: 1.379522, Validation loss: 1.3748, lr: 0.0000\n",
      "Epoch: 817, Training loss: 1.365712, Validation loss: 1.3795, lr: 0.0000\n",
      "Epoch: 818, Training loss: 1.363247, Validation loss: 1.3739, lr: 0.0000\n",
      "Epoch: 819, Training loss: 1.360884, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 820, Training loss: 1.343420, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 821, Training loss: 1.407142, Validation loss: 1.3779, lr: 0.0000\n",
      "Epoch: 822, Training loss: 1.420745, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 823, Training loss: 1.354660, Validation loss: 1.3745, lr: 0.0000\n",
      "Epoch: 824, Training loss: 1.353203, Validation loss: 1.3651, lr: 0.0000\n",
      "Epoch: 825, Training loss: 1.368219, Validation loss: 1.3688, lr: 0.0000\n",
      "Epoch: 826, Training loss: 1.384433, Validation loss: 1.3681, lr: 0.0000\n",
      "Epoch: 827, Training loss: 1.342194, Validation loss: 1.3756, lr: 0.0000\n",
      "Epoch: 828, Training loss: 1.358149, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 829, Training loss: 1.376442, Validation loss: 1.3908, lr: 0.0000\n",
      "Epoch: 830, Training loss: 1.354375, Validation loss: 1.3720, lr: 0.0000\n",
      "Epoch: 831, Training loss: 1.376530, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 832, Training loss: 1.375161, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 833, Training loss: 1.361728, Validation loss: 1.3739, lr: 0.0000\n",
      "Epoch: 834, Training loss: 1.350886, Validation loss: 1.3694, lr: 0.0000\n",
      "Epoch: 835, Training loss: 1.320578, Validation loss: 1.3733, lr: 0.0000\n",
      "Epoch: 836, Training loss: 1.370190, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 837, Training loss: 1.336140, Validation loss: 1.3743, lr: 0.0000\n",
      "Epoch: 838, Training loss: 1.355268, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 839, Training loss: 1.350999, Validation loss: 1.3922, lr: 0.0000\n",
      "Epoch: 840, Training loss: 1.365751, Validation loss: 1.3775, lr: 0.0000\n",
      "Epoch: 841, Training loss: 1.371444, Validation loss: 1.3714, lr: 0.0000\n",
      "Epoch: 842, Training loss: 1.355664, Validation loss: 1.3648, lr: 0.0000\n",
      "Epoch: 843, Training loss: 1.398337, Validation loss: 1.3676, lr: 0.0000\n",
      "Epoch: 844, Training loss: 1.351045, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 845, Training loss: 1.415957, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 846, Training loss: 1.374808, Validation loss: 1.3699, lr: 0.0000\n",
      "Epoch: 847, Training loss: 1.383943, Validation loss: 1.3742, lr: 0.0000\n",
      "Epoch: 848, Training loss: 1.385489, Validation loss: 1.3787, lr: 0.0000\n",
      "Epoch: 849, Training loss: 1.350980, Validation loss: 1.3784, lr: 0.0000\n",
      "Epoch: 850, Training loss: 1.373062, Validation loss: 1.3765, lr: 0.0000\n",
      "Epoch: 851, Training loss: 1.353808, Validation loss: 1.3683, lr: 0.0000\n",
      "Epoch: 852, Training loss: 1.375269, Validation loss: 1.4034, lr: 0.0000\n",
      "Epoch: 853, Training loss: 1.367935, Validation loss: 1.3795, lr: 0.0000\n",
      "Epoch: 854, Training loss: 1.387760, Validation loss: 1.3730, lr: 0.0000\n",
      "Epoch: 855, Training loss: 1.353750, Validation loss: 1.3763, lr: 0.0000\n",
      "Epoch: 856, Training loss: 1.356246, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 857, Training loss: 1.349816, Validation loss: 1.3716, lr: 0.0000\n",
      "Epoch: 858, Training loss: 1.352261, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 859, Training loss: 1.408662, Validation loss: 1.3522, lr: 0.0000\n",
      "Epoch: 860, Training loss: 1.365528, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 861, Training loss: 1.367531, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 862, Training loss: 1.373591, Validation loss: 1.3621, lr: 0.0000\n",
      "Epoch: 863, Training loss: 1.340060, Validation loss: 1.3761, lr: 0.0000\n",
      "Epoch: 864, Training loss: 1.402228, Validation loss: 1.3595, lr: 0.0000\n",
      "Epoch: 865, Training loss: 1.338239, Validation loss: 1.3675, lr: 0.0000\n",
      "Epoch: 866, Training loss: 1.343485, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 867, Training loss: 1.342673, Validation loss: 1.3728, lr: 0.0000\n",
      "Epoch: 868, Training loss: 1.350430, Validation loss: 1.3757, lr: 0.0000\n",
      "Epoch: 869, Training loss: 1.322354, Validation loss: 1.3768, lr: 0.0000\n",
      "Epoch: 870, Training loss: 1.361074, Validation loss: 1.3739, lr: 0.0000\n",
      "Epoch: 871, Training loss: 1.355835, Validation loss: 1.3795, lr: 0.0000\n",
      "Epoch: 872, Training loss: 1.365407, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 873, Training loss: 1.370854, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 874, Training loss: 1.400083, Validation loss: 1.3596, lr: 0.0000\n",
      "Epoch: 875, Training loss: 1.423106, Validation loss: 1.4018, lr: 0.0000\n",
      "Epoch: 876, Training loss: 1.383641, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 877, Training loss: 1.375628, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 878, Training loss: 1.360577, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 879, Training loss: 1.349712, Validation loss: 1.3780, lr: 0.0000\n",
      "Epoch: 880, Training loss: 1.331320, Validation loss: 1.3758, lr: 0.0000\n",
      "Epoch: 881, Training loss: 1.351085, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 882, Training loss: 1.345366, Validation loss: 1.3646, lr: 0.0000\n",
      "Epoch: 883, Training loss: 1.334908, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 884, Training loss: 1.411064, Validation loss: 1.3691, lr: 0.0000\n",
      "Epoch: 885, Training loss: 1.360536, Validation loss: 1.3708, lr: 0.0000\n",
      "Epoch: 886, Training loss: 1.380398, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 887, Training loss: 1.358511, Validation loss: 1.3800, lr: 0.0000\n",
      "Epoch: 888, Training loss: 1.367457, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 889, Training loss: 1.342037, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 890, Training loss: 1.350317, Validation loss: 1.3501, lr: 0.0000\n",
      "Epoch: 891, Training loss: 1.364584, Validation loss: 1.3759, lr: 0.0000\n",
      "Epoch: 892, Training loss: 1.366841, Validation loss: 1.3728, lr: 0.0000\n",
      "Epoch: 893, Training loss: 1.364227, Validation loss: 1.3665, lr: 0.0000\n",
      "Epoch: 894, Training loss: 1.336555, Validation loss: 1.3602, lr: 0.0000\n",
      "Epoch: 895, Training loss: 1.377762, Validation loss: 1.3783, lr: 0.0000\n",
      "Epoch: 896, Training loss: 1.340341, Validation loss: 1.4326, lr: 0.0000\n",
      "Epoch: 897, Training loss: 1.352071, Validation loss: 1.3655, lr: 0.0000\n",
      "Epoch: 898, Training loss: 1.410124, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 899, Training loss: 1.368383, Validation loss: 1.3711, lr: 0.0000\n",
      "Epoch: 900, Training loss: 1.380380, Validation loss: 1.3735, lr: 0.0000\n",
      "Epoch: 901, Training loss: 1.406893, Validation loss: 1.3668, lr: 0.0000\n",
      "Epoch: 902, Training loss: 1.391112, Validation loss: 1.3760, lr: 0.0000\n",
      "Epoch: 903, Training loss: 1.347141, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 904, Training loss: 1.372481, Validation loss: 1.3728, lr: 0.0000\n",
      "Epoch: 905, Training loss: 1.359480, Validation loss: 1.3633, lr: 0.0000\n",
      "Epoch: 906, Training loss: 1.332749, Validation loss: 1.3672, lr: 0.0000\n",
      "Epoch: 907, Training loss: 1.369031, Validation loss: 1.3535, lr: 0.0000\n",
      "Epoch: 908, Training loss: 1.366389, Validation loss: 1.3742, lr: 0.0000\n",
      "Epoch: 909, Training loss: 1.377962, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 910, Training loss: 1.374828, Validation loss: 1.3782, lr: 0.0000\n",
      "Epoch: 911, Training loss: 1.390887, Validation loss: 1.3568, lr: 0.0000\n",
      "Epoch: 912, Training loss: 1.324861, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 913, Training loss: 1.371088, Validation loss: 1.4050, lr: 0.0000\n",
      "Epoch: 914, Training loss: 1.410929, Validation loss: 1.3726, lr: 0.0000\n",
      "Epoch: 915, Training loss: 1.448379, Validation loss: 1.3754, lr: 0.0000\n",
      "Epoch: 916, Training loss: 1.389521, Validation loss: 1.3622, lr: 0.0000\n",
      "Epoch: 917, Training loss: 1.390283, Validation loss: 1.3779, lr: 0.0000\n",
      "Epoch: 918, Training loss: 1.369555, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 919, Training loss: 1.358823, Validation loss: 1.3794, lr: 0.0000\n",
      "Epoch: 920, Training loss: 1.400785, Validation loss: 1.3639, lr: 0.0000\n",
      "Epoch: 921, Training loss: 1.348974, Validation loss: 1.3745, lr: 0.0000\n",
      "Epoch: 922, Training loss: 1.367238, Validation loss: 1.3766, lr: 0.0000\n",
      "Epoch: 923, Training loss: 1.343160, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 924, Training loss: 1.355635, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 925, Training loss: 1.367687, Validation loss: 1.3730, lr: 0.0000\n",
      "Epoch: 926, Training loss: 1.336889, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 927, Training loss: 1.390203, Validation loss: 1.3737, lr: 0.0000\n",
      "Epoch: 928, Training loss: 1.381473, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 929, Training loss: 1.370089, Validation loss: 1.3786, lr: 0.0000\n",
      "Epoch: 930, Training loss: 1.347194, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 931, Training loss: 1.390713, Validation loss: 1.3786, lr: 0.0000\n",
      "Epoch: 932, Training loss: 1.349528, Validation loss: 1.3786, lr: 0.0000\n",
      "Epoch: 933, Training loss: 1.374545, Validation loss: 1.3710, lr: 0.0000\n",
      "Epoch: 934, Training loss: 1.379391, Validation loss: 1.3779, lr: 0.0000\n",
      "Epoch: 935, Training loss: 1.354275, Validation loss: 1.3678, lr: 0.0000\n",
      "Epoch: 936, Training loss: 1.353397, Validation loss: 1.3700, lr: 0.0000\n",
      "Epoch: 937, Training loss: 1.370120, Validation loss: 1.3800, lr: 0.0000\n",
      "Epoch: 938, Training loss: 1.374160, Validation loss: 1.3784, lr: 0.0000\n",
      "Epoch: 939, Training loss: 1.342026, Validation loss: 1.3910, lr: 0.0000\n",
      "Epoch: 940, Training loss: 1.356491, Validation loss: 1.3773, lr: 0.0000\n",
      "Epoch: 941, Training loss: 1.427351, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 942, Training loss: 1.361403, Validation loss: 1.3802, lr: 0.0000\n",
      "Epoch: 943, Training loss: 1.366946, Validation loss: 1.3775, lr: 0.0000\n",
      "Epoch: 944, Training loss: 1.372550, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 945, Training loss: 1.378115, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 946, Training loss: 1.378391, Validation loss: 1.3783, lr: 0.0000\n",
      "Epoch: 947, Training loss: 1.346357, Validation loss: 1.3922, lr: 0.0000\n",
      "Epoch: 948, Training loss: 1.351069, Validation loss: 1.3771, lr: 0.0000\n",
      "Epoch: 949, Training loss: 1.361386, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 950, Training loss: 1.383505, Validation loss: 1.3791, lr: 0.0000\n",
      "Epoch: 951, Training loss: 1.361059, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 952, Training loss: 1.404145, Validation loss: 1.3661, lr: 0.0000\n",
      "Epoch: 953, Training loss: 1.343647, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 954, Training loss: 1.365263, Validation loss: 1.3770, lr: 0.0000\n",
      "Epoch: 955, Training loss: 1.352179, Validation loss: 1.3743, lr: 0.0000\n",
      "Epoch: 956, Training loss: 1.354117, Validation loss: 1.3675, lr: 0.0000\n",
      "Epoch: 957, Training loss: 1.350539, Validation loss: 1.3761, lr: 0.0000\n",
      "Epoch: 958, Training loss: 1.378780, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 959, Training loss: 1.366635, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 960, Training loss: 1.366899, Validation loss: 1.3659, lr: 0.0000\n",
      "Epoch: 961, Training loss: 1.366405, Validation loss: 1.3688, lr: 0.0000\n",
      "Epoch: 962, Training loss: 1.383576, Validation loss: 1.3623, lr: 0.0000\n",
      "Epoch: 963, Training loss: 1.378684, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 964, Training loss: 1.402742, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 965, Training loss: 1.359154, Validation loss: 1.3788, lr: 0.0000\n",
      "Epoch: 966, Training loss: 1.345102, Validation loss: 1.3901, lr: 0.0000\n",
      "Epoch: 967, Training loss: 1.389713, Validation loss: 1.3605, lr: 0.0000\n",
      "Epoch: 968, Training loss: 1.370064, Validation loss: 1.3713, lr: 0.0000\n",
      "Epoch: 969, Training loss: 1.378234, Validation loss: 1.3748, lr: 0.0000\n",
      "Epoch: 970, Training loss: 1.369149, Validation loss: 1.3727, lr: 0.0000\n",
      "Epoch: 971, Training loss: 1.368148, Validation loss: 1.3752, lr: 0.0000\n",
      "Epoch: 972, Training loss: 1.348754, Validation loss: 1.3791, lr: 0.0000\n",
      "Epoch: 973, Training loss: 1.380327, Validation loss: 1.3696, lr: 0.0000\n",
      "Epoch: 974, Training loss: 1.360264, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 975, Training loss: 1.344835, Validation loss: 1.3739, lr: 0.0000\n",
      "Epoch: 976, Training loss: 1.360786, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 977, Training loss: 1.352536, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 978, Training loss: 1.364457, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 979, Training loss: 1.374619, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 980, Training loss: 1.368868, Validation loss: 1.3792, lr: 0.0000\n",
      "Epoch: 981, Training loss: 1.361808, Validation loss: 1.3791, lr: 0.0000\n",
      "Epoch: 982, Training loss: 1.346508, Validation loss: 1.3749, lr: 0.0000\n",
      "Epoch: 983, Training loss: 1.362872, Validation loss: 1.3793, lr: 0.0000\n",
      "Epoch: 984, Training loss: 1.393802, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 985, Training loss: 1.387896, Validation loss: 1.3733, lr: 0.0000\n",
      "Epoch: 986, Training loss: 1.374049, Validation loss: 1.3733, lr: 0.0000\n",
      "Epoch: 987, Training loss: 1.353759, Validation loss: 1.3708, lr: 0.0000\n",
      "Epoch: 988, Training loss: 1.374572, Validation loss: 1.3803, lr: 0.0000\n",
      "Epoch: 989, Training loss: 1.366901, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 990, Training loss: 1.355428, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 991, Training loss: 1.357118, Validation loss: 1.3802, lr: 0.0000\n",
      "Epoch: 992, Training loss: 1.371718, Validation loss: 1.3787, lr: 0.0000\n",
      "Epoch: 993, Training loss: 1.355489, Validation loss: 1.3871, lr: 0.0000\n",
      "Epoch: 994, Training loss: 1.376542, Validation loss: 1.3752, lr: 0.0000\n",
      "Epoch: 995, Training loss: 1.331909, Validation loss: 1.4067, lr: 0.0000\n",
      "Epoch: 996, Training loss: 1.357354, Validation loss: 1.3791, lr: 0.0000\n",
      "Epoch: 997, Training loss: 1.396092, Validation loss: 1.3796, lr: 0.0000\n",
      "Epoch: 998, Training loss: 1.346147, Validation loss: 1.4299, lr: 0.0000\n",
      "Epoch: 999, Training loss: 1.365179, Validation loss: 1.3826, lr: 0.0000\n",
      "Final test loss: 1.3985\n",
      "=== Run 02/10 ===\n",
      "\n",
      "---- Settings: \n",
      "\n",
      "epochs : 1000\n",
      "hidden_channels : [32]\n",
      "out_channels : 10\n",
      "inner_product_features : False\n",
      "batch_size : 64\n",
      "lr : 0.01\n",
      "momentum : 0.9\n",
      "dropout : 0.0\n",
      "batch_norm : batch_norm\n",
      "bias : True\n",
      "order : 2\n",
      "diffusion : True\n",
      "frac_sampled_nb : -1\n",
      "include_positions : False\n",
      "include_self : True\n",
      "vec_norm : False\n",
      "emb_norm : False\n",
      "seed : 0\n",
      "dim_signal : 100\n",
      "dim_emb : 100\n",
      "n_sampled_nb : -1\n",
      "\n",
      "---- Number of features to pass to the MLP:  1010100\n",
      "---- Total number of parameters:  32323627\n",
      "\n",
      "Using device cuda:0\n",
      "\n",
      "---- Training network ...\n",
      "\n",
      "---- Timestamp: 20250614-085052\n",
      "\n",
      " *och: 0, Training loss: 1.408761, Validation loss: 1.3758, lr: 0.0100\n",
      "Epoch: 1, Training loss: 1.390332, Validation loss: 1.5265, lr: 0.0100\n",
      "Epoch: 2, Training loss: 1.385758, Validation loss: 1.3842, lr: 0.0100\n",
      "Epoch: 3, Training loss: 1.391036, Validation loss: 1.3962, lr: 0.0100\n",
      " *och: 4, Training loss: 1.438911, Validation loss: 1.3513, lr: 0.0100\n",
      "Epoch: 5, Training loss: 1.423538, Validation loss: 1.3885, lr: 0.0100\n",
      "Epoch: 6, Training loss: 1.389693, Validation loss: 1.3777, lr: 0.0100\n",
      "Epoch: 7, Training loss: 1.381129, Validation loss: 1.3948, lr: 0.0100\n",
      "Epoch: 8, Training loss: 1.354797, Validation loss: 1.3669, lr: 0.0100\n",
      "Epoch: 9, Training loss: 1.388608, Validation loss: 1.3548, lr: 0.0100\n",
      "Epoch: 10, Training loss: 1.391389, Validation loss: 1.3647, lr: 0.0100\n",
      "Epoch: 11, Training loss: 1.382440, Validation loss: 1.3805, lr: 0.0100\n",
      "Epoch: 12, Training loss: 1.405353, Validation loss: 1.3824, lr: 0.0100\n",
      "Epoch: 13, Training loss: 1.400118, Validation loss: 1.3861, lr: 0.0100\n",
      "Epoch: 14, Training loss: 1.377374, Validation loss: 1.3682, lr: 0.0100\n",
      "Epoch: 15, Training loss: 1.379878, Validation loss: 1.3905, lr: 0.0100\n",
      "Epoch: 16, Training loss: 1.402676, Validation loss: 1.3926, lr: 0.0100\n",
      "Epoch: 17, Training loss: 1.381648, Validation loss: 1.4038, lr: 0.0100\n",
      "Epoch: 18, Training loss: 1.393045, Validation loss: 1.3836, lr: 0.0100\n",
      "Epoch: 19, Training loss: 1.381553, Validation loss: 1.3576, lr: 0.0010\n",
      "Epoch: 20, Training loss: 1.387271, Validation loss: 1.3826, lr: 0.0010\n",
      "Epoch: 21, Training loss: 1.450362, Validation loss: 1.3731, lr: 0.0010\n",
      "Epoch: 22, Training loss: 1.409008, Validation loss: 1.3853, lr: 0.0010\n",
      "Epoch: 23, Training loss: 1.393297, Validation loss: 1.3807, lr: 0.0010\n",
      "Epoch: 24, Training loss: 1.389960, Validation loss: 1.3722, lr: 0.0010\n",
      "Epoch: 25, Training loss: 1.368123, Validation loss: 1.3544, lr: 0.0010\n",
      "Epoch: 26, Training loss: 1.376072, Validation loss: 1.3810, lr: 0.0010\n",
      "Epoch: 27, Training loss: 1.377223, Validation loss: 1.3863, lr: 0.0010\n",
      "Epoch: 28, Training loss: 1.411754, Validation loss: 1.3815, lr: 0.0010\n",
      "Epoch: 29, Training loss: 1.369538, Validation loss: 1.3787, lr: 0.0010\n",
      "Epoch: 30, Training loss: 1.391653, Validation loss: 1.4122, lr: 0.0001\n",
      "Epoch: 31, Training loss: 1.380658, Validation loss: 1.4225, lr: 0.0001\n",
      "Epoch: 32, Training loss: 1.406127, Validation loss: 1.4125, lr: 0.0001\n",
      "Epoch: 33, Training loss: 1.379195, Validation loss: 1.3843, lr: 0.0001\n",
      "Epoch: 34, Training loss: 1.386458, Validation loss: 1.3605, lr: 0.0001\n",
      "Epoch: 35, Training loss: 1.372704, Validation loss: 1.3878, lr: 0.0001\n",
      "Epoch: 36, Training loss: 1.366198, Validation loss: 1.3762, lr: 0.0001\n",
      "Epoch: 37, Training loss: 1.360652, Validation loss: 1.3637, lr: 0.0001\n",
      "Epoch: 38, Training loss: 1.382695, Validation loss: 1.3756, lr: 0.0001\n",
      " *och: 39, Training loss: 1.383312, Validation loss: 1.3416, lr: 0.0001\n",
      "Epoch: 40, Training loss: 1.402343, Validation loss: 1.3539, lr: 0.0001\n",
      "Epoch: 41, Training loss: 1.359417, Validation loss: 1.3896, lr: 0.0000\n",
      "Epoch: 42, Training loss: 1.372081, Validation loss: 1.3973, lr: 0.0000\n",
      "Epoch: 43, Training loss: 1.369883, Validation loss: 1.9127, lr: 0.0000\n",
      "Epoch: 44, Training loss: 1.392155, Validation loss: 1.3792, lr: 0.0000\n",
      "Epoch: 45, Training loss: 1.389348, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 46, Training loss: 1.383969, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 47, Training loss: 1.376610, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 48, Training loss: 1.387369, Validation loss: 1.5875, lr: 0.0000\n",
      "Epoch: 49, Training loss: 1.387700, Validation loss: 1.3963, lr: 0.0000\n",
      "Epoch: 50, Training loss: 1.387722, Validation loss: 1.3772, lr: 0.0000\n",
      "Epoch: 51, Training loss: 1.364329, Validation loss: 1.4053, lr: 0.0000\n",
      "Epoch: 52, Training loss: 1.377293, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 53, Training loss: 1.412960, Validation loss: 1.3786, lr: 0.0000\n",
      "Epoch: 54, Training loss: 1.382556, Validation loss: 1.3809, lr: 0.0000\n",
      "Epoch: 55, Training loss: 1.370016, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 56, Training loss: 1.446244, Validation loss: 1.3783, lr: 0.0000\n",
      "Epoch: 57, Training loss: 1.371295, Validation loss: 1.3998, lr: 0.0000\n",
      "Epoch: 58, Training loss: 1.393143, Validation loss: 1.3615, lr: 0.0000\n",
      "Epoch: 59, Training loss: 1.383025, Validation loss: 1.3693, lr: 0.0000\n",
      "Epoch: 60, Training loss: 1.364873, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 61, Training loss: 1.396363, Validation loss: 1.3790, lr: 0.0000\n",
      "Epoch: 62, Training loss: 1.373883, Validation loss: 1.3910, lr: 0.0000\n",
      "Epoch: 63, Training loss: 1.367356, Validation loss: 1.3802, lr: 0.0000\n",
      "Epoch: 64, Training loss: 1.373135, Validation loss: 1.3427, lr: 0.0000\n",
      "Epoch: 65, Training loss: 1.373736, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 66, Training loss: 1.393924, Validation loss: 1.3521, lr: 0.0000\n",
      "Epoch: 67, Training loss: 1.381611, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 68, Training loss: 1.371163, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 69, Training loss: 1.391062, Validation loss: 1.3669, lr: 0.0000\n",
      "Epoch: 70, Training loss: 1.391537, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 71, Training loss: 1.363163, Validation loss: 1.3643, lr: 0.0000\n",
      "Epoch: 72, Training loss: 1.396858, Validation loss: 1.3715, lr: 0.0000\n",
      "Epoch: 73, Training loss: 1.360590, Validation loss: 1.3650, lr: 0.0000\n",
      "Epoch: 74, Training loss: 1.420435, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 75, Training loss: 1.369055, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 76, Training loss: 1.376899, Validation loss: 1.3708, lr: 0.0000\n",
      "Epoch: 77, Training loss: 1.391642, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 78, Training loss: 1.358881, Validation loss: 1.4212, lr: 0.0000\n",
      "Epoch: 79, Training loss: 1.365380, Validation loss: 1.3673, lr: 0.0000\n",
      "Epoch: 80, Training loss: 1.450497, Validation loss: 1.3911, lr: 0.0000\n",
      "Epoch: 81, Training loss: 1.410412, Validation loss: 1.4037, lr: 0.0000\n",
      "Epoch: 82, Training loss: 1.408179, Validation loss: 1.3899, lr: 0.0000\n",
      "Epoch: 83, Training loss: 1.419865, Validation loss: 1.3797, lr: 0.0000\n",
      "Epoch: 84, Training loss: 1.368767, Validation loss: 1.3779, lr: 0.0000\n",
      "Epoch: 85, Training loss: 1.363351, Validation loss: 1.3721, lr: 0.0000\n",
      "Epoch: 86, Training loss: 1.385322, Validation loss: 1.3790, lr: 0.0000\n",
      "Epoch: 87, Training loss: 1.371468, Validation loss: 1.3728, lr: 0.0000\n",
      "Epoch: 88, Training loss: 1.364417, Validation loss: 1.3798, lr: 0.0000\n",
      "Epoch: 89, Training loss: 1.381517, Validation loss: 1.3773, lr: 0.0000\n",
      "Epoch: 90, Training loss: 1.367698, Validation loss: 1.3662, lr: 0.0000\n",
      "Epoch: 91, Training loss: 1.389657, Validation loss: 1.3879, lr: 0.0000\n",
      "Epoch: 92, Training loss: 1.368870, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 93, Training loss: 1.400924, Validation loss: 1.3903, lr: 0.0000\n",
      "Epoch: 94, Training loss: 1.363742, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 95, Training loss: 1.390870, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 96, Training loss: 1.382984, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 97, Training loss: 1.423242, Validation loss: 1.3878, lr: 0.0000\n",
      "Epoch: 98, Training loss: 1.373458, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 99, Training loss: 1.367157, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 100, Training loss: 1.372795, Validation loss: 1.3668, lr: 0.0000\n",
      "Epoch: 101, Training loss: 1.399027, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 102, Training loss: 1.407044, Validation loss: 1.3597, lr: 0.0000\n",
      "Epoch: 103, Training loss: 1.363357, Validation loss: 1.3809, lr: 0.0000\n",
      "Epoch: 104, Training loss: 1.405615, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 105, Training loss: 1.373589, Validation loss: 1.3628, lr: 0.0000\n",
      "Epoch: 106, Training loss: 1.367576, Validation loss: 1.3605, lr: 0.0000\n",
      "Epoch: 107, Training loss: 1.382320, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 108, Training loss: 1.384559, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 109, Training loss: 1.367123, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 110, Training loss: 1.411539, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 111, Training loss: 1.382451, Validation loss: 1.3793, lr: 0.0000\n",
      "Epoch: 112, Training loss: 1.437848, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 113, Training loss: 1.366554, Validation loss: 1.3702, lr: 0.0000\n",
      "Epoch: 114, Training loss: 1.372373, Validation loss: 1.4001, lr: 0.0000\n",
      "Epoch: 115, Training loss: 1.391155, Validation loss: 1.3908, lr: 0.0000\n",
      "Epoch: 116, Training loss: 1.387020, Validation loss: 1.3792, lr: 0.0000\n",
      "Epoch: 117, Training loss: 1.377576, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 118, Training loss: 1.448389, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 119, Training loss: 1.377364, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 120, Training loss: 1.403050, Validation loss: 1.3758, lr: 0.0000\n",
      "Epoch: 121, Training loss: 1.415708, Validation loss: 1.3771, lr: 0.0000\n",
      "Epoch: 122, Training loss: 1.382370, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 123, Training loss: 1.432294, Validation loss: 1.3895, lr: 0.0000\n",
      "Epoch: 124, Training loss: 1.366510, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 125, Training loss: 1.372977, Validation loss: 1.3646, lr: 0.0000\n",
      "Epoch: 126, Training loss: 1.438996, Validation loss: 1.3906, lr: 0.0000\n",
      "Epoch: 127, Training loss: 1.378196, Validation loss: 1.3752, lr: 0.0000\n",
      "Epoch: 128, Training loss: 1.383270, Validation loss: 1.3779, lr: 0.0000\n",
      "Epoch: 129, Training loss: 1.372919, Validation loss: 1.3713, lr: 0.0000\n",
      "Epoch: 130, Training loss: 1.367859, Validation loss: 1.3777, lr: 0.0000\n",
      "Epoch: 131, Training loss: 1.363571, Validation loss: 1.3948, lr: 0.0000\n",
      "Epoch: 132, Training loss: 1.381490, Validation loss: 1.3922, lr: 0.0000\n",
      "Epoch: 133, Training loss: 1.402759, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 134, Training loss: 1.347708, Validation loss: 1.3900, lr: 0.0000\n",
      "Epoch: 135, Training loss: 1.414095, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 136, Training loss: 1.362107, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 137, Training loss: 1.389712, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 138, Training loss: 1.390332, Validation loss: 1.3634, lr: 0.0000\n",
      "Epoch: 139, Training loss: 1.369176, Validation loss: 1.3591, lr: 0.0000\n",
      "Epoch: 140, Training loss: 1.372181, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 141, Training loss: 1.373419, Validation loss: 1.3802, lr: 0.0000\n",
      "Epoch: 142, Training loss: 1.390705, Validation loss: 1.3738, lr: 0.0000\n",
      "Epoch: 143, Training loss: 1.383741, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 144, Training loss: 1.360035, Validation loss: 1.3875, lr: 0.0000\n",
      "Epoch: 145, Training loss: 1.364481, Validation loss: 1.3657, lr: 0.0000\n",
      "Epoch: 146, Training loss: 1.394668, Validation loss: 1.3690, lr: 0.0000\n",
      "Epoch: 147, Training loss: 1.391218, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 148, Training loss: 1.374221, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 149, Training loss: 1.427774, Validation loss: 1.3943, lr: 0.0000\n",
      "Epoch: 150, Training loss: 1.378039, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 151, Training loss: 1.430400, Validation loss: 1.3749, lr: 0.0000\n",
      "Epoch: 152, Training loss: 1.351357, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 153, Training loss: 1.382754, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 154, Training loss: 1.369169, Validation loss: 1.3678, lr: 0.0000\n",
      "Epoch: 155, Training loss: 1.378738, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 156, Training loss: 1.376205, Validation loss: 1.3800, lr: 0.0000\n",
      "Epoch: 157, Training loss: 1.368008, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 158, Training loss: 1.457174, Validation loss: 1.3875, lr: 0.0000\n",
      "Epoch: 159, Training loss: 1.355265, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 160, Training loss: 1.395907, Validation loss: 1.3715, lr: 0.0000\n",
      "Epoch: 161, Training loss: 1.368411, Validation loss: 1.3872, lr: 0.0000\n",
      "Epoch: 162, Training loss: 1.374742, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 163, Training loss: 1.398918, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 164, Training loss: 1.370222, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 165, Training loss: 1.375789, Validation loss: 1.3888, lr: 0.0000\n",
      "Epoch: 166, Training loss: 1.359102, Validation loss: 1.3615, lr: 0.0000\n",
      "Epoch: 167, Training loss: 1.419626, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 168, Training loss: 1.386715, Validation loss: 1.3877, lr: 0.0000\n",
      "Epoch: 169, Training loss: 1.386396, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 170, Training loss: 1.391236, Validation loss: 1.3767, lr: 0.0000\n",
      "Epoch: 171, Training loss: 1.383534, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 172, Training loss: 1.488969, Validation loss: 1.4705, lr: 0.0000\n",
      "Epoch: 173, Training loss: 1.368654, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 174, Training loss: 1.395914, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 175, Training loss: 1.385173, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 176, Training loss: 1.372001, Validation loss: 1.3766, lr: 0.0000\n",
      "Epoch: 177, Training loss: 1.391334, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 178, Training loss: 1.366102, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 179, Training loss: 1.378529, Validation loss: 1.7975, lr: 0.0000\n",
      "Epoch: 180, Training loss: 1.396126, Validation loss: 1.4035, lr: 0.0000\n",
      "Epoch: 181, Training loss: 1.392184, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 182, Training loss: 1.379208, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 183, Training loss: 1.366937, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 184, Training loss: 1.389818, Validation loss: 1.3928, lr: 0.0000\n",
      "Epoch: 185, Training loss: 1.384725, Validation loss: 1.3785, lr: 0.0000\n",
      "Epoch: 186, Training loss: 1.366494, Validation loss: 1.3573, lr: 0.0000\n",
      "Epoch: 187, Training loss: 1.369396, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 188, Training loss: 1.367969, Validation loss: 1.3759, lr: 0.0000\n",
      "Epoch: 189, Training loss: 1.375080, Validation loss: 1.3719, lr: 0.0000\n",
      "Epoch: 190, Training loss: 1.376189, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 191, Training loss: 1.355738, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 192, Training loss: 1.367318, Validation loss: 1.3796, lr: 0.0000\n",
      "Epoch: 193, Training loss: 1.370958, Validation loss: 1.3698, lr: 0.0000\n",
      "Epoch: 194, Training loss: 1.372345, Validation loss: 1.3730, lr: 0.0000\n",
      "Epoch: 195, Training loss: 1.365820, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 196, Training loss: 1.360313, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 197, Training loss: 1.407230, Validation loss: 1.4367, lr: 0.0000\n",
      "Epoch: 198, Training loss: 1.455790, Validation loss: 1.3698, lr: 0.0000\n",
      "Epoch: 199, Training loss: 1.373945, Validation loss: 1.3993, lr: 0.0000\n",
      "Epoch: 200, Training loss: 1.358112, Validation loss: 1.3792, lr: 0.0000\n",
      "Epoch: 201, Training loss: 1.379472, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 202, Training loss: 1.360160, Validation loss: 1.3657, lr: 0.0000\n",
      "Epoch: 203, Training loss: 1.359619, Validation loss: 1.3874, lr: 0.0000\n",
      "Epoch: 204, Training loss: 1.447690, Validation loss: 1.3789, lr: 0.0000\n",
      "Epoch: 205, Training loss: 1.366993, Validation loss: 1.3745, lr: 0.0000\n",
      "Epoch: 206, Training loss: 1.369774, Validation loss: 1.3724, lr: 0.0000\n",
      "Epoch: 207, Training loss: 1.420796, Validation loss: 1.3556, lr: 0.0000\n",
      "Epoch: 208, Training loss: 1.373335, Validation loss: 1.3797, lr: 0.0000\n",
      "Epoch: 209, Training loss: 1.385710, Validation loss: 1.3964, lr: 0.0000\n",
      "Epoch: 210, Training loss: 1.417042, Validation loss: 1.3906, lr: 0.0000\n",
      "Epoch: 211, Training loss: 1.389979, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 212, Training loss: 1.374494, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 213, Training loss: 1.388363, Validation loss: 1.3715, lr: 0.0000\n",
      "Epoch: 214, Training loss: 1.378137, Validation loss: 1.4055, lr: 0.0000\n",
      "Epoch: 215, Training loss: 1.379573, Validation loss: 1.3883, lr: 0.0000\n",
      "Epoch: 216, Training loss: 1.380952, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 217, Training loss: 1.381605, Validation loss: 1.3799, lr: 0.0000\n",
      "Epoch: 218, Training loss: 1.372603, Validation loss: 1.3775, lr: 0.0000\n",
      "Epoch: 219, Training loss: 1.394723, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 220, Training loss: 1.383179, Validation loss: 1.3783, lr: 0.0000\n",
      "Epoch: 221, Training loss: 1.378817, Validation loss: 1.3877, lr: 0.0000\n",
      "Epoch: 222, Training loss: 1.379383, Validation loss: 1.3475, lr: 0.0000\n",
      "Epoch: 223, Training loss: 1.411861, Validation loss: 1.3608, lr: 0.0000\n",
      "Epoch: 224, Training loss: 1.384221, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 225, Training loss: 1.347367, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 226, Training loss: 1.392842, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 227, Training loss: 1.370016, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 228, Training loss: 1.435725, Validation loss: 1.3715, lr: 0.0000\n",
      "Epoch: 229, Training loss: 1.401889, Validation loss: 1.3580, lr: 0.0000\n",
      "Epoch: 230, Training loss: 1.367164, Validation loss: 1.3742, lr: 0.0000\n",
      "Epoch: 231, Training loss: 1.355563, Validation loss: 1.3940, lr: 0.0000\n",
      "Epoch: 232, Training loss: 1.376467, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 233, Training loss: 1.378120, Validation loss: 1.3897, lr: 0.0000\n",
      "Epoch: 234, Training loss: 1.379030, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 235, Training loss: 1.373562, Validation loss: 1.3932, lr: 0.0000\n",
      "Epoch: 236, Training loss: 1.374344, Validation loss: 1.3906, lr: 0.0000\n",
      "Epoch: 237, Training loss: 1.351692, Validation loss: 1.3893, lr: 0.0000\n",
      "Epoch: 238, Training loss: 1.391908, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 239, Training loss: 1.365935, Validation loss: 1.3798, lr: 0.0000\n",
      "Epoch: 240, Training loss: 1.386582, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 241, Training loss: 1.382879, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 242, Training loss: 1.391918, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 243, Training loss: 1.398954, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 244, Training loss: 1.382544, Validation loss: 1.3687, lr: 0.0000\n",
      "Epoch: 245, Training loss: 1.371594, Validation loss: 1.4790, lr: 0.0000\n",
      "Epoch: 246, Training loss: 1.380888, Validation loss: 1.3768, lr: 0.0000\n",
      "Epoch: 247, Training loss: 1.398756, Validation loss: 1.3710, lr: 0.0000\n",
      "Epoch: 248, Training loss: 1.375621, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 249, Training loss: 1.375997, Validation loss: 1.3873, lr: 0.0000\n",
      "Epoch: 250, Training loss: 1.365903, Validation loss: 1.3740, lr: 0.0000\n",
      "Epoch: 251, Training loss: 1.371909, Validation loss: 1.3875, lr: 0.0000\n",
      "Epoch: 252, Training loss: 1.381974, Validation loss: 1.3685, lr: 0.0000\n",
      "Epoch: 253, Training loss: 1.378485, Validation loss: 1.3788, lr: 0.0000\n",
      "Epoch: 254, Training loss: 1.378260, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 255, Training loss: 1.394397, Validation loss: 1.3762, lr: 0.0000\n",
      "Epoch: 256, Training loss: 1.394446, Validation loss: 1.5308, lr: 0.0000\n",
      "Epoch: 257, Training loss: 1.385110, Validation loss: 1.3702, lr: 0.0000\n",
      "Epoch: 258, Training loss: 1.410733, Validation loss: 1.3923, lr: 0.0000\n",
      "Epoch: 259, Training loss: 1.391844, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 260, Training loss: 1.372421, Validation loss: 1.3762, lr: 0.0000\n",
      "Epoch: 261, Training loss: 1.378264, Validation loss: 1.3856, lr: 0.0000\n",
      " *och: 262, Training loss: 1.358250, Validation loss: 1.3349, lr: 0.0000\n",
      "Epoch: 263, Training loss: 1.383168, Validation loss: 1.3613, lr: 0.0000\n",
      "Epoch: 264, Training loss: 1.361814, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 265, Training loss: 1.373648, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 266, Training loss: 1.373188, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 267, Training loss: 1.398735, Validation loss: 1.4013, lr: 0.0000\n",
      "Epoch: 268, Training loss: 1.374498, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 269, Training loss: 1.352161, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 270, Training loss: 1.384372, Validation loss: 1.3871, lr: 0.0000\n",
      "Epoch: 271, Training loss: 1.389202, Validation loss: 1.3691, lr: 0.0000\n",
      "Epoch: 272, Training loss: 1.410028, Validation loss: 1.3778, lr: 0.0000\n",
      "Epoch: 273, Training loss: 1.392462, Validation loss: 1.3922, lr: 0.0000\n",
      "Epoch: 274, Training loss: 1.387131, Validation loss: 1.3893, lr: 0.0000\n",
      "Epoch: 275, Training loss: 1.376516, Validation loss: 1.3884, lr: 0.0000\n",
      "Epoch: 276, Training loss: 1.358702, Validation loss: 1.3794, lr: 0.0000\n",
      "Epoch: 277, Training loss: 1.370915, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 278, Training loss: 1.383127, Validation loss: 1.3898, lr: 0.0000\n",
      "Epoch: 279, Training loss: 1.374949, Validation loss: 1.3786, lr: 0.0000\n",
      "Epoch: 280, Training loss: 1.393556, Validation loss: 1.3734, lr: 0.0000\n",
      "Epoch: 281, Training loss: 1.385451, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 282, Training loss: 1.386142, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 283, Training loss: 1.396114, Validation loss: 1.3747, lr: 0.0000\n",
      "Epoch: 284, Training loss: 1.387757, Validation loss: 1.3736, lr: 0.0000\n",
      "Epoch: 285, Training loss: 1.399349, Validation loss: 1.4805, lr: 0.0000\n",
      "Epoch: 286, Training loss: 1.386181, Validation loss: 1.3751, lr: 0.0000\n",
      "Epoch: 287, Training loss: 1.364814, Validation loss: 1.3736, lr: 0.0000\n",
      "Epoch: 288, Training loss: 1.377033, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 289, Training loss: 1.362095, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 290, Training loss: 1.362891, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 291, Training loss: 1.383491, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 292, Training loss: 1.369502, Validation loss: 1.3785, lr: 0.0000\n",
      "Epoch: 293, Training loss: 1.437884, Validation loss: 1.3584, lr: 0.0000\n",
      "Epoch: 294, Training loss: 1.377231, Validation loss: 1.3769, lr: 0.0000\n",
      "Epoch: 295, Training loss: 1.389144, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 296, Training loss: 1.375440, Validation loss: 1.3611, lr: 0.0000\n",
      "Epoch: 297, Training loss: 1.408194, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 298, Training loss: 1.387982, Validation loss: 1.3902, lr: 0.0000\n",
      "Epoch: 299, Training loss: 1.379390, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 300, Training loss: 1.396708, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 301, Training loss: 1.378474, Validation loss: 1.3797, lr: 0.0000\n",
      "Epoch: 302, Training loss: 1.402930, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 303, Training loss: 1.391360, Validation loss: 1.3764, lr: 0.0000\n",
      "Epoch: 304, Training loss: 1.369325, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 305, Training loss: 1.371470, Validation loss: 1.3793, lr: 0.0000\n",
      "Epoch: 306, Training loss: 1.394774, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 307, Training loss: 1.394453, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 308, Training loss: 1.362808, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 309, Training loss: 1.420736, Validation loss: 1.3782, lr: 0.0000\n",
      "Epoch: 310, Training loss: 1.375701, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 311, Training loss: 1.359285, Validation loss: 1.3734, lr: 0.0000\n",
      "Epoch: 312, Training loss: 1.358905, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 313, Training loss: 1.391335, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 314, Training loss: 1.382736, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 315, Training loss: 1.372102, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 316, Training loss: 1.392537, Validation loss: 1.3923, lr: 0.0000\n",
      "Epoch: 317, Training loss: 1.379327, Validation loss: 1.3789, lr: 0.0000\n",
      "Epoch: 318, Training loss: 1.380534, Validation loss: 1.4090, lr: 0.0000\n",
      "Epoch: 319, Training loss: 1.493545, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 320, Training loss: 1.364759, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 321, Training loss: 1.354223, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 322, Training loss: 1.396077, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 323, Training loss: 1.357944, Validation loss: 1.3945, lr: 0.0000\n",
      "Epoch: 324, Training loss: 1.391008, Validation loss: 1.3762, lr: 0.0000\n",
      "Epoch: 325, Training loss: 1.500206, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 326, Training loss: 1.373288, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 327, Training loss: 1.388908, Validation loss: 1.3751, lr: 0.0000\n",
      "Epoch: 328, Training loss: 1.380946, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 329, Training loss: 1.381746, Validation loss: 1.3947, lr: 0.0000\n",
      "Epoch: 330, Training loss: 1.376204, Validation loss: 1.3935, lr: 0.0000\n",
      "Epoch: 331, Training loss: 1.510203, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 332, Training loss: 1.374180, Validation loss: 1.3765, lr: 0.0000\n",
      "Epoch: 333, Training loss: 1.418564, Validation loss: 1.3731, lr: 0.0000\n",
      "Epoch: 334, Training loss: 1.383665, Validation loss: 1.3696, lr: 0.0000\n",
      "Epoch: 335, Training loss: 1.376510, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 336, Training loss: 1.367351, Validation loss: 1.3650, lr: 0.0000\n",
      "Epoch: 337, Training loss: 1.379651, Validation loss: 1.3932, lr: 0.0000\n",
      "Epoch: 338, Training loss: 1.377893, Validation loss: 1.3877, lr: 0.0000\n",
      "Epoch: 339, Training loss: 1.374186, Validation loss: 1.3796, lr: 0.0000\n",
      "Epoch: 340, Training loss: 1.387479, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 341, Training loss: 1.364701, Validation loss: 1.3889, lr: 0.0000\n",
      "Epoch: 342, Training loss: 1.374477, Validation loss: 1.3914, lr: 0.0000\n",
      "Epoch: 343, Training loss: 1.371629, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 344, Training loss: 1.367081, Validation loss: 1.4657, lr: 0.0000\n",
      "Epoch: 345, Training loss: 1.369556, Validation loss: 1.3766, lr: 0.0000\n",
      "Epoch: 346, Training loss: 1.390220, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 347, Training loss: 1.392650, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 348, Training loss: 1.372292, Validation loss: 1.3701, lr: 0.0000\n",
      "Epoch: 349, Training loss: 1.362421, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 350, Training loss: 1.381663, Validation loss: 1.3789, lr: 0.0000\n",
      "Epoch: 351, Training loss: 1.379506, Validation loss: 1.3751, lr: 0.0000\n",
      "Epoch: 352, Training loss: 1.384520, Validation loss: 1.3690, lr: 0.0000\n",
      "Epoch: 353, Training loss: 1.380921, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 354, Training loss: 1.361257, Validation loss: 1.3715, lr: 0.0000\n",
      "Epoch: 355, Training loss: 1.348584, Validation loss: 1.3731, lr: 0.0000\n",
      "Epoch: 356, Training loss: 1.367257, Validation loss: 1.4215, lr: 0.0000\n",
      "Epoch: 357, Training loss: 1.369670, Validation loss: 1.3785, lr: 0.0000\n",
      "Epoch: 358, Training loss: 1.398279, Validation loss: 1.3754, lr: 0.0000\n",
      "Epoch: 359, Training loss: 1.394925, Validation loss: 1.3719, lr: 0.0000\n",
      "Epoch: 360, Training loss: 1.393442, Validation loss: 1.3712, lr: 0.0000\n",
      "Epoch: 361, Training loss: 1.377698, Validation loss: 1.3744, lr: 0.0000\n",
      "Epoch: 362, Training loss: 1.391451, Validation loss: 1.4211, lr: 0.0000\n",
      "Epoch: 363, Training loss: 1.380046, Validation loss: 1.3757, lr: 0.0000\n",
      "Epoch: 364, Training loss: 1.387783, Validation loss: 1.3974, lr: 0.0000\n",
      "Epoch: 365, Training loss: 1.382950, Validation loss: 1.3633, lr: 0.0000\n",
      "Epoch: 366, Training loss: 1.385635, Validation loss: 1.3771, lr: 0.0000\n",
      "Epoch: 367, Training loss: 1.360382, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 368, Training loss: 1.380141, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 369, Training loss: 1.363115, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 370, Training loss: 1.357481, Validation loss: 1.3951, lr: 0.0000\n",
      "Epoch: 371, Training loss: 1.373086, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 372, Training loss: 1.362626, Validation loss: 1.3741, lr: 0.0000\n",
      "Epoch: 373, Training loss: 1.399839, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 374, Training loss: 1.387067, Validation loss: 1.3809, lr: 0.0000\n",
      "Epoch: 375, Training loss: 1.407703, Validation loss: 1.4019, lr: 0.0000\n",
      "Epoch: 376, Training loss: 1.370846, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 377, Training loss: 1.380631, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 378, Training loss: 1.397212, Validation loss: 1.3759, lr: 0.0000\n",
      "Epoch: 379, Training loss: 1.395015, Validation loss: 1.3978, lr: 0.0000\n",
      "Epoch: 380, Training loss: 1.407144, Validation loss: 1.3799, lr: 0.0000\n",
      "Epoch: 381, Training loss: 1.373666, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 382, Training loss: 1.364726, Validation loss: 1.3796, lr: 0.0000\n",
      "Epoch: 383, Training loss: 1.363965, Validation loss: 1.3447, lr: 0.0000\n",
      "Epoch: 384, Training loss: 1.387893, Validation loss: 1.3887, lr: 0.0000\n",
      "Epoch: 385, Training loss: 1.407958, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 386, Training loss: 1.404346, Validation loss: 1.3928, lr: 0.0000\n",
      "Epoch: 387, Training loss: 1.379003, Validation loss: 1.3597, lr: 0.0000\n",
      "Epoch: 388, Training loss: 1.400969, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 389, Training loss: 1.398151, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 390, Training loss: 1.374170, Validation loss: 1.3931, lr: 0.0000\n",
      "Epoch: 391, Training loss: 1.383455, Validation loss: 1.3761, lr: 0.0000\n",
      "Epoch: 392, Training loss: 1.379816, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 393, Training loss: 1.373805, Validation loss: 1.3755, lr: 0.0000\n",
      "Epoch: 394, Training loss: 1.347841, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 395, Training loss: 1.359498, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 396, Training loss: 1.356449, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 397, Training loss: 1.362622, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 398, Training loss: 1.537496, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 399, Training loss: 1.375158, Validation loss: 1.3773, lr: 0.0000\n",
      "Epoch: 400, Training loss: 1.380640, Validation loss: 1.4139, lr: 0.0000\n",
      "Epoch: 401, Training loss: 1.371762, Validation loss: 1.3750, lr: 0.0000\n",
      "Epoch: 402, Training loss: 1.389638, Validation loss: 1.3944, lr: 0.0000\n",
      "Epoch: 403, Training loss: 1.376354, Validation loss: 1.3886, lr: 0.0000\n",
      "Epoch: 404, Training loss: 1.398141, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 405, Training loss: 1.393039, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 406, Training loss: 1.365540, Validation loss: 1.3770, lr: 0.0000\n",
      "Epoch: 407, Training loss: 1.369956, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 408, Training loss: 1.375820, Validation loss: 1.3725, lr: 0.0000\n",
      "Epoch: 409, Training loss: 1.391765, Validation loss: 1.4170, lr: 0.0000\n",
      "Epoch: 410, Training loss: 1.387558, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 411, Training loss: 1.403304, Validation loss: 1.3718, lr: 0.0000\n",
      "Epoch: 412, Training loss: 1.392737, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 413, Training loss: 1.370834, Validation loss: 1.3613, lr: 0.0000\n",
      "Epoch: 414, Training loss: 1.390900, Validation loss: 1.3896, lr: 0.0000\n",
      "Epoch: 415, Training loss: 1.383080, Validation loss: 1.3755, lr: 0.0000\n",
      "Epoch: 416, Training loss: 1.361274, Validation loss: 1.3762, lr: 0.0000\n",
      "Epoch: 417, Training loss: 1.357995, Validation loss: 1.3976, lr: 0.0000\n",
      "Epoch: 418, Training loss: 1.376531, Validation loss: 1.3906, lr: 0.0000\n",
      "Epoch: 419, Training loss: 1.375883, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 420, Training loss: 1.443296, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 421, Training loss: 1.378576, Validation loss: 1.3969, lr: 0.0000\n",
      "Epoch: 422, Training loss: 1.391515, Validation loss: 1.4159, lr: 0.0000\n",
      "Epoch: 423, Training loss: 1.394149, Validation loss: 1.3796, lr: 0.0000\n",
      "Epoch: 424, Training loss: 1.370737, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 425, Training loss: 1.357191, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 426, Training loss: 1.399233, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 427, Training loss: 1.380056, Validation loss: 1.3778, lr: 0.0000\n",
      "Epoch: 428, Training loss: 1.363650, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 429, Training loss: 1.386866, Validation loss: 1.3809, lr: 0.0000\n",
      "Epoch: 430, Training loss: 1.398366, Validation loss: 1.3580, lr: 0.0000\n",
      "Epoch: 431, Training loss: 1.382727, Validation loss: 1.3797, lr: 0.0000\n",
      "Epoch: 432, Training loss: 1.381211, Validation loss: 1.3698, lr: 0.0000\n",
      "Epoch: 433, Training loss: 1.374634, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 434, Training loss: 1.379809, Validation loss: 1.3884, lr: 0.0000\n",
      "Epoch: 435, Training loss: 1.405525, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 436, Training loss: 1.386517, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 437, Training loss: 1.377280, Validation loss: 1.3622, lr: 0.0000\n",
      "Epoch: 438, Training loss: 1.441377, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 439, Training loss: 1.370463, Validation loss: 1.3895, lr: 0.0000\n",
      "Epoch: 440, Training loss: 1.379295, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 441, Training loss: 1.362109, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 442, Training loss: 1.379971, Validation loss: 1.3762, lr: 0.0000\n",
      "Epoch: 443, Training loss: 1.388188, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 444, Training loss: 1.372150, Validation loss: 1.3695, lr: 0.0000\n",
      "Epoch: 445, Training loss: 1.389488, Validation loss: 1.3663, lr: 0.0000\n",
      "Epoch: 446, Training loss: 1.378316, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 447, Training loss: 1.382477, Validation loss: 1.4048, lr: 0.0000\n",
      "Epoch: 448, Training loss: 1.377140, Validation loss: 1.3713, lr: 0.0000\n",
      "Epoch: 449, Training loss: 1.384490, Validation loss: 1.3715, lr: 0.0000\n",
      "Epoch: 450, Training loss: 1.385894, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 451, Training loss: 1.407260, Validation loss: 1.3873, lr: 0.0000\n",
      "Epoch: 452, Training loss: 1.392565, Validation loss: 1.3714, lr: 0.0000\n",
      "Epoch: 453, Training loss: 1.392730, Validation loss: 1.3611, lr: 0.0000\n",
      "Epoch: 454, Training loss: 1.361845, Validation loss: 1.4432, lr: 0.0000\n",
      "Epoch: 455, Training loss: 1.376681, Validation loss: 1.3482, lr: 0.0000\n",
      "Epoch: 456, Training loss: 1.453757, Validation loss: 1.3768, lr: 0.0000\n",
      "Epoch: 457, Training loss: 1.388888, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 458, Training loss: 1.387782, Validation loss: 1.3781, lr: 0.0000\n",
      "Epoch: 459, Training loss: 1.396151, Validation loss: 1.5903, lr: 0.0000\n",
      "Epoch: 460, Training loss: 1.376860, Validation loss: 1.3892, lr: 0.0000\n",
      "Epoch: 461, Training loss: 1.401937, Validation loss: 1.3791, lr: 0.0000\n",
      "Epoch: 462, Training loss: 1.374973, Validation loss: 1.3497, lr: 0.0000\n",
      "Epoch: 463, Training loss: 1.433078, Validation loss: 1.3964, lr: 0.0000\n",
      "Epoch: 464, Training loss: 1.394608, Validation loss: 1.4070, lr: 0.0000\n",
      "Epoch: 465, Training loss: 1.374190, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 466, Training loss: 1.400564, Validation loss: 1.3793, lr: 0.0000\n",
      "Epoch: 467, Training loss: 1.365115, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 468, Training loss: 1.370739, Validation loss: 1.3978, lr: 0.0000\n",
      "Epoch: 469, Training loss: 1.376675, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 470, Training loss: 1.407826, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 471, Training loss: 1.369266, Validation loss: 1.3670, lr: 0.0000\n",
      "Epoch: 472, Training loss: 1.359588, Validation loss: 1.3930, lr: 0.0000\n",
      "Epoch: 473, Training loss: 1.398121, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 474, Training loss: 1.372058, Validation loss: 1.3761, lr: 0.0000\n",
      "Epoch: 475, Training loss: 1.456267, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 476, Training loss: 1.360625, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 477, Training loss: 1.405140, Validation loss: 1.3736, lr: 0.0000\n",
      "Epoch: 478, Training loss: 1.445199, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 479, Training loss: 1.383966, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 480, Training loss: 1.389531, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 481, Training loss: 1.405250, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 482, Training loss: 1.389661, Validation loss: 1.3906, lr: 0.0000\n",
      "Epoch: 483, Training loss: 1.385434, Validation loss: 1.3728, lr: 0.0000\n",
      "Epoch: 484, Training loss: 1.368906, Validation loss: 1.3654, lr: 0.0000\n",
      "Epoch: 485, Training loss: 1.387575, Validation loss: 1.3666, lr: 0.0000\n",
      "Epoch: 486, Training loss: 1.428645, Validation loss: 1.3754, lr: 0.0000\n",
      "Epoch: 487, Training loss: 1.388083, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 488, Training loss: 1.369976, Validation loss: 1.3897, lr: 0.0000\n",
      "Epoch: 489, Training loss: 1.380038, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 490, Training loss: 1.372513, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 491, Training loss: 1.368507, Validation loss: 1.3880, lr: 0.0000\n",
      "Epoch: 492, Training loss: 1.363810, Validation loss: 1.3595, lr: 0.0000\n",
      "Epoch: 493, Training loss: 1.371315, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 494, Training loss: 1.388466, Validation loss: 1.3780, lr: 0.0000\n",
      "Epoch: 495, Training loss: 1.372799, Validation loss: 1.3715, lr: 0.0000\n",
      "Epoch: 496, Training loss: 1.377957, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 497, Training loss: 1.390478, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 498, Training loss: 1.395637, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 499, Training loss: 1.374165, Validation loss: 1.3622, lr: 0.0000\n",
      "Epoch: 500, Training loss: 1.405308, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 501, Training loss: 1.389191, Validation loss: 1.3544, lr: 0.0000\n",
      "Epoch: 502, Training loss: 1.373350, Validation loss: 1.4120, lr: 0.0000\n",
      "Epoch: 503, Training loss: 1.403912, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 504, Training loss: 1.377350, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 505, Training loss: 1.383091, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 506, Training loss: 1.365903, Validation loss: 1.3689, lr: 0.0000\n",
      "Epoch: 507, Training loss: 1.417051, Validation loss: 1.3800, lr: 0.0000\n",
      "Epoch: 508, Training loss: 1.365092, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 509, Training loss: 1.380520, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 510, Training loss: 1.383744, Validation loss: 1.3877, lr: 0.0000\n",
      "Epoch: 511, Training loss: 1.394203, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 512, Training loss: 1.358518, Validation loss: 1.3719, lr: 0.0000\n",
      "Epoch: 513, Training loss: 1.366251, Validation loss: 1.3531, lr: 0.0000\n",
      "Epoch: 514, Training loss: 1.391894, Validation loss: 1.3887, lr: 0.0000\n",
      "Epoch: 515, Training loss: 1.374104, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 516, Training loss: 1.362249, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 517, Training loss: 1.364881, Validation loss: 1.3893, lr: 0.0000\n",
      "Epoch: 518, Training loss: 1.412308, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 519, Training loss: 1.375655, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 520, Training loss: 1.412229, Validation loss: 1.3780, lr: 0.0000\n",
      "Epoch: 521, Training loss: 1.361764, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 522, Training loss: 1.375628, Validation loss: 1.3669, lr: 0.0000\n",
      "Epoch: 523, Training loss: 1.377986, Validation loss: 1.3789, lr: 0.0000\n",
      "Epoch: 524, Training loss: 1.373228, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 525, Training loss: 1.408359, Validation loss: 1.3790, lr: 0.0000\n",
      "Epoch: 526, Training loss: 1.400293, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 527, Training loss: 1.408256, Validation loss: 1.3790, lr: 0.0000\n",
      "Epoch: 528, Training loss: 1.427186, Validation loss: 1.3763, lr: 0.0000\n",
      "Epoch: 529, Training loss: 1.366572, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 530, Training loss: 1.371014, Validation loss: 1.3884, lr: 0.0000\n",
      "Epoch: 531, Training loss: 1.373469, Validation loss: 1.4133, lr: 0.0000\n",
      "Epoch: 532, Training loss: 1.382328, Validation loss: 1.3740, lr: 0.0000\n",
      "Epoch: 533, Training loss: 1.402343, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 534, Training loss: 1.436932, Validation loss: 1.3741, lr: 0.0000\n",
      "Epoch: 535, Training loss: 1.387313, Validation loss: 1.3781, lr: 0.0000\n",
      "Epoch: 536, Training loss: 1.357290, Validation loss: 1.3676, lr: 0.0000\n",
      "Epoch: 537, Training loss: 1.380788, Validation loss: 1.3709, lr: 0.0000\n",
      "Epoch: 538, Training loss: 1.379849, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 539, Training loss: 1.384151, Validation loss: 1.3799, lr: 0.0000\n",
      "Epoch: 540, Training loss: 1.393430, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 541, Training loss: 1.363394, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 542, Training loss: 1.387739, Validation loss: 1.3757, lr: 0.0000\n",
      "Epoch: 543, Training loss: 1.386914, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 544, Training loss: 1.388205, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 545, Training loss: 1.364438, Validation loss: 1.3727, lr: 0.0000\n",
      "Epoch: 546, Training loss: 1.385981, Validation loss: 1.3726, lr: 0.0000\n",
      "Epoch: 547, Training loss: 1.374793, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 548, Training loss: 1.383346, Validation loss: 1.3784, lr: 0.0000\n",
      "Epoch: 549, Training loss: 1.374360, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 550, Training loss: 1.374697, Validation loss: 1.3896, lr: 0.0000\n",
      "Epoch: 551, Training loss: 1.404822, Validation loss: 1.3742, lr: 0.0000\n",
      "Epoch: 552, Training loss: 1.365965, Validation loss: 1.3709, lr: 0.0000\n",
      "Epoch: 553, Training loss: 1.392085, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 554, Training loss: 1.373354, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 555, Training loss: 1.366443, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 556, Training loss: 1.402616, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 557, Training loss: 1.368170, Validation loss: 1.3695, lr: 0.0000\n",
      "Epoch: 558, Training loss: 1.438090, Validation loss: 1.3871, lr: 0.0000\n",
      "Epoch: 559, Training loss: 1.389097, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 560, Training loss: 1.357265, Validation loss: 1.3638, lr: 0.0000\n",
      "Epoch: 561, Training loss: 1.428466, Validation loss: 1.3782, lr: 0.0000\n",
      "Epoch: 562, Training loss: 1.410594, Validation loss: 1.3787, lr: 0.0000\n",
      "Epoch: 563, Training loss: 1.362849, Validation loss: 1.3894, lr: 0.0000\n",
      "Epoch: 564, Training loss: 1.384143, Validation loss: 1.3514, lr: 0.0000\n",
      "Epoch: 565, Training loss: 1.386943, Validation loss: 1.3687, lr: 0.0000\n",
      "Epoch: 566, Training loss: 1.392296, Validation loss: 1.3788, lr: 0.0000\n",
      "Epoch: 567, Training loss: 1.356343, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 568, Training loss: 1.388806, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 569, Training loss: 1.361134, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 570, Training loss: 1.380848, Validation loss: 1.3775, lr: 0.0000\n",
      "Epoch: 571, Training loss: 1.362015, Validation loss: 1.4377, lr: 0.0000\n",
      "Epoch: 572, Training loss: 1.383348, Validation loss: 1.3698, lr: 0.0000\n",
      "Epoch: 573, Training loss: 1.462751, Validation loss: 1.3789, lr: 0.0000\n",
      "Epoch: 574, Training loss: 1.389865, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 575, Training loss: 1.389378, Validation loss: 1.3749, lr: 0.0000\n",
      "Epoch: 576, Training loss: 1.394613, Validation loss: 1.3914, lr: 0.0000\n",
      "Epoch: 577, Training loss: 1.365191, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 578, Training loss: 1.370195, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 579, Training loss: 1.376916, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 580, Training loss: 1.348293, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 581, Training loss: 1.383998, Validation loss: 1.3768, lr: 0.0000\n",
      "Epoch: 582, Training loss: 1.391369, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 583, Training loss: 1.372039, Validation loss: 1.3766, lr: 0.0000\n",
      "Epoch: 584, Training loss: 1.377043, Validation loss: 1.3673, lr: 0.0000\n",
      "Epoch: 585, Training loss: 1.384915, Validation loss: 1.3901, lr: 0.0000\n",
      "Epoch: 586, Training loss: 1.364375, Validation loss: 1.3769, lr: 0.0000\n",
      "Epoch: 587, Training loss: 1.375421, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 588, Training loss: 1.381769, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 589, Training loss: 1.388821, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 590, Training loss: 1.396763, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 591, Training loss: 1.437816, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 592, Training loss: 1.381915, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 593, Training loss: 1.387385, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 594, Training loss: 1.365018, Validation loss: 1.3773, lr: 0.0000\n",
      "Epoch: 595, Training loss: 1.388619, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 596, Training loss: 1.384830, Validation loss: 1.4059, lr: 0.0000\n",
      "Epoch: 597, Training loss: 1.364026, Validation loss: 1.3790, lr: 0.0000\n",
      "Epoch: 598, Training loss: 1.412700, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 599, Training loss: 1.399272, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 600, Training loss: 1.375071, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 601, Training loss: 1.385231, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 602, Training loss: 1.383649, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 603, Training loss: 1.359483, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 604, Training loss: 1.378044, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 605, Training loss: 1.444262, Validation loss: 1.3754, lr: 0.0000\n",
      "Epoch: 606, Training loss: 1.374369, Validation loss: 1.3772, lr: 0.0000\n",
      "Epoch: 607, Training loss: 1.382522, Validation loss: 1.3918, lr: 0.0000\n",
      "Epoch: 608, Training loss: 1.440140, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 609, Training loss: 1.369353, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 610, Training loss: 1.362948, Validation loss: 1.3689, lr: 0.0000\n",
      "Epoch: 611, Training loss: 1.377579, Validation loss: 1.4034, lr: 0.0000\n",
      "Epoch: 612, Training loss: 1.391217, Validation loss: 1.4176, lr: 0.0000\n",
      "Epoch: 613, Training loss: 1.383103, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 614, Training loss: 1.378400, Validation loss: 1.3800, lr: 0.0000\n",
      "Epoch: 615, Training loss: 1.353082, Validation loss: 1.3471, lr: 0.0000\n",
      "Epoch: 616, Training loss: 1.378254, Validation loss: 1.3777, lr: 0.0000\n",
      "Epoch: 617, Training loss: 1.407530, Validation loss: 1.3725, lr: 0.0000\n",
      "Epoch: 618, Training loss: 1.406456, Validation loss: 1.3876, lr: 0.0000\n",
      "Epoch: 619, Training loss: 1.393216, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 620, Training loss: 1.380712, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 621, Training loss: 1.395376, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 622, Training loss: 1.379190, Validation loss: 1.3975, lr: 0.0000\n",
      "Epoch: 623, Training loss: 1.373321, Validation loss: 1.3872, lr: 0.0000\n",
      "Epoch: 624, Training loss: 1.379433, Validation loss: 1.3742, lr: 0.0000\n",
      "Epoch: 625, Training loss: 1.449576, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 626, Training loss: 1.360643, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 627, Training loss: 1.387775, Validation loss: 1.3610, lr: 0.0000\n",
      "Epoch: 628, Training loss: 1.385951, Validation loss: 1.3714, lr: 0.0000\n",
      "Epoch: 629, Training loss: 1.367942, Validation loss: 1.3920, lr: 0.0000\n",
      "Epoch: 630, Training loss: 1.362259, Validation loss: 1.3895, lr: 0.0000\n",
      "Epoch: 631, Training loss: 1.385116, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 632, Training loss: 1.404391, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 633, Training loss: 1.382383, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 634, Training loss: 1.356805, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 635, Training loss: 1.393140, Validation loss: 1.3678, lr: 0.0000\n",
      "Epoch: 636, Training loss: 1.372393, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 637, Training loss: 1.373588, Validation loss: 1.3587, lr: 0.0000\n",
      "Epoch: 638, Training loss: 1.381005, Validation loss: 1.3637, lr: 0.0000\n",
      "Epoch: 639, Training loss: 1.399673, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 640, Training loss: 1.381891, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 641, Training loss: 1.375936, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 642, Training loss: 1.377818, Validation loss: 1.3883, lr: 0.0000\n",
      "Epoch: 643, Training loss: 1.385168, Validation loss: 1.3882, lr: 0.0000\n",
      "Epoch: 644, Training loss: 1.383723, Validation loss: 1.3743, lr: 0.0000\n",
      "Epoch: 645, Training loss: 1.389093, Validation loss: 1.3809, lr: 0.0000\n",
      "Epoch: 646, Training loss: 1.427135, Validation loss: 1.3668, lr: 0.0000\n",
      "Epoch: 647, Training loss: 1.360785, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 648, Training loss: 1.480220, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 649, Training loss: 1.362737, Validation loss: 1.3757, lr: 0.0000\n",
      "Epoch: 650, Training loss: 1.390808, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 651, Training loss: 1.365594, Validation loss: 1.3796, lr: 0.0000\n",
      "Epoch: 652, Training loss: 1.380967, Validation loss: 1.3768, lr: 0.0000\n",
      "Epoch: 653, Training loss: 1.399835, Validation loss: 1.3803, lr: 0.0000\n",
      "Epoch: 654, Training loss: 1.374252, Validation loss: 1.3961, lr: 0.0000\n",
      "Epoch: 655, Training loss: 1.370940, Validation loss: 1.3770, lr: 0.0000\n",
      "Epoch: 656, Training loss: 1.388774, Validation loss: 1.3931, lr: 0.0000\n",
      "Epoch: 657, Training loss: 1.383181, Validation loss: 1.3766, lr: 0.0000\n",
      "Epoch: 658, Training loss: 1.390219, Validation loss: 1.3878, lr: 0.0000\n",
      "Epoch: 659, Training loss: 1.400016, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 660, Training loss: 1.401656, Validation loss: 1.4013, lr: 0.0000\n",
      "Epoch: 661, Training loss: 1.373012, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 662, Training loss: 1.370091, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 663, Training loss: 1.384096, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 664, Training loss: 1.369178, Validation loss: 1.3732, lr: 0.0000\n",
      "Epoch: 665, Training loss: 1.379684, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 666, Training loss: 1.378942, Validation loss: 1.3777, lr: 0.0000\n",
      "Epoch: 667, Training loss: 1.372636, Validation loss: 1.3774, lr: 0.0000\n",
      "Epoch: 668, Training loss: 1.368206, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 669, Training loss: 1.385678, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 670, Training loss: 1.386977, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 671, Training loss: 1.408526, Validation loss: 1.3741, lr: 0.0000\n",
      "Epoch: 672, Training loss: 1.380766, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 673, Training loss: 1.360040, Validation loss: 1.3880, lr: 0.0000\n",
      "Epoch: 674, Training loss: 1.379221, Validation loss: 1.3726, lr: 0.0000\n",
      "Epoch: 675, Training loss: 1.381098, Validation loss: 1.3883, lr: 0.0000\n",
      "Epoch: 676, Training loss: 1.383769, Validation loss: 1.3726, lr: 0.0000\n",
      "Epoch: 677, Training loss: 1.379140, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 678, Training loss: 1.375637, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 679, Training loss: 1.412934, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 680, Training loss: 1.372998, Validation loss: 1.3803, lr: 0.0000\n",
      "Epoch: 681, Training loss: 1.366122, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 682, Training loss: 1.396515, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 683, Training loss: 1.411068, Validation loss: 1.3873, lr: 0.0000\n",
      "Epoch: 684, Training loss: 1.378784, Validation loss: 1.3784, lr: 0.0000\n",
      "Epoch: 685, Training loss: 1.361744, Validation loss: 1.3621, lr: 0.0000\n",
      "Epoch: 686, Training loss: 1.431862, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 687, Training loss: 1.404500, Validation loss: 1.3969, lr: 0.0000\n",
      "Epoch: 688, Training loss: 1.414218, Validation loss: 1.3720, lr: 0.0000\n",
      "Epoch: 689, Training loss: 1.386102, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 690, Training loss: 1.392160, Validation loss: 1.3765, lr: 0.0000\n",
      "Epoch: 691, Training loss: 1.380931, Validation loss: 1.3809, lr: 0.0000\n",
      "Epoch: 692, Training loss: 1.437952, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 693, Training loss: 1.355481, Validation loss: 1.3640, lr: 0.0000\n",
      "Epoch: 694, Training loss: 1.384796, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 695, Training loss: 1.464188, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 696, Training loss: 1.418642, Validation loss: 1.3901, lr: 0.0000\n",
      "Epoch: 697, Training loss: 1.367854, Validation loss: 1.3695, lr: 0.0000\n",
      "Epoch: 698, Training loss: 1.359116, Validation loss: 1.3926, lr: 0.0000\n",
      "Epoch: 699, Training loss: 1.379712, Validation loss: 1.4046, lr: 0.0000\n",
      "Epoch: 700, Training loss: 1.350792, Validation loss: 1.3934, lr: 0.0000\n",
      "Epoch: 701, Training loss: 1.401769, Validation loss: 1.3472, lr: 0.0000\n",
      "Epoch: 702, Training loss: 1.358143, Validation loss: 1.3881, lr: 0.0000\n",
      "Epoch: 703, Training loss: 1.377977, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 704, Training loss: 1.380345, Validation loss: 1.3682, lr: 0.0000\n",
      "Epoch: 705, Training loss: 1.379934, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 706, Training loss: 1.401185, Validation loss: 1.4191, lr: 0.0000\n",
      "Epoch: 707, Training loss: 1.407814, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 708, Training loss: 1.359732, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 709, Training loss: 1.376061, Validation loss: 1.3644, lr: 0.0000\n",
      "Epoch: 710, Training loss: 1.375872, Validation loss: 1.3798, lr: 0.0000\n",
      "Epoch: 711, Training loss: 1.399224, Validation loss: 1.3768, lr: 0.0000\n",
      "Epoch: 712, Training loss: 1.359691, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 713, Training loss: 1.400337, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 714, Training loss: 1.368648, Validation loss: 1.3737, lr: 0.0000\n",
      "Epoch: 715, Training loss: 1.363558, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 716, Training loss: 1.376002, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 717, Training loss: 1.393445, Validation loss: 1.3979, lr: 0.0000\n",
      "Epoch: 718, Training loss: 1.384611, Validation loss: 1.4346, lr: 0.0000\n",
      "Epoch: 719, Training loss: 1.419160, Validation loss: 1.4054, lr: 0.0000\n",
      "Epoch: 720, Training loss: 1.393595, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 721, Training loss: 1.375344, Validation loss: 1.3617, lr: 0.0000\n",
      "Epoch: 722, Training loss: 1.352270, Validation loss: 1.3773, lr: 0.0000\n",
      "Epoch: 723, Training loss: 1.386489, Validation loss: 1.3636, lr: 0.0000\n",
      "Epoch: 724, Training loss: 1.394256, Validation loss: 1.3610, lr: 0.0000\n",
      "Epoch: 725, Training loss: 1.371445, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 726, Training loss: 1.392714, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 727, Training loss: 1.380255, Validation loss: 1.3674, lr: 0.0000\n",
      "Epoch: 728, Training loss: 1.377226, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 729, Training loss: 1.400067, Validation loss: 1.3995, lr: 0.0000\n",
      "Epoch: 730, Training loss: 1.371976, Validation loss: 1.3732, lr: 0.0000\n",
      "Epoch: 731, Training loss: 1.372799, Validation loss: 1.3653, lr: 0.0000\n",
      "Epoch: 732, Training loss: 1.390793, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 733, Training loss: 1.382296, Validation loss: 1.3727, lr: 0.0000\n",
      "Epoch: 734, Training loss: 1.398091, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 735, Training loss: 1.367593, Validation loss: 1.3791, lr: 0.0000\n",
      "Epoch: 736, Training loss: 1.377271, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 737, Training loss: 1.386329, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 738, Training loss: 1.382463, Validation loss: 1.3787, lr: 0.0000\n",
      "Epoch: 739, Training loss: 1.384437, Validation loss: 1.3736, lr: 0.0000\n",
      "Epoch: 740, Training loss: 1.365776, Validation loss: 1.3955, lr: 0.0000\n",
      "Epoch: 741, Training loss: 1.344194, Validation loss: 1.3768, lr: 0.0000\n",
      "Epoch: 742, Training loss: 1.380963, Validation loss: 1.3762, lr: 0.0000\n",
      "Epoch: 743, Training loss: 1.380988, Validation loss: 1.4224, lr: 0.0000\n",
      "Epoch: 744, Training loss: 1.370616, Validation loss: 1.3882, lr: 0.0000\n",
      "Epoch: 745, Training loss: 1.365891, Validation loss: 1.3802, lr: 0.0000\n",
      "Epoch: 746, Training loss: 1.402708, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 747, Training loss: 1.392509, Validation loss: 1.3564, lr: 0.0000\n",
      "Epoch: 748, Training loss: 1.434277, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 749, Training loss: 1.379988, Validation loss: 1.3528, lr: 0.0000\n",
      "Epoch: 750, Training loss: 1.384313, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 751, Training loss: 1.364650, Validation loss: 1.3659, lr: 0.0000\n",
      "Epoch: 752, Training loss: 1.373366, Validation loss: 1.3710, lr: 0.0000\n",
      "Epoch: 753, Training loss: 1.389638, Validation loss: 1.3559, lr: 0.0000\n",
      "Epoch: 754, Training loss: 1.361368, Validation loss: 1.4196, lr: 0.0000\n",
      "Epoch: 755, Training loss: 1.376227, Validation loss: 1.3784, lr: 0.0000\n",
      "Epoch: 756, Training loss: 1.377690, Validation loss: 1.3872, lr: 0.0000\n",
      "Epoch: 757, Training loss: 1.355458, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 758, Training loss: 1.356989, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 759, Training loss: 1.392533, Validation loss: 1.3738, lr: 0.0000\n",
      "Epoch: 760, Training loss: 1.385356, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 761, Training loss: 1.388811, Validation loss: 1.3555, lr: 0.0000\n",
      "Epoch: 762, Training loss: 1.373858, Validation loss: 1.4019, lr: 0.0000\n",
      "Epoch: 763, Training loss: 1.366199, Validation loss: 1.4010, lr: 0.0000\n",
      "Epoch: 764, Training loss: 1.377226, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 765, Training loss: 1.359658, Validation loss: 1.3892, lr: 0.0000\n",
      "Epoch: 766, Training loss: 1.395188, Validation loss: 1.3617, lr: 0.0000\n",
      "Epoch: 767, Training loss: 1.384500, Validation loss: 1.3798, lr: 0.0000\n",
      "Epoch: 768, Training loss: 1.376978, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 769, Training loss: 1.378314, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 770, Training loss: 1.376417, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 771, Training loss: 1.374943, Validation loss: 1.3757, lr: 0.0000\n",
      "Epoch: 772, Training loss: 1.395337, Validation loss: 1.3712, lr: 0.0000\n",
      "Epoch: 773, Training loss: 1.398974, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 774, Training loss: 1.367020, Validation loss: 1.3698, lr: 0.0000\n",
      "Epoch: 775, Training loss: 1.377248, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 776, Training loss: 1.371604, Validation loss: 1.3613, lr: 0.0000\n",
      "Epoch: 777, Training loss: 1.400911, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 778, Training loss: 1.356455, Validation loss: 1.3766, lr: 0.0000\n",
      "Epoch: 779, Training loss: 1.373659, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 780, Training loss: 1.430161, Validation loss: 1.3809, lr: 0.0000\n",
      "Epoch: 781, Training loss: 1.379518, Validation loss: 1.3719, lr: 0.0000\n",
      "Epoch: 782, Training loss: 1.376828, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 783, Training loss: 1.411327, Validation loss: 1.3482, lr: 0.0000\n",
      "Epoch: 784, Training loss: 1.386307, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 785, Training loss: 1.358762, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 786, Training loss: 1.374816, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 787, Training loss: 1.379677, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 788, Training loss: 1.373277, Validation loss: 1.3875, lr: 0.0000\n",
      "Epoch: 789, Training loss: 1.367000, Validation loss: 1.3716, lr: 0.0000\n",
      "Epoch: 790, Training loss: 1.368100, Validation loss: 1.3752, lr: 0.0000\n",
      "Epoch: 791, Training loss: 1.399192, Validation loss: 1.3893, lr: 0.0000\n",
      "Epoch: 792, Training loss: 1.387461, Validation loss: 1.3688, lr: 0.0000\n",
      "Epoch: 793, Training loss: 1.385585, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 794, Training loss: 1.368524, Validation loss: 1.3942, lr: 0.0000\n",
      "Epoch: 795, Training loss: 1.391967, Validation loss: 1.4472, lr: 0.0000\n",
      "Epoch: 796, Training loss: 1.386473, Validation loss: 1.3712, lr: 0.0000\n",
      "Epoch: 797, Training loss: 1.382187, Validation loss: 1.6807, lr: 0.0000\n",
      "Epoch: 798, Training loss: 1.388203, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 799, Training loss: 1.365278, Validation loss: 1.3908, lr: 0.0000\n",
      "Epoch: 800, Training loss: 1.378707, Validation loss: 1.3790, lr: 0.0000\n",
      "Epoch: 801, Training loss: 1.371470, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 802, Training loss: 1.374919, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 803, Training loss: 1.378808, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 804, Training loss: 1.391402, Validation loss: 1.3879, lr: 0.0000\n",
      "Epoch: 805, Training loss: 1.407513, Validation loss: 1.3907, lr: 0.0000\n",
      "Epoch: 806, Training loss: 1.380089, Validation loss: 1.3715, lr: 0.0000\n",
      "Epoch: 807, Training loss: 1.447098, Validation loss: 1.4718, lr: 0.0000\n",
      "Epoch: 808, Training loss: 1.364325, Validation loss: 1.3670, lr: 0.0000\n",
      "Epoch: 809, Training loss: 1.383528, Validation loss: 1.3676, lr: 0.0000\n",
      "Epoch: 810, Training loss: 1.382104, Validation loss: 1.3702, lr: 0.0000\n",
      "Epoch: 811, Training loss: 1.373351, Validation loss: 1.3781, lr: 0.0000\n",
      "Epoch: 812, Training loss: 1.391405, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 813, Training loss: 1.375543, Validation loss: 1.3548, lr: 0.0000\n",
      "Epoch: 814, Training loss: 1.363184, Validation loss: 1.3928, lr: 0.0000\n",
      "Epoch: 815, Training loss: 1.409063, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 816, Training loss: 1.384264, Validation loss: 1.3623, lr: 0.0000\n",
      "Epoch: 817, Training loss: 1.407950, Validation loss: 1.3918, lr: 0.0000\n",
      "Epoch: 818, Training loss: 1.368356, Validation loss: 1.4232, lr: 0.0000\n",
      "Epoch: 819, Training loss: 1.405477, Validation loss: 1.3752, lr: 0.0000\n",
      "Epoch: 820, Training loss: 1.355943, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 821, Training loss: 1.372399, Validation loss: 1.3723, lr: 0.0000\n",
      "Epoch: 822, Training loss: 1.367742, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 823, Training loss: 1.384557, Validation loss: 1.3885, lr: 0.0000\n",
      "Epoch: 824, Training loss: 1.370275, Validation loss: 1.3694, lr: 0.0000\n",
      "Epoch: 825, Training loss: 1.368378, Validation loss: 1.3703, lr: 0.0000\n",
      "Epoch: 826, Training loss: 1.436336, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 827, Training loss: 1.368918, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 828, Training loss: 1.375455, Validation loss: 1.3698, lr: 0.0000\n",
      "Epoch: 829, Training loss: 1.384316, Validation loss: 1.3918, lr: 0.0000\n",
      "Epoch: 830, Training loss: 1.383651, Validation loss: 1.3758, lr: 0.0000\n",
      "Epoch: 831, Training loss: 1.369945, Validation loss: 1.4055, lr: 0.0000\n",
      "Epoch: 832, Training loss: 1.373662, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 833, Training loss: 1.388070, Validation loss: 1.3732, lr: 0.0000\n",
      "Epoch: 834, Training loss: 1.375823, Validation loss: 1.3875, lr: 0.0000\n",
      "Epoch: 835, Training loss: 1.383817, Validation loss: 1.4966, lr: 0.0000\n",
      "Epoch: 836, Training loss: 1.375664, Validation loss: 1.3783, lr: 0.0000\n",
      "Epoch: 837, Training loss: 1.372625, Validation loss: 1.3741, lr: 0.0000\n",
      "Epoch: 838, Training loss: 1.385971, Validation loss: 1.3686, lr: 0.0000\n",
      "Epoch: 839, Training loss: 1.408685, Validation loss: 1.3871, lr: 0.0000\n",
      "Epoch: 840, Training loss: 1.362643, Validation loss: 1.3767, lr: 0.0000\n",
      "Epoch: 841, Training loss: 1.381656, Validation loss: 1.3761, lr: 0.0000\n",
      "Epoch: 842, Training loss: 1.363035, Validation loss: 1.3796, lr: 0.0000\n",
      "Epoch: 843, Training loss: 1.358121, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 844, Training loss: 1.384146, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 845, Training loss: 1.401392, Validation loss: 1.3794, lr: 0.0000\n",
      "Epoch: 846, Training loss: 1.370746, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 847, Training loss: 1.368527, Validation loss: 1.3578, lr: 0.0000\n",
      "Epoch: 848, Training loss: 1.397364, Validation loss: 1.4030, lr: 0.0000\n",
      "Epoch: 849, Training loss: 1.415950, Validation loss: 1.3767, lr: 0.0000\n",
      "Epoch: 850, Training loss: 1.366763, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 851, Training loss: 1.367410, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 852, Training loss: 1.419587, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 853, Training loss: 1.362999, Validation loss: 1.4176, lr: 0.0000\n",
      "Epoch: 854, Training loss: 1.378196, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 855, Training loss: 1.373081, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 856, Training loss: 1.372059, Validation loss: 1.3649, lr: 0.0000\n",
      "Epoch: 857, Training loss: 1.376322, Validation loss: 1.3742, lr: 0.0000\n",
      "Epoch: 858, Training loss: 1.366444, Validation loss: 1.3800, lr: 0.0000\n",
      "Epoch: 859, Training loss: 1.395650, Validation loss: 1.3747, lr: 0.0000\n",
      "Epoch: 860, Training loss: 1.365116, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 861, Training loss: 1.384244, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 862, Training loss: 1.369274, Validation loss: 1.4314, lr: 0.0000\n",
      "Epoch: 863, Training loss: 1.369828, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 864, Training loss: 1.393104, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 865, Training loss: 1.399187, Validation loss: 1.3779, lr: 0.0000\n",
      "Epoch: 866, Training loss: 1.400564, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 867, Training loss: 1.474420, Validation loss: 1.3872, lr: 0.0000\n",
      "Epoch: 868, Training loss: 1.381356, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 869, Training loss: 1.383893, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 870, Training loss: 1.374407, Validation loss: 1.3947, lr: 0.0000\n",
      "Epoch: 871, Training loss: 1.370051, Validation loss: 1.3800, lr: 0.0000\n",
      "Epoch: 872, Training loss: 1.367003, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 873, Training loss: 1.383662, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 874, Training loss: 1.375417, Validation loss: 1.3412, lr: 0.0000\n",
      "Epoch: 875, Training loss: 1.375502, Validation loss: 1.3876, lr: 0.0000\n",
      "Epoch: 876, Training loss: 1.365925, Validation loss: 1.3753, lr: 0.0000\n",
      "Epoch: 877, Training loss: 1.384089, Validation loss: 1.3733, lr: 0.0000\n",
      "Epoch: 878, Training loss: 1.381005, Validation loss: 1.3732, lr: 0.0000\n",
      "Epoch: 879, Training loss: 1.389882, Validation loss: 1.3769, lr: 0.0000\n",
      "Epoch: 880, Training loss: 1.367309, Validation loss: 1.3788, lr: 0.0000\n",
      "Epoch: 881, Training loss: 1.382129, Validation loss: 1.3726, lr: 0.0000\n",
      "Epoch: 882, Training loss: 1.373080, Validation loss: 1.3921, lr: 0.0000\n",
      "Epoch: 883, Training loss: 1.396808, Validation loss: 1.4032, lr: 0.0000\n",
      "Epoch: 884, Training loss: 1.389633, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 885, Training loss: 1.397952, Validation loss: 1.3871, lr: 0.0000\n",
      "Epoch: 886, Training loss: 1.471935, Validation loss: 1.3760, lr: 0.0000\n",
      "Epoch: 887, Training loss: 1.364919, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 888, Training loss: 1.375095, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 889, Training loss: 1.384646, Validation loss: 1.3782, lr: 0.0000\n",
      "Epoch: 890, Training loss: 1.365072, Validation loss: 1.3773, lr: 0.0000\n",
      "Epoch: 891, Training loss: 1.403215, Validation loss: 1.3770, lr: 0.0000\n",
      "Epoch: 892, Training loss: 1.379887, Validation loss: 1.3770, lr: 0.0000\n",
      "Epoch: 893, Training loss: 1.376296, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 894, Training loss: 1.387227, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 895, Training loss: 1.396303, Validation loss: 1.3883, lr: 0.0000\n",
      "Epoch: 896, Training loss: 1.370299, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 897, Training loss: 1.363352, Validation loss: 1.3720, lr: 0.0000\n",
      "Epoch: 898, Training loss: 1.360259, Validation loss: 1.3696, lr: 0.0000\n",
      "Epoch: 899, Training loss: 1.383529, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 900, Training loss: 1.380751, Validation loss: 1.3642, lr: 0.0000\n",
      "Epoch: 901, Training loss: 1.387369, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 902, Training loss: 1.583630, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 903, Training loss: 1.370539, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 904, Training loss: 1.376469, Validation loss: 1.3557, lr: 0.0000\n",
      "Epoch: 905, Training loss: 1.397283, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 906, Training loss: 1.390942, Validation loss: 1.3800, lr: 0.0000\n",
      "Epoch: 907, Training loss: 1.378645, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 908, Training loss: 1.373655, Validation loss: 1.3900, lr: 0.0000\n",
      "Epoch: 909, Training loss: 1.402873, Validation loss: 1.3674, lr: 0.0000\n",
      "Epoch: 910, Training loss: 1.355808, Validation loss: 1.3885, lr: 0.0000\n",
      "Epoch: 911, Training loss: 1.410110, Validation loss: 1.4244, lr: 0.0000\n",
      "Epoch: 912, Training loss: 1.390749, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 913, Training loss: 1.389357, Validation loss: 1.3729, lr: 0.0000\n",
      "Epoch: 914, Training loss: 1.446258, Validation loss: 1.3889, lr: 0.0000\n",
      "Epoch: 915, Training loss: 1.375614, Validation loss: 1.3739, lr: 0.0000\n",
      "Epoch: 916, Training loss: 1.398711, Validation loss: 1.3709, lr: 0.0000\n",
      "Epoch: 917, Training loss: 1.378436, Validation loss: 1.3613, lr: 0.0000\n",
      "Epoch: 918, Training loss: 1.401875, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 919, Training loss: 1.373229, Validation loss: 1.3747, lr: 0.0000\n",
      "Epoch: 920, Training loss: 1.365227, Validation loss: 1.4836, lr: 0.0000\n",
      "Epoch: 921, Training loss: 1.398663, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 922, Training loss: 1.367635, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 923, Training loss: 1.374380, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 924, Training loss: 1.393109, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 925, Training loss: 1.403394, Validation loss: 1.3894, lr: 0.0000\n",
      "Epoch: 926, Training loss: 1.391780, Validation loss: 1.3680, lr: 0.0000\n",
      "Epoch: 927, Training loss: 1.384215, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 928, Training loss: 1.421804, Validation loss: 1.3914, lr: 0.0000\n",
      "Epoch: 929, Training loss: 1.367728, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 930, Training loss: 1.367970, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 931, Training loss: 1.382792, Validation loss: 1.4970, lr: 0.0000\n",
      "Epoch: 932, Training loss: 1.385540, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 933, Training loss: 1.372710, Validation loss: 1.3665, lr: 0.0000\n",
      "Epoch: 934, Training loss: 1.391065, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 935, Training loss: 1.371454, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 936, Training loss: 1.368974, Validation loss: 1.3884, lr: 0.0000\n",
      "Epoch: 937, Training loss: 1.370388, Validation loss: 1.3872, lr: 0.0000\n",
      "Epoch: 938, Training loss: 1.393816, Validation loss: 1.3710, lr: 0.0000\n",
      "Epoch: 939, Training loss: 1.410556, Validation loss: 1.4139, lr: 0.0000\n",
      "Epoch: 940, Training loss: 1.535964, Validation loss: 1.3374, lr: 0.0000\n",
      "Epoch: 941, Training loss: 1.366445, Validation loss: 1.3664, lr: 0.0000\n",
      "Epoch: 942, Training loss: 1.460375, Validation loss: 1.3750, lr: 0.0000\n",
      "Epoch: 943, Training loss: 1.368200, Validation loss: 1.3757, lr: 0.0000\n",
      "Epoch: 944, Training loss: 1.375822, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 945, Training loss: 1.390635, Validation loss: 1.3587, lr: 0.0000\n",
      "Epoch: 946, Training loss: 1.362049, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 947, Training loss: 1.372817, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 948, Training loss: 1.375372, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 949, Training loss: 1.375288, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 950, Training loss: 1.393490, Validation loss: 1.3656, lr: 0.0000\n",
      "Epoch: 951, Training loss: 1.388776, Validation loss: 1.3697, lr: 0.0000\n",
      "Epoch: 952, Training loss: 1.386942, Validation loss: 1.3912, lr: 0.0000\n",
      "Epoch: 953, Training loss: 1.383379, Validation loss: 1.3981, lr: 0.0000\n",
      "Epoch: 954, Training loss: 1.373365, Validation loss: 1.3890, lr: 0.0000\n",
      "Epoch: 955, Training loss: 1.371584, Validation loss: 1.3795, lr: 0.0000\n",
      "Epoch: 956, Training loss: 1.346573, Validation loss: 1.3725, lr: 0.0000\n",
      "Epoch: 957, Training loss: 1.372567, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 958, Training loss: 1.378520, Validation loss: 1.3761, lr: 0.0000\n",
      "Epoch: 959, Training loss: 1.392463, Validation loss: 1.3958, lr: 0.0000\n",
      "Epoch: 960, Training loss: 1.413617, Validation loss: 1.3681, lr: 0.0000\n",
      "Epoch: 961, Training loss: 1.364470, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 962, Training loss: 1.388160, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 963, Training loss: 1.422264, Validation loss: 1.3888, lr: 0.0000\n",
      "Epoch: 964, Training loss: 1.398615, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 965, Training loss: 1.366854, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 966, Training loss: 1.383805, Validation loss: 1.3880, lr: 0.0000\n",
      "Epoch: 967, Training loss: 1.373891, Validation loss: 1.3877, lr: 0.0000\n",
      "Epoch: 968, Training loss: 1.393955, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 969, Training loss: 1.381179, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 970, Training loss: 1.371689, Validation loss: 1.3945, lr: 0.0000\n",
      "Epoch: 971, Training loss: 1.366619, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 972, Training loss: 1.450976, Validation loss: 1.4144, lr: 0.0000\n",
      "Epoch: 973, Training loss: 1.373150, Validation loss: 1.3803, lr: 0.0000\n",
      "Epoch: 974, Training loss: 1.370985, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 975, Training loss: 1.377073, Validation loss: 1.3659, lr: 0.0000\n",
      "Epoch: 976, Training loss: 1.392657, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 977, Training loss: 1.380710, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 978, Training loss: 1.389090, Validation loss: 1.3956, lr: 0.0000\n",
      "Epoch: 979, Training loss: 1.399592, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 980, Training loss: 1.390106, Validation loss: 1.3692, lr: 0.0000\n",
      "Epoch: 981, Training loss: 1.358027, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 982, Training loss: 1.365618, Validation loss: 1.3809, lr: 0.0000\n",
      "Epoch: 983, Training loss: 1.358886, Validation loss: 1.3887, lr: 0.0000\n",
      "Epoch: 984, Training loss: 1.383293, Validation loss: 1.3795, lr: 0.0000\n",
      "Epoch: 985, Training loss: 1.366932, Validation loss: 1.3749, lr: 0.0000\n",
      "Epoch: 986, Training loss: 1.381445, Validation loss: 1.3612, lr: 0.0000\n",
      "Epoch: 987, Training loss: 1.378914, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 988, Training loss: 1.368477, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 989, Training loss: 1.394329, Validation loss: 1.4245, lr: 0.0000\n",
      "Epoch: 990, Training loss: 1.366449, Validation loss: 1.3725, lr: 0.0000\n",
      "Epoch: 991, Training loss: 1.373576, Validation loss: 1.3908, lr: 0.0000\n",
      "Epoch: 992, Training loss: 1.396080, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 993, Training loss: 1.583138, Validation loss: 1.3625, lr: 0.0000\n",
      " *och: 994, Training loss: 1.393050, Validation loss: 1.3205, lr: 0.0000\n",
      "Epoch: 995, Training loss: 1.367332, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 996, Training loss: 1.379729, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 997, Training loss: 1.390947, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 998, Training loss: 1.391493, Validation loss: 1.4244, lr: 0.0000\n",
      "Epoch: 999, Training loss: 1.375699, Validation loss: 1.4149, lr: 0.0000\n",
      "Final test loss: 1.3844\n",
      "=== Run 03/10 ===\n",
      "\n",
      "---- Settings: \n",
      "\n",
      "epochs : 1000\n",
      "hidden_channels : [32]\n",
      "out_channels : 10\n",
      "inner_product_features : False\n",
      "batch_size : 64\n",
      "lr : 0.01\n",
      "momentum : 0.9\n",
      "dropout : 0.0\n",
      "batch_norm : batch_norm\n",
      "bias : True\n",
      "order : 2\n",
      "diffusion : True\n",
      "frac_sampled_nb : -1\n",
      "include_positions : False\n",
      "include_self : True\n",
      "vec_norm : False\n",
      "emb_norm : False\n",
      "seed : 0\n",
      "dim_signal : 100\n",
      "dim_emb : 100\n",
      "n_sampled_nb : -1\n",
      "\n",
      "---- Number of features to pass to the MLP:  1010100\n",
      "---- Total number of parameters:  32323627\n",
      "\n",
      "Using device cuda:0\n",
      "\n",
      "---- Training network ...\n",
      "\n",
      "---- Timestamp: 20250614-100243\n",
      "\n",
      " *och: 0, Training loss: 1.397049, Validation loss: 1.4170, lr: 0.0100\n",
      " *och: 1, Training loss: 1.425673, Validation loss: 1.3378, lr: 0.0100\n",
      "Epoch: 2, Training loss: 1.388387, Validation loss: 1.3413, lr: 0.0100\n",
      "Epoch: 3, Training loss: 1.441140, Validation loss: 1.3771, lr: 0.0100\n",
      "Epoch: 4, Training loss: 1.443390, Validation loss: 1.3798, lr: 0.0100\n",
      "Epoch: 5, Training loss: 1.494357, Validation loss: 1.3609, lr: 0.0100\n",
      "Epoch: 6, Training loss: 1.398947, Validation loss: 1.3848, lr: 0.0100\n",
      "Epoch: 7, Training loss: 1.437257, Validation loss: 1.3832, lr: 0.0100\n",
      "Epoch: 8, Training loss: 1.426717, Validation loss: 1.3855, lr: 0.0100\n",
      "Epoch: 9, Training loss: 1.414265, Validation loss: 1.4199, lr: 0.0100\n",
      "Epoch: 10, Training loss: 1.369967, Validation loss: 1.3891, lr: 0.0100\n",
      "Epoch: 11, Training loss: 1.385725, Validation loss: 1.3819, lr: 0.0100\n",
      "Epoch: 12, Training loss: 1.387497, Validation loss: 1.4033, lr: 0.0100\n",
      "Epoch: 13, Training loss: 1.388343, Validation loss: 1.3856, lr: 0.0100\n",
      "Epoch: 14, Training loss: 1.389561, Validation loss: 1.3757, lr: 0.0100\n",
      "Epoch: 15, Training loss: 1.380488, Validation loss: 1.3808, lr: 0.0100\n",
      "Epoch: 16, Training loss: 1.388718, Validation loss: 1.4024, lr: 0.0100\n",
      "Epoch: 17, Training loss: 1.426156, Validation loss: 1.3851, lr: 0.0100\n",
      "Epoch: 18, Training loss: 1.383543, Validation loss: 1.3850, lr: 0.0100\n",
      "Epoch: 19, Training loss: 1.367609, Validation loss: 1.3806, lr: 0.0100\n",
      "Epoch: 20, Training loss: 1.367928, Validation loss: 1.3762, lr: 0.0100\n",
      "Epoch: 21, Training loss: 1.424910, Validation loss: 1.3818, lr: 0.0100\n",
      "Epoch: 22, Training loss: 1.381541, Validation loss: 1.3851, lr: 0.0100\n",
      "Epoch: 23, Training loss: 1.374328, Validation loss: 1.5837, lr: 0.0100\n",
      "Epoch: 24, Training loss: 1.409465, Validation loss: 1.3831, lr: 0.0100\n",
      "Epoch: 25, Training loss: 1.411897, Validation loss: 1.3864, lr: 0.0100\n",
      "Epoch: 26, Training loss: 1.378122, Validation loss: 1.3872, lr: 0.0100\n",
      "Epoch: 27, Training loss: 1.369257, Validation loss: 1.3857, lr: 0.0100\n",
      "Epoch: 28, Training loss: 1.381654, Validation loss: 1.3867, lr: 0.0100\n",
      "Epoch: 29, Training loss: 1.382321, Validation loss: 1.3842, lr: 0.0100\n",
      "Epoch: 30, Training loss: 1.382497, Validation loss: 1.3799, lr: 0.0010\n",
      "Epoch: 31, Training loss: 1.365378, Validation loss: 1.3858, lr: 0.0010\n",
      "Epoch: 32, Training loss: 1.394300, Validation loss: 1.3843, lr: 0.0010\n",
      "Epoch: 33, Training loss: 1.394422, Validation loss: 1.3821, lr: 0.0010\n",
      "Epoch: 34, Training loss: 1.392332, Validation loss: 1.3828, lr: 0.0010\n",
      "Epoch: 35, Training loss: 1.397368, Validation loss: 1.3801, lr: 0.0010\n",
      "Epoch: 36, Training loss: 1.373628, Validation loss: 1.3831, lr: 0.0010\n",
      "Epoch: 37, Training loss: 1.371675, Validation loss: 1.3784, lr: 0.0010\n",
      "Epoch: 38, Training loss: 1.366488, Validation loss: 1.3851, lr: 0.0010\n",
      "Epoch: 39, Training loss: 1.367542, Validation loss: 1.3769, lr: 0.0010\n",
      "Epoch: 40, Training loss: 1.375709, Validation loss: 1.3835, lr: 0.0010\n",
      "Epoch: 41, Training loss: 1.376606, Validation loss: 1.4285, lr: 0.0010\n",
      "Epoch: 42, Training loss: 1.366113, Validation loss: 1.3843, lr: 0.0001\n",
      "Epoch: 43, Training loss: 1.395270, Validation loss: 1.3825, lr: 0.0001\n",
      "Epoch: 44, Training loss: 1.404189, Validation loss: 1.3838, lr: 0.0001\n",
      "Epoch: 45, Training loss: 1.375145, Validation loss: 1.3826, lr: 0.0001\n",
      "Epoch: 46, Training loss: 1.379874, Validation loss: 1.3946, lr: 0.0001\n",
      "Epoch: 47, Training loss: 1.384001, Validation loss: 1.3996, lr: 0.0001\n",
      "Epoch: 48, Training loss: 1.359011, Validation loss: 1.3832, lr: 0.0001\n",
      "Epoch: 49, Training loss: 1.376064, Validation loss: 1.3862, lr: 0.0001\n",
      "Epoch: 50, Training loss: 1.380569, Validation loss: 1.3901, lr: 0.0001\n",
      "Epoch: 51, Training loss: 1.389390, Validation loss: 1.3834, lr: 0.0001\n",
      "Epoch: 52, Training loss: 1.413159, Validation loss: 1.3899, lr: 0.0001\n",
      "Epoch: 53, Training loss: 1.382041, Validation loss: 1.3833, lr: 0.0001\n",
      "Epoch: 54, Training loss: 1.389852, Validation loss: 1.3726, lr: 0.0001\n",
      "Epoch: 55, Training loss: 1.363482, Validation loss: 1.3826, lr: 0.0001\n",
      "Epoch: 56, Training loss: 1.381418, Validation loss: 1.3853, lr: 0.0001\n",
      "Epoch: 57, Training loss: 1.377161, Validation loss: 1.3812, lr: 0.0001\n",
      "Epoch: 58, Training loss: 1.378951, Validation loss: 1.3836, lr: 0.0001\n",
      "Epoch: 59, Training loss: 1.411728, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 60, Training loss: 1.383776, Validation loss: 1.4214, lr: 0.0000\n",
      "Epoch: 61, Training loss: 1.384276, Validation loss: 1.3894, lr: 0.0000\n",
      "Epoch: 62, Training loss: 1.370757, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 63, Training loss: 1.385746, Validation loss: 1.3706, lr: 0.0000\n",
      "Epoch: 64, Training loss: 1.370995, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 65, Training loss: 1.365149, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 66, Training loss: 1.392949, Validation loss: 1.3717, lr: 0.0000\n",
      "Epoch: 67, Training loss: 1.379592, Validation loss: 1.3803, lr: 0.0000\n",
      "Epoch: 68, Training loss: 1.386711, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 69, Training loss: 1.365260, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 70, Training loss: 1.369819, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 71, Training loss: 1.376673, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 72, Training loss: 1.387791, Validation loss: 1.3971, lr: 0.0000\n",
      "Epoch: 73, Training loss: 1.379603, Validation loss: 1.5192, lr: 0.0000\n",
      "Epoch: 74, Training loss: 1.396009, Validation loss: 1.3757, lr: 0.0000\n",
      "Epoch: 75, Training loss: 1.356403, Validation loss: 1.3989, lr: 0.0000\n",
      "Epoch: 76, Training loss: 1.376484, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 77, Training loss: 1.381188, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 78, Training loss: 1.381321, Validation loss: 1.3774, lr: 0.0000\n",
      "Epoch: 79, Training loss: 1.374899, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 80, Training loss: 1.381849, Validation loss: 1.3871, lr: 0.0000\n",
      "Epoch: 81, Training loss: 1.380743, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 82, Training loss: 1.383950, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 83, Training loss: 1.375057, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 84, Training loss: 1.363297, Validation loss: 1.3874, lr: 0.0000\n",
      "Epoch: 85, Training loss: 1.368923, Validation loss: 1.3713, lr: 0.0000\n",
      "Epoch: 86, Training loss: 1.381907, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 87, Training loss: 1.362931, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 88, Training loss: 1.371333, Validation loss: 1.3896, lr: 0.0000\n",
      "Epoch: 89, Training loss: 1.378320, Validation loss: 1.3925, lr: 0.0000\n",
      "Epoch: 90, Training loss: 1.387249, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 91, Training loss: 1.387023, Validation loss: 1.3752, lr: 0.0000\n",
      "Epoch: 92, Training loss: 1.372202, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 93, Training loss: 1.379555, Validation loss: 1.3720, lr: 0.0000\n",
      "Epoch: 94, Training loss: 1.371977, Validation loss: 1.3723, lr: 0.0000\n",
      "Epoch: 95, Training loss: 1.383091, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 96, Training loss: 1.369095, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 97, Training loss: 1.374115, Validation loss: 1.3783, lr: 0.0000\n",
      "Epoch: 98, Training loss: 1.376446, Validation loss: 1.3800, lr: 0.0000\n",
      "Epoch: 99, Training loss: 1.382985, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 100, Training loss: 1.372225, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 101, Training loss: 1.366570, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 102, Training loss: 1.382027, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 103, Training loss: 1.369695, Validation loss: 1.3662, lr: 0.0000\n",
      "Epoch: 104, Training loss: 1.357227, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 105, Training loss: 1.369229, Validation loss: 1.3746, lr: 0.0000\n",
      "Epoch: 106, Training loss: 1.366447, Validation loss: 1.3809, lr: 0.0000\n",
      "Epoch: 107, Training loss: 1.361961, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 108, Training loss: 1.376727, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 109, Training loss: 1.369355, Validation loss: 1.3800, lr: 0.0000\n",
      "Epoch: 110, Training loss: 1.382155, Validation loss: 1.3713, lr: 0.0000\n",
      "Epoch: 111, Training loss: 1.368541, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 112, Training loss: 1.375239, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 113, Training loss: 1.370187, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 114, Training loss: 1.386665, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 115, Training loss: 1.385956, Validation loss: 1.3760, lr: 0.0000\n",
      "Epoch: 116, Training loss: 1.375621, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 117, Training loss: 1.377652, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 118, Training loss: 1.411505, Validation loss: 1.3778, lr: 0.0000\n",
      "Epoch: 119, Training loss: 1.372556, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 120, Training loss: 1.377998, Validation loss: 1.3970, lr: 0.0000\n",
      "Epoch: 121, Training loss: 1.372067, Validation loss: 1.4048, lr: 0.0000\n",
      "Epoch: 122, Training loss: 1.384675, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 123, Training loss: 1.371181, Validation loss: 1.3803, lr: 0.0000\n",
      "Epoch: 124, Training loss: 1.382868, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 125, Training loss: 1.377662, Validation loss: 1.3736, lr: 0.0000\n",
      "Epoch: 126, Training loss: 1.388933, Validation loss: 1.3875, lr: 0.0000\n",
      "Epoch: 127, Training loss: 1.362878, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 128, Training loss: 1.382396, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 129, Training loss: 1.378414, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 130, Training loss: 1.418699, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 131, Training loss: 1.378519, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 132, Training loss: 1.365081, Validation loss: 1.3789, lr: 0.0000\n",
      "Epoch: 133, Training loss: 1.377216, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 134, Training loss: 1.372508, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 135, Training loss: 1.372815, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 136, Training loss: 1.383999, Validation loss: 1.3936, lr: 0.0000\n",
      "Epoch: 137, Training loss: 1.371865, Validation loss: 1.3764, lr: 0.0000\n",
      "Epoch: 138, Training loss: 1.378733, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 139, Training loss: 1.388150, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 140, Training loss: 1.378685, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 141, Training loss: 1.372600, Validation loss: 1.3783, lr: 0.0000\n",
      "Epoch: 142, Training loss: 1.361553, Validation loss: 1.3740, lr: 0.0000\n",
      "Epoch: 143, Training loss: 1.379041, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 144, Training loss: 1.396402, Validation loss: 1.3896, lr: 0.0000\n",
      "Epoch: 145, Training loss: 1.397355, Validation loss: 1.3728, lr: 0.0000\n",
      "Epoch: 146, Training loss: 1.362511, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 147, Training loss: 1.387136, Validation loss: 1.3719, lr: 0.0000\n",
      "Epoch: 148, Training loss: 1.380792, Validation loss: 1.3782, lr: 0.0000\n",
      "Epoch: 149, Training loss: 1.392037, Validation loss: 1.3780, lr: 0.0000\n",
      "Epoch: 150, Training loss: 1.379371, Validation loss: 1.3439, lr: 0.0000\n",
      "Epoch: 151, Training loss: 1.360045, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 152, Training loss: 1.370519, Validation loss: 1.3792, lr: 0.0000\n",
      "Epoch: 153, Training loss: 1.391074, Validation loss: 1.3739, lr: 0.0000\n",
      "Epoch: 154, Training loss: 1.366521, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 155, Training loss: 1.367829, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 156, Training loss: 1.374324, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 157, Training loss: 1.371203, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 158, Training loss: 1.385678, Validation loss: 1.3766, lr: 0.0000\n",
      "Epoch: 159, Training loss: 1.382072, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 160, Training loss: 1.366273, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 161, Training loss: 1.379081, Validation loss: 1.3760, lr: 0.0000\n",
      "Epoch: 162, Training loss: 1.465212, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 163, Training loss: 1.380936, Validation loss: 1.3761, lr: 0.0000\n",
      "Epoch: 164, Training loss: 1.365004, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 165, Training loss: 1.365807, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 166, Training loss: 1.401194, Validation loss: 1.3758, lr: 0.0000\n",
      "Epoch: 167, Training loss: 1.375358, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 168, Training loss: 1.365642, Validation loss: 1.3794, lr: 0.0000\n",
      "Epoch: 169, Training loss: 1.372362, Validation loss: 1.3714, lr: 0.0000\n",
      "Epoch: 170, Training loss: 1.392592, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 171, Training loss: 1.389801, Validation loss: 1.3972, lr: 0.0000\n",
      "Epoch: 172, Training loss: 1.353632, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 173, Training loss: 1.385234, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 174, Training loss: 1.372930, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 175, Training loss: 1.384467, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 176, Training loss: 1.373393, Validation loss: 1.3740, lr: 0.0000\n",
      "Epoch: 177, Training loss: 1.373850, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 178, Training loss: 1.419505, Validation loss: 1.3766, lr: 0.0000\n",
      "Epoch: 179, Training loss: 1.389168, Validation loss: 1.3793, lr: 0.0000\n",
      "Epoch: 180, Training loss: 1.366242, Validation loss: 1.3799, lr: 0.0000\n",
      "Epoch: 181, Training loss: 1.387650, Validation loss: 1.3720, lr: 0.0000\n",
      "Epoch: 182, Training loss: 1.367377, Validation loss: 1.3573, lr: 0.0000\n",
      "Epoch: 183, Training loss: 1.382311, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 184, Training loss: 1.388546, Validation loss: 1.3913, lr: 0.0000\n",
      "Epoch: 185, Training loss: 1.376062, Validation loss: 1.4735, lr: 0.0000\n",
      "Epoch: 186, Training loss: 1.370027, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 187, Training loss: 1.377125, Validation loss: 1.3778, lr: 0.0000\n",
      "Epoch: 188, Training loss: 1.372983, Validation loss: 1.6455, lr: 0.0000\n",
      "Epoch: 189, Training loss: 1.381120, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 190, Training loss: 1.386780, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 191, Training loss: 1.380867, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 192, Training loss: 1.382611, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 193, Training loss: 1.374575, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 194, Training loss: 1.371679, Validation loss: 1.3878, lr: 0.0000\n",
      "Epoch: 195, Training loss: 1.381460, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 196, Training loss: 1.380103, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 197, Training loss: 1.383036, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 198, Training loss: 1.436520, Validation loss: 1.3914, lr: 0.0000\n",
      "Epoch: 199, Training loss: 1.363246, Validation loss: 1.3797, lr: 0.0000\n",
      "Epoch: 200, Training loss: 1.364506, Validation loss: 1.3759, lr: 0.0000\n",
      "Epoch: 201, Training loss: 1.367277, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 202, Training loss: 1.364448, Validation loss: 1.3739, lr: 0.0000\n",
      "Epoch: 203, Training loss: 1.381682, Validation loss: 1.3879, lr: 0.0000\n",
      "Epoch: 204, Training loss: 1.353387, Validation loss: 1.3777, lr: 0.0000\n",
      "Epoch: 205, Training loss: 1.380037, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 206, Training loss: 1.363333, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 207, Training loss: 1.368055, Validation loss: 1.3709, lr: 0.0000\n",
      "Epoch: 208, Training loss: 1.429696, Validation loss: 1.3799, lr: 0.0000\n",
      "Epoch: 209, Training loss: 1.384679, Validation loss: 1.3744, lr: 0.0000\n",
      "Epoch: 210, Training loss: 1.370319, Validation loss: 1.3884, lr: 0.0000\n",
      "Epoch: 211, Training loss: 1.384278, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 212, Training loss: 1.367131, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 213, Training loss: 1.359276, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 214, Training loss: 1.377314, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 215, Training loss: 1.382493, Validation loss: 1.3798, lr: 0.0000\n",
      "Epoch: 216, Training loss: 1.375060, Validation loss: 1.3798, lr: 0.0000\n",
      "Epoch: 217, Training loss: 1.399864, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 218, Training loss: 1.380181, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 219, Training loss: 1.381767, Validation loss: 1.3798, lr: 0.0000\n",
      "Epoch: 220, Training loss: 1.377837, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 221, Training loss: 1.361917, Validation loss: 1.3780, lr: 0.0000\n",
      "Epoch: 222, Training loss: 1.407621, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 223, Training loss: 1.398893, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 224, Training loss: 1.369294, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 225, Training loss: 1.369723, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 226, Training loss: 1.378470, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 227, Training loss: 1.379933, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 228, Training loss: 1.387448, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 229, Training loss: 1.380936, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 230, Training loss: 1.367336, Validation loss: 1.3768, lr: 0.0000\n",
      "Epoch: 231, Training loss: 1.386791, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 232, Training loss: 1.392236, Validation loss: 1.3799, lr: 0.0000\n",
      "Epoch: 233, Training loss: 1.376988, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 234, Training loss: 1.371326, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 235, Training loss: 1.380374, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 236, Training loss: 1.380562, Validation loss: 1.3632, lr: 0.0000\n",
      "Epoch: 237, Training loss: 1.378259, Validation loss: 1.3803, lr: 0.0000\n",
      "Epoch: 238, Training loss: 1.375795, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 239, Training loss: 1.384999, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 240, Training loss: 1.373507, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 241, Training loss: 1.373670, Validation loss: 1.3882, lr: 0.0000\n",
      "Epoch: 242, Training loss: 1.382745, Validation loss: 1.3665, lr: 0.0000\n",
      "Epoch: 243, Training loss: 1.368359, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 244, Training loss: 1.387062, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 245, Training loss: 1.375632, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 246, Training loss: 1.366759, Validation loss: 1.4023, lr: 0.0000\n",
      "Epoch: 247, Training loss: 1.382993, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 248, Training loss: 1.371724, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 249, Training loss: 1.369262, Validation loss: 1.3809, lr: 0.0000\n",
      "Epoch: 250, Training loss: 1.381490, Validation loss: 1.4865, lr: 0.0000\n",
      "Epoch: 251, Training loss: 1.389107, Validation loss: 1.3754, lr: 0.0000\n",
      "Epoch: 252, Training loss: 1.396179, Validation loss: 1.3749, lr: 0.0000\n",
      "Epoch: 253, Training loss: 1.367446, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 254, Training loss: 1.371433, Validation loss: 1.3781, lr: 0.0000\n",
      "Epoch: 255, Training loss: 1.367927, Validation loss: 1.3802, lr: 0.0000\n",
      "Epoch: 256, Training loss: 1.383104, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 257, Training loss: 1.382308, Validation loss: 1.3802, lr: 0.0000\n",
      "Epoch: 258, Training loss: 1.376682, Validation loss: 1.3696, lr: 0.0000\n",
      "Epoch: 259, Training loss: 1.378341, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 260, Training loss: 1.379592, Validation loss: 1.3786, lr: 0.0000\n",
      "Epoch: 261, Training loss: 1.391531, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 262, Training loss: 1.389337, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 263, Training loss: 1.373938, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 264, Training loss: 1.382808, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 265, Training loss: 1.375404, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 266, Training loss: 1.380670, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 267, Training loss: 1.435133, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 268, Training loss: 1.374282, Validation loss: 1.3771, lr: 0.0000\n",
      "Epoch: 269, Training loss: 1.382417, Validation loss: 1.3745, lr: 0.0000\n",
      "Epoch: 270, Training loss: 1.369396, Validation loss: 1.3600, lr: 0.0000\n",
      "Epoch: 271, Training loss: 1.378091, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 272, Training loss: 1.445068, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 273, Training loss: 1.374178, Validation loss: 1.3599, lr: 0.0000\n",
      "Epoch: 274, Training loss: 1.380322, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 275, Training loss: 1.379615, Validation loss: 1.3950, lr: 0.0000\n",
      "Epoch: 276, Training loss: 1.388797, Validation loss: 1.3762, lr: 0.0000\n",
      "Epoch: 277, Training loss: 1.365030, Validation loss: 1.4000, lr: 0.0000\n",
      "Epoch: 278, Training loss: 1.398822, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 279, Training loss: 1.382983, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 280, Training loss: 1.369535, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 281, Training loss: 1.362353, Validation loss: 1.3792, lr: 0.0000\n",
      "Epoch: 282, Training loss: 1.380696, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 283, Training loss: 1.373611, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 284, Training loss: 1.371381, Validation loss: 1.3872, lr: 0.0000\n",
      "Epoch: 285, Training loss: 1.382667, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 286, Training loss: 1.377754, Validation loss: 1.3770, lr: 0.0000\n",
      "Epoch: 287, Training loss: 1.368626, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 288, Training loss: 1.388322, Validation loss: 1.3800, lr: 0.0000\n",
      "Epoch: 289, Training loss: 1.383546, Validation loss: 1.3758, lr: 0.0000\n",
      "Epoch: 290, Training loss: 1.385599, Validation loss: 1.3707, lr: 0.0000\n",
      "Epoch: 291, Training loss: 1.370215, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 292, Training loss: 1.368426, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 293, Training loss: 1.375897, Validation loss: 1.3913, lr: 0.0000\n",
      "Epoch: 294, Training loss: 1.401722, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 295, Training loss: 1.382431, Validation loss: 1.3987, lr: 0.0000\n",
      "Epoch: 296, Training loss: 1.406503, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 297, Training loss: 1.383256, Validation loss: 1.3934, lr: 0.0000\n",
      "Epoch: 298, Training loss: 1.419702, Validation loss: 1.3478, lr: 0.0000\n",
      "Epoch: 299, Training loss: 1.388868, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 300, Training loss: 1.379722, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 301, Training loss: 1.369782, Validation loss: 1.3741, lr: 0.0000\n",
      "Epoch: 302, Training loss: 1.377952, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 303, Training loss: 1.375828, Validation loss: 1.3778, lr: 0.0000\n",
      "Epoch: 304, Training loss: 1.458314, Validation loss: 1.3737, lr: 0.0000\n",
      "Epoch: 305, Training loss: 1.389785, Validation loss: 1.3780, lr: 0.0000\n",
      "Epoch: 306, Training loss: 1.358594, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 307, Training loss: 1.374655, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 308, Training loss: 1.365312, Validation loss: 1.3697, lr: 0.0000\n",
      "Epoch: 309, Training loss: 1.375300, Validation loss: 1.3885, lr: 0.0000\n",
      "Epoch: 310, Training loss: 1.371419, Validation loss: 1.3918, lr: 0.0000\n",
      "Epoch: 311, Training loss: 1.397134, Validation loss: 1.3965, lr: 0.0000\n",
      "Epoch: 312, Training loss: 1.387371, Validation loss: 1.3594, lr: 0.0000\n",
      "Epoch: 313, Training loss: 1.385391, Validation loss: 1.3954, lr: 0.0000\n",
      "Epoch: 314, Training loss: 1.359353, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 315, Training loss: 1.367302, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 316, Training loss: 1.377379, Validation loss: 1.3890, lr: 0.0000\n",
      "Epoch: 317, Training loss: 1.394915, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 318, Training loss: 1.367888, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 319, Training loss: 1.354808, Validation loss: 1.3777, lr: 0.0000\n",
      "Epoch: 320, Training loss: 1.387442, Validation loss: 1.3628, lr: 0.0000\n",
      "Epoch: 321, Training loss: 1.381838, Validation loss: 1.3754, lr: 0.0000\n",
      "Epoch: 322, Training loss: 1.364317, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 323, Training loss: 1.365692, Validation loss: 1.3754, lr: 0.0000\n",
      "Epoch: 324, Training loss: 1.351908, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 325, Training loss: 1.360504, Validation loss: 1.3875, lr: 0.0000\n",
      "Epoch: 326, Training loss: 1.384402, Validation loss: 1.3923, lr: 0.0000\n",
      "Epoch: 327, Training loss: 1.378719, Validation loss: 1.3895, lr: 0.0000\n",
      "Epoch: 328, Training loss: 1.390422, Validation loss: 1.3782, lr: 0.0000\n",
      "Epoch: 329, Training loss: 1.381620, Validation loss: 1.3761, lr: 0.0000\n",
      "Epoch: 330, Training loss: 1.403136, Validation loss: 1.3952, lr: 0.0000\n",
      "Epoch: 331, Training loss: 1.360622, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 332, Training loss: 1.385127, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 333, Training loss: 1.380067, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 334, Training loss: 1.372484, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 335, Training loss: 1.368841, Validation loss: 1.3671, lr: 0.0000\n",
      "Epoch: 336, Training loss: 1.383784, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 337, Training loss: 1.378703, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 338, Training loss: 1.374757, Validation loss: 1.3698, lr: 0.0000\n",
      "Epoch: 339, Training loss: 1.359881, Validation loss: 1.3532, lr: 0.0000\n",
      "Epoch: 340, Training loss: 1.361429, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 341, Training loss: 1.369179, Validation loss: 1.3589, lr: 0.0000\n",
      "Epoch: 342, Training loss: 1.377252, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 343, Training loss: 1.376549, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 344, Training loss: 1.377780, Validation loss: 1.3795, lr: 0.0000\n",
      "Epoch: 345, Training loss: 1.357419, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 346, Training loss: 1.372410, Validation loss: 1.3882, lr: 0.0000\n",
      "Epoch: 347, Training loss: 1.372586, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 348, Training loss: 1.377553, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 349, Training loss: 1.378152, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 350, Training loss: 1.357852, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 351, Training loss: 1.369406, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 352, Training loss: 1.385157, Validation loss: 1.3873, lr: 0.0000\n",
      "Epoch: 353, Training loss: 1.377098, Validation loss: 1.3800, lr: 0.0000\n",
      "Epoch: 354, Training loss: 1.359125, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 355, Training loss: 1.404557, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 356, Training loss: 1.427497, Validation loss: 1.3872, lr: 0.0000\n",
      "Epoch: 357, Training loss: 1.379777, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 358, Training loss: 1.392187, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 359, Training loss: 1.373141, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 360, Training loss: 1.376424, Validation loss: 1.3645, lr: 0.0000\n",
      "Epoch: 361, Training loss: 1.385416, Validation loss: 1.3724, lr: 0.0000\n",
      "Epoch: 362, Training loss: 1.365494, Validation loss: 1.3893, lr: 0.0000\n",
      "Epoch: 363, Training loss: 1.380613, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 364, Training loss: 1.373014, Validation loss: 1.3783, lr: 0.0000\n",
      "Epoch: 365, Training loss: 1.373520, Validation loss: 1.3878, lr: 0.0000\n",
      "Epoch: 366, Training loss: 1.380562, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 367, Training loss: 1.365936, Validation loss: 1.3876, lr: 0.0000\n",
      "Epoch: 368, Training loss: 1.387441, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 369, Training loss: 1.377704, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 370, Training loss: 1.387073, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 371, Training loss: 1.396733, Validation loss: 1.3878, lr: 0.0000\n",
      "Epoch: 372, Training loss: 1.363312, Validation loss: 1.4179, lr: 0.0000\n",
      "Epoch: 373, Training loss: 1.393287, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 374, Training loss: 1.378980, Validation loss: 1.3740, lr: 0.0000\n",
      "Epoch: 375, Training loss: 1.380373, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 376, Training loss: 1.363279, Validation loss: 1.3788, lr: 0.0000\n",
      "Epoch: 377, Training loss: 1.374217, Validation loss: 1.4083, lr: 0.0000\n",
      "Epoch: 378, Training loss: 1.389387, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 379, Training loss: 1.376280, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 380, Training loss: 1.396999, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 381, Training loss: 1.410072, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 382, Training loss: 1.383388, Validation loss: 1.3888, lr: 0.0000\n",
      "Epoch: 383, Training loss: 1.358411, Validation loss: 1.4080, lr: 0.0000\n",
      "Epoch: 384, Training loss: 1.381944, Validation loss: 1.3706, lr: 0.0000\n",
      "Epoch: 385, Training loss: 1.353929, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 386, Training loss: 1.374690, Validation loss: 1.3782, lr: 0.0000\n",
      "Epoch: 387, Training loss: 1.376509, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 388, Training loss: 1.385960, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 389, Training loss: 1.366705, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 390, Training loss: 1.374340, Validation loss: 1.3942, lr: 0.0000\n",
      "Epoch: 391, Training loss: 1.367699, Validation loss: 1.3754, lr: 0.0000\n",
      "Epoch: 392, Training loss: 1.362036, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 393, Training loss: 1.367294, Validation loss: 1.3768, lr: 0.0000\n",
      "Epoch: 394, Training loss: 1.369962, Validation loss: 1.3798, lr: 0.0000\n",
      "Epoch: 395, Training loss: 1.376585, Validation loss: 1.3709, lr: 0.0000\n",
      "Epoch: 396, Training loss: 1.379807, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 397, Training loss: 1.377160, Validation loss: 1.4334, lr: 0.0000\n",
      "Epoch: 398, Training loss: 1.367904, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 399, Training loss: 1.378456, Validation loss: 1.3759, lr: 0.0000\n",
      "Epoch: 400, Training loss: 1.383852, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 401, Training loss: 1.373143, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 402, Training loss: 1.376963, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 403, Training loss: 1.380286, Validation loss: 1.3749, lr: 0.0000\n",
      "Epoch: 404, Training loss: 1.373502, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 405, Training loss: 1.377551, Validation loss: 1.4224, lr: 0.0000\n",
      "Epoch: 406, Training loss: 1.387112, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 407, Training loss: 1.378840, Validation loss: 1.3871, lr: 0.0000\n",
      "Epoch: 408, Training loss: 1.371028, Validation loss: 1.3787, lr: 0.0000\n",
      "Epoch: 409, Training loss: 1.369413, Validation loss: 1.3712, lr: 0.0000\n",
      "Epoch: 410, Training loss: 1.386057, Validation loss: 1.3782, lr: 0.0000\n",
      "Epoch: 411, Training loss: 1.401809, Validation loss: 1.3880, lr: 0.0000\n",
      "Epoch: 412, Training loss: 1.364023, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 413, Training loss: 1.387404, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 414, Training loss: 1.373752, Validation loss: 1.3772, lr: 0.0000\n",
      "Epoch: 415, Training loss: 1.377931, Validation loss: 1.3736, lr: 0.0000\n",
      "Epoch: 416, Training loss: 1.379077, Validation loss: 1.3792, lr: 0.0000\n",
      "Epoch: 417, Training loss: 1.426930, Validation loss: 1.3698, lr: 0.0000\n",
      "Epoch: 418, Training loss: 1.427419, Validation loss: 1.3748, lr: 0.0000\n",
      "Epoch: 419, Training loss: 1.364359, Validation loss: 1.3769, lr: 0.0000\n",
      "Epoch: 420, Training loss: 1.374508, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 421, Training loss: 1.370884, Validation loss: 1.3726, lr: 0.0000\n",
      "Epoch: 422, Training loss: 1.376958, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 423, Training loss: 1.369573, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 424, Training loss: 1.371540, Validation loss: 1.3781, lr: 0.0000\n",
      "Epoch: 425, Training loss: 1.396694, Validation loss: 1.3709, lr: 0.0000\n",
      "Epoch: 426, Training loss: 1.371789, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 427, Training loss: 1.373997, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 428, Training loss: 1.415055, Validation loss: 1.3915, lr: 0.0000\n",
      "Epoch: 429, Training loss: 1.411006, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 430, Training loss: 1.372468, Validation loss: 1.3902, lr: 0.0000\n",
      "Epoch: 431, Training loss: 1.380507, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 432, Training loss: 1.371895, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 433, Training loss: 1.389971, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 434, Training loss: 1.382454, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 435, Training loss: 1.363948, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 436, Training loss: 1.395928, Validation loss: 1.3792, lr: 0.0000\n",
      "Epoch: 437, Training loss: 1.383303, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 438, Training loss: 1.385349, Validation loss: 1.3975, lr: 0.0000\n",
      "Epoch: 439, Training loss: 1.386031, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 440, Training loss: 1.386078, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 441, Training loss: 1.407309, Validation loss: 1.3655, lr: 0.0000\n",
      "Epoch: 442, Training loss: 1.372154, Validation loss: 1.3898, lr: 0.0000\n",
      "Epoch: 443, Training loss: 1.369602, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 444, Training loss: 1.363607, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 445, Training loss: 1.411561, Validation loss: 1.3878, lr: 0.0000\n",
      "Epoch: 446, Training loss: 1.378637, Validation loss: 1.4003, lr: 0.0000\n",
      "Epoch: 447, Training loss: 1.365775, Validation loss: 1.3873, lr: 0.0000\n",
      "Epoch: 448, Training loss: 1.383178, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 449, Training loss: 1.377340, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 450, Training loss: 1.372693, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 451, Training loss: 1.406567, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 452, Training loss: 1.383007, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 453, Training loss: 1.377681, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 454, Training loss: 1.368838, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 455, Training loss: 1.372488, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 456, Training loss: 1.379295, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 457, Training loss: 1.387785, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 458, Training loss: 1.364236, Validation loss: 1.3873, lr: 0.0000\n",
      "Epoch: 459, Training loss: 1.383914, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 460, Training loss: 1.362470, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 461, Training loss: 1.376209, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 462, Training loss: 1.367936, Validation loss: 1.3809, lr: 0.0000\n",
      "Epoch: 463, Training loss: 1.405466, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 464, Training loss: 1.379771, Validation loss: 1.3885, lr: 0.0000\n",
      "Epoch: 465, Training loss: 1.396653, Validation loss: 1.3770, lr: 0.0000\n",
      "Epoch: 466, Training loss: 1.371332, Validation loss: 1.3749, lr: 0.0000\n",
      "Epoch: 467, Training loss: 1.403906, Validation loss: 1.3664, lr: 0.0000\n",
      "Epoch: 468, Training loss: 1.393846, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 469, Training loss: 1.384779, Validation loss: 1.3780, lr: 0.0000\n",
      "Epoch: 470, Training loss: 1.379607, Validation loss: 1.3619, lr: 0.0000\n",
      "Epoch: 471, Training loss: 1.375020, Validation loss: 1.3487, lr: 0.0000\n",
      "Epoch: 472, Training loss: 1.393149, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 473, Training loss: 1.368538, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 474, Training loss: 1.379879, Validation loss: 1.3788, lr: 0.0000\n",
      "Epoch: 475, Training loss: 1.374408, Validation loss: 1.3784, lr: 0.0000\n",
      "Epoch: 476, Training loss: 1.370910, Validation loss: 1.3767, lr: 0.0000\n",
      "Epoch: 477, Training loss: 1.389187, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 478, Training loss: 1.375368, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 479, Training loss: 1.372697, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 480, Training loss: 1.379341, Validation loss: 1.3739, lr: 0.0000\n",
      "Epoch: 481, Training loss: 1.380621, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 482, Training loss: 1.389506, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 483, Training loss: 1.377747, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 484, Training loss: 1.366299, Validation loss: 1.4125, lr: 0.0000\n",
      "Epoch: 485, Training loss: 1.375240, Validation loss: 1.3701, lr: 0.0000\n",
      "Epoch: 486, Training loss: 1.361085, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 487, Training loss: 1.382017, Validation loss: 1.3768, lr: 0.0000\n",
      "Epoch: 488, Training loss: 1.368651, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 489, Training loss: 1.446185, Validation loss: 1.3974, lr: 0.0000\n",
      "Epoch: 490, Training loss: 1.407842, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 491, Training loss: 1.367300, Validation loss: 1.3596, lr: 0.0000\n",
      "Epoch: 492, Training loss: 1.387797, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 493, Training loss: 1.375804, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 494, Training loss: 1.399706, Validation loss: 1.3669, lr: 0.0000\n",
      "Epoch: 495, Training loss: 1.449774, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 496, Training loss: 1.396829, Validation loss: 1.3784, lr: 0.0000\n",
      "Epoch: 497, Training loss: 1.384464, Validation loss: 1.3796, lr: 0.0000\n",
      "Epoch: 498, Training loss: 1.373655, Validation loss: 1.3753, lr: 0.0000\n",
      "Epoch: 499, Training loss: 1.367533, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 500, Training loss: 1.375601, Validation loss: 1.3733, lr: 0.0000\n",
      "Epoch: 501, Training loss: 1.392821, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 502, Training loss: 1.364036, Validation loss: 1.3901, lr: 0.0000\n",
      "Epoch: 503, Training loss: 1.380072, Validation loss: 1.3798, lr: 0.0000\n",
      "Epoch: 504, Training loss: 1.392895, Validation loss: 1.3714, lr: 0.0000\n",
      "Epoch: 505, Training loss: 1.379398, Validation loss: 1.3798, lr: 0.0000\n",
      "Epoch: 506, Training loss: 1.402218, Validation loss: 1.3730, lr: 0.0000\n",
      "Epoch: 507, Training loss: 1.355290, Validation loss: 1.3789, lr: 0.0000\n",
      "Epoch: 508, Training loss: 1.367064, Validation loss: 1.5763, lr: 0.0000\n",
      "Epoch: 509, Training loss: 1.374340, Validation loss: 1.3764, lr: 0.0000\n",
      "Epoch: 510, Training loss: 1.380433, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 511, Training loss: 1.390975, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 512, Training loss: 1.381188, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 513, Training loss: 1.360239, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 514, Training loss: 1.359816, Validation loss: 1.3765, lr: 0.0000\n",
      "Epoch: 515, Training loss: 1.374725, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 516, Training loss: 1.378085, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 517, Training loss: 1.371170, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 518, Training loss: 1.389934, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 519, Training loss: 1.382774, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 520, Training loss: 1.368309, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 521, Training loss: 1.378376, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 522, Training loss: 1.375936, Validation loss: 1.3799, lr: 0.0000\n",
      "Epoch: 523, Training loss: 1.374245, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 524, Training loss: 1.368894, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 525, Training loss: 1.388174, Validation loss: 1.3690, lr: 0.0000\n",
      "Epoch: 526, Training loss: 1.366496, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 527, Training loss: 1.380440, Validation loss: 1.3767, lr: 0.0000\n",
      "Epoch: 528, Training loss: 1.384600, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 529, Training loss: 1.372239, Validation loss: 1.3788, lr: 0.0000\n",
      "Epoch: 530, Training loss: 1.377463, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 531, Training loss: 1.377398, Validation loss: 1.3935, lr: 0.0000\n",
      "Epoch: 532, Training loss: 1.360651, Validation loss: 1.3785, lr: 0.0000\n",
      "Epoch: 533, Training loss: 1.385647, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 534, Training loss: 1.370014, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 535, Training loss: 1.378542, Validation loss: 1.3938, lr: 0.0000\n",
      "Epoch: 536, Training loss: 1.361451, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 537, Training loss: 1.390058, Validation loss: 1.3715, lr: 0.0000\n",
      "Epoch: 538, Training loss: 1.377150, Validation loss: 1.3904, lr: 0.0000\n",
      "Epoch: 539, Training loss: 1.355984, Validation loss: 1.3876, lr: 0.0000\n",
      "Epoch: 540, Training loss: 1.380957, Validation loss: 1.3573, lr: 0.0000\n",
      "Epoch: 541, Training loss: 1.385538, Validation loss: 1.3795, lr: 0.0000\n",
      "Epoch: 542, Training loss: 1.368914, Validation loss: 1.3757, lr: 0.0000\n",
      "Epoch: 543, Training loss: 1.381800, Validation loss: 1.4340, lr: 0.0000\n",
      "Epoch: 544, Training loss: 1.379796, Validation loss: 1.3898, lr: 0.0000\n",
      "Epoch: 545, Training loss: 1.374303, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 546, Training loss: 1.382563, Validation loss: 1.4178, lr: 0.0000\n",
      "Epoch: 547, Training loss: 1.380237, Validation loss: 1.4010, lr: 0.0000\n",
      "Epoch: 548, Training loss: 1.368695, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 549, Training loss: 1.364348, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 550, Training loss: 1.363588, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 551, Training loss: 1.359537, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 552, Training loss: 1.372881, Validation loss: 1.3741, lr: 0.0000\n",
      "Epoch: 553, Training loss: 1.360653, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 554, Training loss: 1.377630, Validation loss: 1.3765, lr: 0.0000\n",
      "Epoch: 555, Training loss: 1.380421, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 556, Training loss: 1.379936, Validation loss: 1.3776, lr: 0.0000\n",
      "Epoch: 557, Training loss: 1.372475, Validation loss: 1.3684, lr: 0.0000\n",
      "Epoch: 558, Training loss: 1.387201, Validation loss: 1.3957, lr: 0.0000\n",
      "Epoch: 559, Training loss: 1.372399, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 560, Training loss: 1.390997, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 561, Training loss: 1.378112, Validation loss: 1.4650, lr: 0.0000\n",
      "Epoch: 562, Training loss: 1.423313, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 563, Training loss: 1.371439, Validation loss: 1.3885, lr: 0.0000\n",
      "Epoch: 564, Training loss: 1.377706, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 565, Training loss: 1.390511, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 566, Training loss: 1.375406, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 567, Training loss: 1.385381, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 568, Training loss: 1.368512, Validation loss: 1.3699, lr: 0.0000\n",
      "Epoch: 569, Training loss: 1.369492, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 570, Training loss: 1.385448, Validation loss: 1.3888, lr: 0.0000\n",
      "Epoch: 571, Training loss: 1.368868, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 572, Training loss: 1.384205, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 573, Training loss: 1.389739, Validation loss: 1.3791, lr: 0.0000\n",
      "Epoch: 574, Training loss: 1.389737, Validation loss: 1.3783, lr: 0.0000\n",
      "Epoch: 575, Training loss: 1.390089, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 576, Training loss: 1.393893, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 577, Training loss: 1.426247, Validation loss: 1.3885, lr: 0.0000\n",
      "Epoch: 578, Training loss: 1.353935, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 579, Training loss: 1.383576, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 580, Training loss: 1.365024, Validation loss: 1.3715, lr: 0.0000\n",
      "Epoch: 581, Training loss: 1.380243, Validation loss: 1.3974, lr: 0.0000\n",
      "Epoch: 582, Training loss: 1.382605, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 583, Training loss: 1.369457, Validation loss: 1.3475, lr: 0.0000\n",
      "Epoch: 584, Training loss: 1.369919, Validation loss: 1.3629, lr: 0.0000\n",
      "Epoch: 585, Training loss: 1.372358, Validation loss: 1.3766, lr: 0.0000\n",
      "Epoch: 586, Training loss: 1.374648, Validation loss: 1.3779, lr: 0.0000\n",
      "Epoch: 587, Training loss: 1.406642, Validation loss: 1.3890, lr: 0.0000\n",
      "Epoch: 588, Training loss: 1.366223, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 589, Training loss: 1.412360, Validation loss: 1.3730, lr: 0.0000\n",
      "Epoch: 590, Training loss: 1.419263, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 591, Training loss: 1.433038, Validation loss: 1.4031, lr: 0.0000\n",
      "Epoch: 592, Training loss: 1.365494, Validation loss: 1.3687, lr: 0.0000\n",
      "Epoch: 593, Training loss: 1.384987, Validation loss: 1.3486, lr: 0.0000\n",
      "Epoch: 594, Training loss: 1.391878, Validation loss: 1.3876, lr: 0.0000\n",
      "Epoch: 595, Training loss: 1.394196, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 596, Training loss: 1.409640, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 597, Training loss: 1.374727, Validation loss: 1.3756, lr: 0.0000\n",
      "Epoch: 598, Training loss: 1.376060, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 599, Training loss: 1.361818, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 600, Training loss: 1.356073, Validation loss: 1.3876, lr: 0.0000\n",
      "Epoch: 601, Training loss: 1.394794, Validation loss: 1.3889, lr: 0.0000\n",
      "Epoch: 602, Training loss: 1.379928, Validation loss: 1.3788, lr: 0.0000\n",
      "Epoch: 603, Training loss: 1.378912, Validation loss: 1.3932, lr: 0.0000\n",
      "Epoch: 604, Training loss: 1.389424, Validation loss: 1.3802, lr: 0.0000\n",
      "Epoch: 605, Training loss: 1.390904, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 606, Training loss: 1.388182, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 607, Training loss: 1.388502, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 608, Training loss: 1.379272, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 609, Training loss: 1.375684, Validation loss: 1.5792, lr: 0.0000\n",
      "Epoch: 610, Training loss: 1.377336, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 611, Training loss: 1.384381, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 612, Training loss: 1.364748, Validation loss: 1.3615, lr: 0.0000\n",
      "Epoch: 613, Training loss: 1.371127, Validation loss: 1.3657, lr: 0.0000\n",
      "Epoch: 614, Training loss: 1.378022, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 615, Training loss: 1.375375, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 616, Training loss: 1.362481, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 617, Training loss: 1.389709, Validation loss: 1.3764, lr: 0.0000\n",
      "Epoch: 618, Training loss: 1.386282, Validation loss: 1.3778, lr: 0.0000\n",
      "Epoch: 619, Training loss: 1.364874, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 620, Training loss: 1.371682, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 621, Training loss: 1.381502, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 622, Training loss: 1.372751, Validation loss: 1.3731, lr: 0.0000\n",
      "Epoch: 623, Training loss: 1.374300, Validation loss: 1.3880, lr: 0.0000\n",
      "Epoch: 624, Training loss: 1.365970, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 625, Training loss: 1.392598, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 626, Training loss: 1.365256, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 627, Training loss: 1.373766, Validation loss: 1.3658, lr: 0.0000\n",
      "Epoch: 628, Training loss: 1.366878, Validation loss: 1.3764, lr: 0.0000\n",
      "Epoch: 629, Training loss: 1.385530, Validation loss: 1.3906, lr: 0.0000\n",
      "Epoch: 630, Training loss: 1.378388, Validation loss: 1.3701, lr: 0.0000\n",
      "Epoch: 631, Training loss: 1.424758, Validation loss: 1.3883, lr: 0.0000\n",
      "Epoch: 632, Training loss: 1.388834, Validation loss: 1.3785, lr: 0.0000\n",
      "Epoch: 633, Training loss: 1.379704, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 634, Training loss: 1.371461, Validation loss: 1.3897, lr: 0.0000\n",
      "Epoch: 635, Training loss: 1.354025, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 636, Training loss: 1.386527, Validation loss: 1.3726, lr: 0.0000\n",
      "Epoch: 637, Training loss: 1.383256, Validation loss: 1.3730, lr: 0.0000\n",
      "Epoch: 638, Training loss: 1.372786, Validation loss: 1.4646, lr: 0.0000\n",
      "Epoch: 639, Training loss: 1.358905, Validation loss: 1.3688, lr: 0.0000\n",
      "Epoch: 640, Training loss: 1.400556, Validation loss: 1.3588, lr: 0.0000\n",
      "Epoch: 641, Training loss: 1.377491, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 642, Training loss: 1.396556, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 643, Training loss: 1.375211, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 644, Training loss: 1.377436, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 645, Training loss: 1.380410, Validation loss: 1.3785, lr: 0.0000\n",
      "Epoch: 646, Training loss: 1.366297, Validation loss: 1.3785, lr: 0.0000\n",
      "Epoch: 647, Training loss: 1.375286, Validation loss: 1.3704, lr: 0.0000\n",
      "Epoch: 648, Training loss: 1.376343, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 649, Training loss: 1.388430, Validation loss: 1.3549, lr: 0.0000\n",
      "Epoch: 650, Training loss: 1.374550, Validation loss: 1.3787, lr: 0.0000\n",
      "Epoch: 651, Training loss: 1.364752, Validation loss: 1.3799, lr: 0.0000\n",
      "Epoch: 652, Training loss: 1.370016, Validation loss: 1.3792, lr: 0.0000\n",
      "Epoch: 653, Training loss: 1.385962, Validation loss: 1.3734, lr: 0.0000\n",
      "Epoch: 654, Training loss: 1.362825, Validation loss: 1.3748, lr: 0.0000\n",
      "Epoch: 655, Training loss: 1.375830, Validation loss: 1.3749, lr: 0.0000\n",
      "Epoch: 656, Training loss: 1.369868, Validation loss: 1.3781, lr: 0.0000\n",
      "Epoch: 657, Training loss: 1.371272, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 658, Training loss: 1.369313, Validation loss: 1.3738, lr: 0.0000\n",
      "Epoch: 659, Training loss: 1.388826, Validation loss: 1.3667, lr: 0.0000\n",
      "Epoch: 660, Training loss: 1.391872, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 661, Training loss: 1.376612, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 662, Training loss: 1.380828, Validation loss: 1.3727, lr: 0.0000\n",
      "Epoch: 663, Training loss: 1.375234, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 664, Training loss: 1.369979, Validation loss: 1.3775, lr: 0.0000\n",
      "Epoch: 665, Training loss: 1.370660, Validation loss: 1.3724, lr: 0.0000\n",
      "Epoch: 666, Training loss: 1.375075, Validation loss: 1.3786, lr: 0.0000\n",
      "Epoch: 667, Training loss: 1.375322, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 668, Training loss: 1.372522, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 669, Training loss: 1.384768, Validation loss: 1.3720, lr: 0.0000\n",
      "Epoch: 670, Training loss: 1.376277, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 671, Training loss: 1.376191, Validation loss: 1.3721, lr: 0.0000\n",
      "Epoch: 672, Training loss: 1.379859, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 673, Training loss: 1.380477, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 674, Training loss: 1.377234, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 675, Training loss: 1.365497, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 676, Training loss: 1.371914, Validation loss: 1.3787, lr: 0.0000\n",
      "Epoch: 677, Training loss: 1.380985, Validation loss: 1.3872, lr: 0.0000\n",
      "Epoch: 678, Training loss: 1.381212, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 679, Training loss: 1.374509, Validation loss: 1.3937, lr: 0.0000\n",
      "Epoch: 680, Training loss: 1.368764, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 681, Training loss: 1.376989, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 682, Training loss: 1.392166, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 683, Training loss: 1.376243, Validation loss: 1.3798, lr: 0.0000\n",
      "Epoch: 684, Training loss: 1.387236, Validation loss: 1.3657, lr: 0.0000\n",
      "Epoch: 685, Training loss: 1.372144, Validation loss: 1.3886, lr: 0.0000\n",
      "Epoch: 686, Training loss: 1.377334, Validation loss: 1.3640, lr: 0.0000\n",
      "Epoch: 687, Training loss: 1.385593, Validation loss: 1.3739, lr: 0.0000\n",
      "Epoch: 688, Training loss: 1.370518, Validation loss: 1.3738, lr: 0.0000\n",
      "Epoch: 689, Training loss: 1.379274, Validation loss: 1.3727, lr: 0.0000\n",
      "Epoch: 690, Training loss: 1.365129, Validation loss: 1.3791, lr: 0.0000\n",
      "Epoch: 691, Training loss: 1.376791, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 692, Training loss: 1.387225, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 693, Training loss: 1.364514, Validation loss: 1.3673, lr: 0.0000\n",
      "Epoch: 694, Training loss: 1.381055, Validation loss: 1.3882, lr: 0.0000\n",
      "Epoch: 695, Training loss: 1.350537, Validation loss: 1.3875, lr: 0.0000\n",
      "Epoch: 696, Training loss: 1.378700, Validation loss: 1.3749, lr: 0.0000\n",
      "Epoch: 697, Training loss: 1.397025, Validation loss: 1.3779, lr: 0.0000\n",
      "Epoch: 698, Training loss: 1.389901, Validation loss: 1.3740, lr: 0.0000\n",
      "Epoch: 699, Training loss: 1.385556, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 700, Training loss: 1.369251, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 701, Training loss: 1.357988, Validation loss: 1.3760, lr: 0.0000\n",
      "Epoch: 702, Training loss: 1.368737, Validation loss: 1.3594, lr: 0.0000\n",
      "Epoch: 703, Training loss: 1.367643, Validation loss: 1.3877, lr: 0.0000\n",
      "Epoch: 704, Training loss: 1.382800, Validation loss: 1.3740, lr: 0.0000\n",
      "Epoch: 705, Training loss: 1.400215, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 706, Training loss: 1.365283, Validation loss: 1.3893, lr: 0.0000\n",
      "Epoch: 707, Training loss: 1.377614, Validation loss: 1.3741, lr: 0.0000\n",
      "Epoch: 708, Training loss: 1.377170, Validation loss: 1.3762, lr: 0.0000\n",
      "Epoch: 709, Training loss: 1.361278, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 710, Training loss: 1.385618, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 711, Training loss: 1.383991, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 712, Training loss: 1.368563, Validation loss: 1.3748, lr: 0.0000\n",
      "Epoch: 713, Training loss: 1.397316, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 714, Training loss: 1.372499, Validation loss: 1.3571, lr: 0.0000\n",
      "Epoch: 715, Training loss: 1.381990, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 716, Training loss: 1.365243, Validation loss: 1.3785, lr: 0.0000\n",
      "Epoch: 717, Training loss: 1.377157, Validation loss: 1.3890, lr: 0.0000\n",
      "Epoch: 718, Training loss: 1.376758, Validation loss: 1.3788, lr: 0.0000\n",
      "Epoch: 719, Training loss: 1.377593, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 720, Training loss: 1.382843, Validation loss: 1.3803, lr: 0.0000\n",
      "Epoch: 721, Training loss: 1.373830, Validation loss: 1.3780, lr: 0.0000\n",
      "Epoch: 722, Training loss: 1.387989, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 723, Training loss: 1.385226, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 724, Training loss: 1.374206, Validation loss: 1.3789, lr: 0.0000\n",
      "Epoch: 725, Training loss: 1.372178, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 726, Training loss: 1.379787, Validation loss: 1.3645, lr: 0.0000\n",
      "Epoch: 727, Training loss: 1.375415, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 728, Training loss: 1.367604, Validation loss: 1.3637, lr: 0.0000\n",
      "Epoch: 729, Training loss: 1.353302, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 730, Training loss: 1.377125, Validation loss: 1.3715, lr: 0.0000\n",
      "Epoch: 731, Training loss: 1.394210, Validation loss: 1.3627, lr: 0.0000\n",
      "Epoch: 732, Training loss: 1.382644, Validation loss: 1.3792, lr: 0.0000\n",
      "Epoch: 733, Training loss: 1.385601, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 734, Training loss: 1.385932, Validation loss: 1.3771, lr: 0.0000\n",
      "Epoch: 735, Training loss: 1.381727, Validation loss: 1.3873, lr: 0.0000\n",
      "Epoch: 736, Training loss: 1.383110, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 737, Training loss: 1.380219, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 738, Training loss: 1.374228, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 739, Training loss: 1.372806, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 740, Training loss: 1.400140, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 741, Training loss: 1.368702, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 742, Training loss: 1.384674, Validation loss: 1.3696, lr: 0.0000\n",
      "Epoch: 743, Training loss: 1.384241, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 744, Training loss: 1.376937, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 745, Training loss: 1.414238, Validation loss: 1.3689, lr: 0.0000\n",
      "Epoch: 746, Training loss: 1.377059, Validation loss: 1.3793, lr: 0.0000\n",
      "Epoch: 747, Training loss: 1.369208, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 748, Training loss: 1.374664, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 749, Training loss: 1.380598, Validation loss: 1.3901, lr: 0.0000\n",
      "Epoch: 750, Training loss: 1.382039, Validation loss: 1.3873, lr: 0.0000\n",
      "Epoch: 751, Training loss: 1.404665, Validation loss: 1.3880, lr: 0.0000\n",
      "Epoch: 752, Training loss: 1.372368, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 753, Training loss: 1.392717, Validation loss: 1.3672, lr: 0.0000\n",
      "Epoch: 754, Training loss: 1.374756, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 755, Training loss: 1.384788, Validation loss: 1.3885, lr: 0.0000\n",
      "Epoch: 756, Training loss: 1.369484, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 757, Training loss: 1.368121, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 758, Training loss: 1.374958, Validation loss: 1.3803, lr: 0.0000\n",
      "Epoch: 759, Training loss: 1.369305, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 760, Training loss: 1.389714, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 761, Training loss: 1.378342, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 762, Training loss: 1.372487, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 763, Training loss: 1.366040, Validation loss: 1.3871, lr: 0.0000\n",
      "Epoch: 764, Training loss: 1.367120, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 765, Training loss: 1.372633, Validation loss: 1.3782, lr: 0.0000\n",
      "Epoch: 766, Training loss: 1.392473, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 767, Training loss: 1.383810, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 768, Training loss: 1.390064, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 769, Training loss: 1.375481, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 770, Training loss: 1.361623, Validation loss: 1.3671, lr: 0.0000\n",
      "Epoch: 771, Training loss: 1.386642, Validation loss: 1.3878, lr: 0.0000\n",
      "Epoch: 772, Training loss: 1.366938, Validation loss: 1.3763, lr: 0.0000\n",
      "Epoch: 773, Training loss: 1.363473, Validation loss: 1.3698, lr: 0.0000\n",
      "Epoch: 774, Training loss: 1.397149, Validation loss: 1.3744, lr: 0.0000\n",
      "Epoch: 775, Training loss: 1.402881, Validation loss: 1.3732, lr: 0.0000\n",
      "Epoch: 776, Training loss: 1.378324, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 777, Training loss: 1.374220, Validation loss: 1.3877, lr: 0.0000\n",
      "Epoch: 778, Training loss: 1.359095, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 779, Training loss: 1.385731, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 780, Training loss: 1.380920, Validation loss: 1.3740, lr: 0.0000\n",
      "Epoch: 781, Training loss: 1.390569, Validation loss: 1.3762, lr: 0.0000\n",
      "Epoch: 782, Training loss: 1.369096, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 783, Training loss: 1.374306, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 784, Training loss: 1.377613, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 785, Training loss: 1.379239, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 786, Training loss: 1.383158, Validation loss: 1.3757, lr: 0.0000\n",
      "Epoch: 787, Training loss: 1.378664, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 788, Training loss: 1.377673, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 789, Training loss: 1.375651, Validation loss: 1.3720, lr: 0.0000\n",
      "Epoch: 790, Training loss: 1.371967, Validation loss: 1.3664, lr: 0.0000\n",
      "Epoch: 791, Training loss: 1.367469, Validation loss: 1.3795, lr: 0.0000\n",
      "Epoch: 792, Training loss: 1.377675, Validation loss: 1.3892, lr: 0.0000\n",
      "Epoch: 793, Training loss: 1.371165, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 794, Training loss: 1.370550, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 795, Training loss: 1.392081, Validation loss: 1.3895, lr: 0.0000\n",
      "Epoch: 796, Training loss: 1.392644, Validation loss: 1.3790, lr: 0.0000\n",
      "Epoch: 797, Training loss: 1.383920, Validation loss: 1.3735, lr: 0.0000\n",
      "Epoch: 798, Training loss: 1.372380, Validation loss: 1.3890, lr: 0.0000\n",
      "Epoch: 799, Training loss: 1.378628, Validation loss: 1.3744, lr: 0.0000\n",
      "Epoch: 800, Training loss: 1.376568, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 801, Training loss: 1.385238, Validation loss: 1.3989, lr: 0.0000\n",
      "Epoch: 802, Training loss: 1.365784, Validation loss: 1.3774, lr: 0.0000\n",
      "Epoch: 803, Training loss: 1.358232, Validation loss: 1.3771, lr: 0.0000\n",
      "Epoch: 804, Training loss: 1.364275, Validation loss: 1.3802, lr: 0.0000\n",
      "Epoch: 805, Training loss: 1.369720, Validation loss: 1.3910, lr: 0.0000\n",
      "Epoch: 806, Training loss: 1.396406, Validation loss: 1.3705, lr: 0.0000\n",
      "Epoch: 807, Training loss: 1.370036, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 808, Training loss: 1.366241, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 809, Training loss: 1.379218, Validation loss: 1.3886, lr: 0.0000\n",
      "Epoch: 810, Training loss: 1.374962, Validation loss: 1.3640, lr: 0.0000\n",
      "Epoch: 811, Training loss: 1.371037, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 812, Training loss: 1.367833, Validation loss: 1.3707, lr: 0.0000\n",
      "Epoch: 813, Training loss: 1.368951, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 814, Training loss: 1.398676, Validation loss: 1.3941, lr: 0.0000\n",
      "Epoch: 815, Training loss: 1.374482, Validation loss: 1.3667, lr: 0.0000\n",
      "Epoch: 816, Training loss: 1.374400, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 817, Training loss: 1.369316, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 818, Training loss: 1.365118, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 819, Training loss: 1.378661, Validation loss: 1.3871, lr: 0.0000\n",
      "Epoch: 820, Training loss: 1.370287, Validation loss: 1.3734, lr: 0.0000\n",
      "Epoch: 821, Training loss: 1.374844, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 822, Training loss: 1.383366, Validation loss: 1.3922, lr: 0.0000\n",
      "Epoch: 823, Training loss: 1.363674, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 824, Training loss: 1.362629, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 825, Training loss: 1.374900, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 826, Training loss: 1.373810, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 827, Training loss: 1.368780, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 828, Training loss: 1.372616, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 829, Training loss: 1.378282, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 830, Training loss: 1.392719, Validation loss: 1.3908, lr: 0.0000\n",
      "Epoch: 831, Training loss: 1.374947, Validation loss: 1.3796, lr: 0.0000\n",
      "Epoch: 832, Training loss: 1.373816, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 833, Training loss: 1.391073, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 834, Training loss: 1.379768, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 835, Training loss: 1.390749, Validation loss: 1.3873, lr: 0.0000\n",
      "Epoch: 836, Training loss: 1.386419, Validation loss: 1.3974, lr: 0.0000\n",
      "Epoch: 837, Training loss: 1.375579, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 838, Training loss: 1.378394, Validation loss: 1.3725, lr: 0.0000\n",
      "Epoch: 839, Training loss: 1.387477, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 840, Training loss: 1.366639, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 841, Training loss: 1.370723, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 842, Training loss: 1.387809, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 843, Training loss: 1.367825, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 844, Training loss: 1.373619, Validation loss: 1.3694, lr: 0.0000\n",
      "Epoch: 845, Training loss: 1.376509, Validation loss: 1.3775, lr: 0.0000\n",
      "Epoch: 846, Training loss: 1.365331, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 847, Training loss: 1.373092, Validation loss: 1.3642, lr: 0.0000\n",
      "Epoch: 848, Training loss: 1.379407, Validation loss: 1.3761, lr: 0.0000\n",
      "Epoch: 849, Training loss: 1.381278, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 850, Training loss: 1.386291, Validation loss: 1.3726, lr: 0.0000\n",
      "Epoch: 851, Training loss: 1.390707, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 852, Training loss: 1.390153, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 853, Training loss: 1.384895, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 854, Training loss: 1.374599, Validation loss: 1.3738, lr: 0.0000\n",
      "Epoch: 855, Training loss: 1.382992, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 856, Training loss: 1.365013, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 857, Training loss: 1.369894, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 858, Training loss: 1.385230, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 859, Training loss: 1.388117, Validation loss: 1.3764, lr: 0.0000\n",
      "Epoch: 860, Training loss: 1.367034, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 861, Training loss: 1.383870, Validation loss: 1.4024, lr: 0.0000\n",
      "Epoch: 862, Training loss: 1.378916, Validation loss: 1.3641, lr: 0.0000\n",
      "Epoch: 863, Training loss: 1.430055, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 864, Training loss: 1.371267, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 865, Training loss: 1.372879, Validation loss: 1.3892, lr: 0.0000\n",
      "Epoch: 866, Training loss: 1.391705, Validation loss: 1.3714, lr: 0.0000\n",
      "Epoch: 867, Training loss: 1.373279, Validation loss: 1.3775, lr: 0.0000\n",
      "Epoch: 868, Training loss: 1.377220, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 869, Training loss: 1.382427, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 870, Training loss: 1.380523, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 871, Training loss: 1.368156, Validation loss: 1.3781, lr: 0.0000\n",
      "Epoch: 872, Training loss: 1.369444, Validation loss: 1.3877, lr: 0.0000\n",
      "Epoch: 873, Training loss: 1.366419, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 874, Training loss: 1.361681, Validation loss: 1.3803, lr: 0.0000\n",
      "Epoch: 875, Training loss: 1.370761, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 876, Training loss: 1.368573, Validation loss: 1.3726, lr: 0.0000\n",
      "Epoch: 877, Training loss: 1.385397, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 878, Training loss: 1.389389, Validation loss: 1.3786, lr: 0.0000\n",
      "Epoch: 879, Training loss: 1.378418, Validation loss: 1.3793, lr: 0.0000\n",
      "Epoch: 880, Training loss: 1.380329, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 881, Training loss: 1.365872, Validation loss: 1.3773, lr: 0.0000\n",
      "Epoch: 882, Training loss: 1.376118, Validation loss: 1.3775, lr: 0.0000\n",
      "Epoch: 883, Training loss: 1.364737, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 884, Training loss: 1.364126, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 885, Training loss: 1.357230, Validation loss: 1.3873, lr: 0.0000\n",
      "Epoch: 886, Training loss: 1.374451, Validation loss: 1.3881, lr: 0.0000\n",
      "Epoch: 887, Training loss: 1.394462, Validation loss: 1.3981, lr: 0.0000\n",
      "Epoch: 888, Training loss: 1.383136, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 889, Training loss: 1.372615, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 890, Training loss: 1.380332, Validation loss: 1.3920, lr: 0.0000\n",
      "Epoch: 891, Training loss: 1.361272, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 892, Training loss: 1.368218, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 893, Training loss: 1.370922, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 894, Training loss: 1.392202, Validation loss: 1.3901, lr: 0.0000\n",
      "Epoch: 895, Training loss: 1.361771, Validation loss: 1.3759, lr: 0.0000\n",
      "Epoch: 896, Training loss: 1.368339, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 897, Training loss: 1.366679, Validation loss: 1.3621, lr: 0.0000\n",
      "Epoch: 898, Training loss: 1.382560, Validation loss: 1.3909, lr: 0.0000\n",
      "Epoch: 899, Training loss: 1.376211, Validation loss: 1.3503, lr: 0.0000\n",
      "Epoch: 900, Training loss: 1.397502, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 901, Training loss: 1.383141, Validation loss: 1.3770, lr: 0.0000\n",
      "Epoch: 902, Training loss: 1.385201, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 903, Training loss: 1.381257, Validation loss: 1.3764, lr: 0.0000\n",
      "Epoch: 904, Training loss: 1.385152, Validation loss: 1.3785, lr: 0.0000\n",
      "Epoch: 905, Training loss: 1.379605, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 906, Training loss: 1.371888, Validation loss: 1.3652, lr: 0.0000\n",
      "Epoch: 907, Training loss: 1.369642, Validation loss: 1.3733, lr: 0.0000\n",
      "Epoch: 908, Training loss: 1.378450, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 909, Training loss: 1.365915, Validation loss: 1.3872, lr: 0.0000\n",
      "Epoch: 910, Training loss: 1.369460, Validation loss: 1.3701, lr: 0.0000\n",
      "Epoch: 911, Training loss: 1.359011, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 912, Training loss: 1.372447, Validation loss: 1.3717, lr: 0.0000\n",
      "Epoch: 913, Training loss: 1.440738, Validation loss: 1.3679, lr: 0.0000\n",
      "Epoch: 914, Training loss: 1.370606, Validation loss: 1.3787, lr: 0.0000\n",
      "Epoch: 915, Training loss: 1.368074, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 916, Training loss: 1.376028, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 917, Training loss: 1.343842, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 918, Training loss: 1.392296, Validation loss: 1.3770, lr: 0.0000\n",
      "Epoch: 919, Training loss: 1.415277, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 920, Training loss: 1.375359, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 921, Training loss: 1.400822, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 922, Training loss: 1.375648, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 923, Training loss: 1.380799, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 924, Training loss: 1.383790, Validation loss: 1.3760, lr: 0.0000\n",
      "Epoch: 925, Training loss: 1.381123, Validation loss: 1.3777, lr: 0.0000\n",
      "Epoch: 926, Training loss: 1.378409, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 927, Training loss: 1.359396, Validation loss: 1.3802, lr: 0.0000\n",
      "Epoch: 928, Training loss: 1.372034, Validation loss: 1.3378, lr: 0.0000\n",
      "Epoch: 929, Training loss: 1.372054, Validation loss: 1.3765, lr: 0.0000\n",
      "Epoch: 930, Training loss: 1.365329, Validation loss: 1.3576, lr: 0.0000\n",
      "Epoch: 931, Training loss: 1.387249, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 932, Training loss: 1.381391, Validation loss: 1.3627, lr: 0.0000\n",
      "Epoch: 933, Training loss: 1.383448, Validation loss: 1.3884, lr: 0.0000\n",
      "Epoch: 934, Training loss: 1.367038, Validation loss: 1.3660, lr: 0.0000\n",
      "Epoch: 935, Training loss: 1.386573, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 936, Training loss: 1.385597, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 937, Training loss: 1.385426, Validation loss: 1.3893, lr: 0.0000\n",
      "Epoch: 938, Training loss: 1.376214, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 939, Training loss: 1.379446, Validation loss: 1.3770, lr: 0.0000\n",
      "Epoch: 940, Training loss: 1.399072, Validation loss: 1.3771, lr: 0.0000\n",
      "Epoch: 941, Training loss: 1.405167, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 942, Training loss: 1.374654, Validation loss: 1.3777, lr: 0.0000\n",
      "Epoch: 943, Training loss: 1.376978, Validation loss: 1.3787, lr: 0.0000\n",
      "Epoch: 944, Training loss: 1.365542, Validation loss: 1.3738, lr: 0.0000\n",
      "Epoch: 945, Training loss: 1.380452, Validation loss: 1.3885, lr: 0.0000\n",
      "Epoch: 946, Training loss: 1.366119, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 947, Training loss: 1.377875, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 948, Training loss: 1.384594, Validation loss: 1.3773, lr: 0.0000\n",
      "Epoch: 949, Training loss: 1.389994, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 950, Training loss: 1.380411, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 951, Training loss: 1.368116, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 952, Training loss: 1.361329, Validation loss: 1.4581, lr: 0.0000\n",
      "Epoch: 953, Training loss: 1.375548, Validation loss: 1.3770, lr: 0.0000\n",
      "Epoch: 954, Training loss: 1.358989, Validation loss: 1.3723, lr: 0.0000\n",
      "Epoch: 955, Training loss: 1.355973, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 956, Training loss: 1.381910, Validation loss: 1.3759, lr: 0.0000\n",
      "Epoch: 957, Training loss: 1.368796, Validation loss: 1.3693, lr: 0.0000\n",
      "Epoch: 958, Training loss: 1.372779, Validation loss: 1.3769, lr: 0.0000\n",
      "Epoch: 959, Training loss: 1.376736, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 960, Training loss: 1.382680, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 961, Training loss: 1.389870, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 962, Training loss: 1.375548, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 963, Training loss: 1.384676, Validation loss: 1.3872, lr: 0.0000\n",
      "Epoch: 964, Training loss: 1.365561, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 965, Training loss: 1.371538, Validation loss: 1.3776, lr: 0.0000\n",
      "Epoch: 966, Training loss: 1.380945, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 967, Training loss: 1.355819, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 968, Training loss: 1.371066, Validation loss: 1.3681, lr: 0.0000\n",
      "Epoch: 969, Training loss: 1.404710, Validation loss: 1.3782, lr: 0.0000\n",
      "Epoch: 970, Training loss: 1.352907, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 971, Training loss: 1.356200, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 972, Training loss: 1.377954, Validation loss: 1.3874, lr: 0.0000\n",
      "Epoch: 973, Training loss: 1.374949, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 974, Training loss: 1.370611, Validation loss: 1.3717, lr: 0.0000\n",
      "Epoch: 975, Training loss: 1.378385, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 976, Training loss: 1.390625, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 977, Training loss: 1.373960, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 978, Training loss: 1.385484, Validation loss: 1.3729, lr: 0.0000\n",
      "Epoch: 979, Training loss: 1.383155, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 980, Training loss: 1.375488, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 981, Training loss: 1.383407, Validation loss: 1.3760, lr: 0.0000\n",
      "Epoch: 982, Training loss: 1.383779, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 983, Training loss: 1.375353, Validation loss: 1.3588, lr: 0.0000\n",
      "Epoch: 984, Training loss: 1.368667, Validation loss: 1.3676, lr: 0.0000\n",
      "Epoch: 985, Training loss: 1.375716, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 986, Training loss: 1.359249, Validation loss: 1.4010, lr: 0.0000\n",
      "Epoch: 987, Training loss: 1.403764, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 988, Training loss: 1.376310, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 989, Training loss: 1.367333, Validation loss: 1.3677, lr: 0.0000\n",
      "Epoch: 990, Training loss: 1.367303, Validation loss: 1.3933, lr: 0.0000\n",
      "Epoch: 991, Training loss: 1.373960, Validation loss: 1.3877, lr: 0.0000\n",
      "Epoch: 992, Training loss: 1.370942, Validation loss: 1.3716, lr: 0.0000\n",
      "Epoch: 993, Training loss: 1.379476, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 994, Training loss: 1.377384, Validation loss: 1.3676, lr: 0.0000\n",
      "Epoch: 995, Training loss: 1.401632, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 996, Training loss: 1.376893, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 997, Training loss: 1.372623, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 998, Training loss: 1.371646, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 999, Training loss: 1.382808, Validation loss: 1.3810, lr: 0.0000\n",
      "Final test loss: 1.3736\n",
      "=== Run 04/10 ===\n",
      "\n",
      "---- Settings: \n",
      "\n",
      "epochs : 1000\n",
      "hidden_channels : [32]\n",
      "out_channels : 10\n",
      "inner_product_features : False\n",
      "batch_size : 64\n",
      "lr : 0.01\n",
      "momentum : 0.9\n",
      "dropout : 0.0\n",
      "batch_norm : batch_norm\n",
      "bias : True\n",
      "order : 2\n",
      "diffusion : True\n",
      "frac_sampled_nb : -1\n",
      "include_positions : False\n",
      "include_self : True\n",
      "vec_norm : False\n",
      "emb_norm : False\n",
      "seed : 0\n",
      "dim_signal : 100\n",
      "dim_emb : 100\n",
      "n_sampled_nb : -1\n",
      "\n",
      "---- Number of features to pass to the MLP:  1010100\n",
      "---- Total number of parameters:  32323627\n",
      "\n",
      "Using device cuda:0\n",
      "\n",
      "---- Training network ...\n",
      "\n",
      "---- Timestamp: 20250614-111423\n",
      "\n",
      " *och: 0, Training loss: 1.462986, Validation loss: 1.4293, lr: 0.0100\n",
      " *och: 1, Training loss: 1.383766, Validation loss: 1.3527, lr: 0.0100\n",
      "Epoch: 2, Training loss: 1.381471, Validation loss: 2.5646, lr: 0.0100\n",
      " *och: 3, Training loss: 1.405305, Validation loss: 1.3475, lr: 0.0100\n",
      "Epoch: 4, Training loss: 1.414661, Validation loss: 1.3912, lr: 0.0100\n",
      "Epoch: 5, Training loss: 1.373867, Validation loss: 1.3742, lr: 0.0100\n",
      "Epoch: 6, Training loss: 1.404669, Validation loss: 1.3969, lr: 0.0100\n",
      "Epoch: 7, Training loss: 1.435311, Validation loss: 1.3612, lr: 0.0100\n",
      "Epoch: 8, Training loss: 1.405225, Validation loss: 1.3847, lr: 0.0100\n",
      "Epoch: 9, Training loss: 1.369706, Validation loss: 1.3786, lr: 0.0100\n",
      "Epoch: 10, Training loss: 1.340082, Validation loss: 1.3655, lr: 0.0100\n",
      "Epoch: 11, Training loss: 1.368499, Validation loss: 1.4004, lr: 0.0100\n",
      "Epoch: 12, Training loss: 1.405076, Validation loss: 1.3602, lr: 0.0100\n",
      "Epoch: 13, Training loss: 1.371679, Validation loss: 1.3802, lr: 0.0100\n",
      "Epoch: 14, Training loss: 1.359000, Validation loss: 1.3597, lr: 0.0100\n",
      "Epoch: 15, Training loss: 1.380808, Validation loss: 1.3817, lr: 0.0100\n",
      "Epoch: 16, Training loss: 1.387050, Validation loss: 1.3557, lr: 0.0100\n",
      "Epoch: 17, Training loss: 1.361257, Validation loss: 1.3619, lr: 0.0100\n",
      "Epoch: 18, Training loss: 1.399761, Validation loss: 1.3924, lr: 0.0100\n",
      "Epoch: 19, Training loss: 1.394554, Validation loss: 1.3988, lr: 0.0100\n",
      "Epoch: 20, Training loss: 1.373671, Validation loss: 1.3756, lr: 0.0100\n",
      "Epoch: 21, Training loss: 1.380039, Validation loss: 1.3803, lr: 0.0010\n",
      "Epoch: 22, Training loss: 1.439555, Validation loss: 1.3839, lr: 0.0010\n",
      "Epoch: 23, Training loss: 1.347376, Validation loss: 1.3782, lr: 0.0010\n",
      "Epoch: 24, Training loss: 1.362765, Validation loss: 1.3745, lr: 0.0010\n",
      "Epoch: 25, Training loss: 1.364427, Validation loss: 1.3827, lr: 0.0010\n",
      "Epoch: 26, Training loss: 1.366139, Validation loss: 1.3747, lr: 0.0010\n",
      "Epoch: 27, Training loss: 1.385146, Validation loss: 1.4039, lr: 0.0010\n",
      "Epoch: 28, Training loss: 1.378763, Validation loss: 1.3820, lr: 0.0010\n",
      "Epoch: 29, Training loss: 1.386104, Validation loss: 1.3977, lr: 0.0010\n",
      "Epoch: 30, Training loss: 1.337894, Validation loss: 1.3808, lr: 0.0010\n",
      "Epoch: 31, Training loss: 1.370967, Validation loss: 1.3784, lr: 0.0010\n",
      "Epoch: 32, Training loss: 1.362866, Validation loss: 1.3804, lr: 0.0010\n",
      "Epoch: 33, Training loss: 1.350482, Validation loss: 1.3716, lr: 0.0010\n",
      "Epoch: 34, Training loss: 1.359078, Validation loss: 1.3598, lr: 0.0010\n",
      "Epoch: 35, Training loss: 1.379377, Validation loss: 1.3876, lr: 0.0010\n",
      "Epoch: 36, Training loss: 1.375576, Validation loss: 1.3822, lr: 0.0010\n",
      "Epoch: 37, Training loss: 1.372952, Validation loss: 1.3722, lr: 0.0010\n",
      "Epoch: 38, Training loss: 1.385150, Validation loss: 1.3702, lr: 0.0010\n",
      "Epoch: 39, Training loss: 1.370140, Validation loss: 1.3554, lr: 0.0010\n",
      "Epoch: 40, Training loss: 1.404086, Validation loss: 1.3800, lr: 0.0010\n",
      "Epoch: 41, Training loss: 1.373329, Validation loss: 1.3722, lr: 0.0001\n",
      "Epoch: 42, Training loss: 1.359556, Validation loss: 1.3895, lr: 0.0001\n",
      "Epoch: 43, Training loss: 1.385516, Validation loss: 1.3775, lr: 0.0001\n",
      "Epoch: 44, Training loss: 1.355475, Validation loss: 1.3705, lr: 0.0001\n",
      "Epoch: 45, Training loss: 1.339550, Validation loss: 1.3761, lr: 0.0001\n",
      "Epoch: 46, Training loss: 1.372323, Validation loss: 1.3819, lr: 0.0001\n",
      "Epoch: 47, Training loss: 1.358888, Validation loss: 1.3775, lr: 0.0001\n",
      "Epoch: 48, Training loss: 1.355811, Validation loss: 1.3962, lr: 0.0001\n",
      "Epoch: 49, Training loss: 1.361650, Validation loss: 1.3829, lr: 0.0001\n",
      "Epoch: 50, Training loss: 1.411528, Validation loss: 1.3948, lr: 0.0001\n",
      "Epoch: 51, Training loss: 1.362779, Validation loss: 1.3802, lr: 0.0001\n",
      "Epoch: 52, Training loss: 1.363801, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 53, Training loss: 1.385844, Validation loss: 1.3654, lr: 0.0000\n",
      "Epoch: 54, Training loss: 1.374409, Validation loss: 1.3608, lr: 0.0000\n",
      "Epoch: 55, Training loss: 1.357824, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 56, Training loss: 1.369447, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 57, Training loss: 1.376416, Validation loss: 1.3625, lr: 0.0000\n",
      "Epoch: 58, Training loss: 1.414709, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 59, Training loss: 1.348024, Validation loss: 1.3679, lr: 0.0000\n",
      "Epoch: 60, Training loss: 1.359722, Validation loss: 1.3697, lr: 0.0000\n",
      "Epoch: 61, Training loss: 1.353999, Validation loss: 1.3780, lr: 0.0000\n",
      "Epoch: 62, Training loss: 1.348879, Validation loss: 1.3770, lr: 0.0000\n",
      "Epoch: 63, Training loss: 1.375340, Validation loss: 1.3793, lr: 0.0000\n",
      "Epoch: 64, Training loss: 1.367644, Validation loss: 1.4113, lr: 0.0000\n",
      "Epoch: 65, Training loss: 1.348929, Validation loss: 1.3725, lr: 0.0000\n",
      "Epoch: 66, Training loss: 1.378904, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 67, Training loss: 1.349801, Validation loss: 1.3774, lr: 0.0000\n",
      "Epoch: 68, Training loss: 1.365419, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 69, Training loss: 1.384561, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 70, Training loss: 1.382071, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 71, Training loss: 1.413329, Validation loss: 1.3667, lr: 0.0000\n",
      "Epoch: 72, Training loss: 1.355049, Validation loss: 1.3717, lr: 0.0000\n",
      "Epoch: 73, Training loss: 1.378598, Validation loss: 1.3657, lr: 0.0000\n",
      "Epoch: 74, Training loss: 1.361920, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 75, Training loss: 1.371910, Validation loss: 1.3906, lr: 0.0000\n",
      "Epoch: 76, Training loss: 1.347481, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 77, Training loss: 1.371927, Validation loss: 1.3598, lr: 0.0000\n",
      "Epoch: 78, Training loss: 1.355957, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 79, Training loss: 1.375979, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 80, Training loss: 1.466143, Validation loss: 1.3790, lr: 0.0000\n",
      "Epoch: 81, Training loss: 1.357125, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 82, Training loss: 1.393891, Validation loss: 1.3993, lr: 0.0000\n",
      "Epoch: 83, Training loss: 1.349621, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 84, Training loss: 1.363258, Validation loss: 1.4737, lr: 0.0000\n",
      "Epoch: 85, Training loss: 1.368827, Validation loss: 1.3721, lr: 0.0000\n",
      "Epoch: 86, Training loss: 1.350522, Validation loss: 1.3634, lr: 0.0000\n",
      "Epoch: 87, Training loss: 1.391233, Validation loss: 1.4075, lr: 0.0000\n",
      "Epoch: 88, Training loss: 1.377856, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 89, Training loss: 1.349577, Validation loss: 1.3747, lr: 0.0000\n",
      "Epoch: 90, Training loss: 1.351584, Validation loss: 1.3764, lr: 0.0000\n",
      "Epoch: 91, Training loss: 1.365268, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 92, Training loss: 1.379378, Validation loss: 1.3706, lr: 0.0000\n",
      "Epoch: 93, Training loss: 1.361596, Validation loss: 1.3782, lr: 0.0000\n",
      "Epoch: 94, Training loss: 1.375588, Validation loss: 1.3583, lr: 0.0000\n",
      "Epoch: 95, Training loss: 1.353102, Validation loss: 1.3633, lr: 0.0000\n",
      "Epoch: 96, Training loss: 1.386898, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 97, Training loss: 1.363712, Validation loss: 1.3635, lr: 0.0000\n",
      "Epoch: 98, Training loss: 1.365664, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 99, Training loss: 1.366728, Validation loss: 1.3897, lr: 0.0000\n",
      "Epoch: 100, Training loss: 1.398198, Validation loss: 1.3901, lr: 0.0000\n",
      "Epoch: 101, Training loss: 1.386725, Validation loss: 1.3725, lr: 0.0000\n",
      "Epoch: 102, Training loss: 1.366071, Validation loss: 1.3724, lr: 0.0000\n",
      "Epoch: 103, Training loss: 1.369371, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 104, Training loss: 1.361125, Validation loss: 1.3796, lr: 0.0000\n",
      "Epoch: 105, Training loss: 1.369710, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 106, Training loss: 1.352294, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 107, Training loss: 1.388836, Validation loss: 1.3713, lr: 0.0000\n",
      "Epoch: 108, Training loss: 1.375601, Validation loss: 1.3756, lr: 0.0000\n",
      "Epoch: 109, Training loss: 1.361971, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 110, Training loss: 1.446400, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 111, Training loss: 1.366035, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 112, Training loss: 1.375100, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 113, Training loss: 1.366728, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 114, Training loss: 1.352181, Validation loss: 1.3782, lr: 0.0000\n",
      "Epoch: 115, Training loss: 1.358441, Validation loss: 1.3570, lr: 0.0000\n",
      "Epoch: 116, Training loss: 1.343995, Validation loss: 1.3619, lr: 0.0000\n",
      "Epoch: 117, Training loss: 1.368584, Validation loss: 1.3913, lr: 0.0000\n",
      "Epoch: 118, Training loss: 1.379782, Validation loss: 1.3736, lr: 0.0000\n",
      "Epoch: 119, Training loss: 1.383063, Validation loss: 1.3734, lr: 0.0000\n",
      "Epoch: 120, Training loss: 1.356426, Validation loss: 1.3883, lr: 0.0000\n",
      "Epoch: 121, Training loss: 1.375806, Validation loss: 1.3650, lr: 0.0000\n",
      "Epoch: 122, Training loss: 1.341254, Validation loss: 1.3635, lr: 0.0000\n",
      "Epoch: 123, Training loss: 1.370548, Validation loss: 1.3705, lr: 0.0000\n",
      "Epoch: 124, Training loss: 1.361526, Validation loss: 1.3728, lr: 0.0000\n",
      "Epoch: 125, Training loss: 1.372488, Validation loss: 1.3740, lr: 0.0000\n",
      "Epoch: 126, Training loss: 1.343643, Validation loss: 1.3788, lr: 0.0000\n",
      "Epoch: 127, Training loss: 1.359745, Validation loss: 1.3713, lr: 0.0000\n",
      "Epoch: 128, Training loss: 1.407250, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 129, Training loss: 1.354461, Validation loss: 1.3780, lr: 0.0000\n",
      "Epoch: 130, Training loss: 1.358347, Validation loss: 1.3786, lr: 0.0000\n",
      "Epoch: 131, Training loss: 1.392521, Validation loss: 1.3906, lr: 0.0000\n",
      "Epoch: 132, Training loss: 1.386237, Validation loss: 1.3586, lr: 0.0000\n",
      "Epoch: 133, Training loss: 1.403031, Validation loss: 1.3779, lr: 0.0000\n",
      "Epoch: 134, Training loss: 1.359882, Validation loss: 1.3798, lr: 0.0000\n",
      "Epoch: 135, Training loss: 1.352182, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 136, Training loss: 1.361855, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 137, Training loss: 1.374014, Validation loss: 1.3825, lr: 0.0000\n",
      " *och: 138, Training loss: 1.359983, Validation loss: 1.3319, lr: 0.0000\n",
      "Epoch: 139, Training loss: 1.365769, Validation loss: 1.3654, lr: 0.0000\n",
      "Epoch: 140, Training loss: 1.380772, Validation loss: 1.3679, lr: 0.0000\n",
      "Epoch: 141, Training loss: 1.367379, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 142, Training loss: 1.406105, Validation loss: 1.3659, lr: 0.0000\n",
      "Epoch: 143, Training loss: 1.370035, Validation loss: 1.3880, lr: 0.0000\n",
      "Epoch: 144, Training loss: 1.361255, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 145, Training loss: 1.470148, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 146, Training loss: 1.350706, Validation loss: 1.3872, lr: 0.0000\n",
      "Epoch: 147, Training loss: 1.371032, Validation loss: 1.3633, lr: 0.0000\n",
      "Epoch: 148, Training loss: 1.403786, Validation loss: 1.3764, lr: 0.0000\n",
      "Epoch: 149, Training loss: 1.410299, Validation loss: 1.3912, lr: 0.0000\n",
      "Epoch: 150, Training loss: 1.363052, Validation loss: 1.3676, lr: 0.0000\n",
      "Epoch: 151, Training loss: 1.353904, Validation loss: 1.3701, lr: 0.0000\n",
      "Epoch: 152, Training loss: 1.378283, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 153, Training loss: 1.347023, Validation loss: 1.3957, lr: 0.0000\n",
      "Epoch: 154, Training loss: 1.350798, Validation loss: 1.3663, lr: 0.0000\n",
      "Epoch: 155, Training loss: 1.350715, Validation loss: 1.3688, lr: 0.0000\n",
      "Epoch: 156, Training loss: 1.385112, Validation loss: 1.3653, lr: 0.0000\n",
      "Epoch: 157, Training loss: 1.382921, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 158, Training loss: 1.346545, Validation loss: 1.3936, lr: 0.0000\n",
      "Epoch: 159, Training loss: 1.371234, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 160, Training loss: 1.368682, Validation loss: 1.4023, lr: 0.0000\n",
      "Epoch: 161, Training loss: 1.375827, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 162, Training loss: 1.363418, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 163, Training loss: 1.405986, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 164, Training loss: 1.377573, Validation loss: 1.3680, lr: 0.0000\n",
      "Epoch: 165, Training loss: 1.355667, Validation loss: 1.3667, lr: 0.0000\n",
      "Epoch: 166, Training loss: 1.379284, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 167, Training loss: 1.358254, Validation loss: 1.3758, lr: 0.0000\n",
      "Epoch: 168, Training loss: 1.390808, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 169, Training loss: 1.355088, Validation loss: 1.3712, lr: 0.0000\n",
      "Epoch: 170, Training loss: 1.371641, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 171, Training loss: 1.366829, Validation loss: 1.3562, lr: 0.0000\n",
      "Epoch: 172, Training loss: 1.434519, Validation loss: 1.4001, lr: 0.0000\n",
      "Epoch: 173, Training loss: 1.369835, Validation loss: 1.3769, lr: 0.0000\n",
      "Epoch: 174, Training loss: 1.351962, Validation loss: 1.3646, lr: 0.0000\n",
      "Epoch: 175, Training loss: 1.369244, Validation loss: 1.3658, lr: 0.0000\n",
      "Epoch: 176, Training loss: 1.350848, Validation loss: 1.3766, lr: 0.0000\n",
      "Epoch: 177, Training loss: 1.344938, Validation loss: 1.3606, lr: 0.0000\n",
      "Epoch: 178, Training loss: 1.361423, Validation loss: 1.3770, lr: 0.0000\n",
      "Epoch: 179, Training loss: 1.370687, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 180, Training loss: 1.390675, Validation loss: 1.3799, lr: 0.0000\n",
      "Epoch: 181, Training loss: 1.371105, Validation loss: 1.3764, lr: 0.0000\n",
      "Epoch: 182, Training loss: 1.359337, Validation loss: 1.3771, lr: 0.0000\n",
      "Epoch: 183, Training loss: 1.359920, Validation loss: 1.3702, lr: 0.0000\n",
      "Epoch: 184, Training loss: 1.368493, Validation loss: 1.3674, lr: 0.0000\n",
      "Epoch: 185, Training loss: 1.391722, Validation loss: 1.3733, lr: 0.0000\n",
      "Epoch: 186, Training loss: 1.351202, Validation loss: 1.3725, lr: 0.0000\n",
      "Epoch: 187, Training loss: 1.346068, Validation loss: 1.3641, lr: 0.0000\n",
      "Epoch: 188, Training loss: 1.355834, Validation loss: 1.3643, lr: 0.0000\n",
      "Epoch: 189, Training loss: 1.359050, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 190, Training loss: 1.362757, Validation loss: 1.3872, lr: 0.0000\n",
      "Epoch: 191, Training loss: 1.360542, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 192, Training loss: 1.428524, Validation loss: 1.3774, lr: 0.0000\n",
      "Epoch: 193, Training loss: 1.395738, Validation loss: 1.3710, lr: 0.0000\n",
      "Epoch: 194, Training loss: 1.372185, Validation loss: 1.3499, lr: 0.0000\n",
      "Epoch: 195, Training loss: 1.373695, Validation loss: 1.3875, lr: 0.0000\n",
      "Epoch: 196, Training loss: 1.339541, Validation loss: 1.3752, lr: 0.0000\n",
      "Epoch: 197, Training loss: 1.363395, Validation loss: 1.3661, lr: 0.0000\n",
      "Epoch: 198, Training loss: 1.357742, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 199, Training loss: 1.358901, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 200, Training loss: 1.376861, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 201, Training loss: 1.363939, Validation loss: 1.3738, lr: 0.0000\n",
      "Epoch: 202, Training loss: 1.348178, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 203, Training loss: 1.360136, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 204, Training loss: 1.389475, Validation loss: 1.3797, lr: 0.0000\n",
      "Epoch: 205, Training loss: 1.366435, Validation loss: 1.3705, lr: 0.0000\n",
      "Epoch: 206, Training loss: 1.356874, Validation loss: 1.4040, lr: 0.0000\n",
      "Epoch: 207, Training loss: 1.379003, Validation loss: 1.3777, lr: 0.0000\n",
      "Epoch: 208, Training loss: 1.360619, Validation loss: 1.3780, lr: 0.0000\n",
      "Epoch: 209, Training loss: 1.479910, Validation loss: 1.3876, lr: 0.0000\n",
      "Epoch: 210, Training loss: 1.383500, Validation loss: 1.3758, lr: 0.0000\n",
      "Epoch: 211, Training loss: 1.352276, Validation loss: 1.3768, lr: 0.0000\n",
      "Epoch: 212, Training loss: 1.367980, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 213, Training loss: 1.359035, Validation loss: 1.3641, lr: 0.0000\n",
      "Epoch: 214, Training loss: 1.366646, Validation loss: 1.3380, lr: 0.0000\n",
      "Epoch: 215, Training loss: 1.389972, Validation loss: 1.3906, lr: 0.0000\n",
      "Epoch: 216, Training loss: 1.386733, Validation loss: 1.3760, lr: 0.0000\n",
      "Epoch: 217, Training loss: 1.357241, Validation loss: 1.4795, lr: 0.0000\n",
      "Epoch: 218, Training loss: 1.353829, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 219, Training loss: 1.384480, Validation loss: 1.3751, lr: 0.0000\n",
      "Epoch: 220, Training loss: 1.376790, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 221, Training loss: 1.361868, Validation loss: 1.3661, lr: 0.0000\n",
      "Epoch: 222, Training loss: 1.361568, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 223, Training loss: 1.368990, Validation loss: 1.3882, lr: 0.0000\n",
      "Epoch: 224, Training loss: 1.360042, Validation loss: 1.3777, lr: 0.0000\n",
      "Epoch: 225, Training loss: 1.379316, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 226, Training loss: 1.355142, Validation loss: 1.3802, lr: 0.0000\n",
      "Epoch: 227, Training loss: 1.362782, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 228, Training loss: 1.352674, Validation loss: 1.3883, lr: 0.0000\n",
      "Epoch: 229, Training loss: 1.367234, Validation loss: 1.3773, lr: 0.0000\n",
      "Epoch: 230, Training loss: 1.353773, Validation loss: 1.3629, lr: 0.0000\n",
      "Epoch: 231, Training loss: 1.373652, Validation loss: 1.3681, lr: 0.0000\n",
      "Epoch: 232, Training loss: 1.361875, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 233, Training loss: 1.378656, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 234, Training loss: 1.371649, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 235, Training loss: 1.362484, Validation loss: 1.3775, lr: 0.0000\n",
      "Epoch: 236, Training loss: 1.382283, Validation loss: 1.3655, lr: 0.0000\n",
      "Epoch: 237, Training loss: 1.379881, Validation loss: 1.3906, lr: 0.0000\n",
      "Epoch: 238, Training loss: 1.414683, Validation loss: 1.3691, lr: 0.0000\n",
      "Epoch: 239, Training loss: 1.376587, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 240, Training loss: 1.362701, Validation loss: 1.3660, lr: 0.0000\n",
      "Epoch: 241, Training loss: 1.363211, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 242, Training loss: 1.415575, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 243, Training loss: 1.368927, Validation loss: 1.3781, lr: 0.0000\n",
      "Epoch: 244, Training loss: 1.375403, Validation loss: 1.3625, lr: 0.0000\n",
      "Epoch: 245, Training loss: 1.360977, Validation loss: 1.3734, lr: 0.0000\n",
      "Epoch: 246, Training loss: 1.372282, Validation loss: 1.4443, lr: 0.0000\n",
      "Epoch: 247, Training loss: 1.355564, Validation loss: 1.3532, lr: 0.0000\n",
      "Epoch: 248, Training loss: 1.361121, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 249, Training loss: 1.396979, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 250, Training loss: 1.370327, Validation loss: 1.3637, lr: 0.0000\n",
      "Epoch: 251, Training loss: 1.375402, Validation loss: 1.3786, lr: 0.0000\n",
      "Epoch: 252, Training loss: 1.355841, Validation loss: 1.3875, lr: 0.0000\n",
      "Epoch: 253, Training loss: 1.337402, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 254, Training loss: 1.372161, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 255, Training loss: 1.362049, Validation loss: 1.3575, lr: 0.0000\n",
      "Epoch: 256, Training loss: 1.362030, Validation loss: 1.3603, lr: 0.0000\n",
      "Epoch: 257, Training loss: 1.400106, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 258, Training loss: 1.344658, Validation loss: 1.3634, lr: 0.0000\n",
      "Epoch: 259, Training loss: 1.369209, Validation loss: 1.3759, lr: 0.0000\n",
      "Epoch: 260, Training loss: 1.353804, Validation loss: 1.3744, lr: 0.0000\n",
      "Epoch: 261, Training loss: 1.353439, Validation loss: 1.3712, lr: 0.0000\n",
      "Epoch: 262, Training loss: 1.370708, Validation loss: 1.3892, lr: 0.0000\n",
      "Epoch: 263, Training loss: 1.357914, Validation loss: 1.3942, lr: 0.0000\n",
      "Epoch: 264, Training loss: 1.397369, Validation loss: 1.3791, lr: 0.0000\n",
      "Epoch: 265, Training loss: 1.354808, Validation loss: 1.3800, lr: 0.0000\n",
      "Epoch: 266, Training loss: 1.374699, Validation loss: 1.4173, lr: 0.0000\n",
      "Epoch: 267, Training loss: 1.353837, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 268, Training loss: 1.348948, Validation loss: 1.3626, lr: 0.0000\n",
      "Epoch: 269, Training loss: 1.359422, Validation loss: 1.3950, lr: 0.0000\n",
      "Epoch: 270, Training loss: 1.381421, Validation loss: 1.3775, lr: 0.0000\n",
      "Epoch: 271, Training loss: 1.344222, Validation loss: 1.3906, lr: 0.0000\n",
      "Epoch: 272, Training loss: 1.346819, Validation loss: 1.4114, lr: 0.0000\n",
      "Epoch: 273, Training loss: 1.410160, Validation loss: 1.3672, lr: 0.0000\n",
      "Epoch: 274, Training loss: 1.354088, Validation loss: 1.3499, lr: 0.0000\n",
      "Epoch: 275, Training loss: 1.400574, Validation loss: 1.3499, lr: 0.0000\n",
      "Epoch: 276, Training loss: 1.378413, Validation loss: 1.3724, lr: 0.0000\n",
      "Epoch: 277, Training loss: 1.360050, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 278, Training loss: 1.349785, Validation loss: 1.3713, lr: 0.0000\n",
      "Epoch: 279, Training loss: 1.364077, Validation loss: 1.3725, lr: 0.0000\n",
      "Epoch: 280, Training loss: 1.363120, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 281, Training loss: 1.362520, Validation loss: 1.3953, lr: 0.0000\n",
      "Epoch: 282, Training loss: 1.379703, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 283, Training loss: 1.337285, Validation loss: 1.3933, lr: 0.0000\n",
      "Epoch: 284, Training loss: 1.354788, Validation loss: 1.3727, lr: 0.0000\n",
      "Epoch: 285, Training loss: 1.354334, Validation loss: 1.3913, lr: 0.0000\n",
      "Epoch: 286, Training loss: 1.360810, Validation loss: 1.3789, lr: 0.0000\n",
      "Epoch: 287, Training loss: 1.358327, Validation loss: 1.3766, lr: 0.0000\n",
      "Epoch: 288, Training loss: 1.367016, Validation loss: 1.3792, lr: 0.0000\n",
      "Epoch: 289, Training loss: 1.353504, Validation loss: 1.3883, lr: 0.0000\n",
      "Epoch: 290, Training loss: 1.369486, Validation loss: 1.3781, lr: 0.0000\n",
      "Epoch: 291, Training loss: 1.375710, Validation loss: 1.3943, lr: 0.0000\n",
      "Epoch: 292, Training loss: 1.359151, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 293, Training loss: 1.364748, Validation loss: 1.3753, lr: 0.0000\n",
      "Epoch: 294, Training loss: 1.404714, Validation loss: 1.3734, lr: 0.0000\n",
      "Epoch: 295, Training loss: 1.374943, Validation loss: 1.3697, lr: 0.0000\n",
      "Epoch: 296, Training loss: 1.377566, Validation loss: 1.3936, lr: 0.0000\n",
      "Epoch: 297, Training loss: 1.350450, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 298, Training loss: 1.371677, Validation loss: 1.3661, lr: 0.0000\n",
      "Epoch: 299, Training loss: 1.349303, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 300, Training loss: 1.358725, Validation loss: 1.3752, lr: 0.0000\n",
      "Epoch: 301, Training loss: 1.363217, Validation loss: 1.3736, lr: 0.0000\n",
      "Epoch: 302, Training loss: 1.342889, Validation loss: 1.3677, lr: 0.0000\n",
      "Epoch: 303, Training loss: 1.371200, Validation loss: 1.3691, lr: 0.0000\n",
      "Epoch: 304, Training loss: 1.344104, Validation loss: 1.3744, lr: 0.0000\n",
      "Epoch: 305, Training loss: 1.384123, Validation loss: 1.3783, lr: 0.0000\n",
      "Epoch: 306, Training loss: 1.375289, Validation loss: 1.3876, lr: 0.0000\n",
      "Epoch: 307, Training loss: 1.376100, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 308, Training loss: 1.368837, Validation loss: 1.3477, lr: 0.0000\n",
      "Epoch: 309, Training loss: 1.374490, Validation loss: 1.3889, lr: 0.0000\n",
      "Epoch: 310, Training loss: 1.371605, Validation loss: 1.3767, lr: 0.0000\n",
      "Epoch: 311, Training loss: 1.371215, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 312, Training loss: 1.357300, Validation loss: 1.3663, lr: 0.0000\n",
      "Epoch: 313, Training loss: 1.339407, Validation loss: 1.3786, lr: 0.0000\n",
      "Epoch: 314, Training loss: 1.367542, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 315, Training loss: 1.361575, Validation loss: 1.3958, lr: 0.0000\n",
      "Epoch: 316, Training loss: 1.356547, Validation loss: 1.3711, lr: 0.0000\n",
      "Epoch: 317, Training loss: 1.360279, Validation loss: 1.5718, lr: 0.0000\n",
      "Epoch: 318, Training loss: 1.386389, Validation loss: 1.3803, lr: 0.0000\n",
      "Epoch: 319, Training loss: 1.390653, Validation loss: 1.3874, lr: 0.0000\n",
      "Epoch: 320, Training loss: 1.352710, Validation loss: 1.3787, lr: 0.0000\n",
      "Epoch: 321, Training loss: 1.342370, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 322, Training loss: 1.354410, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 323, Training loss: 1.372843, Validation loss: 1.3553, lr: 0.0000\n",
      "Epoch: 324, Training loss: 1.367531, Validation loss: 1.3798, lr: 0.0000\n",
      "Epoch: 325, Training loss: 1.381831, Validation loss: 1.3653, lr: 0.0000\n",
      "Epoch: 326, Training loss: 1.363834, Validation loss: 1.3727, lr: 0.0000\n",
      "Epoch: 327, Training loss: 1.408941, Validation loss: 1.3775, lr: 0.0000\n",
      "Epoch: 328, Training loss: 1.384148, Validation loss: 1.3902, lr: 0.0000\n",
      "Epoch: 329, Training loss: 1.361124, Validation loss: 1.3759, lr: 0.0000\n",
      "Epoch: 330, Training loss: 1.350269, Validation loss: 1.3686, lr: 0.0000\n",
      "Epoch: 331, Training loss: 1.344112, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 332, Training loss: 1.375831, Validation loss: 1.3971, lr: 0.0000\n",
      "Epoch: 333, Training loss: 1.346555, Validation loss: 1.3872, lr: 0.0000\n",
      "Epoch: 334, Training loss: 1.358842, Validation loss: 1.3782, lr: 0.0000\n",
      "Epoch: 335, Training loss: 1.370293, Validation loss: 1.3949, lr: 0.0000\n",
      "Epoch: 336, Training loss: 1.346475, Validation loss: 1.3883, lr: 0.0000\n",
      "Epoch: 337, Training loss: 1.372264, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 338, Training loss: 1.486594, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 339, Training loss: 1.360389, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 340, Training loss: 1.386678, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 341, Training loss: 1.351721, Validation loss: 1.3741, lr: 0.0000\n",
      "Epoch: 342, Training loss: 1.369975, Validation loss: 1.3665, lr: 0.0000\n",
      "Epoch: 343, Training loss: 1.362211, Validation loss: 1.3751, lr: 0.0000\n",
      "Epoch: 344, Training loss: 1.404837, Validation loss: 1.3716, lr: 0.0000\n",
      "Epoch: 345, Training loss: 1.365143, Validation loss: 1.3682, lr: 0.0000\n",
      "Epoch: 346, Training loss: 1.354281, Validation loss: 1.3878, lr: 0.0000\n",
      "Epoch: 347, Training loss: 1.391549, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 348, Training loss: 1.354890, Validation loss: 1.3632, lr: 0.0000\n",
      "Epoch: 349, Training loss: 1.398423, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 350, Training loss: 1.355028, Validation loss: 1.3739, lr: 0.0000\n",
      "Epoch: 351, Training loss: 1.377685, Validation loss: 1.3497, lr: 0.0000\n",
      "Epoch: 352, Training loss: 1.383238, Validation loss: 1.3796, lr: 0.0000\n",
      "Epoch: 353, Training loss: 1.358852, Validation loss: 1.3917, lr: 0.0000\n",
      "Epoch: 354, Training loss: 1.379998, Validation loss: 1.3631, lr: 0.0000\n",
      "Epoch: 355, Training loss: 1.379486, Validation loss: 1.3523, lr: 0.0000\n",
      "Epoch: 356, Training loss: 1.371914, Validation loss: 1.3750, lr: 0.0000\n",
      " *och: 357, Training loss: 1.453728, Validation loss: 1.2965, lr: 0.0000\n",
      "Epoch: 358, Training loss: 1.359374, Validation loss: 1.3785, lr: 0.0000\n",
      "Epoch: 359, Training loss: 1.388888, Validation loss: 1.4681, lr: 0.0000\n",
      "Epoch: 360, Training loss: 1.377095, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 361, Training loss: 1.393389, Validation loss: 1.3873, lr: 0.0000\n",
      "Epoch: 362, Training loss: 1.372871, Validation loss: 1.3780, lr: 0.0000\n",
      "Epoch: 363, Training loss: 1.381282, Validation loss: 1.3802, lr: 0.0000\n",
      "Epoch: 364, Training loss: 1.369265, Validation loss: 1.3764, lr: 0.0000\n",
      "Epoch: 365, Training loss: 1.362483, Validation loss: 1.3352, lr: 0.0000\n",
      "Epoch: 366, Training loss: 1.374976, Validation loss: 1.3761, lr: 0.0000\n",
      "Epoch: 367, Training loss: 1.381471, Validation loss: 1.3767, lr: 0.0000\n",
      "Epoch: 368, Training loss: 1.376614, Validation loss: 1.3927, lr: 0.0000\n",
      "Epoch: 369, Training loss: 1.384752, Validation loss: 1.4110, lr: 0.0000\n",
      "Epoch: 370, Training loss: 1.399117, Validation loss: 1.3795, lr: 0.0000\n",
      "Epoch: 371, Training loss: 1.395118, Validation loss: 1.3929, lr: 0.0000\n",
      "Epoch: 372, Training loss: 1.364953, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 373, Training loss: 1.366169, Validation loss: 1.3753, lr: 0.0000\n",
      "Epoch: 374, Training loss: 1.383353, Validation loss: 1.3901, lr: 0.0000\n",
      "Epoch: 375, Training loss: 1.352668, Validation loss: 1.3643, lr: 0.0000\n",
      "Epoch: 376, Training loss: 1.355009, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 377, Training loss: 1.361309, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 378, Training loss: 1.421430, Validation loss: 1.3721, lr: 0.0000\n",
      "Epoch: 379, Training loss: 1.378756, Validation loss: 1.4384, lr: 0.0000\n",
      "Epoch: 380, Training loss: 1.357498, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 381, Training loss: 1.379817, Validation loss: 1.3565, lr: 0.0000\n",
      "Epoch: 382, Training loss: 1.348809, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 383, Training loss: 1.372545, Validation loss: 1.3935, lr: 0.0000\n",
      "Epoch: 384, Training loss: 1.368075, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 385, Training loss: 1.359785, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 386, Training loss: 1.387465, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 387, Training loss: 1.359571, Validation loss: 1.3746, lr: 0.0000\n",
      "Epoch: 388, Training loss: 1.403430, Validation loss: 1.3628, lr: 0.0000\n",
      "Epoch: 389, Training loss: 1.368676, Validation loss: 1.3995, lr: 0.0000\n",
      "Epoch: 390, Training loss: 1.365676, Validation loss: 1.3735, lr: 0.0000\n",
      "Epoch: 391, Training loss: 1.354541, Validation loss: 1.3547, lr: 0.0000\n",
      "Epoch: 392, Training loss: 1.383349, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 393, Training loss: 1.390792, Validation loss: 1.3758, lr: 0.0000\n",
      "Epoch: 394, Training loss: 1.378870, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 395, Training loss: 1.368210, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 396, Training loss: 1.379065, Validation loss: 1.3783, lr: 0.0000\n",
      "Epoch: 397, Training loss: 1.370788, Validation loss: 1.3948, lr: 0.0000\n",
      "Epoch: 398, Training loss: 1.364494, Validation loss: 1.5761, lr: 0.0000\n",
      "Epoch: 399, Training loss: 1.370895, Validation loss: 1.3949, lr: 0.0000\n",
      "Epoch: 400, Training loss: 1.351241, Validation loss: 1.3637, lr: 0.0000\n",
      "Epoch: 401, Training loss: 1.361673, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 402, Training loss: 1.358655, Validation loss: 1.3783, lr: 0.0000\n",
      "Epoch: 403, Training loss: 1.362394, Validation loss: 1.3479, lr: 0.0000\n",
      "Epoch: 404, Training loss: 1.358597, Validation loss: 1.3669, lr: 0.0000\n",
      "Epoch: 405, Training loss: 1.349349, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 406, Training loss: 1.349798, Validation loss: 1.3909, lr: 0.0000\n",
      "Epoch: 407, Training loss: 1.358656, Validation loss: 1.3697, lr: 0.0000\n",
      "Epoch: 408, Training loss: 1.363942, Validation loss: 1.3429, lr: 0.0000\n",
      "Epoch: 409, Training loss: 1.420044, Validation loss: 1.3732, lr: 0.0000\n",
      "Epoch: 410, Training loss: 1.370829, Validation loss: 1.3781, lr: 0.0000\n",
      "Epoch: 411, Training loss: 1.364180, Validation loss: 1.3585, lr: 0.0000\n",
      "Epoch: 412, Training loss: 1.369400, Validation loss: 1.3775, lr: 0.0000\n",
      "Epoch: 413, Training loss: 1.382419, Validation loss: 1.3414, lr: 0.0000\n",
      "Epoch: 414, Training loss: 1.370068, Validation loss: 1.3940, lr: 0.0000\n",
      "Epoch: 415, Training loss: 1.339967, Validation loss: 1.3771, lr: 0.0000\n",
      "Epoch: 416, Training loss: 1.350497, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 417, Training loss: 1.356652, Validation loss: 1.4017, lr: 0.0000\n",
      "Epoch: 418, Training loss: 1.397170, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 419, Training loss: 1.366280, Validation loss: 1.3692, lr: 0.0000\n",
      "Epoch: 420, Training loss: 1.383911, Validation loss: 1.3755, lr: 0.0000\n",
      "Epoch: 421, Training loss: 1.368768, Validation loss: 1.3874, lr: 0.0000\n",
      "Epoch: 422, Training loss: 1.378076, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 423, Training loss: 1.356285, Validation loss: 1.4486, lr: 0.0000\n",
      "Epoch: 424, Training loss: 1.363814, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 425, Training loss: 1.361366, Validation loss: 1.3584, lr: 0.0000\n",
      "Epoch: 426, Training loss: 1.342324, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 427, Training loss: 1.372784, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 428, Training loss: 1.388399, Validation loss: 1.3514, lr: 0.0000\n",
      "Epoch: 429, Training loss: 1.369223, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 430, Training loss: 1.363704, Validation loss: 1.3181, lr: 0.0000\n",
      "Epoch: 431, Training loss: 1.354907, Validation loss: 1.3765, lr: 0.0000\n",
      "Epoch: 432, Training loss: 1.357583, Validation loss: 1.3644, lr: 0.0000\n",
      "Epoch: 433, Training loss: 1.381352, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 434, Training loss: 1.354574, Validation loss: 1.3785, lr: 0.0000\n",
      "Epoch: 435, Training loss: 1.352087, Validation loss: 1.4119, lr: 0.0000\n",
      "Epoch: 436, Training loss: 1.366659, Validation loss: 1.7056, lr: 0.0000\n",
      "Epoch: 437, Training loss: 1.343178, Validation loss: 1.3693, lr: 0.0000\n",
      "Epoch: 438, Training loss: 1.362274, Validation loss: 1.4341, lr: 0.0000\n",
      "Epoch: 439, Training loss: 1.369197, Validation loss: 1.3672, lr: 0.0000\n",
      "Epoch: 440, Training loss: 1.372807, Validation loss: 1.3794, lr: 0.0000\n",
      "Epoch: 441, Training loss: 1.363888, Validation loss: 1.3921, lr: 0.0000\n",
      "Epoch: 442, Training loss: 1.359494, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 443, Training loss: 1.356050, Validation loss: 1.3797, lr: 0.0000\n",
      "Epoch: 444, Training loss: 1.351596, Validation loss: 1.3809, lr: 0.0000\n",
      "Epoch: 445, Training loss: 1.347731, Validation loss: 1.3889, lr: 0.0000\n",
      "Epoch: 446, Training loss: 1.373164, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 447, Training loss: 1.364470, Validation loss: 1.3899, lr: 0.0000\n",
      "Epoch: 448, Training loss: 1.365541, Validation loss: 1.3775, lr: 0.0000\n",
      "Epoch: 449, Training loss: 1.353706, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 450, Training loss: 1.381029, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 451, Training loss: 1.352437, Validation loss: 1.3888, lr: 0.0000\n",
      "Epoch: 452, Training loss: 1.353612, Validation loss: 1.3674, lr: 0.0000\n",
      "Epoch: 453, Training loss: 1.351464, Validation loss: 1.3613, lr: 0.0000\n",
      "Epoch: 454, Training loss: 1.418657, Validation loss: 1.3598, lr: 0.0000\n",
      "Epoch: 455, Training loss: 1.374039, Validation loss: 1.3881, lr: 0.0000\n",
      "Epoch: 456, Training loss: 1.359125, Validation loss: 1.3792, lr: 0.0000\n",
      "Epoch: 457, Training loss: 1.357291, Validation loss: 1.4064, lr: 0.0000\n",
      "Epoch: 458, Training loss: 1.367301, Validation loss: 1.3742, lr: 0.0000\n",
      "Epoch: 459, Training loss: 1.358710, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 460, Training loss: 1.370228, Validation loss: 1.3685, lr: 0.0000\n",
      "Epoch: 461, Training loss: 1.362668, Validation loss: 1.3770, lr: 0.0000\n",
      "Epoch: 462, Training loss: 1.373945, Validation loss: 1.3751, lr: 0.0000\n",
      "Epoch: 463, Training loss: 1.382180, Validation loss: 1.3894, lr: 0.0000\n",
      "Epoch: 464, Training loss: 1.378847, Validation loss: 1.3782, lr: 0.0000\n",
      "Epoch: 465, Training loss: 1.378860, Validation loss: 1.3794, lr: 0.0000\n",
      "Epoch: 466, Training loss: 1.338293, Validation loss: 1.4819, lr: 0.0000\n",
      "Epoch: 467, Training loss: 1.365118, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 468, Training loss: 1.359853, Validation loss: 1.3777, lr: 0.0000\n",
      "Epoch: 469, Training loss: 1.353657, Validation loss: 1.3424, lr: 0.0000\n",
      "Epoch: 470, Training loss: 1.417053, Validation loss: 1.3896, lr: 0.0000\n",
      "Epoch: 471, Training loss: 1.352612, Validation loss: 1.3900, lr: 0.0000\n",
      "Epoch: 472, Training loss: 1.346381, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 473, Training loss: 1.400201, Validation loss: 1.3809, lr: 0.0000\n",
      "Epoch: 474, Training loss: 1.355009, Validation loss: 1.3597, lr: 0.0000\n",
      "Epoch: 475, Training loss: 1.357519, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 476, Training loss: 1.367961, Validation loss: 1.9763, lr: 0.0000\n",
      "Epoch: 477, Training loss: 1.385743, Validation loss: 1.3793, lr: 0.0000\n",
      "Epoch: 478, Training loss: 1.370389, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 479, Training loss: 1.384217, Validation loss: 1.3756, lr: 0.0000\n",
      "Epoch: 480, Training loss: 1.377891, Validation loss: 1.3789, lr: 0.0000\n",
      "Epoch: 481, Training loss: 1.355500, Validation loss: 1.3591, lr: 0.0000\n",
      "Epoch: 482, Training loss: 1.383293, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 483, Training loss: 1.351306, Validation loss: 1.3566, lr: 0.0000\n",
      "Epoch: 484, Training loss: 1.388337, Validation loss: 1.3770, lr: 0.0000\n",
      "Epoch: 485, Training loss: 1.373560, Validation loss: 1.3943, lr: 0.0000\n",
      "Epoch: 486, Training loss: 1.352845, Validation loss: 1.3757, lr: 0.0000\n",
      "Epoch: 487, Training loss: 1.357452, Validation loss: 1.3751, lr: 0.0000\n",
      "Epoch: 488, Training loss: 1.367484, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 489, Training loss: 1.361710, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 490, Training loss: 1.370783, Validation loss: 1.3751, lr: 0.0000\n",
      "Epoch: 491, Training loss: 1.370651, Validation loss: 1.3669, lr: 0.0000\n",
      "Epoch: 492, Training loss: 1.382757, Validation loss: 1.3697, lr: 0.0000\n",
      "Epoch: 493, Training loss: 1.359240, Validation loss: 1.5259, lr: 0.0000\n",
      "Epoch: 494, Training loss: 1.373261, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 495, Training loss: 1.357051, Validation loss: 1.3740, lr: 0.0000\n",
      "Epoch: 496, Training loss: 1.402545, Validation loss: 1.3700, lr: 0.0000\n",
      "Epoch: 497, Training loss: 1.363338, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 498, Training loss: 1.330940, Validation loss: 1.3700, lr: 0.0000\n",
      "Epoch: 499, Training loss: 1.357834, Validation loss: 1.3533, lr: 0.0000\n",
      "Epoch: 500, Training loss: 1.397479, Validation loss: 1.3769, lr: 0.0000\n",
      "Epoch: 501, Training loss: 1.358083, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 502, Training loss: 1.417383, Validation loss: 1.3695, lr: 0.0000\n",
      "Epoch: 503, Training loss: 1.367628, Validation loss: 1.3647, lr: 0.0000\n",
      "Epoch: 504, Training loss: 1.370396, Validation loss: 1.3711, lr: 0.0000\n",
      "Epoch: 505, Training loss: 1.374049, Validation loss: 1.3602, lr: 0.0000\n",
      "Epoch: 506, Training loss: 1.333962, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 507, Training loss: 1.351779, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 508, Training loss: 1.368321, Validation loss: 1.3717, lr: 0.0000\n",
      "Epoch: 509, Training loss: 1.372873, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 510, Training loss: 1.375661, Validation loss: 1.3768, lr: 0.0000\n",
      "Epoch: 511, Training loss: 1.350699, Validation loss: 1.3684, lr: 0.0000\n",
      "Epoch: 512, Training loss: 1.404963, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 513, Training loss: 1.372943, Validation loss: 1.3876, lr: 0.0000\n",
      "Epoch: 514, Training loss: 1.365022, Validation loss: 1.3799, lr: 0.0000\n",
      "Epoch: 515, Training loss: 1.381442, Validation loss: 1.3740, lr: 0.0000\n",
      "Epoch: 516, Training loss: 1.395256, Validation loss: 1.3698, lr: 0.0000\n",
      "Epoch: 517, Training loss: 1.379591, Validation loss: 1.3788, lr: 0.0000\n",
      "Epoch: 518, Training loss: 1.356286, Validation loss: 1.3781, lr: 0.0000\n",
      "Epoch: 519, Training loss: 1.362654, Validation loss: 1.3710, lr: 0.0000\n",
      "Epoch: 520, Training loss: 1.361921, Validation loss: 1.3783, lr: 0.0000\n",
      "Epoch: 521, Training loss: 1.369501, Validation loss: 1.3524, lr: 0.0000\n",
      "Epoch: 522, Training loss: 1.367016, Validation loss: 1.3779, lr: 0.0000\n",
      "Epoch: 523, Training loss: 1.369228, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 524, Training loss: 1.370464, Validation loss: 1.3725, lr: 0.0000\n",
      "Epoch: 525, Training loss: 1.353933, Validation loss: 1.4133, lr: 0.0000\n",
      "Epoch: 526, Training loss: 1.361213, Validation loss: 1.3796, lr: 0.0000\n",
      "Epoch: 527, Training loss: 1.351743, Validation loss: 1.3624, lr: 0.0000\n",
      "Epoch: 528, Training loss: 1.365972, Validation loss: 1.3748, lr: 0.0000\n",
      "Epoch: 529, Training loss: 1.361269, Validation loss: 1.3708, lr: 0.0000\n",
      "Epoch: 530, Training loss: 1.345981, Validation loss: 1.3577, lr: 0.0000\n",
      "Epoch: 531, Training loss: 1.373811, Validation loss: 1.3682, lr: 0.0000\n",
      "Epoch: 532, Training loss: 1.384852, Validation loss: 1.3953, lr: 0.0000\n",
      "Epoch: 533, Training loss: 1.375629, Validation loss: 1.3710, lr: 0.0000\n",
      "Epoch: 534, Training loss: 1.355955, Validation loss: 1.3770, lr: 0.0000\n",
      "Epoch: 535, Training loss: 1.378504, Validation loss: 1.3553, lr: 0.0000\n",
      "Epoch: 536, Training loss: 1.368439, Validation loss: 1.3752, lr: 0.0000\n",
      "Epoch: 537, Training loss: 1.359345, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 538, Training loss: 1.337924, Validation loss: 1.3911, lr: 0.0000\n",
      "Epoch: 539, Training loss: 1.369002, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 540, Training loss: 1.360286, Validation loss: 1.3749, lr: 0.0000\n",
      "Epoch: 541, Training loss: 1.361753, Validation loss: 1.3885, lr: 0.0000\n",
      "Epoch: 542, Training loss: 1.356740, Validation loss: 1.3981, lr: 0.0000\n",
      "Epoch: 543, Training loss: 1.344052, Validation loss: 1.3775, lr: 0.0000\n",
      "Epoch: 544, Training loss: 1.352585, Validation loss: 1.3809, lr: 0.0000\n",
      "Epoch: 545, Training loss: 1.338463, Validation loss: 1.3767, lr: 0.0000\n",
      "Epoch: 546, Training loss: 1.351849, Validation loss: 1.3786, lr: 0.0000\n",
      "Epoch: 547, Training loss: 1.365556, Validation loss: 1.3687, lr: 0.0000\n",
      "Epoch: 548, Training loss: 1.366349, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 549, Training loss: 1.358594, Validation loss: 1.3760, lr: 0.0000\n",
      "Epoch: 550, Training loss: 1.362448, Validation loss: 1.3743, lr: 0.0000\n",
      "Epoch: 551, Training loss: 1.391773, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 552, Training loss: 1.357762, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 553, Training loss: 1.357494, Validation loss: 1.3695, lr: 0.0000\n",
      "Epoch: 554, Training loss: 1.356863, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 555, Training loss: 1.397732, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 556, Training loss: 1.355943, Validation loss: 1.3742, lr: 0.0000\n",
      "Epoch: 557, Training loss: 1.349898, Validation loss: 1.3795, lr: 0.0000\n",
      "Epoch: 558, Training loss: 1.343572, Validation loss: 1.3738, lr: 0.0000\n",
      "Epoch: 559, Training loss: 1.379408, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 560, Training loss: 1.380858, Validation loss: 1.3734, lr: 0.0000\n",
      "Epoch: 561, Training loss: 1.347370, Validation loss: 1.3746, lr: 0.0000\n",
      "Epoch: 562, Training loss: 1.393349, Validation loss: 1.3781, lr: 0.0000\n",
      "Epoch: 563, Training loss: 1.349689, Validation loss: 1.3762, lr: 0.0000\n",
      "Epoch: 564, Training loss: 1.401912, Validation loss: 1.3746, lr: 0.0000\n",
      "Epoch: 565, Training loss: 1.349970, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 566, Training loss: 1.361858, Validation loss: 1.3620, lr: 0.0000\n",
      "Epoch: 567, Training loss: 1.380295, Validation loss: 1.3640, lr: 0.0000\n",
      "Epoch: 568, Training loss: 1.383402, Validation loss: 1.3781, lr: 0.0000\n",
      "Epoch: 569, Training loss: 1.364140, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 570, Training loss: 1.386459, Validation loss: 1.3778, lr: 0.0000\n",
      "Epoch: 571, Training loss: 1.358424, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 572, Training loss: 1.354118, Validation loss: 1.3649, lr: 0.0000\n",
      "Epoch: 573, Training loss: 1.367240, Validation loss: 1.3734, lr: 0.0000\n",
      "Epoch: 574, Training loss: 1.376326, Validation loss: 1.3795, lr: 0.0000\n",
      "Epoch: 575, Training loss: 1.372780, Validation loss: 1.3694, lr: 0.0000\n",
      "Epoch: 576, Training loss: 1.353642, Validation loss: 1.3698, lr: 0.0000\n",
      "Epoch: 577, Training loss: 1.367748, Validation loss: 1.4021, lr: 0.0000\n",
      "Epoch: 578, Training loss: 1.365072, Validation loss: 1.3685, lr: 0.0000\n",
      "Epoch: 579, Training loss: 1.371894, Validation loss: 1.3733, lr: 0.0000\n",
      "Epoch: 580, Training loss: 1.368955, Validation loss: 1.3784, lr: 0.0000\n",
      "Epoch: 581, Training loss: 1.355513, Validation loss: 1.3694, lr: 0.0000\n",
      "Epoch: 582, Training loss: 1.388433, Validation loss: 1.3726, lr: 0.0000\n",
      "Epoch: 583, Training loss: 1.397047, Validation loss: 1.3883, lr: 0.0000\n",
      "Epoch: 584, Training loss: 1.394224, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 585, Training loss: 1.353709, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 586, Training loss: 1.367025, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 587, Training loss: 1.361277, Validation loss: 1.3923, lr: 0.0000\n",
      "Epoch: 588, Training loss: 1.365515, Validation loss: 1.3756, lr: 0.0000\n",
      "Epoch: 589, Training loss: 1.362900, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 590, Training loss: 1.365122, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 591, Training loss: 1.352649, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 592, Training loss: 1.360675, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 593, Training loss: 1.372237, Validation loss: 1.3727, lr: 0.0000\n",
      "Epoch: 594, Training loss: 1.346330, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 595, Training loss: 1.357122, Validation loss: 1.3878, lr: 0.0000\n",
      "Epoch: 596, Training loss: 1.360462, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 597, Training loss: 1.357252, Validation loss: 1.3664, lr: 0.0000\n",
      "Epoch: 598, Training loss: 1.376357, Validation loss: 1.3899, lr: 0.0000\n",
      "Epoch: 599, Training loss: 1.380913, Validation loss: 1.3802, lr: 0.0000\n",
      "Epoch: 600, Training loss: 1.385565, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 601, Training loss: 1.358140, Validation loss: 1.3793, lr: 0.0000\n",
      "Epoch: 602, Training loss: 1.382882, Validation loss: 1.3657, lr: 0.0000\n",
      "Epoch: 603, Training loss: 1.385946, Validation loss: 1.3735, lr: 0.0000\n",
      "Epoch: 604, Training loss: 1.351928, Validation loss: 1.3725, lr: 0.0000\n",
      "Epoch: 605, Training loss: 1.375453, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 606, Training loss: 1.356513, Validation loss: 1.3766, lr: 0.0000\n",
      "Epoch: 607, Training loss: 1.356448, Validation loss: 1.3776, lr: 0.0000\n",
      "Epoch: 608, Training loss: 1.356895, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 609, Training loss: 1.368255, Validation loss: 1.3392, lr: 0.0000\n",
      "Epoch: 610, Training loss: 1.343932, Validation loss: 1.3763, lr: 0.0000\n",
      "Epoch: 611, Training loss: 1.361725, Validation loss: 1.3763, lr: 0.0000\n",
      "Epoch: 612, Training loss: 1.380904, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 613, Training loss: 1.357790, Validation loss: 1.3630, lr: 0.0000\n",
      "Epoch: 614, Training loss: 1.372165, Validation loss: 1.3443, lr: 0.0000\n",
      "Epoch: 615, Training loss: 1.359539, Validation loss: 1.3696, lr: 0.0000\n",
      "Epoch: 616, Training loss: 1.334852, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 617, Training loss: 1.378815, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 618, Training loss: 1.364739, Validation loss: 1.3627, lr: 0.0000\n",
      "Epoch: 619, Training loss: 1.431865, Validation loss: 1.3598, lr: 0.0000\n",
      "Epoch: 620, Training loss: 1.381248, Validation loss: 1.3760, lr: 0.0000\n",
      "Epoch: 621, Training loss: 1.370633, Validation loss: 1.3782, lr: 0.0000\n",
      "Epoch: 622, Training loss: 1.357651, Validation loss: 1.3937, lr: 0.0000\n",
      "Epoch: 623, Training loss: 1.352135, Validation loss: 1.3251, lr: 0.0000\n",
      "Epoch: 624, Training loss: 1.349158, Validation loss: 1.4025, lr: 0.0000\n",
      "Epoch: 625, Training loss: 1.354247, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 626, Training loss: 1.347946, Validation loss: 1.3791, lr: 0.0000\n",
      "Epoch: 627, Training loss: 1.363946, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 628, Training loss: 1.364356, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 629, Training loss: 1.384524, Validation loss: 1.3912, lr: 0.0000\n",
      "Epoch: 630, Training loss: 1.370742, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 631, Training loss: 1.371955, Validation loss: 1.4061, lr: 0.0000\n",
      "Epoch: 632, Training loss: 1.369166, Validation loss: 1.3584, lr: 0.0000\n",
      "Epoch: 633, Training loss: 1.347280, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 634, Training loss: 1.362237, Validation loss: 1.3889, lr: 0.0000\n",
      "Epoch: 635, Training loss: 1.373695, Validation loss: 1.3745, lr: 0.0000\n",
      "Epoch: 636, Training loss: 1.369303, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 637, Training loss: 1.343767, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 638, Training loss: 1.368908, Validation loss: 1.3750, lr: 0.0000\n",
      "Epoch: 639, Training loss: 1.362409, Validation loss: 1.3726, lr: 0.0000\n",
      "Epoch: 640, Training loss: 1.363727, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 641, Training loss: 1.359215, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 642, Training loss: 1.406124, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 643, Training loss: 1.389366, Validation loss: 1.3590, lr: 0.0000\n",
      "Epoch: 644, Training loss: 1.341914, Validation loss: 1.3964, lr: 0.0000\n",
      "Epoch: 645, Training loss: 1.350463, Validation loss: 1.3669, lr: 0.0000\n",
      "Epoch: 646, Training loss: 1.339768, Validation loss: 1.3744, lr: 0.0000\n",
      "Epoch: 647, Training loss: 1.381777, Validation loss: 1.3706, lr: 0.0000\n",
      "Epoch: 648, Training loss: 1.398486, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 649, Training loss: 1.347481, Validation loss: 1.4756, lr: 0.0000\n",
      "Epoch: 650, Training loss: 1.374358, Validation loss: 1.3788, lr: 0.0000\n",
      "Epoch: 651, Training loss: 1.349449, Validation loss: 1.3666, lr: 0.0000\n",
      "Epoch: 652, Training loss: 1.357389, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 653, Training loss: 1.358285, Validation loss: 1.3579, lr: 0.0000\n",
      "Epoch: 654, Training loss: 1.354781, Validation loss: 1.3769, lr: 0.0000\n",
      "Epoch: 655, Training loss: 1.353889, Validation loss: 1.4005, lr: 0.0000\n",
      "Epoch: 656, Training loss: 1.370517, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 657, Training loss: 1.384590, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 658, Training loss: 1.359589, Validation loss: 1.3797, lr: 0.0000\n",
      "Epoch: 659, Training loss: 1.382159, Validation loss: 1.3708, lr: 0.0000\n",
      "Epoch: 660, Training loss: 1.377092, Validation loss: 1.3890, lr: 0.0000\n",
      "Epoch: 661, Training loss: 1.370324, Validation loss: 1.3631, lr: 0.0000\n",
      "Epoch: 662, Training loss: 1.356734, Validation loss: 1.3759, lr: 0.0000\n",
      "Epoch: 663, Training loss: 1.378484, Validation loss: 1.3753, lr: 0.0000\n",
      "Epoch: 664, Training loss: 1.381900, Validation loss: 1.3764, lr: 0.0000\n",
      "Epoch: 665, Training loss: 1.375448, Validation loss: 1.3706, lr: 0.0000\n",
      "Epoch: 666, Training loss: 1.419854, Validation loss: 1.3711, lr: 0.0000\n",
      "Epoch: 667, Training loss: 1.359805, Validation loss: 1.3945, lr: 0.0000\n",
      "Epoch: 668, Training loss: 1.379683, Validation loss: 1.3749, lr: 0.0000\n",
      "Epoch: 669, Training loss: 1.356033, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 670, Training loss: 1.384000, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 671, Training loss: 1.351889, Validation loss: 1.3795, lr: 0.0000\n",
      "Epoch: 672, Training loss: 1.376335, Validation loss: 1.3745, lr: 0.0000\n",
      "Epoch: 673, Training loss: 1.370415, Validation loss: 1.3650, lr: 0.0000\n",
      "Epoch: 674, Training loss: 1.369680, Validation loss: 1.3901, lr: 0.0000\n",
      "Epoch: 675, Training loss: 1.343595, Validation loss: 1.3613, lr: 0.0000\n",
      "Epoch: 676, Training loss: 1.378025, Validation loss: 1.3691, lr: 0.0000\n",
      "Epoch: 677, Training loss: 1.376237, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 678, Training loss: 1.339857, Validation loss: 1.3733, lr: 0.0000\n",
      "Epoch: 679, Training loss: 1.359288, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 680, Training loss: 1.367916, Validation loss: 1.3423, lr: 0.0000\n",
      "Epoch: 681, Training loss: 1.387128, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 682, Training loss: 1.373321, Validation loss: 1.3765, lr: 0.0000\n",
      "Epoch: 683, Training loss: 1.369309, Validation loss: 1.3761, lr: 0.0000\n",
      "Epoch: 684, Training loss: 1.380447, Validation loss: 1.3714, lr: 0.0000\n",
      "Epoch: 685, Training loss: 1.370527, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 686, Training loss: 1.376904, Validation loss: 1.3793, lr: 0.0000\n",
      "Epoch: 687, Training loss: 1.399235, Validation loss: 1.3939, lr: 0.0000\n",
      "Epoch: 688, Training loss: 1.350714, Validation loss: 1.3798, lr: 0.0000\n",
      "Epoch: 689, Training loss: 1.355079, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 690, Training loss: 1.359967, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 691, Training loss: 1.356345, Validation loss: 1.3696, lr: 0.0000\n",
      "Epoch: 692, Training loss: 1.403287, Validation loss: 1.3766, lr: 0.0000\n",
      "Epoch: 693, Training loss: 1.351132, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 694, Training loss: 1.359319, Validation loss: 1.3936, lr: 0.0000\n",
      "Epoch: 695, Training loss: 1.361310, Validation loss: 1.3760, lr: 0.0000\n",
      "Epoch: 696, Training loss: 1.364719, Validation loss: 1.3747, lr: 0.0000\n",
      "Epoch: 697, Training loss: 1.377372, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 698, Training loss: 1.343800, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 699, Training loss: 1.380145, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 700, Training loss: 1.387835, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 701, Training loss: 1.365144, Validation loss: 1.3887, lr: 0.0000\n",
      "Epoch: 702, Training loss: 1.363970, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 703, Training loss: 1.352713, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 704, Training loss: 1.362676, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 705, Training loss: 1.358453, Validation loss: 1.3880, lr: 0.0000\n",
      "Epoch: 706, Training loss: 1.348091, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 707, Training loss: 1.382790, Validation loss: 1.3901, lr: 0.0000\n",
      "Epoch: 708, Training loss: 1.380990, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 709, Training loss: 1.361770, Validation loss: 1.3743, lr: 0.0000\n",
      "Epoch: 710, Training loss: 1.352574, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 711, Training loss: 1.376151, Validation loss: 1.3792, lr: 0.0000\n",
      "Epoch: 712, Training loss: 1.374856, Validation loss: 1.3978, lr: 0.0000\n",
      "Epoch: 713, Training loss: 1.385286, Validation loss: 1.3681, lr: 0.0000\n",
      "Epoch: 714, Training loss: 1.379838, Validation loss: 1.3794, lr: 0.0000\n",
      "Epoch: 715, Training loss: 1.365106, Validation loss: 1.3737, lr: 0.0000\n",
      "Epoch: 716, Training loss: 1.358675, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 717, Training loss: 1.349966, Validation loss: 1.3765, lr: 0.0000\n",
      "Epoch: 718, Training loss: 1.376188, Validation loss: 1.3881, lr: 0.0000\n",
      "Epoch: 719, Training loss: 1.364707, Validation loss: 1.3885, lr: 0.0000\n",
      "Epoch: 720, Training loss: 1.354053, Validation loss: 1.3762, lr: 0.0000\n",
      "Epoch: 721, Training loss: 1.357005, Validation loss: 1.3588, lr: 0.0000\n",
      "Epoch: 722, Training loss: 1.365891, Validation loss: 1.3892, lr: 0.0000\n",
      "Epoch: 723, Training loss: 1.355731, Validation loss: 1.3685, lr: 0.0000\n",
      "Epoch: 724, Training loss: 1.394456, Validation loss: 1.3446, lr: 0.0000\n",
      "Epoch: 725, Training loss: 1.394073, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 726, Training loss: 1.350150, Validation loss: 1.3638, lr: 0.0000\n",
      "Epoch: 727, Training loss: 1.367135, Validation loss: 1.3759, lr: 0.0000\n",
      "Epoch: 728, Training loss: 1.379152, Validation loss: 1.3778, lr: 0.0000\n",
      "Epoch: 729, Training loss: 1.362583, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 730, Training loss: 1.381230, Validation loss: 1.3710, lr: 0.0000\n",
      "Epoch: 731, Training loss: 1.369917, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 732, Training loss: 1.360368, Validation loss: 1.3803, lr: 0.0000\n",
      "Epoch: 733, Training loss: 1.368725, Validation loss: 1.3650, lr: 0.0000\n",
      "Epoch: 734, Training loss: 1.388896, Validation loss: 1.3738, lr: 0.0000\n",
      "Epoch: 735, Training loss: 1.376396, Validation loss: 1.3628, lr: 0.0000\n",
      "Epoch: 736, Training loss: 1.356987, Validation loss: 1.3679, lr: 0.0000\n",
      "Epoch: 737, Training loss: 1.369767, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 738, Training loss: 1.369720, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 739, Training loss: 1.358952, Validation loss: 1.3751, lr: 0.0000\n",
      "Epoch: 740, Training loss: 1.349763, Validation loss: 1.3689, lr: 0.0000\n",
      "Epoch: 741, Training loss: 1.371040, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 742, Training loss: 1.387939, Validation loss: 1.3750, lr: 0.0000\n",
      "Epoch: 743, Training loss: 1.380446, Validation loss: 1.3752, lr: 0.0000\n",
      "Epoch: 744, Training loss: 1.361948, Validation loss: 1.3966, lr: 0.0000\n",
      "Epoch: 745, Training loss: 1.349560, Validation loss: 1.3735, lr: 0.0000\n",
      "Epoch: 746, Training loss: 1.389821, Validation loss: 1.3784, lr: 0.0000\n",
      "Epoch: 747, Training loss: 1.409491, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 748, Training loss: 1.362933, Validation loss: 1.3603, lr: 0.0000\n",
      "Epoch: 749, Training loss: 1.352225, Validation loss: 1.3449, lr: 0.0000\n",
      "Epoch: 750, Training loss: 1.371813, Validation loss: 1.3754, lr: 0.0000\n",
      "Epoch: 751, Training loss: 1.365945, Validation loss: 1.3782, lr: 0.0000\n",
      "Epoch: 752, Training loss: 1.367239, Validation loss: 1.3668, lr: 0.0000\n",
      "Epoch: 753, Training loss: 1.348412, Validation loss: 1.3386, lr: 0.0000\n",
      "Epoch: 754, Training loss: 1.358468, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 755, Training loss: 1.398414, Validation loss: 1.3779, lr: 0.0000\n",
      "Epoch: 756, Training loss: 1.353178, Validation loss: 1.3782, lr: 0.0000\n",
      "Epoch: 757, Training loss: 1.377606, Validation loss: 1.3744, lr: 0.0000\n",
      "Epoch: 758, Training loss: 1.348259, Validation loss: 1.3752, lr: 0.0000\n",
      "Epoch: 759, Training loss: 1.343065, Validation loss: 1.3711, lr: 0.0000\n",
      "Epoch: 760, Training loss: 1.355289, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 761, Training loss: 1.366301, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 762, Training loss: 1.357858, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 763, Training loss: 1.364631, Validation loss: 1.3748, lr: 0.0000\n",
      "Epoch: 764, Training loss: 1.345428, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 765, Training loss: 1.355358, Validation loss: 1.3778, lr: 0.0000\n",
      "Epoch: 766, Training loss: 1.363522, Validation loss: 1.3710, lr: 0.0000\n",
      "Epoch: 767, Training loss: 1.373954, Validation loss: 1.3574, lr: 0.0000\n",
      "Epoch: 768, Training loss: 1.390896, Validation loss: 1.3749, lr: 0.0000\n",
      "Epoch: 769, Training loss: 1.402141, Validation loss: 1.3783, lr: 0.0000\n",
      "Epoch: 770, Training loss: 1.369874, Validation loss: 1.3637, lr: 0.0000\n",
      "Epoch: 771, Training loss: 1.361384, Validation loss: 1.3650, lr: 0.0000\n",
      "Epoch: 772, Training loss: 1.340431, Validation loss: 1.3571, lr: 0.0000\n",
      "Epoch: 773, Training loss: 1.405827, Validation loss: 1.3724, lr: 0.0000\n",
      "Epoch: 774, Training loss: 1.378249, Validation loss: 1.3740, lr: 0.0000\n",
      "Epoch: 775, Training loss: 1.361733, Validation loss: 1.3774, lr: 0.0000\n",
      "Epoch: 776, Training loss: 1.385685, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 777, Training loss: 1.345789, Validation loss: 1.3788, lr: 0.0000\n",
      "Epoch: 778, Training loss: 1.354691, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 779, Training loss: 1.367155, Validation loss: 1.3620, lr: 0.0000\n",
      "Epoch: 780, Training loss: 1.354627, Validation loss: 1.3741, lr: 0.0000\n",
      "Epoch: 781, Training loss: 1.356780, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 782, Training loss: 1.387871, Validation loss: 1.3734, lr: 0.0000\n",
      "Epoch: 783, Training loss: 1.346623, Validation loss: 1.4582, lr: 0.0000\n",
      "Epoch: 784, Training loss: 1.384044, Validation loss: 1.3765, lr: 0.0000\n",
      "Epoch: 785, Training loss: 1.379680, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 786, Training loss: 1.355588, Validation loss: 1.3482, lr: 0.0000\n",
      "Epoch: 787, Training loss: 1.377151, Validation loss: 1.3286, lr: 0.0000\n",
      "Epoch: 788, Training loss: 1.375479, Validation loss: 1.4284, lr: 0.0000\n",
      "Epoch: 789, Training loss: 1.525209, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 790, Training loss: 1.344158, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 791, Training loss: 1.387330, Validation loss: 1.3732, lr: 0.0000\n",
      "Epoch: 792, Training loss: 1.350548, Validation loss: 1.3748, lr: 0.0000\n",
      "Epoch: 793, Training loss: 1.381871, Validation loss: 1.3725, lr: 0.0000\n",
      "Epoch: 794, Training loss: 1.366232, Validation loss: 1.3764, lr: 0.0000\n",
      "Epoch: 795, Training loss: 1.382333, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 796, Training loss: 1.356488, Validation loss: 1.3898, lr: 0.0000\n",
      "Epoch: 797, Training loss: 1.378093, Validation loss: 1.3974, lr: 0.0000\n",
      "Epoch: 798, Training loss: 1.346547, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 799, Training loss: 1.371163, Validation loss: 1.3786, lr: 0.0000\n",
      "Epoch: 800, Training loss: 1.363689, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 801, Training loss: 1.362184, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 802, Training loss: 1.387064, Validation loss: 1.3488, lr: 0.0000\n",
      "Epoch: 803, Training loss: 1.340859, Validation loss: 1.3796, lr: 0.0000\n",
      "Epoch: 804, Training loss: 1.359681, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 805, Training loss: 1.361717, Validation loss: 1.3748, lr: 0.0000\n",
      "Epoch: 806, Training loss: 1.402197, Validation loss: 1.3780, lr: 0.0000\n",
      "Epoch: 807, Training loss: 1.388610, Validation loss: 1.4090, lr: 0.0000\n",
      "Epoch: 808, Training loss: 1.355264, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 809, Training loss: 1.353611, Validation loss: 1.3699, lr: 0.0000\n",
      "Epoch: 810, Training loss: 1.368075, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 811, Training loss: 1.365745, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 812, Training loss: 1.405819, Validation loss: 1.3772, lr: 0.0000\n",
      "Epoch: 813, Training loss: 1.380593, Validation loss: 1.3720, lr: 0.0000\n",
      "Epoch: 814, Training loss: 1.358667, Validation loss: 1.3737, lr: 0.0000\n",
      "Epoch: 815, Training loss: 1.366135, Validation loss: 1.3698, lr: 0.0000\n",
      "Epoch: 816, Training loss: 1.355648, Validation loss: 1.3937, lr: 0.0000\n",
      "Epoch: 817, Training loss: 1.367454, Validation loss: 1.3580, lr: 0.0000\n",
      "Epoch: 818, Training loss: 1.367781, Validation loss: 1.3756, lr: 0.0000\n",
      "Epoch: 819, Training loss: 1.357380, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 820, Training loss: 1.392951, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 821, Training loss: 1.362759, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 822, Training loss: 1.359382, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 823, Training loss: 1.389340, Validation loss: 1.3696, lr: 0.0000\n",
      "Epoch: 824, Training loss: 1.370134, Validation loss: 1.3709, lr: 0.0000\n",
      "Epoch: 825, Training loss: 1.347269, Validation loss: 1.3677, lr: 0.0000\n",
      "Epoch: 826, Training loss: 1.382226, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 827, Training loss: 1.382087, Validation loss: 1.6715, lr: 0.0000\n",
      "Epoch: 828, Training loss: 1.419081, Validation loss: 1.3803, lr: 0.0000\n",
      "Epoch: 829, Training loss: 1.373084, Validation loss: 1.3780, lr: 0.0000\n",
      "Epoch: 830, Training loss: 1.352599, Validation loss: 1.3676, lr: 0.0000\n",
      "Epoch: 831, Training loss: 1.356064, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 832, Training loss: 1.355487, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 833, Training loss: 1.362106, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 834, Training loss: 1.352173, Validation loss: 1.3888, lr: 0.0000\n",
      "Epoch: 835, Training loss: 1.384443, Validation loss: 1.3747, lr: 0.0000\n",
      "Epoch: 836, Training loss: 1.413488, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 837, Training loss: 1.384938, Validation loss: 1.3781, lr: 0.0000\n",
      "Epoch: 838, Training loss: 1.369313, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 839, Training loss: 1.363418, Validation loss: 1.3786, lr: 0.0000\n",
      "Epoch: 840, Training loss: 1.367108, Validation loss: 1.3799, lr: 0.0000\n",
      "Epoch: 841, Training loss: 1.416865, Validation loss: 1.3956, lr: 0.0000\n",
      "Epoch: 842, Training loss: 1.357406, Validation loss: 1.3754, lr: 0.0000\n",
      "Epoch: 843, Training loss: 1.361534, Validation loss: 1.3742, lr: 0.0000\n",
      "Epoch: 844, Training loss: 1.380145, Validation loss: 1.3652, lr: 0.0000\n",
      "Epoch: 845, Training loss: 1.358752, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 846, Training loss: 1.372353, Validation loss: 1.3532, lr: 0.0000\n",
      "Epoch: 847, Training loss: 1.375570, Validation loss: 1.4776, lr: 0.0000\n",
      "Epoch: 848, Training loss: 1.385853, Validation loss: 1.3795, lr: 0.0000\n",
      "Epoch: 849, Training loss: 1.367333, Validation loss: 1.3793, lr: 0.0000\n",
      "Epoch: 850, Training loss: 1.370229, Validation loss: 1.3678, lr: 0.0000\n",
      "Epoch: 851, Training loss: 1.375280, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 852, Training loss: 1.331792, Validation loss: 1.3912, lr: 0.0000\n",
      "Epoch: 853, Training loss: 1.382474, Validation loss: 1.3761, lr: 0.0000\n",
      "Epoch: 854, Training loss: 1.358112, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 855, Training loss: 1.357074, Validation loss: 1.3462, lr: 0.0000\n",
      "Epoch: 856, Training loss: 1.363808, Validation loss: 1.3760, lr: 0.0000\n",
      "Epoch: 857, Training loss: 1.384979, Validation loss: 1.3780, lr: 0.0000\n",
      "Epoch: 858, Training loss: 1.399700, Validation loss: 1.3568, lr: 0.0000\n",
      "Epoch: 859, Training loss: 1.346554, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 860, Training loss: 1.358970, Validation loss: 1.3766, lr: 0.0000\n",
      "Epoch: 861, Training loss: 1.384539, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 862, Training loss: 1.376207, Validation loss: 1.3691, lr: 0.0000\n",
      "Epoch: 863, Training loss: 1.370210, Validation loss: 1.3983, lr: 0.0000\n",
      "Epoch: 864, Training loss: 1.358422, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 865, Training loss: 1.378752, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 866, Training loss: 1.365680, Validation loss: 1.3969, lr: 0.0000\n",
      "Epoch: 867, Training loss: 1.365253, Validation loss: 1.4068, lr: 0.0000\n",
      "Epoch: 868, Training loss: 1.338350, Validation loss: 1.3725, lr: 0.0000\n",
      "Epoch: 869, Training loss: 1.379909, Validation loss: 1.3886, lr: 0.0000\n",
      "Epoch: 870, Training loss: 1.384406, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 871, Training loss: 1.348938, Validation loss: 1.3780, lr: 0.0000\n",
      "Epoch: 872, Training loss: 1.353630, Validation loss: 1.3793, lr: 0.0000\n",
      "Epoch: 873, Training loss: 1.362590, Validation loss: 1.3761, lr: 0.0000\n",
      "Epoch: 874, Training loss: 1.363306, Validation loss: 1.3763, lr: 0.0000\n",
      "Epoch: 875, Training loss: 1.390898, Validation loss: 1.3891, lr: 0.0000\n",
      "Epoch: 876, Training loss: 1.381815, Validation loss: 1.3871, lr: 0.0000\n",
      "Epoch: 877, Training loss: 1.386141, Validation loss: 1.3742, lr: 0.0000\n",
      "Epoch: 878, Training loss: 1.363700, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 879, Training loss: 1.342161, Validation loss: 1.3799, lr: 0.0000\n",
      "Epoch: 880, Training loss: 1.369713, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 881, Training loss: 1.366376, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 882, Training loss: 1.382352, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 883, Training loss: 1.357883, Validation loss: 1.3780, lr: 0.0000\n",
      "Epoch: 884, Training loss: 1.360581, Validation loss: 1.3799, lr: 0.0000\n",
      "Epoch: 885, Training loss: 1.352254, Validation loss: 1.3789, lr: 0.0000\n",
      "Epoch: 886, Training loss: 1.340392, Validation loss: 1.3660, lr: 0.0000\n",
      "Epoch: 887, Training loss: 1.400647, Validation loss: 1.3765, lr: 0.0000\n",
      "Epoch: 888, Training loss: 1.425792, Validation loss: 1.3502, lr: 0.0000\n",
      "Epoch: 889, Training loss: 1.363793, Validation loss: 1.3731, lr: 0.0000\n",
      "Epoch: 890, Training loss: 1.374335, Validation loss: 1.3688, lr: 0.0000\n",
      "Epoch: 891, Training loss: 1.366549, Validation loss: 1.3741, lr: 0.0000\n",
      "Epoch: 892, Training loss: 1.375323, Validation loss: 1.4065, lr: 0.0000\n",
      "Epoch: 893, Training loss: 1.374142, Validation loss: 1.3729, lr: 0.0000\n",
      "Epoch: 894, Training loss: 1.346344, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 895, Training loss: 1.367714, Validation loss: 1.4011, lr: 0.0000\n",
      "Epoch: 896, Training loss: 1.354570, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 897, Training loss: 1.394614, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 898, Training loss: 1.366041, Validation loss: 1.3754, lr: 0.0000\n",
      "Epoch: 899, Training loss: 1.388207, Validation loss: 1.3787, lr: 0.0000\n",
      "Epoch: 900, Training loss: 1.367370, Validation loss: 1.3767, lr: 0.0000\n",
      "Epoch: 901, Training loss: 1.383287, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 902, Training loss: 1.359556, Validation loss: 1.3434, lr: 0.0000\n",
      "Epoch: 903, Training loss: 1.375149, Validation loss: 1.3591, lr: 0.0000\n",
      "Epoch: 904, Training loss: 1.352891, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 905, Training loss: 1.397774, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 906, Training loss: 1.351518, Validation loss: 1.3527, lr: 0.0000\n",
      "Epoch: 907, Training loss: 1.347626, Validation loss: 1.3753, lr: 0.0000\n",
      "Epoch: 908, Training loss: 1.360772, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 909, Training loss: 1.371208, Validation loss: 1.3673, lr: 0.0000\n",
      "Epoch: 910, Training loss: 1.359818, Validation loss: 1.3979, lr: 0.0000\n",
      "Epoch: 911, Training loss: 1.352847, Validation loss: 1.3685, lr: 0.0000\n",
      "Epoch: 912, Training loss: 1.355307, Validation loss: 1.3742, lr: 0.0000\n",
      "Epoch: 913, Training loss: 1.360141, Validation loss: 1.3715, lr: 0.0000\n",
      "Epoch: 914, Training loss: 1.377831, Validation loss: 1.3949, lr: 0.0000\n",
      "Epoch: 915, Training loss: 1.378894, Validation loss: 1.3581, lr: 0.0000\n",
      "Epoch: 916, Training loss: 1.360767, Validation loss: 1.3610, lr: 0.0000\n",
      "Epoch: 917, Training loss: 1.364379, Validation loss: 1.3744, lr: 0.0000\n",
      "Epoch: 918, Training loss: 1.363962, Validation loss: 1.3742, lr: 0.0000\n",
      "Epoch: 919, Training loss: 1.349754, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 920, Training loss: 1.374755, Validation loss: 1.3569, lr: 0.0000\n",
      "Epoch: 921, Training loss: 1.344653, Validation loss: 1.3661, lr: 0.0000\n",
      "Epoch: 922, Training loss: 1.347631, Validation loss: 1.3785, lr: 0.0000\n",
      "Epoch: 923, Training loss: 1.427006, Validation loss: 1.3886, lr: 0.0000\n",
      "Epoch: 924, Training loss: 1.379315, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 925, Training loss: 1.382188, Validation loss: 1.3724, lr: 0.0000\n",
      "Epoch: 926, Training loss: 1.374392, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 927, Training loss: 1.336443, Validation loss: 1.3777, lr: 0.0000\n",
      "Epoch: 928, Training loss: 1.359774, Validation loss: 1.3756, lr: 0.0000\n",
      "Epoch: 929, Training loss: 1.356910, Validation loss: 1.3765, lr: 0.0000\n",
      "Epoch: 930, Training loss: 1.420798, Validation loss: 1.3781, lr: 0.0000\n",
      "Epoch: 931, Training loss: 1.376516, Validation loss: 1.3797, lr: 0.0000\n",
      "Epoch: 932, Training loss: 1.357909, Validation loss: 1.3710, lr: 0.0000\n",
      "Epoch: 933, Training loss: 1.367997, Validation loss: 1.4487, lr: 0.0000\n",
      "Epoch: 934, Training loss: 1.365554, Validation loss: 1.3770, lr: 0.0000\n",
      "Epoch: 935, Training loss: 1.352421, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 936, Training loss: 1.348283, Validation loss: 1.3953, lr: 0.0000\n",
      "Epoch: 937, Training loss: 1.371378, Validation loss: 1.3749, lr: 0.0000\n",
      "Epoch: 938, Training loss: 1.359398, Validation loss: 1.3777, lr: 0.0000\n",
      "Epoch: 939, Training loss: 1.359572, Validation loss: 1.4042, lr: 0.0000\n",
      "Epoch: 940, Training loss: 1.354648, Validation loss: 1.3758, lr: 0.0000\n",
      "Epoch: 941, Training loss: 1.358199, Validation loss: 1.3660, lr: 0.0000\n",
      "Epoch: 942, Training loss: 1.364452, Validation loss: 1.3934, lr: 0.0000\n",
      "Epoch: 943, Training loss: 1.331683, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 944, Training loss: 1.378499, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 945, Training loss: 1.407899, Validation loss: 1.3765, lr: 0.0000\n",
      "Epoch: 946, Training loss: 1.356547, Validation loss: 1.3942, lr: 0.0000\n",
      "Epoch: 947, Training loss: 1.405557, Validation loss: 1.3635, lr: 0.0000\n",
      "Epoch: 948, Training loss: 1.356119, Validation loss: 1.3765, lr: 0.0000\n",
      "Epoch: 949, Training loss: 1.341935, Validation loss: 1.3797, lr: 0.0000\n",
      "Epoch: 950, Training loss: 1.364892, Validation loss: 1.3608, lr: 0.0000\n",
      "Epoch: 951, Training loss: 1.405980, Validation loss: 1.3726, lr: 0.0000\n",
      "Epoch: 952, Training loss: 1.408955, Validation loss: 1.3766, lr: 0.0000\n",
      "Epoch: 953, Training loss: 1.361830, Validation loss: 1.3642, lr: 0.0000\n",
      "Epoch: 954, Training loss: 1.357423, Validation loss: 1.3979, lr: 0.0000\n",
      "Epoch: 955, Training loss: 1.366168, Validation loss: 1.3790, lr: 0.0000\n",
      "Epoch: 956, Training loss: 1.372380, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 957, Training loss: 1.348693, Validation loss: 1.3780, lr: 0.0000\n",
      "Epoch: 958, Training loss: 1.367388, Validation loss: 1.3696, lr: 0.0000\n",
      "Epoch: 959, Training loss: 1.360224, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 960, Training loss: 1.352865, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 961, Training loss: 1.384572, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 962, Training loss: 1.387896, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 963, Training loss: 1.373751, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 964, Training loss: 1.387697, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 965, Training loss: 1.358122, Validation loss: 1.3764, lr: 0.0000\n",
      "Epoch: 966, Training loss: 1.382981, Validation loss: 1.3793, lr: 0.0000\n",
      "Epoch: 967, Training loss: 1.409920, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 968, Training loss: 1.364871, Validation loss: 1.3630, lr: 0.0000\n",
      "Epoch: 969, Training loss: 1.377254, Validation loss: 1.3930, lr: 0.0000\n",
      "Epoch: 970, Training loss: 1.363170, Validation loss: 1.3595, lr: 0.0000\n",
      "Epoch: 971, Training loss: 1.349499, Validation loss: 1.3763, lr: 0.0000\n",
      "Epoch: 972, Training loss: 1.363796, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 973, Training loss: 1.434705, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 974, Training loss: 1.360206, Validation loss: 1.3792, lr: 0.0000\n",
      "Epoch: 975, Training loss: 1.356969, Validation loss: 1.3775, lr: 0.0000\n",
      "Epoch: 976, Training loss: 1.360394, Validation loss: 1.3690, lr: 0.0000\n",
      "Epoch: 977, Training loss: 1.361995, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 978, Training loss: 1.373682, Validation loss: 1.3788, lr: 0.0000\n",
      "Epoch: 979, Training loss: 1.352077, Validation loss: 1.3759, lr: 0.0000\n",
      "Epoch: 980, Training loss: 1.358061, Validation loss: 1.3499, lr: 0.0000\n",
      "Epoch: 981, Training loss: 1.377898, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 982, Training loss: 1.375099, Validation loss: 1.3717, lr: 0.0000\n",
      "Epoch: 983, Training loss: 1.369489, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 984, Training loss: 1.382814, Validation loss: 1.3654, lr: 0.0000\n",
      "Epoch: 985, Training loss: 1.372204, Validation loss: 1.3488, lr: 0.0000\n",
      "Epoch: 986, Training loss: 1.363286, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 987, Training loss: 1.367214, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 988, Training loss: 1.346130, Validation loss: 1.3762, lr: 0.0000\n",
      "Epoch: 989, Training loss: 1.351896, Validation loss: 1.3941, lr: 0.0000\n",
      "Epoch: 990, Training loss: 1.355478, Validation loss: 1.3792, lr: 0.0000\n",
      "Epoch: 991, Training loss: 1.349013, Validation loss: 1.3535, lr: 0.0000\n",
      "Epoch: 992, Training loss: 1.367201, Validation loss: 1.3792, lr: 0.0000\n",
      "Epoch: 993, Training loss: 1.367676, Validation loss: 1.3933, lr: 0.0000\n",
      "Epoch: 994, Training loss: 1.348528, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 995, Training loss: 1.366752, Validation loss: 1.3790, lr: 0.0000\n",
      "Epoch: 996, Training loss: 1.377286, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 997, Training loss: 1.401668, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 998, Training loss: 1.381548, Validation loss: 1.3683, lr: 0.0000\n",
      "Epoch: 999, Training loss: 1.371941, Validation loss: 1.3799, lr: 0.0000\n",
      "Final test loss: 1.3850\n",
      "=== Run 05/10 ===\n",
      "\n",
      "---- Settings: \n",
      "\n",
      "epochs : 1000\n",
      "hidden_channels : [32]\n",
      "out_channels : 10\n",
      "inner_product_features : False\n",
      "batch_size : 64\n",
      "lr : 0.01\n",
      "momentum : 0.9\n",
      "dropout : 0.0\n",
      "batch_norm : batch_norm\n",
      "bias : True\n",
      "order : 2\n",
      "diffusion : True\n",
      "frac_sampled_nb : -1\n",
      "include_positions : False\n",
      "include_self : True\n",
      "vec_norm : False\n",
      "emb_norm : False\n",
      "seed : 0\n",
      "dim_signal : 100\n",
      "dim_emb : 100\n",
      "n_sampled_nb : -1\n",
      "\n",
      "---- Number of features to pass to the MLP:  1010100\n",
      "---- Total number of parameters:  32323627\n",
      "\n",
      "Using device cuda:0\n",
      "\n",
      "---- Training network ...\n",
      "\n",
      "---- Timestamp: 20250614-122610\n",
      "\n",
      " *och: 0, Training loss: 1.459368, Validation loss: 1.6195, lr: 0.0100\n",
      " *och: 1, Training loss: 1.473905, Validation loss: 1.3885, lr: 0.0100\n",
      " *och: 2, Training loss: 1.391045, Validation loss: 1.3499, lr: 0.0100\n",
      "Epoch: 3, Training loss: 1.376636, Validation loss: 1.3684, lr: 0.0100\n",
      "Epoch: 4, Training loss: 1.400780, Validation loss: 1.4237, lr: 0.0100\n",
      "Epoch: 5, Training loss: 1.369180, Validation loss: 1.4337, lr: 0.0100\n",
      "Epoch: 6, Training loss: 1.376981, Validation loss: 1.3813, lr: 0.0100\n",
      "Epoch: 7, Training loss: 1.386946, Validation loss: 1.3795, lr: 0.0100\n",
      "Epoch: 8, Training loss: 1.418345, Validation loss: 1.3807, lr: 0.0100\n",
      "Epoch: 9, Training loss: 1.398008, Validation loss: 1.3933, lr: 0.0100\n",
      "Epoch: 10, Training loss: 1.378052, Validation loss: 1.3880, lr: 0.0100\n",
      "Epoch: 11, Training loss: 1.521963, Validation loss: 1.3851, lr: 0.0100\n",
      "Epoch: 12, Training loss: 1.376098, Validation loss: 1.3845, lr: 0.0100\n",
      "Epoch: 13, Training loss: 1.405809, Validation loss: 1.3867, lr: 0.0100\n",
      "Epoch: 14, Training loss: 1.372564, Validation loss: 1.3912, lr: 0.0100\n",
      "Epoch: 15, Training loss: 1.412043, Validation loss: 1.3729, lr: 0.0100\n",
      "Epoch: 16, Training loss: 1.387086, Validation loss: 1.3864, lr: 0.0010\n",
      "Epoch: 17, Training loss: 1.405216, Validation loss: 1.3669, lr: 0.0010\n",
      "Epoch: 18, Training loss: 1.367540, Validation loss: 1.3810, lr: 0.0010\n",
      "Epoch: 19, Training loss: 1.451968, Validation loss: 1.3795, lr: 0.0010\n",
      "Epoch: 20, Training loss: 1.376752, Validation loss: 1.3811, lr: 0.0010\n",
      "Epoch: 21, Training loss: 1.409227, Validation loss: 1.3819, lr: 0.0010\n",
      "Epoch: 22, Training loss: 1.388383, Validation loss: 1.3777, lr: 0.0010\n",
      "Epoch: 23, Training loss: 1.360251, Validation loss: 1.3853, lr: 0.0010\n",
      "Epoch: 24, Training loss: 1.391016, Validation loss: 1.3833, lr: 0.0010\n",
      "Epoch: 25, Training loss: 1.372553, Validation loss: 1.3840, lr: 0.0010\n",
      "Epoch: 26, Training loss: 1.390622, Validation loss: 1.3850, lr: 0.0010\n",
      "Epoch: 27, Training loss: 1.370692, Validation loss: 1.3844, lr: 0.0010\n",
      "Epoch: 28, Training loss: 1.390792, Validation loss: 1.3878, lr: 0.0010\n",
      "Epoch: 29, Training loss: 1.369638, Validation loss: 1.3838, lr: 0.0010\n",
      "Epoch: 30, Training loss: 1.371911, Validation loss: 1.3835, lr: 0.0010\n",
      "Epoch: 31, Training loss: 1.368138, Validation loss: 1.3826, lr: 0.0010\n",
      "Epoch: 32, Training loss: 1.347448, Validation loss: 1.3858, lr: 0.0010\n",
      "Epoch: 33, Training loss: 1.378487, Validation loss: 1.3784, lr: 0.0010\n",
      "Epoch: 34, Training loss: 1.378314, Validation loss: 1.3701, lr: 0.0010\n",
      "Epoch: 35, Training loss: 1.365027, Validation loss: 1.3865, lr: 0.0010\n",
      "Epoch: 36, Training loss: 1.370420, Validation loss: 1.3680, lr: 0.0010\n",
      "Epoch: 37, Training loss: 1.379138, Validation loss: 1.3831, lr: 0.0010\n",
      "Epoch: 38, Training loss: 1.375232, Validation loss: 1.3794, lr: 0.0010\n",
      "Epoch: 39, Training loss: 1.371163, Validation loss: 1.3823, lr: 0.0010\n",
      "Epoch: 40, Training loss: 1.385282, Validation loss: 1.3943, lr: 0.0010\n",
      "Epoch: 41, Training loss: 1.371060, Validation loss: 1.4041, lr: 0.0010\n",
      "Epoch: 42, Training loss: 1.381634, Validation loss: 1.3859, lr: 0.0010\n",
      "Epoch: 43, Training loss: 1.374319, Validation loss: 1.3782, lr: 0.0001\n",
      "Epoch: 44, Training loss: 1.369973, Validation loss: 1.3879, lr: 0.0001\n",
      "Epoch: 45, Training loss: 1.366710, Validation loss: 1.3709, lr: 0.0001\n",
      "Epoch: 46, Training loss: 1.384356, Validation loss: 1.3693, lr: 0.0001\n",
      "Epoch: 47, Training loss: 1.376483, Validation loss: 1.3576, lr: 0.0001\n",
      "Epoch: 48, Training loss: 1.383452, Validation loss: 1.3884, lr: 0.0001\n",
      "Epoch: 49, Training loss: 1.367673, Validation loss: 1.3769, lr: 0.0001\n",
      "Epoch: 50, Training loss: 1.373321, Validation loss: 1.3895, lr: 0.0001\n",
      "Epoch: 51, Training loss: 1.372437, Validation loss: 1.3815, lr: 0.0001\n",
      "Epoch: 52, Training loss: 1.410600, Validation loss: 1.3899, lr: 0.0001\n",
      "Epoch: 53, Training loss: 1.373212, Validation loss: 1.3884, lr: 0.0001\n",
      "Epoch: 54, Training loss: 1.397915, Validation loss: 1.7113, lr: 0.0000\n",
      "Epoch: 55, Training loss: 1.379572, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 56, Training loss: 1.366026, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 57, Training loss: 1.380692, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 58, Training loss: 1.384455, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 59, Training loss: 1.379831, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 60, Training loss: 1.378009, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 61, Training loss: 1.387609, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 62, Training loss: 1.366781, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 63, Training loss: 1.364560, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 64, Training loss: 1.398169, Validation loss: 1.3980, lr: 0.0000\n",
      "Epoch: 65, Training loss: 1.378220, Validation loss: 1.3921, lr: 0.0000\n",
      "Epoch: 66, Training loss: 1.370577, Validation loss: 1.3774, lr: 0.0000\n",
      "Epoch: 67, Training loss: 1.380991, Validation loss: 1.3778, lr: 0.0000\n",
      "Epoch: 68, Training loss: 1.376960, Validation loss: 1.3879, lr: 0.0000\n",
      "Epoch: 69, Training loss: 1.374758, Validation loss: 1.3745, lr: 0.0000\n",
      "Epoch: 70, Training loss: 1.363769, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 71, Training loss: 1.396008, Validation loss: 1.3733, lr: 0.0000\n",
      "Epoch: 72, Training loss: 1.365926, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 73, Training loss: 1.377828, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 74, Training loss: 1.390323, Validation loss: 1.3795, lr: 0.0000\n",
      "Epoch: 75, Training loss: 1.366508, Validation loss: 1.3661, lr: 0.0000\n",
      "Epoch: 76, Training loss: 1.372149, Validation loss: 1.3893, lr: 0.0000\n",
      "Epoch: 77, Training loss: 1.373503, Validation loss: 1.3772, lr: 0.0000\n",
      "Epoch: 78, Training loss: 1.370588, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 79, Training loss: 1.347980, Validation loss: 1.3887, lr: 0.0000\n",
      "Epoch: 80, Training loss: 1.378846, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 81, Training loss: 1.378920, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 82, Training loss: 1.364614, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 83, Training loss: 1.356590, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 84, Training loss: 1.390537, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 85, Training loss: 1.400533, Validation loss: 1.4020, lr: 0.0000\n",
      "Epoch: 86, Training loss: 1.379928, Validation loss: 1.3643, lr: 0.0000\n",
      "Epoch: 87, Training loss: 1.366929, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 88, Training loss: 1.366106, Validation loss: 1.3687, lr: 0.0000\n",
      "Epoch: 89, Training loss: 1.371994, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 90, Training loss: 1.392236, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 91, Training loss: 1.388881, Validation loss: 1.4047, lr: 0.0000\n",
      "Epoch: 92, Training loss: 1.372138, Validation loss: 1.3778, lr: 0.0000\n",
      "Epoch: 93, Training loss: 1.383160, Validation loss: 1.3771, lr: 0.0000\n",
      "Epoch: 94, Training loss: 1.461623, Validation loss: 1.3713, lr: 0.0000\n",
      "Epoch: 95, Training loss: 1.382218, Validation loss: 1.3880, lr: 0.0000\n",
      "Epoch: 96, Training loss: 1.396428, Validation loss: 1.3974, lr: 0.0000\n",
      "Epoch: 97, Training loss: 1.386099, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 98, Training loss: 1.386246, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 99, Training loss: 1.409659, Validation loss: 1.3775, lr: 0.0000\n",
      "Epoch: 100, Training loss: 1.366193, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 101, Training loss: 1.386943, Validation loss: 1.3673, lr: 0.0000\n",
      "Epoch: 102, Training loss: 1.371729, Validation loss: 1.3895, lr: 0.0000\n",
      "Epoch: 103, Training loss: 1.384876, Validation loss: 1.3753, lr: 0.0000\n",
      "Epoch: 104, Training loss: 1.389445, Validation loss: 1.4089, lr: 0.0000\n",
      "Epoch: 105, Training loss: 1.386131, Validation loss: 1.3778, lr: 0.0000\n",
      "Epoch: 106, Training loss: 1.370591, Validation loss: 1.4132, lr: 0.0000\n",
      "Epoch: 107, Training loss: 1.399108, Validation loss: 2.0124, lr: 0.0000\n",
      "Epoch: 108, Training loss: 1.394961, Validation loss: 1.3778, lr: 0.0000\n",
      "Epoch: 109, Training loss: 1.364402, Validation loss: 1.3759, lr: 0.0000\n",
      "Epoch: 110, Training loss: 1.370122, Validation loss: 1.3707, lr: 0.0000\n",
      "Epoch: 111, Training loss: 1.400161, Validation loss: 1.3710, lr: 0.0000\n",
      "Epoch: 112, Training loss: 1.419766, Validation loss: 1.3793, lr: 0.0000\n",
      "Epoch: 113, Training loss: 1.425351, Validation loss: 1.3726, lr: 0.0000\n",
      "Epoch: 114, Training loss: 1.356308, Validation loss: 1.3803, lr: 0.0000\n",
      "Epoch: 115, Training loss: 1.379952, Validation loss: 1.3628, lr: 0.0000\n",
      "Epoch: 116, Training loss: 1.366794, Validation loss: 1.3903, lr: 0.0000\n",
      "Epoch: 117, Training loss: 1.376698, Validation loss: 1.4234, lr: 0.0000\n",
      "Epoch: 118, Training loss: 1.372206, Validation loss: 1.3726, lr: 0.0000\n",
      "Epoch: 119, Training loss: 1.368267, Validation loss: 1.3880, lr: 0.0000\n",
      "Epoch: 120, Training loss: 1.378711, Validation loss: 1.3564, lr: 0.0000\n",
      "Epoch: 121, Training loss: 1.377648, Validation loss: 1.3910, lr: 0.0000\n",
      "Epoch: 122, Training loss: 1.397957, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 123, Training loss: 1.367344, Validation loss: 1.3875, lr: 0.0000\n",
      "Epoch: 124, Training loss: 1.360833, Validation loss: 1.3676, lr: 0.0000\n",
      "Epoch: 125, Training loss: 1.347474, Validation loss: 1.3715, lr: 0.0000\n",
      "Epoch: 126, Training loss: 1.381246, Validation loss: 1.3785, lr: 0.0000\n",
      "Epoch: 127, Training loss: 1.377065, Validation loss: 1.3930, lr: 0.0000\n",
      "Epoch: 128, Training loss: 1.370947, Validation loss: 1.3876, lr: 0.0000\n",
      "Epoch: 129, Training loss: 1.390693, Validation loss: 1.3788, lr: 0.0000\n",
      "Epoch: 130, Training loss: 1.391755, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 131, Training loss: 1.372282, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 132, Training loss: 1.366971, Validation loss: 1.3809, lr: 0.0000\n",
      "Epoch: 133, Training loss: 1.379699, Validation loss: 1.3890, lr: 0.0000\n",
      "Epoch: 134, Training loss: 1.377654, Validation loss: 1.3963, lr: 0.0000\n",
      "Epoch: 135, Training loss: 1.379326, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 136, Training loss: 1.375211, Validation loss: 1.3731, lr: 0.0000\n",
      "Epoch: 137, Training loss: 1.376086, Validation loss: 1.3665, lr: 0.0000\n",
      "Epoch: 138, Training loss: 1.373501, Validation loss: 1.3645, lr: 0.0000\n",
      "Epoch: 139, Training loss: 1.370780, Validation loss: 1.3779, lr: 0.0000\n",
      "Epoch: 140, Training loss: 1.367953, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 141, Training loss: 1.378032, Validation loss: 1.3702, lr: 0.0000\n",
      "Epoch: 142, Training loss: 1.396346, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 143, Training loss: 1.391026, Validation loss: 1.3879, lr: 0.0000\n",
      "Epoch: 144, Training loss: 1.423751, Validation loss: 1.3790, lr: 0.0000\n",
      "Epoch: 145, Training loss: 1.373419, Validation loss: 1.3908, lr: 0.0000\n",
      "Epoch: 146, Training loss: 1.375067, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 147, Training loss: 1.369491, Validation loss: 1.3901, lr: 0.0000\n",
      "Epoch: 148, Training loss: 1.424774, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 149, Training loss: 1.383951, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 150, Training loss: 1.369947, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 151, Training loss: 1.364249, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 152, Training loss: 1.404530, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 153, Training loss: 1.383872, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 154, Training loss: 1.379056, Validation loss: 1.3756, lr: 0.0000\n",
      "Epoch: 155, Training loss: 1.372129, Validation loss: 1.3754, lr: 0.0000\n",
      "Epoch: 156, Training loss: 1.373488, Validation loss: 1.3798, lr: 0.0000\n",
      "Epoch: 157, Training loss: 1.371701, Validation loss: 1.3915, lr: 0.0000\n",
      "Epoch: 158, Training loss: 1.362881, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 159, Training loss: 1.393723, Validation loss: 1.3875, lr: 0.0000\n",
      "Epoch: 160, Training loss: 1.369891, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 161, Training loss: 1.388861, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 162, Training loss: 1.401540, Validation loss: 1.3914, lr: 0.0000\n",
      "Epoch: 163, Training loss: 1.397895, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 164, Training loss: 1.373911, Validation loss: 1.3945, lr: 0.0000\n",
      "Epoch: 165, Training loss: 1.367162, Validation loss: 1.3914, lr: 0.0000\n",
      "Epoch: 166, Training loss: 1.371232, Validation loss: 1.5501, lr: 0.0000\n",
      "Epoch: 167, Training loss: 1.365466, Validation loss: 1.3772, lr: 0.0000\n",
      "Epoch: 168, Training loss: 1.358146, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 169, Training loss: 1.385461, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 170, Training loss: 1.385549, Validation loss: 1.3789, lr: 0.0000\n",
      "Epoch: 171, Training loss: 1.376062, Validation loss: 1.3777, lr: 0.0000\n",
      "Epoch: 172, Training loss: 1.364570, Validation loss: 1.3779, lr: 0.0000\n",
      "Epoch: 173, Training loss: 1.367796, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 174, Training loss: 1.368151, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 175, Training loss: 1.372340, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 176, Training loss: 1.366861, Validation loss: 1.3803, lr: 0.0000\n",
      "Epoch: 177, Training loss: 1.381829, Validation loss: 1.3899, lr: 0.0000\n",
      "Epoch: 178, Training loss: 1.393837, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 179, Training loss: 1.380300, Validation loss: 1.3794, lr: 0.0000\n",
      "Epoch: 180, Training loss: 1.384126, Validation loss: 1.3755, lr: 0.0000\n",
      "Epoch: 181, Training loss: 1.366985, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 182, Training loss: 1.360916, Validation loss: 1.3876, lr: 0.0000\n",
      "Epoch: 183, Training loss: 1.369598, Validation loss: 1.3797, lr: 0.0000\n",
      "Epoch: 184, Training loss: 1.384155, Validation loss: 1.3774, lr: 0.0000\n",
      "Epoch: 185, Training loss: 1.428821, Validation loss: 1.3791, lr: 0.0000\n",
      "Epoch: 186, Training loss: 1.396205, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 187, Training loss: 1.372430, Validation loss: 1.3789, lr: 0.0000\n",
      "Epoch: 188, Training loss: 1.380576, Validation loss: 1.3954, lr: 0.0000\n",
      "Epoch: 189, Training loss: 1.364686, Validation loss: 1.3722, lr: 0.0000\n",
      "Epoch: 190, Training loss: 1.418538, Validation loss: 1.3750, lr: 0.0000\n",
      "Epoch: 191, Training loss: 1.374189, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 192, Training loss: 1.375161, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 193, Training loss: 1.389697, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 194, Training loss: 1.372637, Validation loss: 1.3761, lr: 0.0000\n",
      "Epoch: 195, Training loss: 1.382682, Validation loss: 1.3814, lr: 0.0000\n",
      " *och: 196, Training loss: 1.352482, Validation loss: 1.3454, lr: 0.0000\n",
      "Epoch: 197, Training loss: 1.364333, Validation loss: 1.4772, lr: 0.0000\n",
      "Epoch: 198, Training loss: 1.398743, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 199, Training loss: 1.355559, Validation loss: 1.3777, lr: 0.0000\n",
      "Epoch: 200, Training loss: 1.357452, Validation loss: 1.3764, lr: 0.0000\n",
      "Epoch: 201, Training loss: 1.381614, Validation loss: 1.3890, lr: 0.0000\n",
      "Epoch: 202, Training loss: 1.409955, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 203, Training loss: 1.380952, Validation loss: 1.3797, lr: 0.0000\n",
      "Epoch: 204, Training loss: 1.372268, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 205, Training loss: 1.366551, Validation loss: 1.3889, lr: 0.0000\n",
      "Epoch: 206, Training loss: 1.400943, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 207, Training loss: 1.383617, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 208, Training loss: 1.366889, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 209, Training loss: 1.398193, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 210, Training loss: 1.373697, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 211, Training loss: 1.357220, Validation loss: 1.3918, lr: 0.0000\n",
      "Epoch: 212, Training loss: 1.420705, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 213, Training loss: 1.391877, Validation loss: 1.3896, lr: 0.0000\n",
      "Epoch: 214, Training loss: 1.375390, Validation loss: 1.3898, lr: 0.0000\n",
      "Epoch: 215, Training loss: 1.380965, Validation loss: 1.3775, lr: 0.0000\n",
      "Epoch: 216, Training loss: 1.389376, Validation loss: 1.4775, lr: 0.0000\n",
      "Epoch: 217, Training loss: 1.380967, Validation loss: 1.3703, lr: 0.0000\n",
      "Epoch: 218, Training loss: 1.373006, Validation loss: 1.3785, lr: 0.0000\n",
      "Epoch: 219, Training loss: 1.388169, Validation loss: 1.3802, lr: 0.0000\n",
      "Epoch: 220, Training loss: 1.392566, Validation loss: 1.3872, lr: 0.0000\n",
      "Epoch: 221, Training loss: 1.364574, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 222, Training loss: 1.387457, Validation loss: 1.4771, lr: 0.0000\n",
      "Epoch: 223, Training loss: 1.377679, Validation loss: 1.3800, lr: 0.0000\n",
      "Epoch: 224, Training loss: 1.389153, Validation loss: 1.3647, lr: 0.0000\n",
      "Epoch: 225, Training loss: 1.378427, Validation loss: 1.3796, lr: 0.0000\n",
      "Epoch: 226, Training loss: 1.374470, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 227, Training loss: 1.351431, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 228, Training loss: 1.382971, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 229, Training loss: 1.376923, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 230, Training loss: 1.387982, Validation loss: 1.3929, lr: 0.0000\n",
      "Epoch: 231, Training loss: 1.366609, Validation loss: 1.3700, lr: 0.0000\n",
      "Epoch: 232, Training loss: 1.381117, Validation loss: 1.3794, lr: 0.0000\n",
      "Epoch: 233, Training loss: 1.388207, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 234, Training loss: 1.364449, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 235, Training loss: 1.378726, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 236, Training loss: 1.393177, Validation loss: 1.3781, lr: 0.0000\n",
      "Epoch: 237, Training loss: 1.401165, Validation loss: 1.3793, lr: 0.0000\n",
      "Epoch: 238, Training loss: 1.401720, Validation loss: 1.3653, lr: 0.0000\n",
      "Epoch: 239, Training loss: 1.374335, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 240, Training loss: 1.378712, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 241, Training loss: 1.391036, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 242, Training loss: 1.373824, Validation loss: 1.3792, lr: 0.0000\n",
      "Epoch: 243, Training loss: 1.388129, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 244, Training loss: 1.399314, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 245, Training loss: 1.401871, Validation loss: 1.3695, lr: 0.0000\n",
      "Epoch: 246, Training loss: 1.388502, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 247, Training loss: 1.385730, Validation loss: 1.3773, lr: 0.0000\n",
      "Epoch: 248, Training loss: 1.377957, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 249, Training loss: 1.373091, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 250, Training loss: 1.370341, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 251, Training loss: 1.364599, Validation loss: 1.3746, lr: 0.0000\n",
      "Epoch: 252, Training loss: 1.380672, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 253, Training loss: 1.385381, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 254, Training loss: 1.392391, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 255, Training loss: 1.394281, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 256, Training loss: 1.365736, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 257, Training loss: 1.370811, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 258, Training loss: 1.376493, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 259, Training loss: 1.368540, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 260, Training loss: 1.380607, Validation loss: 1.4454, lr: 0.0000\n",
      "Epoch: 261, Training loss: 1.389880, Validation loss: 1.3881, lr: 0.0000\n",
      "Epoch: 262, Training loss: 1.367454, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 263, Training loss: 1.379756, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 264, Training loss: 1.371448, Validation loss: 1.3785, lr: 0.0000\n",
      "Epoch: 265, Training loss: 1.363818, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 266, Training loss: 1.363576, Validation loss: 1.3645, lr: 0.0000\n",
      "Epoch: 267, Training loss: 1.363561, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 268, Training loss: 1.383290, Validation loss: 1.3879, lr: 0.0000\n",
      "Epoch: 269, Training loss: 1.392598, Validation loss: 1.3764, lr: 0.0000\n",
      "Epoch: 270, Training loss: 1.392162, Validation loss: 1.3787, lr: 0.0000\n",
      "Epoch: 271, Training loss: 1.368385, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 272, Training loss: 1.390327, Validation loss: 1.3786, lr: 0.0000\n",
      "Epoch: 273, Training loss: 1.363671, Validation loss: 1.3753, lr: 0.0000\n",
      "Epoch: 274, Training loss: 1.370264, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 275, Training loss: 1.366556, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 276, Training loss: 1.383945, Validation loss: 1.3772, lr: 0.0000\n",
      "Epoch: 277, Training loss: 1.386533, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 278, Training loss: 1.376309, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 279, Training loss: 1.367629, Validation loss: 1.3873, lr: 0.0000\n",
      "Epoch: 280, Training loss: 1.396450, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 281, Training loss: 1.376406, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 282, Training loss: 1.373398, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 283, Training loss: 1.370530, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 284, Training loss: 1.368493, Validation loss: 1.3876, lr: 0.0000\n",
      "Epoch: 285, Training loss: 1.381015, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 286, Training loss: 1.442497, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 287, Training loss: 1.378785, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 288, Training loss: 1.397686, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 289, Training loss: 1.370768, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 290, Training loss: 1.373173, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 291, Training loss: 1.362715, Validation loss: 3.1408, lr: 0.0000\n",
      "Epoch: 292, Training loss: 1.366598, Validation loss: 1.3809, lr: 0.0000\n",
      "Epoch: 293, Training loss: 1.362253, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 294, Training loss: 1.447301, Validation loss: 1.3898, lr: 0.0000\n",
      "Epoch: 295, Training loss: 1.388911, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 296, Training loss: 1.395685, Validation loss: 1.3927, lr: 0.0000\n",
      "Epoch: 297, Training loss: 1.388033, Validation loss: 1.3701, lr: 0.0000\n",
      "Epoch: 298, Training loss: 1.357872, Validation loss: 1.3701, lr: 0.0000\n",
      "Epoch: 299, Training loss: 1.378441, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 300, Training loss: 1.443765, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 301, Training loss: 1.422243, Validation loss: 1.3731, lr: 0.0000\n",
      "Epoch: 302, Training loss: 1.352836, Validation loss: 1.3684, lr: 0.0000\n",
      "Epoch: 303, Training loss: 1.363026, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 304, Training loss: 1.360463, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 305, Training loss: 1.366111, Validation loss: 1.3879, lr: 0.0000\n",
      "Epoch: 306, Training loss: 1.366033, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 307, Training loss: 1.384979, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 308, Training loss: 1.418037, Validation loss: 1.3941, lr: 0.0000\n",
      "Epoch: 309, Training loss: 1.372590, Validation loss: 1.3751, lr: 0.0000\n",
      "Epoch: 310, Training loss: 1.361011, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 311, Training loss: 1.382028, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 312, Training loss: 1.381960, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 313, Training loss: 1.377686, Validation loss: 1.3475, lr: 0.0000\n",
      "Epoch: 314, Training loss: 1.390205, Validation loss: 1.3733, lr: 0.0000\n",
      "Epoch: 315, Training loss: 1.378476, Validation loss: 1.3669, lr: 0.0000\n",
      "Epoch: 316, Training loss: 1.384089, Validation loss: 1.3885, lr: 0.0000\n",
      "Epoch: 317, Training loss: 1.411553, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 318, Training loss: 1.355467, Validation loss: 1.3735, lr: 0.0000\n",
      "Epoch: 319, Training loss: 1.400888, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 320, Training loss: 1.377539, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 321, Training loss: 1.370290, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 322, Training loss: 1.368341, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 323, Training loss: 1.383264, Validation loss: 1.3716, lr: 0.0000\n",
      "Epoch: 324, Training loss: 1.380276, Validation loss: 1.3771, lr: 0.0000\n",
      "Epoch: 325, Training loss: 1.380084, Validation loss: 1.3788, lr: 0.0000\n",
      "Epoch: 326, Training loss: 1.363991, Validation loss: 1.3754, lr: 0.0000\n",
      "Epoch: 327, Training loss: 1.381094, Validation loss: 1.3900, lr: 0.0000\n",
      "Epoch: 328, Training loss: 1.392683, Validation loss: 1.3774, lr: 0.0000\n",
      "Epoch: 329, Training loss: 1.391472, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 330, Training loss: 1.369506, Validation loss: 1.3692, lr: 0.0000\n",
      "Epoch: 331, Training loss: 1.426702, Validation loss: 1.3875, lr: 0.0000\n",
      "Epoch: 332, Training loss: 1.367771, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 333, Training loss: 1.396701, Validation loss: 1.4180, lr: 0.0000\n",
      "Epoch: 334, Training loss: 1.379711, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 335, Training loss: 1.387339, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 336, Training loss: 1.391841, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 337, Training loss: 1.378188, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 338, Training loss: 1.371421, Validation loss: 1.3809, lr: 0.0000\n",
      "Epoch: 339, Training loss: 1.386325, Validation loss: 1.3771, lr: 0.0000\n",
      "Epoch: 340, Training loss: 1.368309, Validation loss: 1.3661, lr: 0.0000\n",
      "Epoch: 341, Training loss: 1.400252, Validation loss: 1.3773, lr: 0.0000\n",
      "Epoch: 342, Training loss: 1.373826, Validation loss: 1.3757, lr: 0.0000\n",
      "Epoch: 343, Training loss: 1.374207, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 344, Training loss: 1.362336, Validation loss: 1.3757, lr: 0.0000\n",
      "Epoch: 345, Training loss: 1.378264, Validation loss: 1.3749, lr: 0.0000\n",
      "Epoch: 346, Training loss: 1.379034, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 347, Training loss: 1.374489, Validation loss: 1.3742, lr: 0.0000\n",
      "Epoch: 348, Training loss: 1.364433, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 349, Training loss: 1.376824, Validation loss: 1.3798, lr: 0.0000\n",
      "Epoch: 350, Training loss: 1.412040, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 351, Training loss: 1.401043, Validation loss: 1.3722, lr: 0.0000\n",
      "Epoch: 352, Training loss: 1.372251, Validation loss: 1.3679, lr: 0.0000\n",
      "Epoch: 353, Training loss: 1.369276, Validation loss: 1.3803, lr: 0.0000\n",
      "Epoch: 354, Training loss: 1.381203, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 355, Training loss: 1.373218, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 356, Training loss: 1.384725, Validation loss: 1.3838, lr: 0.0000\n",
      " *och: 357, Training loss: 1.362837, Validation loss: 1.3422, lr: 0.0000\n",
      "Epoch: 358, Training loss: 1.368962, Validation loss: 1.3667, lr: 0.0000\n",
      "Epoch: 359, Training loss: 1.424418, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 360, Training loss: 1.398177, Validation loss: 1.3751, lr: 0.0000\n",
      "Epoch: 361, Training loss: 1.362115, Validation loss: 1.3730, lr: 0.0000\n",
      "Epoch: 362, Training loss: 1.389173, Validation loss: 1.3721, lr: 0.0000\n",
      "Epoch: 363, Training loss: 1.378321, Validation loss: 1.3714, lr: 0.0000\n",
      "Epoch: 364, Training loss: 1.359578, Validation loss: 1.3790, lr: 0.0000\n",
      "Epoch: 365, Training loss: 1.388387, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 366, Training loss: 1.403904, Validation loss: 1.3642, lr: 0.0000\n",
      "Epoch: 367, Training loss: 1.372498, Validation loss: 1.3732, lr: 0.0000\n",
      "Epoch: 368, Training loss: 1.360237, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 369, Training loss: 1.382566, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 370, Training loss: 1.366854, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 371, Training loss: 1.385307, Validation loss: 1.4062, lr: 0.0000\n",
      "Epoch: 372, Training loss: 1.371394, Validation loss: 1.3949, lr: 0.0000\n",
      "Epoch: 373, Training loss: 1.373761, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 374, Training loss: 1.405372, Validation loss: 1.3749, lr: 0.0000\n",
      "Epoch: 375, Training loss: 1.380851, Validation loss: 1.4101, lr: 0.0000\n",
      "Epoch: 376, Training loss: 1.366106, Validation loss: 1.4504, lr: 0.0000\n",
      "Epoch: 377, Training loss: 1.393977, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 378, Training loss: 1.381908, Validation loss: 1.3915, lr: 0.0000\n",
      "Epoch: 379, Training loss: 1.372312, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 380, Training loss: 1.388782, Validation loss: 1.3796, lr: 0.0000\n",
      "Epoch: 381, Training loss: 1.388928, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 382, Training loss: 1.413786, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 383, Training loss: 1.394583, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 384, Training loss: 1.359978, Validation loss: 1.3780, lr: 0.0000\n",
      "Epoch: 385, Training loss: 1.373475, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 386, Training loss: 1.367171, Validation loss: 1.3751, lr: 0.0000\n",
      "Epoch: 387, Training loss: 1.377174, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 388, Training loss: 1.386079, Validation loss: 1.3581, lr: 0.0000\n",
      "Epoch: 389, Training loss: 1.377088, Validation loss: 1.3896, lr: 0.0000\n",
      "Epoch: 390, Training loss: 1.378780, Validation loss: 1.3872, lr: 0.0000\n",
      "Epoch: 391, Training loss: 1.365296, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 392, Training loss: 1.370183, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 393, Training loss: 1.396270, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 394, Training loss: 1.393951, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 395, Training loss: 1.428824, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 396, Training loss: 1.366165, Validation loss: 1.3773, lr: 0.0000\n",
      "Epoch: 397, Training loss: 1.349278, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 398, Training loss: 1.365696, Validation loss: 1.4218, lr: 0.0000\n",
      "Epoch: 399, Training loss: 1.372927, Validation loss: 1.3758, lr: 0.0000\n",
      "Epoch: 400, Training loss: 1.376149, Validation loss: 1.4097, lr: 0.0000\n",
      "Epoch: 401, Training loss: 1.380152, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 402, Training loss: 1.372868, Validation loss: 1.3876, lr: 0.0000\n",
      "Epoch: 403, Training loss: 1.385402, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 404, Training loss: 1.380121, Validation loss: 1.3730, lr: 0.0000\n",
      "Epoch: 405, Training loss: 1.399978, Validation loss: 1.3772, lr: 0.0000\n",
      "Epoch: 406, Training loss: 1.367835, Validation loss: 1.3595, lr: 0.0000\n",
      "Epoch: 407, Training loss: 1.376331, Validation loss: 1.3787, lr: 0.0000\n",
      "Epoch: 408, Training loss: 1.394709, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 409, Training loss: 1.374666, Validation loss: 1.3960, lr: 0.0000\n",
      "Epoch: 410, Training loss: 1.377352, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 411, Training loss: 1.372852, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 412, Training loss: 1.375628, Validation loss: 1.3809, lr: 0.0000\n",
      "Epoch: 413, Training loss: 1.417649, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 414, Training loss: 1.388369, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 415, Training loss: 1.379713, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 416, Training loss: 1.366079, Validation loss: 1.3703, lr: 0.0000\n",
      "Epoch: 417, Training loss: 1.373276, Validation loss: 1.3743, lr: 0.0000\n",
      "Epoch: 418, Training loss: 1.372993, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 419, Training loss: 1.360819, Validation loss: 1.3669, lr: 0.0000\n",
      "Epoch: 420, Training loss: 1.365735, Validation loss: 1.3657, lr: 0.0000\n",
      "Epoch: 421, Training loss: 1.370745, Validation loss: 1.3577, lr: 0.0000\n",
      "Epoch: 422, Training loss: 1.378405, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 423, Training loss: 1.388678, Validation loss: 1.3764, lr: 0.0000\n",
      "Epoch: 424, Training loss: 1.407834, Validation loss: 1.3913, lr: 0.0000\n",
      "Epoch: 425, Training loss: 1.381086, Validation loss: 1.3610, lr: 0.0000\n",
      "Epoch: 426, Training loss: 1.361043, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 427, Training loss: 1.388885, Validation loss: 1.3953, lr: 0.0000\n",
      "Epoch: 428, Training loss: 1.417698, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 429, Training loss: 1.407018, Validation loss: 1.3803, lr: 0.0000\n",
      "Epoch: 430, Training loss: 1.362393, Validation loss: 1.3791, lr: 0.0000\n",
      "Epoch: 431, Training loss: 1.379687, Validation loss: 1.3899, lr: 0.0000\n",
      "Epoch: 432, Training loss: 1.373392, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 433, Training loss: 1.368890, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 434, Training loss: 1.377420, Validation loss: 1.3775, lr: 0.0000\n",
      "Epoch: 435, Training loss: 1.383834, Validation loss: 1.3771, lr: 0.0000\n",
      "Epoch: 436, Training loss: 1.346898, Validation loss: 1.3795, lr: 0.0000\n",
      "Epoch: 437, Training loss: 1.393222, Validation loss: 1.3873, lr: 0.0000\n",
      "Epoch: 438, Training loss: 1.357625, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 439, Training loss: 1.375311, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 440, Training loss: 1.492054, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 441, Training loss: 1.371362, Validation loss: 1.3786, lr: 0.0000\n",
      "Epoch: 442, Training loss: 1.358780, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 443, Training loss: 1.389440, Validation loss: 1.3779, lr: 0.0000\n",
      "Epoch: 444, Training loss: 1.392086, Validation loss: 1.3677, lr: 0.0000\n",
      "Epoch: 445, Training loss: 1.371351, Validation loss: 1.3768, lr: 0.0000\n",
      "Epoch: 446, Training loss: 1.371754, Validation loss: 1.3961, lr: 0.0000\n",
      "Epoch: 447, Training loss: 1.408623, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 448, Training loss: 1.379572, Validation loss: 1.3742, lr: 0.0000\n",
      "Epoch: 449, Training loss: 1.357768, Validation loss: 1.3705, lr: 0.0000\n",
      "Epoch: 450, Training loss: 1.362008, Validation loss: 1.3890, lr: 0.0000\n",
      "Epoch: 451, Training loss: 1.415574, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 452, Training loss: 1.364676, Validation loss: 1.3649, lr: 0.0000\n",
      "Epoch: 453, Training loss: 1.366288, Validation loss: 1.3796, lr: 0.0000\n",
      "Epoch: 454, Training loss: 1.367474, Validation loss: 1.3871, lr: 0.0000\n",
      "Epoch: 455, Training loss: 1.395913, Validation loss: 1.3673, lr: 0.0000\n",
      "Epoch: 456, Training loss: 1.374540, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 457, Training loss: 1.376996, Validation loss: 1.3712, lr: 0.0000\n",
      "Epoch: 458, Training loss: 1.411333, Validation loss: 1.3873, lr: 0.0000\n",
      "Epoch: 459, Training loss: 1.360715, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 460, Training loss: 1.366774, Validation loss: 1.3876, lr: 0.0000\n",
      " *och: 461, Training loss: 1.379782, Validation loss: 1.3398, lr: 0.0000\n",
      "Epoch: 462, Training loss: 1.418154, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 463, Training loss: 1.377581, Validation loss: 1.3782, lr: 0.0000\n",
      "Epoch: 464, Training loss: 1.376941, Validation loss: 1.3571, lr: 0.0000\n",
      "Epoch: 465, Training loss: 1.378302, Validation loss: 1.3690, lr: 0.0000\n",
      "Epoch: 466, Training loss: 1.379797, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 467, Training loss: 1.374889, Validation loss: 1.3881, lr: 0.0000\n",
      "Epoch: 468, Training loss: 1.422257, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 469, Training loss: 1.365768, Validation loss: 1.3879, lr: 0.0000\n",
      "Epoch: 470, Training loss: 1.366985, Validation loss: 1.4085, lr: 0.0000\n",
      "Epoch: 471, Training loss: 1.386049, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 472, Training loss: 1.396044, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 473, Training loss: 1.373183, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 474, Training loss: 1.363437, Validation loss: 1.3899, lr: 0.0000\n",
      "Epoch: 475, Training loss: 1.371334, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 476, Training loss: 1.390692, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 477, Training loss: 1.357279, Validation loss: 1.3757, lr: 0.0000\n",
      "Epoch: 478, Training loss: 1.372296, Validation loss: 1.3877, lr: 0.0000\n",
      "Epoch: 479, Training loss: 1.394126, Validation loss: 1.3893, lr: 0.0000\n",
      "Epoch: 480, Training loss: 1.414451, Validation loss: 1.3945, lr: 0.0000\n",
      "Epoch: 481, Training loss: 1.369206, Validation loss: 1.3740, lr: 0.0000\n",
      "Epoch: 482, Training loss: 1.359869, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 483, Training loss: 1.372428, Validation loss: 1.3775, lr: 0.0000\n",
      "Epoch: 484, Training loss: 1.384890, Validation loss: 1.3879, lr: 0.0000\n",
      "Epoch: 485, Training loss: 1.395739, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 486, Training loss: 1.393120, Validation loss: 1.3873, lr: 0.0000\n",
      "Epoch: 487, Training loss: 1.374414, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 488, Training loss: 1.404651, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 489, Training loss: 1.379514, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 490, Training loss: 1.384487, Validation loss: 1.3745, lr: 0.0000\n",
      "Epoch: 491, Training loss: 1.420154, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 492, Training loss: 1.417502, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 493, Training loss: 1.367800, Validation loss: 1.3894, lr: 0.0000\n",
      "Epoch: 494, Training loss: 1.381805, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 495, Training loss: 1.382024, Validation loss: 1.3757, lr: 0.0000\n",
      "Epoch: 496, Training loss: 1.373989, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 497, Training loss: 1.437646, Validation loss: 1.3736, lr: 0.0000\n",
      "Epoch: 498, Training loss: 1.365820, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 499, Training loss: 1.369363, Validation loss: 1.3671, lr: 0.0000\n",
      "Epoch: 500, Training loss: 1.379431, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 501, Training loss: 1.377025, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 502, Training loss: 1.361121, Validation loss: 1.3724, lr: 0.0000\n",
      " *och: 503, Training loss: 1.372873, Validation loss: 1.3302, lr: 0.0000\n",
      "Epoch: 504, Training loss: 1.377452, Validation loss: 1.3712, lr: 0.0000\n",
      "Epoch: 505, Training loss: 1.376322, Validation loss: 1.3780, lr: 0.0000\n",
      "Epoch: 506, Training loss: 1.398233, Validation loss: 1.3708, lr: 0.0000\n",
      "Epoch: 507, Training loss: 1.378918, Validation loss: 1.3752, lr: 0.0000\n",
      "Epoch: 508, Training loss: 1.381008, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 509, Training loss: 1.375039, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 510, Training loss: 1.376829, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 511, Training loss: 1.381877, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 512, Training loss: 1.391850, Validation loss: 1.3576, lr: 0.0000\n",
      "Epoch: 513, Training loss: 1.371874, Validation loss: 1.3614, lr: 0.0000\n",
      "Epoch: 514, Training loss: 1.363015, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 515, Training loss: 1.366849, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 516, Training loss: 1.380955, Validation loss: 1.3690, lr: 0.0000\n",
      "Epoch: 517, Training loss: 1.363339, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 518, Training loss: 1.370010, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 519, Training loss: 1.377547, Validation loss: 1.3758, lr: 0.0000\n",
      "Epoch: 520, Training loss: 1.386266, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 521, Training loss: 1.357600, Validation loss: 1.3901, lr: 0.0000\n",
      "Epoch: 522, Training loss: 1.376419, Validation loss: 1.3803, lr: 0.0000\n",
      "Epoch: 523, Training loss: 1.370233, Validation loss: 1.3706, lr: 0.0000\n",
      "Epoch: 524, Training loss: 1.364014, Validation loss: 1.3799, lr: 0.0000\n",
      "Epoch: 525, Training loss: 1.382846, Validation loss: 1.3735, lr: 0.0000\n",
      "Epoch: 526, Training loss: 1.371446, Validation loss: 1.3748, lr: 0.0000\n",
      "Epoch: 527, Training loss: 1.358554, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 528, Training loss: 1.378711, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 529, Training loss: 1.376814, Validation loss: 1.3598, lr: 0.0000\n",
      "Epoch: 530, Training loss: 1.385666, Validation loss: 1.3800, lr: 0.0000\n",
      "Epoch: 531, Training loss: 1.388406, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 532, Training loss: 1.407482, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 533, Training loss: 1.385407, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 534, Training loss: 1.382597, Validation loss: 1.3985, lr: 0.0000\n",
      "Epoch: 535, Training loss: 1.359525, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 536, Training loss: 1.368019, Validation loss: 1.3712, lr: 0.0000\n",
      "Epoch: 537, Training loss: 1.385238, Validation loss: 1.3790, lr: 0.0000\n",
      "Epoch: 538, Training loss: 1.378819, Validation loss: 1.3922, lr: 0.0000\n",
      "Epoch: 539, Training loss: 1.362678, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 540, Training loss: 1.384190, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 541, Training loss: 1.366182, Validation loss: 1.3762, lr: 0.0000\n",
      "Epoch: 542, Training loss: 1.396789, Validation loss: 1.3913, lr: 0.0000\n",
      "Epoch: 543, Training loss: 1.375070, Validation loss: 1.4703, lr: 0.0000\n",
      "Epoch: 544, Training loss: 1.378024, Validation loss: 1.3758, lr: 0.0000\n",
      "Epoch: 545, Training loss: 1.373010, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 546, Training loss: 1.384963, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 547, Training loss: 1.375075, Validation loss: 1.3757, lr: 0.0000\n",
      "Epoch: 548, Training loss: 1.380625, Validation loss: 1.3884, lr: 0.0000\n",
      "Epoch: 549, Training loss: 1.363807, Validation loss: 1.3775, lr: 0.0000\n",
      "Epoch: 550, Training loss: 1.363694, Validation loss: 1.3925, lr: 0.0000\n",
      "Epoch: 551, Training loss: 1.375643, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 552, Training loss: 1.370792, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 553, Training loss: 1.401842, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 554, Training loss: 1.382336, Validation loss: 1.3627, lr: 0.0000\n",
      "Epoch: 555, Training loss: 1.363154, Validation loss: 1.5467, lr: 0.0000\n",
      "Epoch: 556, Training loss: 1.402434, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 557, Training loss: 1.358937, Validation loss: 1.3782, lr: 0.0000\n",
      "Epoch: 558, Training loss: 1.419008, Validation loss: 1.3768, lr: 0.0000\n",
      "Epoch: 559, Training loss: 1.381871, Validation loss: 1.3735, lr: 0.0000\n",
      "Epoch: 560, Training loss: 1.361441, Validation loss: 1.3797, lr: 0.0000\n",
      "Epoch: 561, Training loss: 1.393285, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 562, Training loss: 1.387725, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 563, Training loss: 1.387630, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 564, Training loss: 1.382176, Validation loss: 1.3683, lr: 0.0000\n",
      "Epoch: 565, Training loss: 1.379293, Validation loss: 1.3726, lr: 0.0000\n",
      "Epoch: 566, Training loss: 1.428206, Validation loss: 1.3797, lr: 0.0000\n",
      "Epoch: 567, Training loss: 1.376648, Validation loss: 1.4257, lr: 0.0000\n",
      "Epoch: 568, Training loss: 1.393881, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 569, Training loss: 1.374579, Validation loss: 1.3789, lr: 0.0000\n",
      "Epoch: 570, Training loss: 1.391817, Validation loss: 1.3802, lr: 0.0000\n",
      "Epoch: 571, Training loss: 1.381067, Validation loss: 1.3583, lr: 0.0000\n",
      "Epoch: 572, Training loss: 1.371359, Validation loss: 1.3761, lr: 0.0000\n",
      "Epoch: 573, Training loss: 1.378177, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 574, Training loss: 1.376723, Validation loss: 1.6074, lr: 0.0000\n",
      "Epoch: 575, Training loss: 1.366514, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 576, Training loss: 1.378401, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 577, Training loss: 1.376078, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 578, Training loss: 1.357374, Validation loss: 1.3756, lr: 0.0000\n",
      "Epoch: 579, Training loss: 1.383808, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 580, Training loss: 1.377631, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 581, Training loss: 1.365670, Validation loss: 1.3777, lr: 0.0000\n",
      "Epoch: 582, Training loss: 1.370385, Validation loss: 1.4204, lr: 0.0000\n",
      "Epoch: 583, Training loss: 1.384350, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 584, Training loss: 1.381788, Validation loss: 1.3689, lr: 0.0000\n",
      "Epoch: 585, Training loss: 1.394654, Validation loss: 1.3732, lr: 0.0000\n",
      "Epoch: 586, Training loss: 1.368965, Validation loss: 1.3925, lr: 0.0000\n",
      "Epoch: 587, Training loss: 1.407063, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 588, Training loss: 1.368804, Validation loss: 1.3880, lr: 0.0000\n",
      "Epoch: 589, Training loss: 1.399701, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 590, Training loss: 1.363987, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 591, Training loss: 1.377437, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 592, Training loss: 1.377385, Validation loss: 1.3764, lr: 0.0000\n",
      "Epoch: 593, Training loss: 1.372879, Validation loss: 1.3458, lr: 0.0000\n",
      "Epoch: 594, Training loss: 1.382317, Validation loss: 1.3700, lr: 0.0000\n",
      "Epoch: 595, Training loss: 1.363209, Validation loss: 1.3797, lr: 0.0000\n",
      "Epoch: 596, Training loss: 1.391690, Validation loss: 1.3658, lr: 0.0000\n",
      "Epoch: 597, Training loss: 1.356329, Validation loss: 1.3717, lr: 0.0000\n",
      "Epoch: 598, Training loss: 1.384894, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 599, Training loss: 1.367456, Validation loss: 1.3483, lr: 0.0000\n",
      "Epoch: 600, Training loss: 1.373687, Validation loss: 1.3796, lr: 0.0000\n",
      "Epoch: 601, Training loss: 1.378397, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 602, Training loss: 1.369008, Validation loss: 1.3708, lr: 0.0000\n",
      "Epoch: 603, Training loss: 1.393857, Validation loss: 1.3777, lr: 0.0000\n",
      "Epoch: 604, Training loss: 1.394692, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 605, Training loss: 1.404138, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 606, Training loss: 1.361504, Validation loss: 1.3497, lr: 0.0000\n",
      "Epoch: 607, Training loss: 1.368161, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 608, Training loss: 1.357472, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 609, Training loss: 1.391014, Validation loss: 1.3787, lr: 0.0000\n",
      "Epoch: 610, Training loss: 1.385882, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 611, Training loss: 1.370302, Validation loss: 1.3917, lr: 0.0000\n",
      "Epoch: 612, Training loss: 1.375587, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 613, Training loss: 1.358424, Validation loss: 1.3759, lr: 0.0000\n",
      "Epoch: 614, Training loss: 1.371243, Validation loss: 1.3734, lr: 0.0000\n",
      "Epoch: 615, Training loss: 1.371759, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 616, Training loss: 1.375370, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 617, Training loss: 1.369229, Validation loss: 1.3796, lr: 0.0000\n",
      "Epoch: 618, Training loss: 1.380514, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 619, Training loss: 1.393425, Validation loss: 1.3910, lr: 0.0000\n",
      "Epoch: 620, Training loss: 1.434859, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 621, Training loss: 1.400404, Validation loss: 1.3784, lr: 0.0000\n",
      "Epoch: 622, Training loss: 1.376095, Validation loss: 1.3777, lr: 0.0000\n",
      "Epoch: 623, Training loss: 1.382097, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 624, Training loss: 1.367401, Validation loss: 1.3724, lr: 0.0000\n",
      "Epoch: 625, Training loss: 1.378797, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 626, Training loss: 1.376044, Validation loss: 1.3705, lr: 0.0000\n",
      "Epoch: 627, Training loss: 1.380430, Validation loss: 1.3758, lr: 0.0000\n",
      "Epoch: 628, Training loss: 1.370029, Validation loss: 1.3777, lr: 0.0000\n",
      "Epoch: 629, Training loss: 1.384618, Validation loss: 1.3778, lr: 0.0000\n",
      "Epoch: 630, Training loss: 1.391623, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 631, Training loss: 1.391177, Validation loss: 1.3803, lr: 0.0000\n",
      "Epoch: 633, Training loss: 1.393238, Validation loss: 1.3646, lr: 0.0000\n",
      "Epoch: 634, Training loss: 1.373551, Validation loss: 1.3700, lr: 0.0000\n",
      "Epoch: 635, Training loss: 1.376819, Validation loss: 1.4542, lr: 0.0000\n",
      "Epoch: 636, Training loss: 1.372998, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 637, Training loss: 1.352476, Validation loss: 1.3687, lr: 0.0000\n",
      "Epoch: 638, Training loss: 1.364834, Validation loss: 1.3734, lr: 0.0000\n",
      "Epoch: 639, Training loss: 1.374223, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 640, Training loss: 1.368817, Validation loss: 1.3924, lr: 0.0000\n",
      "Epoch: 641, Training loss: 1.377948, Validation loss: 1.3788, lr: 0.0000\n",
      "Epoch: 642, Training loss: 1.390327, Validation loss: 1.3386, lr: 0.0000\n",
      "Epoch: 643, Training loss: 1.389960, Validation loss: 1.3717, lr: 0.0000\n",
      "Epoch: 644, Training loss: 1.368653, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 645, Training loss: 1.408099, Validation loss: 1.3701, lr: 0.0000\n",
      "Epoch: 646, Training loss: 1.367459, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 647, Training loss: 1.388980, Validation loss: 1.3877, lr: 0.0000\n",
      "Epoch: 648, Training loss: 1.411580, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 649, Training loss: 1.357862, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 650, Training loss: 1.374961, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 651, Training loss: 1.369364, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 652, Training loss: 1.375619, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 653, Training loss: 1.359838, Validation loss: 1.3767, lr: 0.0000\n",
      "Epoch: 654, Training loss: 1.388256, Validation loss: 1.3793, lr: 0.0000\n",
      "Epoch: 655, Training loss: 1.348355, Validation loss: 1.3494, lr: 0.0000\n",
      "Epoch: 656, Training loss: 1.389104, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 657, Training loss: 1.363266, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 658, Training loss: 1.373071, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 659, Training loss: 1.404609, Validation loss: 1.3773, lr: 0.0000\n",
      "Epoch: 660, Training loss: 1.380243, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 661, Training loss: 1.382062, Validation loss: 1.3715, lr: 0.0000\n",
      "Epoch: 662, Training loss: 1.383619, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 663, Training loss: 1.385379, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 664, Training loss: 1.375956, Validation loss: 1.3605, lr: 0.0000\n",
      "Epoch: 665, Training loss: 1.375227, Validation loss: 1.3560, lr: 0.0000\n",
      "Epoch: 666, Training loss: 1.361636, Validation loss: 1.3897, lr: 0.0000\n",
      "Epoch: 667, Training loss: 1.353800, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 668, Training loss: 1.382636, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 669, Training loss: 1.362633, Validation loss: 1.3712, lr: 0.0000\n",
      "Epoch: 670, Training loss: 1.380879, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 671, Training loss: 1.370635, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 672, Training loss: 1.374740, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 673, Training loss: 1.386465, Validation loss: 1.3757, lr: 0.0000\n",
      "Epoch: 674, Training loss: 1.399105, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 675, Training loss: 1.380013, Validation loss: 1.3757, lr: 0.0000\n",
      "Epoch: 676, Training loss: 1.388140, Validation loss: 1.3933, lr: 0.0000\n",
      "Epoch: 677, Training loss: 1.411584, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 678, Training loss: 1.369393, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 679, Training loss: 1.357368, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 680, Training loss: 1.360437, Validation loss: 1.3789, lr: 0.0000\n",
      "Epoch: 681, Training loss: 1.371532, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 682, Training loss: 1.373793, Validation loss: 1.3727, lr: 0.0000\n",
      "Epoch: 683, Training loss: 1.407663, Validation loss: 1.3782, lr: 0.0000\n",
      "Epoch: 684, Training loss: 1.371111, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 685, Training loss: 1.373831, Validation loss: 1.3715, lr: 0.0000\n",
      "Epoch: 686, Training loss: 1.368153, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 687, Training loss: 1.357247, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 688, Training loss: 1.370072, Validation loss: 1.3881, lr: 0.0000\n",
      "Epoch: 689, Training loss: 1.395686, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 690, Training loss: 1.370608, Validation loss: 1.3722, lr: 0.0000\n",
      "Epoch: 691, Training loss: 1.357427, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 692, Training loss: 1.411222, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 693, Training loss: 1.371552, Validation loss: 1.3877, lr: 0.0000\n",
      "Epoch: 694, Training loss: 1.356121, Validation loss: 1.3800, lr: 0.0000\n",
      "Epoch: 695, Training loss: 1.373065, Validation loss: 1.3798, lr: 0.0000\n",
      "Epoch: 696, Training loss: 1.421475, Validation loss: 1.3737, lr: 0.0000\n",
      "Epoch: 697, Training loss: 1.349661, Validation loss: 1.3522, lr: 0.0000\n",
      "Epoch: 698, Training loss: 1.387575, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 699, Training loss: 1.369819, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 700, Training loss: 1.361928, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 701, Training loss: 1.396857, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 702, Training loss: 1.418663, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 703, Training loss: 1.369416, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 704, Training loss: 1.388657, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 705, Training loss: 1.374585, Validation loss: 1.3741, lr: 0.0000\n",
      "Epoch: 706, Training loss: 1.379203, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 707, Training loss: 1.389081, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 708, Training loss: 1.433042, Validation loss: 1.3722, lr: 0.0000\n",
      "Epoch: 709, Training loss: 1.372223, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 710, Training loss: 1.346124, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 711, Training loss: 1.363830, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 712, Training loss: 1.362648, Validation loss: 1.3756, lr: 0.0000\n",
      "Epoch: 713, Training loss: 1.372334, Validation loss: 1.3770, lr: 0.0000\n",
      "Epoch: 714, Training loss: 1.373926, Validation loss: 1.3897, lr: 0.0000\n",
      "Epoch: 715, Training loss: 1.387828, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 716, Training loss: 1.368454, Validation loss: 1.3732, lr: 0.0000\n",
      "Epoch: 717, Training loss: 1.379840, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 718, Training loss: 1.370646, Validation loss: 1.3503, lr: 0.0000\n",
      "Epoch: 719, Training loss: 1.403889, Validation loss: 1.3705, lr: 0.0000\n",
      "Epoch: 720, Training loss: 1.385850, Validation loss: 1.3608, lr: 0.0000\n",
      "Epoch: 721, Training loss: 1.367780, Validation loss: 1.3727, lr: 0.0000\n",
      "Epoch: 722, Training loss: 1.398966, Validation loss: 1.3755, lr: 0.0000\n",
      "Epoch: 723, Training loss: 1.379759, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 724, Training loss: 1.355549, Validation loss: 1.3800, lr: 0.0000\n",
      "Epoch: 725, Training loss: 1.378266, Validation loss: 1.3712, lr: 0.0000\n",
      "Epoch: 726, Training loss: 1.379955, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 727, Training loss: 1.390346, Validation loss: 1.3795, lr: 0.0000\n",
      "Epoch: 728, Training loss: 1.369994, Validation loss: 1.3746, lr: 0.0000\n",
      "Epoch: 729, Training loss: 1.391400, Validation loss: 1.3684, lr: 0.0000\n",
      "Epoch: 730, Training loss: 1.428483, Validation loss: 1.6058, lr: 0.0000\n",
      "Epoch: 731, Training loss: 1.368892, Validation loss: 1.3896, lr: 0.0000\n",
      "Epoch: 732, Training loss: 1.383748, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 733, Training loss: 1.379290, Validation loss: 1.3737, lr: 0.0000\n",
      "Epoch: 734, Training loss: 1.379687, Validation loss: 1.3716, lr: 0.0000\n",
      " *och: 735, Training loss: 1.368142, Validation loss: 1.3269, lr: 0.0000\n",
      "Epoch: 736, Training loss: 1.382113, Validation loss: 1.3905, lr: 0.0000\n",
      "Epoch: 737, Training loss: 1.382962, Validation loss: 1.3598, lr: 0.0000\n",
      "Epoch: 738, Training loss: 1.356308, Validation loss: 1.3874, lr: 0.0000\n",
      "Epoch: 739, Training loss: 1.382236, Validation loss: 1.4104, lr: 0.0000\n",
      "Epoch: 740, Training loss: 1.393937, Validation loss: 1.3782, lr: 0.0000\n",
      "Epoch: 741, Training loss: 1.366233, Validation loss: 1.3619, lr: 0.0000\n",
      "Epoch: 742, Training loss: 1.377284, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 743, Training loss: 1.375401, Validation loss: 1.3878, lr: 0.0000\n",
      "Epoch: 744, Training loss: 1.364885, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 745, Training loss: 1.374909, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 746, Training loss: 1.367898, Validation loss: 1.3657, lr: 0.0000\n",
      "Epoch: 747, Training loss: 1.376839, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 748, Training loss: 1.372596, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 749, Training loss: 1.378802, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 750, Training loss: 1.431632, Validation loss: 1.3776, lr: 0.0000\n",
      "Epoch: 751, Training loss: 1.373638, Validation loss: 1.3797, lr: 0.0000\n",
      "Epoch: 752, Training loss: 1.392827, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 753, Training loss: 1.369466, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 754, Training loss: 1.357977, Validation loss: 1.3758, lr: 0.0000\n",
      "Epoch: 755, Training loss: 1.360823, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 756, Training loss: 1.401921, Validation loss: 1.3628, lr: 0.0000\n",
      "Epoch: 757, Training loss: 1.368862, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 758, Training loss: 1.379052, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 759, Training loss: 1.377209, Validation loss: 1.3800, lr: 0.0000\n",
      "Epoch: 760, Training loss: 1.373220, Validation loss: 1.3784, lr: 0.0000\n",
      "Epoch: 761, Training loss: 1.349660, Validation loss: 1.4265, lr: 0.0000\n",
      "Epoch: 762, Training loss: 1.360283, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 763, Training loss: 1.351249, Validation loss: 1.3776, lr: 0.0000\n",
      "Epoch: 764, Training loss: 1.407110, Validation loss: 1.3774, lr: 0.0000\n",
      "Epoch: 765, Training loss: 1.365355, Validation loss: 1.3962, lr: 0.0000\n",
      "Epoch: 766, Training loss: 1.358924, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 767, Training loss: 1.391349, Validation loss: 1.3798, lr: 0.0000\n",
      "Epoch: 768, Training loss: 1.385105, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 769, Training loss: 1.368124, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 770, Training loss: 1.361483, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 771, Training loss: 1.361259, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 772, Training loss: 1.392636, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 773, Training loss: 1.377909, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 774, Training loss: 1.411607, Validation loss: 1.3766, lr: 0.0000\n",
      "Epoch: 775, Training loss: 1.380331, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 776, Training loss: 1.442239, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 777, Training loss: 1.374985, Validation loss: 1.3905, lr: 0.0000\n",
      "Epoch: 778, Training loss: 1.377519, Validation loss: 1.3748, lr: 0.0000\n",
      "Epoch: 779, Training loss: 1.350452, Validation loss: 1.3879, lr: 0.0000\n",
      "Epoch: 780, Training loss: 1.375967, Validation loss: 1.3754, lr: 0.0000\n",
      "Epoch: 781, Training loss: 1.365549, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 782, Training loss: 1.352620, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 783, Training loss: 1.355760, Validation loss: 1.3762, lr: 0.0000\n",
      "Epoch: 784, Training loss: 1.383991, Validation loss: 1.3893, lr: 0.0000\n",
      "Epoch: 785, Training loss: 1.394655, Validation loss: 1.3672, lr: 0.0000\n",
      "Epoch: 786, Training loss: 1.401138, Validation loss: 1.3783, lr: 0.0000\n",
      "Epoch: 787, Training loss: 1.454089, Validation loss: 1.3809, lr: 0.0000\n",
      "Epoch: 788, Training loss: 1.365225, Validation loss: 1.3982, lr: 0.0000\n",
      "Epoch: 789, Training loss: 1.390321, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 790, Training loss: 1.388642, Validation loss: 1.3640, lr: 0.0000\n",
      "Epoch: 791, Training loss: 1.380891, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 792, Training loss: 1.421074, Validation loss: 1.3654, lr: 0.0000\n",
      "Epoch: 793, Training loss: 1.386076, Validation loss: 1.3880, lr: 0.0000\n",
      "Epoch: 794, Training loss: 1.414576, Validation loss: 1.3714, lr: 0.0000\n",
      "Epoch: 795, Training loss: 1.401893, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 796, Training loss: 1.374992, Validation loss: 1.3795, lr: 0.0000\n",
      "Epoch: 797, Training loss: 1.426048, Validation loss: 1.3679, lr: 0.0000\n",
      "Epoch: 798, Training loss: 1.376861, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 799, Training loss: 1.374445, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 800, Training loss: 1.375165, Validation loss: 1.3779, lr: 0.0000\n",
      "Epoch: 801, Training loss: 1.368813, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 802, Training loss: 1.415340, Validation loss: 1.3584, lr: 0.0000\n",
      "Epoch: 803, Training loss: 1.365639, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 804, Training loss: 1.372853, Validation loss: 1.5112, lr: 0.0000\n",
      "Epoch: 805, Training loss: 1.386979, Validation loss: 1.4038, lr: 0.0000\n",
      "Epoch: 806, Training loss: 1.381628, Validation loss: 1.3685, lr: 0.0000\n",
      "Epoch: 807, Training loss: 1.397887, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 808, Training loss: 1.374695, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 809, Training loss: 1.365534, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 810, Training loss: 1.382573, Validation loss: 1.3785, lr: 0.0000\n",
      "Epoch: 811, Training loss: 1.378924, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 812, Training loss: 1.377129, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 813, Training loss: 1.374163, Validation loss: 1.3594, lr: 0.0000\n",
      "Epoch: 814, Training loss: 1.372779, Validation loss: 1.3799, lr: 0.0000\n",
      "Epoch: 815, Training loss: 1.355317, Validation loss: 1.3753, lr: 0.0000\n",
      "Epoch: 816, Training loss: 1.377545, Validation loss: 1.3771, lr: 0.0000\n",
      "Epoch: 817, Training loss: 1.362332, Validation loss: 1.3570, lr: 0.0000\n",
      "Epoch: 818, Training loss: 1.363232, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 819, Training loss: 1.364921, Validation loss: 1.3990, lr: 0.0000\n",
      "Epoch: 820, Training loss: 1.376680, Validation loss: 1.3965, lr: 0.0000\n",
      "Epoch: 821, Training loss: 1.386273, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 822, Training loss: 1.388213, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 823, Training loss: 1.359013, Validation loss: 1.3593, lr: 0.0000\n",
      "Epoch: 824, Training loss: 1.393030, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 825, Training loss: 1.366029, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 826, Training loss: 1.379686, Validation loss: 1.3736, lr: 0.0000\n",
      "Epoch: 827, Training loss: 1.385553, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 828, Training loss: 1.375910, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 829, Training loss: 1.371186, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 830, Training loss: 1.368464, Validation loss: 1.3773, lr: 0.0000\n",
      "Epoch: 831, Training loss: 1.372868, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 832, Training loss: 1.375520, Validation loss: 1.3785, lr: 0.0000\n",
      "Epoch: 833, Training loss: 1.379477, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 834, Training loss: 1.373620, Validation loss: 1.3656, lr: 0.0000\n",
      "Epoch: 835, Training loss: 1.380421, Validation loss: 1.3757, lr: 0.0000\n",
      "Epoch: 836, Training loss: 1.393197, Validation loss: 1.3758, lr: 0.0000\n",
      "Epoch: 837, Training loss: 1.395543, Validation loss: 1.4222, lr: 0.0000\n",
      "Epoch: 838, Training loss: 1.384551, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 839, Training loss: 1.379258, Validation loss: 1.3730, lr: 0.0000\n",
      "Epoch: 840, Training loss: 1.383492, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 841, Training loss: 1.368402, Validation loss: 1.3910, lr: 0.0000\n",
      "Epoch: 842, Training loss: 1.361189, Validation loss: 1.3777, lr: 0.0000\n",
      "Epoch: 843, Training loss: 1.425563, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 844, Training loss: 1.365396, Validation loss: 1.3537, lr: 0.0000\n",
      "Epoch: 845, Training loss: 1.362613, Validation loss: 1.3907, lr: 0.0000\n",
      "Epoch: 846, Training loss: 1.389532, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 847, Training loss: 1.353793, Validation loss: 1.3752, lr: 0.0000\n",
      "Epoch: 848, Training loss: 1.362788, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 849, Training loss: 1.379137, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 850, Training loss: 1.387374, Validation loss: 1.4497, lr: 0.0000\n",
      "Epoch: 851, Training loss: 1.390422, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 852, Training loss: 1.377152, Validation loss: 1.3883, lr: 0.0000\n",
      "Epoch: 853, Training loss: 1.368744, Validation loss: 1.3797, lr: 0.0000\n",
      "Epoch: 854, Training loss: 1.378535, Validation loss: 1.3879, lr: 0.0000\n",
      "Epoch: 855, Training loss: 1.375656, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 856, Training loss: 1.384057, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 857, Training loss: 1.416006, Validation loss: 1.3798, lr: 0.0000\n",
      "Epoch: 858, Training loss: 1.367864, Validation loss: 1.3883, lr: 0.0000\n",
      "Epoch: 859, Training loss: 1.359145, Validation loss: 1.3740, lr: 0.0000\n",
      "Epoch: 860, Training loss: 1.375187, Validation loss: 1.3646, lr: 0.0000\n",
      "Epoch: 861, Training loss: 1.400406, Validation loss: 1.3798, lr: 0.0000\n",
      "Epoch: 862, Training loss: 1.379703, Validation loss: 1.3758, lr: 0.0000\n",
      "Epoch: 863, Training loss: 1.363691, Validation loss: 1.3650, lr: 0.0000\n",
      "Epoch: 864, Training loss: 1.388876, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 865, Training loss: 1.381324, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 866, Training loss: 1.373921, Validation loss: 1.3293, lr: 0.0000\n",
      "Epoch: 867, Training loss: 1.390901, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 868, Training loss: 1.398247, Validation loss: 1.3749, lr: 0.0000\n",
      "Epoch: 869, Training loss: 1.368042, Validation loss: 1.3755, lr: 0.0000\n",
      "Epoch: 870, Training loss: 1.357421, Validation loss: 1.3785, lr: 0.0000\n",
      "Epoch: 871, Training loss: 1.364017, Validation loss: 1.3781, lr: 0.0000\n",
      "Epoch: 872, Training loss: 1.412796, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 873, Training loss: 1.395856, Validation loss: 1.3887, lr: 0.0000\n",
      "Epoch: 874, Training loss: 1.365955, Validation loss: 1.3800, lr: 0.0000\n",
      "Epoch: 875, Training loss: 1.388976, Validation loss: 1.3601, lr: 0.0000\n",
      "Epoch: 876, Training loss: 1.390498, Validation loss: 1.3725, lr: 0.0000\n",
      "Epoch: 877, Training loss: 1.378017, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 878, Training loss: 1.397519, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 879, Training loss: 1.378874, Validation loss: 1.3742, lr: 0.0000\n",
      "Epoch: 880, Training loss: 1.373513, Validation loss: 1.3794, lr: 0.0000\n",
      "Epoch: 881, Training loss: 1.396207, Validation loss: 1.3784, lr: 0.0000\n",
      "Epoch: 882, Training loss: 1.381927, Validation loss: 1.3712, lr: 0.0000\n",
      "Epoch: 883, Training loss: 1.375463, Validation loss: 1.3782, lr: 0.0000\n",
      "Epoch: 884, Training loss: 1.361266, Validation loss: 1.6188, lr: 0.0000\n",
      "Epoch: 885, Training loss: 1.370750, Validation loss: 1.3654, lr: 0.0000\n",
      "Epoch: 886, Training loss: 1.374699, Validation loss: 1.3779, lr: 0.0000\n",
      "Epoch: 887, Training loss: 1.378479, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 888, Training loss: 1.375566, Validation loss: 1.3871, lr: 0.0000\n",
      "Epoch: 889, Training loss: 1.348431, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 890, Training loss: 1.365722, Validation loss: 1.3872, lr: 0.0000\n",
      "Epoch: 891, Training loss: 1.388744, Validation loss: 1.3759, lr: 0.0000\n",
      "Epoch: 892, Training loss: 1.388712, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 893, Training loss: 1.377702, Validation loss: 1.3698, lr: 0.0000\n",
      "Epoch: 894, Training loss: 1.381118, Validation loss: 1.3896, lr: 0.0000\n",
      "Epoch: 895, Training loss: 1.362994, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 896, Training loss: 1.375156, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 897, Training loss: 1.370036, Validation loss: 1.3705, lr: 0.0000\n",
      "Epoch: 898, Training loss: 1.366458, Validation loss: 1.3721, lr: 0.0000\n",
      "Epoch: 899, Training loss: 1.383080, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 900, Training loss: 1.368195, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 901, Training loss: 1.376487, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 902, Training loss: 1.385584, Validation loss: 1.3927, lr: 0.0000\n",
      "Epoch: 903, Training loss: 1.373247, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 904, Training loss: 1.373850, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 905, Training loss: 1.378387, Validation loss: 1.3708, lr: 0.0000\n",
      "Epoch: 906, Training loss: 1.422729, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 907, Training loss: 1.384503, Validation loss: 1.3692, lr: 0.0000\n",
      "Epoch: 908, Training loss: 1.373485, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 909, Training loss: 1.372794, Validation loss: 1.3799, lr: 0.0000\n",
      "Epoch: 910, Training loss: 1.390434, Validation loss: 1.3791, lr: 0.0000\n",
      "Epoch: 911, Training loss: 1.374600, Validation loss: 1.3779, lr: 0.0000\n",
      "Epoch: 912, Training loss: 1.364607, Validation loss: 1.3512, lr: 0.0000\n",
      "Epoch: 913, Training loss: 1.378114, Validation loss: 1.3781, lr: 0.0000\n",
      "Epoch: 914, Training loss: 1.365592, Validation loss: 1.3619, lr: 0.0000\n",
      "Epoch: 915, Training loss: 1.366049, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 916, Training loss: 1.361200, Validation loss: 1.4044, lr: 0.0000\n",
      "Epoch: 917, Training loss: 1.389137, Validation loss: 1.3762, lr: 0.0000\n",
      "Epoch: 918, Training loss: 1.387904, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 919, Training loss: 1.369666, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 920, Training loss: 1.378240, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 921, Training loss: 1.365819, Validation loss: 1.3885, lr: 0.0000\n",
      "Epoch: 922, Training loss: 1.381379, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 923, Training loss: 1.364891, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 924, Training loss: 1.380316, Validation loss: 1.3809, lr: 0.0000\n",
      "Epoch: 925, Training loss: 1.386073, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 926, Training loss: 1.418104, Validation loss: 1.3710, lr: 0.0000\n",
      "Epoch: 927, Training loss: 1.376175, Validation loss: 1.3757, lr: 0.0000\n",
      "Epoch: 928, Training loss: 1.392558, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 929, Training loss: 1.393466, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 930, Training loss: 1.398932, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 931, Training loss: 1.378846, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 932, Training loss: 1.368362, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 933, Training loss: 1.382681, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 934, Training loss: 1.386178, Validation loss: 1.3787, lr: 0.0000\n",
      "Epoch: 935, Training loss: 1.371141, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 936, Training loss: 1.340918, Validation loss: 1.3956, lr: 0.0000\n",
      "Epoch: 937, Training loss: 1.359690, Validation loss: 1.3755, lr: 0.0000\n",
      "Epoch: 938, Training loss: 1.382204, Validation loss: 1.3728, lr: 0.0000\n",
      "Epoch: 939, Training loss: 1.360744, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 940, Training loss: 1.358634, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 941, Training loss: 1.355293, Validation loss: 1.3772, lr: 0.0000\n",
      "Epoch: 942, Training loss: 1.355678, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 943, Training loss: 1.379584, Validation loss: 1.3998, lr: 0.0000\n",
      "Epoch: 944, Training loss: 1.359876, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 945, Training loss: 1.410097, Validation loss: 1.3795, lr: 0.0000\n",
      "Epoch: 946, Training loss: 1.345457, Validation loss: 1.3547, lr: 0.0000\n",
      "Epoch: 947, Training loss: 1.383184, Validation loss: 1.3735, lr: 0.0000\n",
      "Epoch: 948, Training loss: 1.379747, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 949, Training loss: 1.373052, Validation loss: 1.3883, lr: 0.0000\n",
      "Epoch: 950, Training loss: 1.355415, Validation loss: 1.3923, lr: 0.0000\n",
      "Epoch: 951, Training loss: 1.384463, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 952, Training loss: 1.374643, Validation loss: 1.3769, lr: 0.0000\n",
      "Epoch: 953, Training loss: 1.377503, Validation loss: 1.3928, lr: 0.0000\n",
      "Epoch: 954, Training loss: 1.365468, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 955, Training loss: 1.371271, Validation loss: 1.3790, lr: 0.0000\n",
      "Epoch: 956, Training loss: 1.372446, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 957, Training loss: 1.382687, Validation loss: 1.3476, lr: 0.0000\n",
      "Epoch: 958, Training loss: 1.363322, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 959, Training loss: 1.369921, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 960, Training loss: 1.395703, Validation loss: 1.3790, lr: 0.0000\n",
      "Epoch: 961, Training loss: 1.362140, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 962, Training loss: 1.397783, Validation loss: 1.3962, lr: 0.0000\n",
      "Epoch: 963, Training loss: 1.380466, Validation loss: 1.5031, lr: 0.0000\n",
      "Epoch: 964, Training loss: 1.369809, Validation loss: 1.3799, lr: 0.0000\n",
      "Epoch: 965, Training loss: 1.388633, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 966, Training loss: 1.378457, Validation loss: 1.3796, lr: 0.0000\n",
      "Epoch: 967, Training loss: 1.375559, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 968, Training loss: 1.368974, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 969, Training loss: 1.406205, Validation loss: 1.3876, lr: 0.0000\n",
      "Epoch: 970, Training loss: 1.406113, Validation loss: 1.3946, lr: 0.0000\n",
      "Epoch: 971, Training loss: 1.367936, Validation loss: 1.3708, lr: 0.0000\n",
      "Epoch: 972, Training loss: 1.396029, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 973, Training loss: 1.402918, Validation loss: 1.3710, lr: 0.0000\n",
      "Epoch: 974, Training loss: 1.385064, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 975, Training loss: 1.349936, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 976, Training loss: 1.365456, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 977, Training loss: 1.380285, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 978, Training loss: 1.410212, Validation loss: 1.3715, lr: 0.0000\n",
      "Epoch: 979, Training loss: 1.361141, Validation loss: 1.4091, lr: 0.0000\n",
      "Epoch: 980, Training loss: 1.382317, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 981, Training loss: 1.375190, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 982, Training loss: 1.372269, Validation loss: 1.3731, lr: 0.0000\n",
      "Epoch: 983, Training loss: 1.346459, Validation loss: 1.3904, lr: 0.0000\n",
      "Epoch: 984, Training loss: 1.412409, Validation loss: 1.3797, lr: 0.0000\n",
      "Epoch: 985, Training loss: 1.387333, Validation loss: 1.3799, lr: 0.0000\n",
      "Epoch: 986, Training loss: 1.395434, Validation loss: 1.3875, lr: 0.0000\n",
      "Epoch: 987, Training loss: 1.367920, Validation loss: 1.3532, lr: 0.0000\n",
      "Epoch: 988, Training loss: 1.376186, Validation loss: 1.3774, lr: 0.0000\n",
      "Epoch: 989, Training loss: 1.414223, Validation loss: 1.3729, lr: 0.0000\n",
      "Epoch: 990, Training loss: 1.367865, Validation loss: 1.3944, lr: 0.0000\n",
      "Epoch: 991, Training loss: 1.375603, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 992, Training loss: 1.368957, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 993, Training loss: 1.369030, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 994, Training loss: 1.362135, Validation loss: 1.3752, lr: 0.0000\n",
      "Epoch: 995, Training loss: 1.368985, Validation loss: 1.3885, lr: 0.0000\n",
      "Epoch: 996, Training loss: 1.359890, Validation loss: 1.3626, lr: 0.0000\n",
      "Epoch: 997, Training loss: 1.394721, Validation loss: 1.3802, lr: 0.0000\n",
      "Epoch: 998, Training loss: 1.358582, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 999, Training loss: 1.376372, Validation loss: 1.3757, lr: 0.0000\n",
      "Final test loss: 1.4042\n",
      "=== Run 06/10 ===\n",
      "\n",
      "---- Settings: \n",
      "\n",
      "epochs : 1000\n",
      "hidden_channels : [32]\n",
      "out_channels : 10\n",
      "inner_product_features : False\n",
      "batch_size : 64\n",
      "lr : 0.01\n",
      "momentum : 0.9\n",
      "dropout : 0.0\n",
      "batch_norm : batch_norm\n",
      "bias : True\n",
      "order : 2\n",
      "diffusion : True\n",
      "frac_sampled_nb : -1\n",
      "include_positions : False\n",
      "include_self : True\n",
      "vec_norm : False\n",
      "emb_norm : False\n",
      "seed : 0\n",
      "dim_signal : 100\n",
      "dim_emb : 100\n",
      "n_sampled_nb : -1\n",
      "\n",
      "---- Number of features to pass to the MLP:  1010100\n",
      "---- Total number of parameters:  32323627\n",
      "\n",
      "Using device cuda:0\n",
      "\n",
      "---- Training network ...\n",
      "\n",
      "---- Timestamp: 20250614-133801\n",
      "\n",
      " *och: 0, Training loss: 1.438204, Validation loss: 1.4156, lr: 0.0100\n",
      " *och: 1, Training loss: 1.468651, Validation loss: 1.3489, lr: 0.0100\n",
      "Epoch: 2, Training loss: 1.731499, Validation loss: 1.4031, lr: 0.0100\n",
      "Epoch: 3, Training loss: 1.417394, Validation loss: 1.3869, lr: 0.0100\n",
      "Epoch: 4, Training loss: 1.430382, Validation loss: 1.3762, lr: 0.0100\n",
      "Epoch: 5, Training loss: 1.415911, Validation loss: 1.3588, lr: 0.0100\n",
      "Epoch: 6, Training loss: 1.390239, Validation loss: 1.3855, lr: 0.0100\n",
      "Epoch: 7, Training loss: 1.395780, Validation loss: 1.3673, lr: 0.0100\n",
      "Epoch: 8, Training loss: 1.452655, Validation loss: 1.3964, lr: 0.0100\n",
      "Epoch: 9, Training loss: 1.384839, Validation loss: 1.3920, lr: 0.0100\n",
      "Epoch: 10, Training loss: 1.404655, Validation loss: 1.3585, lr: 0.0100\n",
      "Epoch: 11, Training loss: 1.380562, Validation loss: 1.3886, lr: 0.0100\n",
      "Epoch: 12, Training loss: 1.393544, Validation loss: 1.3804, lr: 0.0100\n",
      "Epoch: 13, Training loss: 1.386100, Validation loss: 2.5802, lr: 0.0100\n",
      "Epoch: 14, Training loss: 1.377779, Validation loss: 1.3777, lr: 0.0100\n",
      "Epoch: 15, Training loss: 1.389296, Validation loss: 1.3788, lr: 0.0100\n",
      "Epoch: 16, Training loss: 1.375649, Validation loss: 1.3858, lr: 0.0100\n",
      "Epoch: 17, Training loss: 1.361806, Validation loss: 1.3898, lr: 0.0100\n",
      "Epoch: 18, Training loss: 1.368980, Validation loss: 1.3739, lr: 0.0100\n",
      "Epoch: 19, Training loss: 1.406089, Validation loss: 1.3853, lr: 0.0100\n",
      "Epoch: 20, Training loss: 1.395071, Validation loss: 1.3840, lr: 0.0100\n",
      " *och: 21, Training loss: 1.399266, Validation loss: 1.2915, lr: 0.0100\n",
      "Epoch: 22, Training loss: 1.412065, Validation loss: 1.3863, lr: 0.0100\n",
      "Epoch: 23, Training loss: 1.360092, Validation loss: 1.3772, lr: 0.0100\n",
      "Epoch: 24, Training loss: 1.370294, Validation loss: 1.4025, lr: 0.0100\n",
      "Epoch: 25, Training loss: 1.368209, Validation loss: 1.3897, lr: 0.0100\n",
      "Epoch: 26, Training loss: 1.376916, Validation loss: 1.3851, lr: 0.0100\n",
      "Epoch: 27, Training loss: 1.384816, Validation loss: 1.3844, lr: 0.0100\n",
      "Epoch: 28, Training loss: 1.368246, Validation loss: 1.3704, lr: 0.0100\n",
      "Epoch: 29, Training loss: 1.373043, Validation loss: 1.3711, lr: 0.0100\n",
      "Epoch: 30, Training loss: 1.376157, Validation loss: 1.3641, lr: 0.0100\n",
      "Epoch: 31, Training loss: 1.373426, Validation loss: 1.3774, lr: 0.0100\n",
      "Epoch: 32, Training loss: 1.372363, Validation loss: 1.3854, lr: 0.0100\n",
      "Epoch: 33, Training loss: 1.393065, Validation loss: 1.3811, lr: 0.0100\n",
      "Epoch: 34, Training loss: 1.373445, Validation loss: 1.3718, lr: 0.0010\n",
      "Epoch: 35, Training loss: 1.354321, Validation loss: 1.3707, lr: 0.0010\n",
      "Epoch: 36, Training loss: 1.361945, Validation loss: 1.3851, lr: 0.0010\n",
      "Epoch: 37, Training loss: 1.365294, Validation loss: 1.3812, lr: 0.0010\n",
      "Epoch: 38, Training loss: 1.384206, Validation loss: 1.3802, lr: 0.0010\n",
      "Epoch: 39, Training loss: 1.385111, Validation loss: 1.3859, lr: 0.0010\n",
      "Epoch: 40, Training loss: 1.351726, Validation loss: 1.3843, lr: 0.0010\n",
      "Epoch: 41, Training loss: 1.381074, Validation loss: 1.3726, lr: 0.0010\n",
      "Epoch: 42, Training loss: 1.367135, Validation loss: 1.3575, lr: 0.0010\n",
      "Epoch: 43, Training loss: 1.393723, Validation loss: 1.3829, lr: 0.0010\n",
      "Epoch: 44, Training loss: 1.386262, Validation loss: 1.3862, lr: 0.0010\n",
      "Epoch: 45, Training loss: 1.359006, Validation loss: 1.3482, lr: 0.0010\n",
      "Epoch: 46, Training loss: 1.360814, Validation loss: 1.3829, lr: 0.0010\n",
      "Epoch: 47, Training loss: 1.381876, Validation loss: 1.3856, lr: 0.0010\n",
      "Epoch: 48, Training loss: 1.352611, Validation loss: 1.3650, lr: 0.0010\n",
      "Epoch: 49, Training loss: 1.364071, Validation loss: 1.3857, lr: 0.0010\n",
      "Epoch: 50, Training loss: 1.362041, Validation loss: 1.3811, lr: 0.0010\n",
      "Epoch: 51, Training loss: 1.371757, Validation loss: 1.4190, lr: 0.0001\n",
      "Epoch: 52, Training loss: 1.356017, Validation loss: 1.3848, lr: 0.0001\n",
      "Epoch: 53, Training loss: 1.353126, Validation loss: 1.3804, lr: 0.0001\n",
      "Epoch: 54, Training loss: 1.365740, Validation loss: 1.3752, lr: 0.0001\n",
      "Epoch: 55, Training loss: 1.350508, Validation loss: 1.3727, lr: 0.0001\n",
      "Epoch: 56, Training loss: 1.375755, Validation loss: 1.3785, lr: 0.0001\n",
      "Epoch: 57, Training loss: 1.367470, Validation loss: 1.3746, lr: 0.0001\n",
      "Epoch: 58, Training loss: 1.391500, Validation loss: 1.3803, lr: 0.0001\n",
      "Epoch: 59, Training loss: 1.376794, Validation loss: 1.3680, lr: 0.0001\n",
      "Epoch: 60, Training loss: 1.376679, Validation loss: 1.3856, lr: 0.0001\n",
      "Epoch: 61, Training loss: 1.386619, Validation loss: 1.4043, lr: 0.0001\n",
      "Epoch: 62, Training loss: 1.377407, Validation loss: 1.3279, lr: 0.0001\n",
      "Epoch: 63, Training loss: 1.369716, Validation loss: 1.3726, lr: 0.0001\n",
      "Epoch: 64, Training loss: 1.348434, Validation loss: 1.3553, lr: 0.0001\n",
      "Epoch: 65, Training loss: 1.351959, Validation loss: 1.3842, lr: 0.0001\n",
      "Epoch: 66, Training loss: 1.350985, Validation loss: 1.3860, lr: 0.0001\n",
      "Epoch: 67, Training loss: 1.368130, Validation loss: 1.3830, lr: 0.0001\n",
      "Epoch: 68, Training loss: 1.365890, Validation loss: 1.3679, lr: 0.0001\n",
      "Epoch: 69, Training loss: 1.385013, Validation loss: 1.3806, lr: 0.0001\n",
      "Epoch: 70, Training loss: 1.381627, Validation loss: 1.3482, lr: 0.0001\n",
      "Epoch: 71, Training loss: 1.372798, Validation loss: 1.3791, lr: 0.0001\n",
      "Epoch: 72, Training loss: 1.359871, Validation loss: 1.3575, lr: 0.0001\n",
      "Epoch: 73, Training loss: 1.409525, Validation loss: 1.3579, lr: 0.0001\n",
      "Epoch: 74, Training loss: 1.367202, Validation loss: 1.3542, lr: 0.0001\n",
      "Epoch: 75, Training loss: 1.370586, Validation loss: 1.3598, lr: 0.0000\n",
      "Epoch: 76, Training loss: 1.343135, Validation loss: 1.5775, lr: 0.0000\n",
      "Epoch: 77, Training loss: 1.388665, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 78, Training loss: 1.371234, Validation loss: 1.5490, lr: 0.0000\n",
      "Epoch: 79, Training loss: 1.352223, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 80, Training loss: 1.377916, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 81, Training loss: 1.369204, Validation loss: 1.3759, lr: 0.0000\n",
      "Epoch: 82, Training loss: 1.351804, Validation loss: 1.3687, lr: 0.0000\n",
      "Epoch: 83, Training loss: 1.353980, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 84, Training loss: 1.393077, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 85, Training loss: 1.365884, Validation loss: 1.3642, lr: 0.0000\n",
      "Epoch: 86, Training loss: 1.366108, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 87, Training loss: 1.380316, Validation loss: 1.3881, lr: 0.0000\n",
      "Epoch: 88, Training loss: 1.378577, Validation loss: 1.3619, lr: 0.0000\n",
      "Epoch: 89, Training loss: 1.357462, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 90, Training loss: 1.388356, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 91, Training loss: 1.384978, Validation loss: 1.3589, lr: 0.0000\n",
      "Epoch: 92, Training loss: 1.345543, Validation loss: 1.3578, lr: 0.0000\n",
      "Epoch: 93, Training loss: 1.369596, Validation loss: 1.3997, lr: 0.0000\n",
      "Epoch: 94, Training loss: 1.528120, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 95, Training loss: 1.354475, Validation loss: 1.3668, lr: 0.0000\n",
      "Epoch: 96, Training loss: 1.357691, Validation loss: 1.3746, lr: 0.0000\n",
      "Epoch: 97, Training loss: 1.357781, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 98, Training loss: 1.368237, Validation loss: 1.4384, lr: 0.0000\n",
      "Epoch: 99, Training loss: 1.380708, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 100, Training loss: 1.356498, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 101, Training loss: 1.357431, Validation loss: 1.3474, lr: 0.0000\n",
      "Epoch: 102, Training loss: 1.356295, Validation loss: 1.3723, lr: 0.0000\n",
      "Epoch: 103, Training loss: 1.364812, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 104, Training loss: 1.364970, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 105, Training loss: 1.359786, Validation loss: 1.3696, lr: 0.0000\n",
      "Epoch: 106, Training loss: 1.367695, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 107, Training loss: 1.371408, Validation loss: 1.3456, lr: 0.0000\n",
      "Epoch: 108, Training loss: 1.359661, Validation loss: 1.3780, lr: 0.0000\n",
      "Epoch: 109, Training loss: 1.352627, Validation loss: 1.3617, lr: 0.0000\n",
      "Epoch: 110, Training loss: 1.359851, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 111, Training loss: 1.371884, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 112, Training loss: 1.356985, Validation loss: 1.3803, lr: 0.0000\n",
      "Epoch: 113, Training loss: 1.377339, Validation loss: 1.3709, lr: 0.0000\n",
      "Epoch: 114, Training loss: 1.374231, Validation loss: 1.3786, lr: 0.0000\n",
      "Epoch: 115, Training loss: 1.362119, Validation loss: 1.3761, lr: 0.0000\n",
      "Epoch: 116, Training loss: 1.361423, Validation loss: 1.3739, lr: 0.0000\n",
      "Epoch: 117, Training loss: 1.363745, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 118, Training loss: 1.366148, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 119, Training loss: 1.371284, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 120, Training loss: 1.344582, Validation loss: 1.3879, lr: 0.0000\n",
      "Epoch: 121, Training loss: 1.361389, Validation loss: 1.3738, lr: 0.0000\n",
      "Epoch: 122, Training loss: 1.396198, Validation loss: 1.3735, lr: 0.0000\n",
      "Epoch: 123, Training loss: 1.361342, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 124, Training loss: 1.375820, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 125, Training loss: 1.371605, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 126, Training loss: 1.371310, Validation loss: 1.3771, lr: 0.0000\n",
      "Epoch: 127, Training loss: 1.447334, Validation loss: 1.3793, lr: 0.0000\n",
      "Epoch: 128, Training loss: 1.371989, Validation loss: 1.4070, lr: 0.0000\n",
      "Epoch: 129, Training loss: 1.360829, Validation loss: 1.3759, lr: 0.0000\n",
      "Epoch: 130, Training loss: 1.353591, Validation loss: 1.3797, lr: 0.0000\n",
      "Epoch: 131, Training loss: 1.360816, Validation loss: 1.3793, lr: 0.0000\n",
      "Epoch: 132, Training loss: 1.343450, Validation loss: 1.3529, lr: 0.0000\n",
      "Epoch: 133, Training loss: 1.358851, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 134, Training loss: 1.355211, Validation loss: 1.4255, lr: 0.0000\n",
      "Epoch: 135, Training loss: 1.380484, Validation loss: 1.3885, lr: 0.0000\n",
      "Epoch: 136, Training loss: 1.380954, Validation loss: 1.3342, lr: 0.0000\n",
      "Epoch: 137, Training loss: 1.358519, Validation loss: 1.6524, lr: 0.0000\n",
      "Epoch: 138, Training loss: 1.384481, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 139, Training loss: 1.391566, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 140, Training loss: 1.355840, Validation loss: 1.3745, lr: 0.0000\n",
      "Epoch: 141, Training loss: 1.369863, Validation loss: 1.3706, lr: 0.0000\n",
      "Epoch: 142, Training loss: 1.358591, Validation loss: 1.3773, lr: 0.0000\n",
      "Epoch: 143, Training loss: 1.373257, Validation loss: 1.3779, lr: 0.0000\n",
      "Epoch: 144, Training loss: 1.365062, Validation loss: 1.3872, lr: 0.0000\n",
      "Epoch: 145, Training loss: 1.355395, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 146, Training loss: 1.356197, Validation loss: 1.3730, lr: 0.0000\n",
      "Epoch: 147, Training loss: 1.376710, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 148, Training loss: 1.354590, Validation loss: 1.3783, lr: 0.0000\n",
      "Epoch: 149, Training loss: 1.344767, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 150, Training loss: 1.372832, Validation loss: 1.4061, lr: 0.0000\n",
      "Epoch: 151, Training loss: 1.354943, Validation loss: 1.4000, lr: 0.0000\n",
      "Epoch: 152, Training loss: 1.372126, Validation loss: 1.3503, lr: 0.0000\n",
      "Epoch: 153, Training loss: 1.361220, Validation loss: 1.3786, lr: 0.0000\n",
      "Epoch: 154, Training loss: 1.370792, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 155, Training loss: 1.361890, Validation loss: 1.3872, lr: 0.0000\n",
      "Epoch: 156, Training loss: 1.360537, Validation loss: 1.3707, lr: 0.0000\n",
      "Epoch: 157, Training loss: 1.359678, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 158, Training loss: 1.389357, Validation loss: 1.3942, lr: 0.0000\n",
      "Epoch: 159, Training loss: 1.358965, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 160, Training loss: 1.375856, Validation loss: 1.3640, lr: 0.0000\n",
      "Epoch: 161, Training loss: 1.364845, Validation loss: 1.3885, lr: 0.0000\n",
      "Epoch: 162, Training loss: 1.392311, Validation loss: 1.3336, lr: 0.0000\n",
      "Epoch: 163, Training loss: 1.356346, Validation loss: 1.3775, lr: 0.0000\n",
      "Epoch: 164, Training loss: 1.362712, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 165, Training loss: 1.365400, Validation loss: 1.3809, lr: 0.0000\n",
      "Epoch: 166, Training loss: 1.357244, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 167, Training loss: 1.361977, Validation loss: 1.3754, lr: 0.0000\n",
      "Epoch: 168, Training loss: 1.358134, Validation loss: 1.3285, lr: 0.0000\n",
      "Epoch: 169, Training loss: 1.356865, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 170, Training loss: 1.375389, Validation loss: 1.3911, lr: 0.0000\n",
      "Epoch: 171, Training loss: 1.363608, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 172, Training loss: 1.355578, Validation loss: 1.3731, lr: 0.0000\n",
      "Epoch: 173, Training loss: 1.380501, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 174, Training loss: 1.364189, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 175, Training loss: 1.361953, Validation loss: 1.3725, lr: 0.0000\n",
      "Epoch: 176, Training loss: 1.347163, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 177, Training loss: 1.356615, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 178, Training loss: 1.359644, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 179, Training loss: 1.335974, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 180, Training loss: 1.346071, Validation loss: 1.3195, lr: 0.0000\n",
      "Epoch: 181, Training loss: 1.361807, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 182, Training loss: 1.355199, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 183, Training loss: 1.365925, Validation loss: 1.3572, lr: 0.0000\n",
      "Epoch: 184, Training loss: 1.371863, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 185, Training loss: 1.375700, Validation loss: 1.3560, lr: 0.0000\n",
      "Epoch: 186, Training loss: 1.336264, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 187, Training loss: 1.370889, Validation loss: 1.3171, lr: 0.0000\n",
      "Epoch: 188, Training loss: 1.360337, Validation loss: 1.3781, lr: 0.0000\n",
      "Epoch: 189, Training loss: 1.353185, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 190, Training loss: 1.356086, Validation loss: 1.3763, lr: 0.0000\n",
      "Epoch: 191, Training loss: 1.410937, Validation loss: 1.3649, lr: 0.0000\n",
      "Epoch: 192, Training loss: 1.374909, Validation loss: 1.3243, lr: 0.0000\n",
      "Epoch: 193, Training loss: 1.369099, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 194, Training loss: 1.388093, Validation loss: 1.3794, lr: 0.0000\n",
      "Epoch: 195, Training loss: 1.368269, Validation loss: 1.3786, lr: 0.0000\n",
      "Epoch: 196, Training loss: 1.354804, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 197, Training loss: 1.361975, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 198, Training loss: 1.363212, Validation loss: 1.3467, lr: 0.0000\n",
      "Epoch: 199, Training loss: 1.362085, Validation loss: 1.3612, lr: 0.0000\n",
      "Epoch: 200, Training loss: 1.348438, Validation loss: 1.5038, lr: 0.0000\n",
      "Epoch: 201, Training loss: 1.357404, Validation loss: 1.3666, lr: 0.0000\n",
      "Epoch: 202, Training loss: 1.373684, Validation loss: 1.3685, lr: 0.0000\n",
      "Epoch: 203, Training loss: 1.364786, Validation loss: 1.3881, lr: 0.0000\n",
      "Epoch: 204, Training loss: 1.365804, Validation loss: 1.3735, lr: 0.0000\n",
      "Epoch: 205, Training loss: 1.358362, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 206, Training loss: 1.361697, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 207, Training loss: 1.351508, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 208, Training loss: 1.378410, Validation loss: 1.3539, lr: 0.0000\n",
      "Epoch: 209, Training loss: 1.365379, Validation loss: 1.5063, lr: 0.0000\n",
      "Epoch: 210, Training loss: 1.371002, Validation loss: 1.3792, lr: 0.0000\n",
      "Epoch: 211, Training loss: 1.357023, Validation loss: 1.3750, lr: 0.0000\n",
      "Epoch: 212, Training loss: 1.382480, Validation loss: 1.3326, lr: 0.0000\n",
      "Epoch: 213, Training loss: 1.443941, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 214, Training loss: 1.377878, Validation loss: 1.3722, lr: 0.0000\n",
      "Epoch: 215, Training loss: 1.353830, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 216, Training loss: 1.357301, Validation loss: 1.5102, lr: 0.0000\n",
      "Epoch: 217, Training loss: 1.383612, Validation loss: 1.3786, lr: 0.0000\n",
      "Epoch: 218, Training loss: 1.343417, Validation loss: 1.3775, lr: 0.0000\n",
      "Epoch: 219, Training loss: 1.351876, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 220, Training loss: 1.381547, Validation loss: 1.3799, lr: 0.0000\n",
      "Epoch: 221, Training loss: 1.369642, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 222, Training loss: 1.372570, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 223, Training loss: 1.360307, Validation loss: 1.3747, lr: 0.0000\n",
      "Epoch: 224, Training loss: 1.366931, Validation loss: 1.3875, lr: 0.0000\n",
      "Epoch: 225, Training loss: 1.368463, Validation loss: 1.3759, lr: 0.0000\n",
      "Epoch: 226, Training loss: 1.359908, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 227, Training loss: 1.366771, Validation loss: 1.3800, lr: 0.0000\n",
      "Epoch: 228, Training loss: 1.350922, Validation loss: 1.3775, lr: 0.0000\n",
      "Epoch: 229, Training loss: 1.380514, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 230, Training loss: 1.378387, Validation loss: 1.3701, lr: 0.0000\n",
      "Epoch: 231, Training loss: 1.357696, Validation loss: 1.3794, lr: 0.0000\n",
      "Epoch: 232, Training loss: 1.369832, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 233, Training loss: 1.383631, Validation loss: 1.3930, lr: 0.0000\n",
      "Epoch: 234, Training loss: 1.337858, Validation loss: 1.3871, lr: 0.0000\n",
      "Epoch: 235, Training loss: 1.345738, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 236, Training loss: 1.360373, Validation loss: 1.3401, lr: 0.0000\n",
      "Epoch: 237, Training loss: 1.347168, Validation loss: 1.3890, lr: 0.0000\n",
      "Epoch: 238, Training loss: 1.381080, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 239, Training loss: 1.380051, Validation loss: 1.3690, lr: 0.0000\n",
      "Epoch: 240, Training loss: 1.394328, Validation loss: 1.3752, lr: 0.0000\n",
      "Epoch: 241, Training loss: 1.373024, Validation loss: 1.3783, lr: 0.0000\n",
      "Epoch: 242, Training loss: 1.359419, Validation loss: 1.3764, lr: 0.0000\n",
      "Epoch: 243, Training loss: 1.361050, Validation loss: 1.3796, lr: 0.0000\n",
      "Epoch: 244, Training loss: 1.381079, Validation loss: 1.3764, lr: 0.0000\n",
      "Epoch: 245, Training loss: 1.384738, Validation loss: 1.4051, lr: 0.0000\n",
      "Epoch: 246, Training loss: 1.373365, Validation loss: 1.3746, lr: 0.0000\n",
      "Epoch: 247, Training loss: 1.376677, Validation loss: 1.3433, lr: 0.0000\n",
      "Epoch: 248, Training loss: 1.451028, Validation loss: 1.3784, lr: 0.0000\n",
      "Epoch: 249, Training loss: 1.403801, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 250, Training loss: 1.356179, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 251, Training loss: 1.337785, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 252, Training loss: 1.357502, Validation loss: 1.3679, lr: 0.0000\n",
      "Epoch: 253, Training loss: 1.347633, Validation loss: 1.4204, lr: 0.0000\n",
      "Epoch: 254, Training loss: 1.369088, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 255, Training loss: 1.348646, Validation loss: 1.3681, lr: 0.0000\n",
      "Epoch: 256, Training loss: 1.361635, Validation loss: 1.3526, lr: 0.0000\n",
      "Epoch: 257, Training loss: 1.352922, Validation loss: 1.3794, lr: 0.0000\n",
      "Epoch: 258, Training loss: 1.348678, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 259, Training loss: 1.378646, Validation loss: 1.3768, lr: 0.0000\n",
      "Epoch: 260, Training loss: 1.378203, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 261, Training loss: 1.365836, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 262, Training loss: 1.420161, Validation loss: 1.3752, lr: 0.0000\n",
      "Epoch: 263, Training loss: 1.372847, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 264, Training loss: 1.423155, Validation loss: 1.3910, lr: 0.0000\n",
      "Epoch: 265, Training loss: 1.368080, Validation loss: 1.3617, lr: 0.0000\n",
      "Epoch: 266, Training loss: 1.350400, Validation loss: 1.3900, lr: 0.0000\n",
      "Epoch: 267, Training loss: 1.381508, Validation loss: 1.3809, lr: 0.0000\n",
      "Epoch: 268, Training loss: 1.354134, Validation loss: 1.3752, lr: 0.0000\n",
      "Epoch: 269, Training loss: 1.364878, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 270, Training loss: 1.377617, Validation loss: 1.3809, lr: 0.0000\n",
      "Epoch: 271, Training loss: 1.381702, Validation loss: 1.3896, lr: 0.0000\n",
      "Epoch: 272, Training loss: 1.356609, Validation loss: 1.3738, lr: 0.0000\n",
      "Epoch: 273, Training loss: 1.350654, Validation loss: 1.3872, lr: 0.0000\n",
      "Epoch: 274, Training loss: 1.366945, Validation loss: 1.4403, lr: 0.0000\n",
      "Epoch: 275, Training loss: 1.371635, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 276, Training loss: 1.367334, Validation loss: 1.3751, lr: 0.0000\n",
      "Epoch: 277, Training loss: 1.372879, Validation loss: 2.0237, lr: 0.0000\n",
      "Epoch: 278, Training loss: 1.373102, Validation loss: 1.3784, lr: 0.0000\n",
      "Epoch: 279, Training loss: 1.425216, Validation loss: 1.3646, lr: 0.0000\n",
      "Epoch: 280, Training loss: 1.361506, Validation loss: 1.4673, lr: 0.0000\n",
      "Epoch: 281, Training loss: 1.453828, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 282, Training loss: 1.377804, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 283, Training loss: 1.388603, Validation loss: 1.3967, lr: 0.0000\n",
      "Epoch: 284, Training loss: 1.369852, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 285, Training loss: 1.406269, Validation loss: 1.3682, lr: 0.0000\n",
      "Epoch: 286, Training loss: 1.359888, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 287, Training loss: 1.360263, Validation loss: 1.3558, lr: 0.0000\n",
      "Epoch: 288, Training loss: 1.375985, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 289, Training loss: 1.363307, Validation loss: 1.3904, lr: 0.0000\n",
      "Epoch: 290, Training loss: 1.360505, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 291, Training loss: 1.380478, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 292, Training loss: 1.353256, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 293, Training loss: 1.349612, Validation loss: 1.3726, lr: 0.0000\n",
      "Epoch: 294, Training loss: 1.374798, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 295, Training loss: 1.372737, Validation loss: 1.3771, lr: 0.0000\n",
      "Epoch: 296, Training loss: 1.346064, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 297, Training loss: 1.356640, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 298, Training loss: 1.371361, Validation loss: 1.3762, lr: 0.0000\n",
      "Epoch: 299, Training loss: 1.385578, Validation loss: 1.3895, lr: 0.0000\n",
      "Epoch: 300, Training loss: 1.356233, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 301, Training loss: 1.357183, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 302, Training loss: 1.374701, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 303, Training loss: 1.377631, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 304, Training loss: 1.374144, Validation loss: 1.3558, lr: 0.0000\n",
      "Epoch: 305, Training loss: 1.350919, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 306, Training loss: 1.377465, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 307, Training loss: 1.363154, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 308, Training loss: 1.355419, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 309, Training loss: 1.342731, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 310, Training loss: 1.387680, Validation loss: 1.3739, lr: 0.0000\n",
      "Epoch: 311, Training loss: 1.377594, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 312, Training loss: 1.363305, Validation loss: 1.3767, lr: 0.0000\n",
      "Epoch: 313, Training loss: 1.362003, Validation loss: 1.3458, lr: 0.0000\n",
      "Epoch: 314, Training loss: 1.336807, Validation loss: 1.3757, lr: 0.0000\n",
      "Epoch: 315, Training loss: 1.360198, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 316, Training loss: 1.376205, Validation loss: 1.3139, lr: 0.0000\n",
      "Epoch: 317, Training loss: 1.379769, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 318, Training loss: 1.373375, Validation loss: 1.3414, lr: 0.0000\n",
      "Epoch: 319, Training loss: 1.381966, Validation loss: 1.3746, lr: 0.0000\n",
      "Epoch: 320, Training loss: 1.382674, Validation loss: 1.3882, lr: 0.0000\n",
      "Epoch: 321, Training loss: 1.377211, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 322, Training loss: 1.364423, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 323, Training loss: 1.394628, Validation loss: 1.3803, lr: 0.0000\n",
      "Epoch: 324, Training loss: 1.372867, Validation loss: 1.4148, lr: 0.0000\n",
      "Epoch: 325, Training loss: 1.363047, Validation loss: 1.3786, lr: 0.0000\n",
      "Epoch: 326, Training loss: 1.359568, Validation loss: 1.3680, lr: 0.0000\n",
      "Epoch: 327, Training loss: 1.344922, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 328, Training loss: 1.379310, Validation loss: 1.3368, lr: 0.0000\n",
      "Epoch: 329, Training loss: 1.357613, Validation loss: 1.3352, lr: 0.0000\n",
      "Epoch: 330, Training loss: 1.371164, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 331, Training loss: 1.369436, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 332, Training loss: 1.347126, Validation loss: 1.3611, lr: 0.0000\n",
      "Epoch: 333, Training loss: 1.371056, Validation loss: 1.4054, lr: 0.0000\n",
      "Epoch: 334, Training loss: 1.369848, Validation loss: 1.3550, lr: 0.0000\n",
      "Epoch: 335, Training loss: 1.361169, Validation loss: 1.3469, lr: 0.0000\n",
      "Epoch: 336, Training loss: 1.371939, Validation loss: 1.3377, lr: 0.0000\n",
      "Epoch: 337, Training loss: 1.383324, Validation loss: 1.3753, lr: 0.0000\n",
      "Epoch: 338, Training loss: 1.347823, Validation loss: 1.3881, lr: 0.0000\n",
      "Epoch: 339, Training loss: 1.349066, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 340, Training loss: 1.367393, Validation loss: 1.3926, lr: 0.0000\n",
      "Epoch: 341, Training loss: 1.370218, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 342, Training loss: 1.392795, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 343, Training loss: 1.372080, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 344, Training loss: 1.374103, Validation loss: 1.4294, lr: 0.0000\n",
      "Epoch: 345, Training loss: 1.360263, Validation loss: 1.3930, lr: 0.0000\n",
      "Epoch: 346, Training loss: 1.373688, Validation loss: 1.3533, lr: 0.0000\n",
      "Epoch: 347, Training loss: 1.387772, Validation loss: 1.4402, lr: 0.0000\n",
      "Epoch: 348, Training loss: 1.371060, Validation loss: 1.3946, lr: 0.0000\n",
      "Epoch: 349, Training loss: 1.365046, Validation loss: 1.3540, lr: 0.0000\n",
      "Epoch: 350, Training loss: 1.371760, Validation loss: 1.3618, lr: 0.0000\n",
      "Epoch: 351, Training loss: 1.364355, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 352, Training loss: 1.362189, Validation loss: 1.3753, lr: 0.0000\n",
      "Epoch: 353, Training loss: 1.381823, Validation loss: 1.3725, lr: 0.0000\n",
      "Epoch: 354, Training loss: 1.346788, Validation loss: 1.3737, lr: 0.0000\n",
      "Epoch: 355, Training loss: 1.374016, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 356, Training loss: 1.360649, Validation loss: 1.3485, lr: 0.0000\n",
      "Epoch: 357, Training loss: 1.384608, Validation loss: 1.3720, lr: 0.0000\n",
      "Epoch: 358, Training loss: 1.377139, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 359, Training loss: 1.367727, Validation loss: 2.9641, lr: 0.0000\n",
      "Epoch: 360, Training loss: 1.371042, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 361, Training loss: 1.359060, Validation loss: 1.3661, lr: 0.0000\n",
      "Epoch: 362, Training loss: 1.363888, Validation loss: 1.3569, lr: 0.0000\n",
      "Epoch: 363, Training loss: 1.361881, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 364, Training loss: 1.368929, Validation loss: 1.3571, lr: 0.0000\n",
      "Epoch: 365, Training loss: 1.382544, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 366, Training loss: 1.371264, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 367, Training loss: 1.306768, Validation loss: 1.3773, lr: 0.0000\n",
      "Epoch: 368, Training loss: 1.350253, Validation loss: 1.3185, lr: 0.0000\n",
      "Epoch: 369, Training loss: 1.365235, Validation loss: 1.3905, lr: 0.0000\n",
      "Epoch: 370, Training loss: 1.361908, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 371, Training loss: 1.375292, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 372, Training loss: 1.374046, Validation loss: 1.3781, lr: 0.0000\n",
      "Epoch: 373, Training loss: 1.357835, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 374, Training loss: 1.352607, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 375, Training loss: 1.367769, Validation loss: 1.4030, lr: 0.0000\n",
      "Epoch: 376, Training loss: 1.359236, Validation loss: 1.3746, lr: 0.0000\n",
      "Epoch: 377, Training loss: 1.352840, Validation loss: 1.3669, lr: 0.0000\n",
      "Epoch: 378, Training loss: 1.365705, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 379, Training loss: 1.375195, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 380, Training loss: 1.370892, Validation loss: 1.3878, lr: 0.0000\n",
      "Epoch: 381, Training loss: 1.359770, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 382, Training loss: 1.358554, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 383, Training loss: 1.357619, Validation loss: 1.3887, lr: 0.0000\n",
      "Epoch: 384, Training loss: 1.341854, Validation loss: 1.3378, lr: 0.0000\n",
      "Epoch: 385, Training loss: 1.385539, Validation loss: 1.3681, lr: 0.0000\n",
      "Epoch: 386, Training loss: 1.364793, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 387, Training loss: 1.422368, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 388, Training loss: 1.412829, Validation loss: 1.3520, lr: 0.0000\n",
      "Epoch: 389, Training loss: 1.374138, Validation loss: 1.9888, lr: 0.0000\n",
      "Epoch: 390, Training loss: 1.360305, Validation loss: 1.3561, lr: 0.0000\n",
      "Epoch: 391, Training loss: 1.374539, Validation loss: 1.3781, lr: 0.0000\n",
      "Epoch: 392, Training loss: 1.375963, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 393, Training loss: 1.359799, Validation loss: 1.3752, lr: 0.0000\n",
      "Epoch: 394, Training loss: 1.367705, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 395, Training loss: 1.355311, Validation loss: 1.3658, lr: 0.0000\n",
      "Epoch: 396, Training loss: 1.373978, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 397, Training loss: 1.355352, Validation loss: 1.4038, lr: 0.0000\n",
      "Epoch: 398, Training loss: 1.354950, Validation loss: 1.3768, lr: 0.0000\n",
      "Epoch: 399, Training loss: 1.367101, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 400, Training loss: 1.365553, Validation loss: 1.3643, lr: 0.0000\n",
      "Epoch: 401, Training loss: 1.359629, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 402, Training loss: 1.357446, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 403, Training loss: 1.347116, Validation loss: 1.3883, lr: 0.0000\n",
      "Epoch: 404, Training loss: 1.368825, Validation loss: 1.3742, lr: 0.0000\n",
      "Epoch: 405, Training loss: 1.345079, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 406, Training loss: 1.362875, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 407, Training loss: 1.363293, Validation loss: 1.3797, lr: 0.0000\n",
      "Epoch: 408, Training loss: 1.372018, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 409, Training loss: 1.372449, Validation loss: 1.4040, lr: 0.0000\n",
      "Epoch: 410, Training loss: 1.369013, Validation loss: 1.3785, lr: 0.0000\n",
      "Epoch: 411, Training loss: 1.364983, Validation loss: 1.3898, lr: 0.0000\n",
      "Epoch: 412, Training loss: 1.360045, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 413, Training loss: 1.378306, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 414, Training loss: 1.358545, Validation loss: 1.3615, lr: 0.0000\n",
      "Epoch: 415, Training loss: 1.367784, Validation loss: 1.4931, lr: 0.0000\n",
      "Epoch: 416, Training loss: 1.391946, Validation loss: 1.3317, lr: 0.0000\n",
      "Epoch: 417, Training loss: 1.364283, Validation loss: 1.3588, lr: 0.0000\n",
      "Epoch: 418, Training loss: 1.385583, Validation loss: 1.3516, lr: 0.0000\n",
      "Epoch: 419, Training loss: 1.351661, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 420, Training loss: 1.366849, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 421, Training loss: 1.361083, Validation loss: 1.3364, lr: 0.0000\n",
      "Epoch: 422, Training loss: 1.367754, Validation loss: 1.4119, lr: 0.0000\n",
      "Epoch: 423, Training loss: 1.361529, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 424, Training loss: 1.395279, Validation loss: 1.3533, lr: 0.0000\n",
      "Epoch: 425, Training loss: 1.353048, Validation loss: 1.3528, lr: 0.0000\n",
      "Epoch: 426, Training loss: 1.369502, Validation loss: 1.3886, lr: 0.0000\n",
      "Epoch: 427, Training loss: 1.359384, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 428, Training loss: 1.368178, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 429, Training loss: 1.339696, Validation loss: 1.3944, lr: 0.0000\n",
      "Epoch: 430, Training loss: 1.437770, Validation loss: 1.3594, lr: 0.0000\n",
      "Epoch: 431, Training loss: 1.365137, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 432, Training loss: 1.356480, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 433, Training loss: 1.356780, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 434, Training loss: 1.368315, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 435, Training loss: 1.360570, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 436, Training loss: 1.351048, Validation loss: 1.3797, lr: 0.0000\n",
      "Epoch: 437, Training loss: 1.410866, Validation loss: 1.3912, lr: 0.0000\n",
      "Epoch: 438, Training loss: 1.359205, Validation loss: 1.3772, lr: 0.0000\n",
      "Epoch: 439, Training loss: 1.359998, Validation loss: 1.3760, lr: 0.0000\n",
      "Epoch: 440, Training loss: 1.362000, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 441, Training loss: 1.417855, Validation loss: 1.3968, lr: 0.0000\n",
      "Epoch: 442, Training loss: 1.363154, Validation loss: 1.3874, lr: 0.0000\n",
      "Epoch: 443, Training loss: 1.367463, Validation loss: 1.3657, lr: 0.0000\n",
      "Epoch: 444, Training loss: 1.363270, Validation loss: 1.3905, lr: 0.0000\n",
      "Epoch: 445, Training loss: 1.365223, Validation loss: 1.3803, lr: 0.0000\n",
      "Epoch: 446, Training loss: 1.361647, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 447, Training loss: 1.347571, Validation loss: 1.3703, lr: 0.0000\n",
      "Epoch: 448, Training loss: 1.356743, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 449, Training loss: 1.358421, Validation loss: 1.3727, lr: 0.0000\n",
      "Epoch: 450, Training loss: 1.364954, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 451, Training loss: 1.345154, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 452, Training loss: 1.357609, Validation loss: 1.3676, lr: 0.0000\n",
      "Epoch: 453, Training loss: 1.378691, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 454, Training loss: 1.358038, Validation loss: 1.3785, lr: 0.0000\n",
      "Epoch: 455, Training loss: 1.365777, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 456, Training loss: 1.365461, Validation loss: 1.3674, lr: 0.0000\n",
      "Epoch: 457, Training loss: 1.370315, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 458, Training loss: 1.366144, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 459, Training loss: 1.376994, Validation loss: 1.3765, lr: 0.0000\n",
      "Epoch: 460, Training loss: 1.401141, Validation loss: 1.3780, lr: 0.0000\n",
      "Epoch: 461, Training loss: 1.376490, Validation loss: 1.5551, lr: 0.0000\n",
      "Epoch: 462, Training loss: 1.348627, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 463, Training loss: 1.463745, Validation loss: 1.3663, lr: 0.0000\n",
      "Epoch: 464, Training loss: 1.381615, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 465, Training loss: 1.352103, Validation loss: 1.3686, lr: 0.0000\n",
      "Epoch: 466, Training loss: 1.355788, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 467, Training loss: 1.362304, Validation loss: 1.3802, lr: 0.0000\n",
      "Epoch: 468, Training loss: 1.342636, Validation loss: 1.4528, lr: 0.0000\n",
      "Epoch: 469, Training loss: 1.363585, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 470, Training loss: 1.360028, Validation loss: 1.3688, lr: 0.0000\n",
      "Epoch: 471, Training loss: 1.379328, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 472, Training loss: 1.369414, Validation loss: 1.3735, lr: 0.0000\n",
      "Epoch: 473, Training loss: 1.376758, Validation loss: 1.3677, lr: 0.0000\n",
      "Epoch: 474, Training loss: 1.370432, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 475, Training loss: 1.375687, Validation loss: 1.3653, lr: 0.0000\n",
      "Epoch: 476, Training loss: 1.390061, Validation loss: 1.3787, lr: 0.0000\n",
      "Epoch: 477, Training loss: 1.379916, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 478, Training loss: 1.359990, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 479, Training loss: 1.362755, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 480, Training loss: 1.371767, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 481, Training loss: 1.362282, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 482, Training loss: 1.378260, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 483, Training loss: 1.351053, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 484, Training loss: 1.355395, Validation loss: 1.3572, lr: 0.0000\n",
      "Epoch: 485, Training loss: 1.354463, Validation loss: 1.3739, lr: 0.0000\n",
      "Epoch: 486, Training loss: 1.364872, Validation loss: 1.3798, lr: 0.0000\n",
      "Epoch: 487, Training loss: 1.357273, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 488, Training loss: 1.448649, Validation loss: 1.3210, lr: 0.0000\n",
      "Epoch: 489, Training loss: 1.378197, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 490, Training loss: 1.370725, Validation loss: 1.3781, lr: 0.0000\n",
      "Epoch: 491, Training loss: 1.386332, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 492, Training loss: 1.369486, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 493, Training loss: 1.409089, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 494, Training loss: 1.366847, Validation loss: 1.3573, lr: 0.0000\n",
      "Epoch: 495, Training loss: 1.371365, Validation loss: 1.3529, lr: 0.0000\n",
      "Epoch: 496, Training loss: 1.349622, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 497, Training loss: 1.387502, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 498, Training loss: 1.374880, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 499, Training loss: 1.363467, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 500, Training loss: 1.339379, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 501, Training loss: 1.348676, Validation loss: 1.3754, lr: 0.0000\n",
      "Epoch: 502, Training loss: 1.390091, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 503, Training loss: 1.368922, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 504, Training loss: 1.373051, Validation loss: 1.3780, lr: 0.0000\n",
      "Epoch: 505, Training loss: 1.429187, Validation loss: 1.3779, lr: 0.0000\n",
      "Epoch: 506, Training loss: 1.363417, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 507, Training loss: 1.374539, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 508, Training loss: 1.388177, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 509, Training loss: 1.358749, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 510, Training loss: 1.352073, Validation loss: 1.3969, lr: 0.0000\n",
      "Epoch: 511, Training loss: 1.404763, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 512, Training loss: 1.367882, Validation loss: 1.3788, lr: 0.0000\n",
      "Epoch: 513, Training loss: 1.374834, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 514, Training loss: 1.361240, Validation loss: 1.6180, lr: 0.0000\n",
      "Epoch: 515, Training loss: 1.347189, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 516, Training loss: 1.376333, Validation loss: 1.3537, lr: 0.0000\n",
      "Epoch: 517, Training loss: 1.358456, Validation loss: 1.3905, lr: 0.0000\n",
      "Epoch: 518, Training loss: 1.355610, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 519, Training loss: 1.358313, Validation loss: 1.3483, lr: 0.0000\n",
      "Epoch: 520, Training loss: 1.377607, Validation loss: 2.4109, lr: 0.0000\n",
      "Epoch: 521, Training loss: 1.358488, Validation loss: 1.3369, lr: 0.0000\n",
      "Epoch: 522, Training loss: 1.354486, Validation loss: 1.3765, lr: 0.0000\n",
      "Epoch: 523, Training loss: 1.365139, Validation loss: 1.3771, lr: 0.0000\n",
      "Epoch: 524, Training loss: 1.376032, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 525, Training loss: 1.352765, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 526, Training loss: 1.372849, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 527, Training loss: 1.377199, Validation loss: 1.4227, lr: 0.0000\n",
      "Epoch: 528, Training loss: 1.364672, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 529, Training loss: 1.338622, Validation loss: 1.3768, lr: 0.0000\n",
      "Epoch: 530, Training loss: 1.360753, Validation loss: 1.3417, lr: 0.0000\n",
      "Epoch: 531, Training loss: 1.362588, Validation loss: 1.3965, lr: 0.0000\n",
      "Epoch: 532, Training loss: 1.360698, Validation loss: 1.3798, lr: 0.0000\n",
      "Epoch: 533, Training loss: 1.351059, Validation loss: 1.3388, lr: 0.0000\n",
      "Epoch: 534, Training loss: 1.406724, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 535, Training loss: 1.374415, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 536, Training loss: 1.349025, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 537, Training loss: 1.384842, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 538, Training loss: 1.359224, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 539, Training loss: 1.362513, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 540, Training loss: 1.377303, Validation loss: 1.3548, lr: 0.0000\n",
      "Epoch: 541, Training loss: 1.376106, Validation loss: 1.3775, lr: 0.0000\n",
      "Epoch: 542, Training loss: 1.432481, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 543, Training loss: 1.359980, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 544, Training loss: 1.360797, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 545, Training loss: 1.368593, Validation loss: 1.3463, lr: 0.0000\n",
      "Epoch: 546, Training loss: 1.366272, Validation loss: 1.3612, lr: 0.0000\n",
      "Epoch: 547, Training loss: 1.378246, Validation loss: 1.3787, lr: 0.0000\n",
      "Epoch: 548, Training loss: 1.372467, Validation loss: 1.4112, lr: 0.0000\n",
      "Epoch: 549, Training loss: 1.362472, Validation loss: 1.3747, lr: 0.0000\n",
      "Epoch: 550, Training loss: 1.337330, Validation loss: 1.3311, lr: 0.0000\n",
      "Epoch: 551, Training loss: 1.340386, Validation loss: 1.3773, lr: 0.0000\n",
      "Epoch: 552, Training loss: 1.342746, Validation loss: 1.3503, lr: 0.0000\n",
      "Epoch: 553, Training loss: 1.361572, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 554, Training loss: 1.351177, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 555, Training loss: 1.369183, Validation loss: 1.3716, lr: 0.0000\n",
      "Epoch: 556, Training loss: 1.386851, Validation loss: 1.3782, lr: 0.0000\n",
      "Epoch: 557, Training loss: 1.367016, Validation loss: 1.3872, lr: 0.0000\n",
      "Epoch: 558, Training loss: 1.363263, Validation loss: 1.3950, lr: 0.0000\n",
      "Epoch: 559, Training loss: 1.367603, Validation loss: 1.3232, lr: 0.0000\n",
      "Epoch: 560, Training loss: 1.342152, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 561, Training loss: 1.380632, Validation loss: 1.3772, lr: 0.0000\n",
      "Epoch: 562, Training loss: 1.383980, Validation loss: 1.3531, lr: 0.0000\n",
      "Epoch: 563, Training loss: 1.339044, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 564, Training loss: 1.379318, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 565, Training loss: 1.368070, Validation loss: 1.3463, lr: 0.0000\n",
      "Epoch: 566, Training loss: 1.354834, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 567, Training loss: 1.367081, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 568, Training loss: 1.378633, Validation loss: 1.3490, lr: 0.0000\n",
      "Epoch: 569, Training loss: 1.358047, Validation loss: 1.4528, lr: 0.0000\n",
      "Epoch: 570, Training loss: 1.366975, Validation loss: 1.3871, lr: 0.0000\n",
      "Epoch: 571, Training loss: 1.375804, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 572, Training loss: 1.351972, Validation loss: 1.3538, lr: 0.0000\n",
      "Epoch: 573, Training loss: 1.361406, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 574, Training loss: 1.361226, Validation loss: 1.3772, lr: 0.0000\n",
      "Epoch: 575, Training loss: 1.367556, Validation loss: 1.4776, lr: 0.0000\n",
      "Epoch: 576, Training loss: 1.373117, Validation loss: 1.3764, lr: 0.0000\n",
      "Epoch: 577, Training loss: 1.378602, Validation loss: 1.3779, lr: 0.0000\n",
      "Epoch: 578, Training loss: 1.383114, Validation loss: 1.3650, lr: 0.0000\n",
      "Epoch: 579, Training loss: 1.374214, Validation loss: 1.3543, lr: 0.0000\n",
      "Epoch: 580, Training loss: 1.363760, Validation loss: 1.3792, lr: 0.0000\n",
      "Epoch: 581, Training loss: 1.355287, Validation loss: 1.3691, lr: 0.0000\n",
      "Epoch: 582, Training loss: 1.367192, Validation loss: 1.3713, lr: 0.0000\n",
      "Epoch: 583, Training loss: 1.370236, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 584, Training loss: 1.366024, Validation loss: 1.3497, lr: 0.0000\n",
      "Epoch: 585, Training loss: 1.359080, Validation loss: 1.3755, lr: 0.0000\n",
      "Epoch: 586, Training loss: 1.359834, Validation loss: 1.3428, lr: 0.0000\n",
      "Epoch: 587, Training loss: 1.373172, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 588, Training loss: 1.383941, Validation loss: 1.3791, lr: 0.0000\n",
      "Epoch: 589, Training loss: 1.365478, Validation loss: 1.3787, lr: 0.0000\n",
      "Epoch: 590, Training loss: 1.364248, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 591, Training loss: 1.356823, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 592, Training loss: 1.350727, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 593, Training loss: 1.364451, Validation loss: 1.3790, lr: 0.0000\n",
      "Epoch: 594, Training loss: 1.364746, Validation loss: 1.3376, lr: 0.0000\n",
      "Epoch: 595, Training loss: 1.336592, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 596, Training loss: 1.355067, Validation loss: 1.3617, lr: 0.0000\n",
      "Epoch: 597, Training loss: 1.376764, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 598, Training loss: 1.335886, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 599, Training loss: 1.350995, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 600, Training loss: 1.375438, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 601, Training loss: 1.372476, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 602, Training loss: 1.368952, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 603, Training loss: 1.373144, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 604, Training loss: 1.373108, Validation loss: 1.3544, lr: 0.0000\n",
      "Epoch: 605, Training loss: 1.368135, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 606, Training loss: 1.349500, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 607, Training loss: 1.382325, Validation loss: 1.3622, lr: 0.0000\n",
      "Epoch: 608, Training loss: 1.378738, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 609, Training loss: 1.386540, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 610, Training loss: 1.370955, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 611, Training loss: 1.355530, Validation loss: 1.3748, lr: 0.0000\n",
      "Epoch: 612, Training loss: 1.380026, Validation loss: 1.3798, lr: 0.0000\n",
      "Epoch: 613, Training loss: 1.365754, Validation loss: 1.3767, lr: 0.0000\n",
      "Epoch: 614, Training loss: 1.372811, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 615, Training loss: 1.365654, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 616, Training loss: 1.352973, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 617, Training loss: 1.350166, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 618, Training loss: 1.369127, Validation loss: 1.3560, lr: 0.0000\n",
      "Epoch: 619, Training loss: 1.365201, Validation loss: 1.3781, lr: 0.0000\n",
      "Epoch: 620, Training loss: 1.337412, Validation loss: 1.3798, lr: 0.0000\n",
      "Epoch: 621, Training loss: 1.386486, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 622, Training loss: 1.368713, Validation loss: 1.3561, lr: 0.0000\n",
      "Epoch: 623, Training loss: 1.376805, Validation loss: 1.3744, lr: 0.0000\n",
      "Epoch: 624, Training loss: 1.400537, Validation loss: 1.3778, lr: 0.0000\n",
      "Epoch: 625, Training loss: 1.369038, Validation loss: 1.3948, lr: 0.0000\n",
      "Epoch: 626, Training loss: 1.360260, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 627, Training loss: 1.347019, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 628, Training loss: 1.369177, Validation loss: 1.4196, lr: 0.0000\n",
      "Epoch: 629, Training loss: 1.358157, Validation loss: 1.3799, lr: 0.0000\n",
      "Epoch: 630, Training loss: 1.358937, Validation loss: 1.3517, lr: 0.0000\n",
      "Epoch: 631, Training loss: 1.343972, Validation loss: 1.3739, lr: 0.0000\n",
      "Epoch: 632, Training loss: 1.365917, Validation loss: 1.3752, lr: 0.0000\n",
      "Epoch: 633, Training loss: 1.397499, Validation loss: 1.3379, lr: 0.0000\n",
      "Epoch: 634, Training loss: 1.361469, Validation loss: 1.3783, lr: 0.0000\n",
      "Epoch: 635, Training loss: 1.399211, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 636, Training loss: 1.371948, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 637, Training loss: 1.468330, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 638, Training loss: 1.342403, Validation loss: 1.3680, lr: 0.0000\n",
      "Epoch: 639, Training loss: 1.389901, Validation loss: 1.3256, lr: 0.0000\n",
      "Epoch: 640, Training loss: 1.370928, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 641, Training loss: 1.362893, Validation loss: 1.3779, lr: 0.0000\n",
      "Epoch: 642, Training loss: 1.373713, Validation loss: 1.3666, lr: 0.0000\n",
      "Epoch: 643, Training loss: 1.365072, Validation loss: 1.3798, lr: 0.0000\n",
      "Epoch: 644, Training loss: 1.379340, Validation loss: 1.3790, lr: 0.0000\n",
      "Epoch: 645, Training loss: 1.368889, Validation loss: 1.3735, lr: 0.0000\n",
      "Epoch: 646, Training loss: 1.336771, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 647, Training loss: 1.349039, Validation loss: 1.3792, lr: 0.0000\n",
      "Epoch: 648, Training loss: 1.401671, Validation loss: 1.4184, lr: 0.0000\n",
      "Epoch: 649, Training loss: 1.367426, Validation loss: 1.3375, lr: 0.0000\n",
      "Epoch: 650, Training loss: 1.368696, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 651, Training loss: 1.368049, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 652, Training loss: 1.370802, Validation loss: 1.3980, lr: 0.0000\n",
      "Epoch: 653, Training loss: 1.365953, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 654, Training loss: 1.357854, Validation loss: 1.3745, lr: 0.0000\n",
      "Epoch: 655, Training loss: 1.359932, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 656, Training loss: 1.371932, Validation loss: 1.3783, lr: 0.0000\n",
      "Epoch: 657, Training loss: 1.364233, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 658, Training loss: 1.384781, Validation loss: 1.4461, lr: 0.0000\n",
      "Epoch: 659, Training loss: 1.359768, Validation loss: 1.4059, lr: 0.0000\n",
      "Epoch: 660, Training loss: 1.371152, Validation loss: 1.3581, lr: 0.0000\n",
      "Epoch: 661, Training loss: 1.382472, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 662, Training loss: 1.357594, Validation loss: 1.3800, lr: 0.0000\n",
      "Epoch: 663, Training loss: 1.360237, Validation loss: 1.3755, lr: 0.0000\n",
      "Epoch: 664, Training loss: 1.354703, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 665, Training loss: 1.374470, Validation loss: 1.3905, lr: 0.0000\n",
      "Epoch: 666, Training loss: 1.372407, Validation loss: 1.3776, lr: 0.0000\n",
      "Epoch: 667, Training loss: 1.434450, Validation loss: 1.3968, lr: 0.0000\n",
      "Epoch: 668, Training loss: 1.562915, Validation loss: 1.3882, lr: 0.0000\n",
      "Epoch: 669, Training loss: 1.391418, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 670, Training loss: 1.341678, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 671, Training loss: 1.374543, Validation loss: 1.3792, lr: 0.0000\n",
      "Epoch: 672, Training loss: 1.357492, Validation loss: 1.3875, lr: 0.0000\n",
      "Epoch: 673, Training loss: 1.358387, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 674, Training loss: 1.361444, Validation loss: 1.3481, lr: 0.0000\n",
      "Epoch: 675, Training loss: 1.349353, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 676, Training loss: 1.380861, Validation loss: 1.3769, lr: 0.0000\n",
      "Epoch: 677, Training loss: 1.369059, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 678, Training loss: 1.373637, Validation loss: 1.3881, lr: 0.0000\n",
      "Epoch: 679, Training loss: 1.366702, Validation loss: 1.3767, lr: 0.0000\n",
      "Epoch: 680, Training loss: 1.362374, Validation loss: 1.3490, lr: 0.0000\n",
      "Epoch: 681, Training loss: 1.375669, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 682, Training loss: 1.396252, Validation loss: 1.5250, lr: 0.0000\n",
      "Epoch: 683, Training loss: 1.382391, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 684, Training loss: 1.369628, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 685, Training loss: 1.366927, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 686, Training loss: 1.468215, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 687, Training loss: 1.377173, Validation loss: 1.4118, lr: 0.0000\n",
      "Epoch: 688, Training loss: 1.352243, Validation loss: 1.3552, lr: 0.0000\n",
      "Epoch: 689, Training loss: 1.366643, Validation loss: 1.3699, lr: 0.0000\n",
      "Epoch: 690, Training loss: 1.381197, Validation loss: 1.3709, lr: 0.0000\n",
      "Epoch: 691, Training loss: 1.366071, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 692, Training loss: 1.365512, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 693, Training loss: 1.354921, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 694, Training loss: 1.387154, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 695, Training loss: 1.355453, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 696, Training loss: 1.391587, Validation loss: 1.3888, lr: 0.0000\n",
      "Epoch: 697, Training loss: 1.343817, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 698, Training loss: 1.355449, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 699, Training loss: 1.353186, Validation loss: 1.3431, lr: 0.0000\n",
      "Epoch: 700, Training loss: 1.340274, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 701, Training loss: 1.353463, Validation loss: 1.4034, lr: 0.0000\n",
      "Epoch: 702, Training loss: 1.358917, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 703, Training loss: 1.356522, Validation loss: 1.3505, lr: 0.0000\n",
      "Epoch: 704, Training loss: 1.391818, Validation loss: 1.3793, lr: 0.0000\n",
      "Epoch: 705, Training loss: 1.342883, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 706, Training loss: 1.361791, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 707, Training loss: 1.385403, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 708, Training loss: 1.360859, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 709, Training loss: 1.336427, Validation loss: 1.3909, lr: 0.0000\n",
      "Epoch: 710, Training loss: 1.357777, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 711, Training loss: 1.363752, Validation loss: 1.3551, lr: 0.0000\n",
      "Epoch: 712, Training loss: 1.381201, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 713, Training loss: 1.370404, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 714, Training loss: 1.356136, Validation loss: 1.3792, lr: 0.0000\n",
      "Epoch: 715, Training loss: 1.374830, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 716, Training loss: 1.362130, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 717, Training loss: 1.361977, Validation loss: 1.3570, lr: 0.0000\n",
      "Epoch: 718, Training loss: 1.354657, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 719, Training loss: 1.326957, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 720, Training loss: 1.382438, Validation loss: 1.3713, lr: 0.0000\n",
      "Epoch: 721, Training loss: 1.386351, Validation loss: 1.3796, lr: 0.0000\n",
      "Epoch: 722, Training loss: 1.364298, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 723, Training loss: 1.373492, Validation loss: 1.4038, lr: 0.0000\n",
      "Epoch: 724, Training loss: 1.369912, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 725, Training loss: 1.356948, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 726, Training loss: 1.379765, Validation loss: 1.3767, lr: 0.0000\n",
      "Epoch: 727, Training loss: 1.359223, Validation loss: 1.3915, lr: 0.0000\n",
      "Epoch: 728, Training loss: 1.391175, Validation loss: 1.3597, lr: 0.0000\n",
      "Epoch: 729, Training loss: 1.369054, Validation loss: 1.3784, lr: 0.0000\n",
      "Epoch: 730, Training loss: 1.369952, Validation loss: 1.3767, lr: 0.0000\n",
      "Epoch: 731, Training loss: 1.354352, Validation loss: 1.3631, lr: 0.0000\n",
      "Epoch: 732, Training loss: 1.371159, Validation loss: 1.3711, lr: 0.0000\n",
      "Epoch: 733, Training loss: 1.369530, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 734, Training loss: 1.366160, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 735, Training loss: 1.368864, Validation loss: 1.5286, lr: 0.0000\n",
      "Epoch: 736, Training loss: 1.364109, Validation loss: 1.3620, lr: 0.0000\n",
      "Epoch: 737, Training loss: 1.372359, Validation loss: 1.3784, lr: 0.0000\n",
      "Epoch: 738, Training loss: 1.384293, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 739, Training loss: 1.357578, Validation loss: 1.4085, lr: 0.0000\n",
      "Epoch: 740, Training loss: 1.376360, Validation loss: 1.3679, lr: 0.0000\n",
      "Epoch: 741, Training loss: 1.362911, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 742, Training loss: 1.354359, Validation loss: 1.3757, lr: 0.0000\n",
      "Epoch: 743, Training loss: 1.367635, Validation loss: 1.3433, lr: 0.0000\n",
      "Epoch: 744, Training loss: 1.353622, Validation loss: 1.4638, lr: 0.0000\n",
      "Epoch: 745, Training loss: 1.364108, Validation loss: 1.3771, lr: 0.0000\n",
      "Epoch: 746, Training loss: 1.359662, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 747, Training loss: 1.357291, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 748, Training loss: 1.341055, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 749, Training loss: 1.375288, Validation loss: 1.3786, lr: 0.0000\n",
      "Epoch: 750, Training loss: 1.396318, Validation loss: 1.3463, lr: 0.0000\n",
      "Epoch: 751, Training loss: 1.389599, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 752, Training loss: 1.360324, Validation loss: 1.4452, lr: 0.0000\n",
      "Epoch: 753, Training loss: 1.413537, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 754, Training loss: 1.405517, Validation loss: 1.3743, lr: 0.0000\n",
      "Epoch: 755, Training loss: 1.379777, Validation loss: 1.3593, lr: 0.0000\n",
      "Epoch: 756, Training loss: 1.357939, Validation loss: 1.3293, lr: 0.0000\n",
      "Epoch: 757, Training loss: 1.367264, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 758, Training loss: 1.393568, Validation loss: 1.3785, lr: 0.0000\n",
      "Epoch: 759, Training loss: 1.336717, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 760, Training loss: 1.353312, Validation loss: 1.3966, lr: 0.0000\n",
      "Epoch: 761, Training loss: 1.375093, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 762, Training loss: 1.347316, Validation loss: 1.3757, lr: 0.0000\n",
      "Epoch: 763, Training loss: 1.429970, Validation loss: 1.3803, lr: 0.0000\n",
      "Epoch: 764, Training loss: 1.363494, Validation loss: 1.3798, lr: 0.0000\n",
      "Epoch: 765, Training loss: 1.351221, Validation loss: 1.3778, lr: 0.0000\n",
      "Epoch: 766, Training loss: 1.366644, Validation loss: 1.4551, lr: 0.0000\n",
      "Epoch: 767, Training loss: 1.366407, Validation loss: 1.3468, lr: 0.0000\n",
      "Epoch: 768, Training loss: 1.363679, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 769, Training loss: 1.354500, Validation loss: 1.3711, lr: 0.0000\n",
      "Epoch: 770, Training loss: 1.339370, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 771, Training loss: 1.367749, Validation loss: 1.3523, lr: 0.0000\n",
      "Epoch: 772, Training loss: 1.360816, Validation loss: 1.3703, lr: 0.0000\n",
      "Epoch: 773, Training loss: 1.404376, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 774, Training loss: 1.354931, Validation loss: 1.3391, lr: 0.0000\n",
      "Epoch: 775, Training loss: 1.383535, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 776, Training loss: 1.385837, Validation loss: 1.3793, lr: 0.0000\n",
      "Epoch: 777, Training loss: 1.374429, Validation loss: 1.3329, lr: 0.0000\n",
      "Epoch: 778, Training loss: 1.379244, Validation loss: 1.3225, lr: 0.0000\n",
      "Epoch: 779, Training loss: 1.372577, Validation loss: 1.3436, lr: 0.0000\n",
      "Epoch: 780, Training loss: 1.368659, Validation loss: 1.3399, lr: 0.0000\n",
      "Epoch: 781, Training loss: 1.360098, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 782, Training loss: 1.379349, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 783, Training loss: 1.363535, Validation loss: 1.3947, lr: 0.0000\n",
      "Epoch: 784, Training loss: 1.367585, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 785, Training loss: 1.359737, Validation loss: 1.3874, lr: 0.0000\n",
      "Epoch: 786, Training loss: 1.381703, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 787, Training loss: 1.363501, Validation loss: 1.3802, lr: 0.0000\n",
      "Epoch: 788, Training loss: 1.350331, Validation loss: 1.3799, lr: 0.0000\n",
      "Epoch: 789, Training loss: 1.358810, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 790, Training loss: 1.351142, Validation loss: 1.3789, lr: 0.0000\n",
      "Epoch: 791, Training loss: 1.347945, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 792, Training loss: 1.379536, Validation loss: 1.3758, lr: 0.0000\n",
      "Epoch: 793, Training loss: 1.342297, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 794, Training loss: 1.391248, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 795, Training loss: 1.358969, Validation loss: 1.3788, lr: 0.0000\n",
      "Epoch: 796, Training loss: 1.372623, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 797, Training loss: 1.378289, Validation loss: 1.3715, lr: 0.0000\n",
      "Epoch: 798, Training loss: 1.355357, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 799, Training loss: 1.358884, Validation loss: 1.3786, lr: 0.0000\n",
      "Epoch: 800, Training loss: 1.351428, Validation loss: 1.3737, lr: 0.0000\n",
      "Epoch: 801, Training loss: 1.385769, Validation loss: 1.6406, lr: 0.0000\n",
      "Epoch: 802, Training loss: 1.383600, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 803, Training loss: 1.368356, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 804, Training loss: 1.371377, Validation loss: 1.3792, lr: 0.0000\n",
      "Epoch: 805, Training loss: 1.371917, Validation loss: 1.3883, lr: 0.0000\n",
      "Epoch: 806, Training loss: 1.409727, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 807, Training loss: 1.397779, Validation loss: 1.5331, lr: 0.0000\n",
      "Epoch: 808, Training loss: 1.368953, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 809, Training loss: 1.365537, Validation loss: 1.3775, lr: 0.0000\n",
      "Epoch: 810, Training loss: 1.380294, Validation loss: 1.3789, lr: 0.0000\n",
      "Epoch: 811, Training loss: 1.359742, Validation loss: 1.3760, lr: 0.0000\n",
      "Epoch: 812, Training loss: 1.380337, Validation loss: 1.3075, lr: 0.0000\n",
      "Epoch: 813, Training loss: 1.347769, Validation loss: 1.3770, lr: 0.0000\n",
      "Epoch: 814, Training loss: 1.359299, Validation loss: 1.3755, lr: 0.0000\n",
      "Epoch: 815, Training loss: 1.349522, Validation loss: 1.3357, lr: 0.0000\n",
      "Epoch: 816, Training loss: 1.361965, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 817, Training loss: 1.374032, Validation loss: 1.3701, lr: 0.0000\n",
      "Epoch: 818, Training loss: 1.357904, Validation loss: 1.3605, lr: 0.0000\n",
      "Epoch: 819, Training loss: 1.353724, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 820, Training loss: 1.346027, Validation loss: 1.4705, lr: 0.0000\n",
      "Epoch: 821, Training loss: 1.364464, Validation loss: 1.3742, lr: 0.0000\n",
      "Epoch: 822, Training loss: 1.357381, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 823, Training loss: 1.342436, Validation loss: 1.3735, lr: 0.0000\n",
      "Epoch: 824, Training loss: 1.365470, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 825, Training loss: 1.335637, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 826, Training loss: 1.363943, Validation loss: 1.7299, lr: 0.0000\n",
      "Epoch: 827, Training loss: 1.360815, Validation loss: 1.3873, lr: 0.0000\n",
      "Epoch: 828, Training loss: 1.374750, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 829, Training loss: 1.367329, Validation loss: 1.3757, lr: 0.0000\n",
      "Epoch: 830, Training loss: 1.365141, Validation loss: 1.3593, lr: 0.0000\n",
      "Epoch: 831, Training loss: 1.363817, Validation loss: 1.6324, lr: 0.0000\n",
      "Epoch: 832, Training loss: 1.366255, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 833, Training loss: 1.423352, Validation loss: 1.3791, lr: 0.0000\n",
      "Epoch: 834, Training loss: 1.368527, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 835, Training loss: 1.361219, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 836, Training loss: 1.354961, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 837, Training loss: 1.368653, Validation loss: 1.4001, lr: 0.0000\n",
      "Epoch: 838, Training loss: 1.356144, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 839, Training loss: 1.370765, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 840, Training loss: 1.355048, Validation loss: 1.3711, lr: 0.0000\n",
      "Epoch: 841, Training loss: 1.442839, Validation loss: 1.3647, lr: 0.0000\n",
      "Epoch: 842, Training loss: 1.366965, Validation loss: 1.3889, lr: 0.0000\n",
      "Epoch: 843, Training loss: 1.368139, Validation loss: 1.3554, lr: 0.0000\n",
      "Epoch: 844, Training loss: 1.378579, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 845, Training loss: 1.391799, Validation loss: 1.3769, lr: 0.0000\n",
      "Epoch: 846, Training loss: 1.374013, Validation loss: 1.4113, lr: 0.0000\n",
      "Epoch: 847, Training loss: 1.360087, Validation loss: 1.4509, lr: 0.0000\n",
      "Epoch: 848, Training loss: 1.370232, Validation loss: 1.3887, lr: 0.0000\n",
      "Epoch: 849, Training loss: 1.381994, Validation loss: 1.3728, lr: 0.0000\n",
      "Epoch: 850, Training loss: 1.360886, Validation loss: 1.3797, lr: 0.0000\n",
      "Epoch: 851, Training loss: 1.384091, Validation loss: 1.3717, lr: 0.0000\n",
      "Epoch: 852, Training loss: 1.364045, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 853, Training loss: 1.354121, Validation loss: 1.3774, lr: 0.0000\n",
      "Epoch: 854, Training loss: 1.375753, Validation loss: 1.3530, lr: 0.0000\n",
      "Epoch: 855, Training loss: 1.365496, Validation loss: 1.4073, lr: 0.0000\n",
      "Epoch: 856, Training loss: 1.352054, Validation loss: 1.3582, lr: 0.0000\n",
      "Epoch: 857, Training loss: 1.338186, Validation loss: 1.3986, lr: 0.0000\n",
      "Epoch: 858, Training loss: 1.368822, Validation loss: 1.3896, lr: 0.0000\n",
      "Epoch: 859, Training loss: 1.372572, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 860, Training loss: 1.401507, Validation loss: 1.3772, lr: 0.0000\n",
      "Epoch: 861, Training loss: 1.357679, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 862, Training loss: 1.364414, Validation loss: 1.3746, lr: 0.0000\n",
      "Epoch: 863, Training loss: 1.369016, Validation loss: 1.3546, lr: 0.0000\n",
      "Epoch: 864, Training loss: 1.365948, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 865, Training loss: 1.344122, Validation loss: 1.3609, lr: 0.0000\n",
      "Epoch: 866, Training loss: 1.417836, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 867, Training loss: 1.338431, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 868, Training loss: 1.359908, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 869, Training loss: 1.367308, Validation loss: 1.3744, lr: 0.0000\n",
      "Epoch: 870, Training loss: 1.350642, Validation loss: 1.3758, lr: 0.0000\n",
      "Epoch: 871, Training loss: 1.371892, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 872, Training loss: 1.398913, Validation loss: 1.3573, lr: 0.0000\n",
      "Epoch: 873, Training loss: 1.365050, Validation loss: 1.3600, lr: 0.0000\n",
      "Epoch: 874, Training loss: 1.367097, Validation loss: 1.4690, lr: 0.0000\n",
      "Epoch: 875, Training loss: 1.353813, Validation loss: 1.3779, lr: 0.0000\n",
      "Epoch: 876, Training loss: 1.374131, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 877, Training loss: 1.368181, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 878, Training loss: 1.366320, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 879, Training loss: 1.356730, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 880, Training loss: 1.382578, Validation loss: 1.3180, lr: 0.0000\n",
      "Epoch: 881, Training loss: 1.371720, Validation loss: 1.3759, lr: 0.0000\n",
      "Epoch: 882, Training loss: 1.422916, Validation loss: 1.3671, lr: 0.0000\n",
      "Epoch: 883, Training loss: 1.368212, Validation loss: 1.3763, lr: 0.0000\n",
      "Epoch: 884, Training loss: 1.378029, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 885, Training loss: 1.373661, Validation loss: 1.3356, lr: 0.0000\n",
      "Epoch: 886, Training loss: 1.346057, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 887, Training loss: 1.364137, Validation loss: 1.3664, lr: 0.0000\n",
      "Epoch: 888, Training loss: 1.374820, Validation loss: 1.4344, lr: 0.0000\n",
      "Epoch: 889, Training loss: 1.331994, Validation loss: 1.3892, lr: 0.0000\n",
      "Epoch: 890, Training loss: 1.346457, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 891, Training loss: 1.363963, Validation loss: 1.3789, lr: 0.0000\n",
      "Epoch: 892, Training loss: 1.416917, Validation loss: 1.3968, lr: 0.0000\n",
      "Epoch: 893, Training loss: 1.357334, Validation loss: 1.3906, lr: 0.0000\n",
      "Epoch: 894, Training loss: 1.372663, Validation loss: 1.3885, lr: 0.0000\n",
      "Epoch: 895, Training loss: 1.359880, Validation loss: 1.3731, lr: 0.0000\n",
      "Epoch: 896, Training loss: 1.366440, Validation loss: 3.5408, lr: 0.0000\n",
      "Epoch: 897, Training loss: 1.368780, Validation loss: 1.3874, lr: 0.0000\n",
      "Epoch: 898, Training loss: 1.332731, Validation loss: 1.3774, lr: 0.0000\n",
      "Epoch: 899, Training loss: 1.403277, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 900, Training loss: 1.368589, Validation loss: 1.3468, lr: 0.0000\n",
      "Epoch: 901, Training loss: 1.369034, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 902, Training loss: 1.360759, Validation loss: 1.3881, lr: 0.0000\n",
      "Epoch: 903, Training loss: 1.355585, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 904, Training loss: 1.359653, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 905, Training loss: 1.391948, Validation loss: 1.3779, lr: 0.0000\n",
      "Epoch: 906, Training loss: 1.358427, Validation loss: 1.3423, lr: 0.0000\n",
      "Epoch: 907, Training loss: 1.364477, Validation loss: 1.3731, lr: 0.0000\n",
      "Epoch: 908, Training loss: 1.446559, Validation loss: 1.3739, lr: 0.0000\n",
      "Epoch: 909, Training loss: 1.376217, Validation loss: 1.3579, lr: 0.0000\n",
      "Epoch: 910, Training loss: 1.353478, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 911, Training loss: 1.372968, Validation loss: 1.3779, lr: 0.0000\n",
      "Epoch: 912, Training loss: 1.372570, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 913, Training loss: 1.366321, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 914, Training loss: 1.384881, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 915, Training loss: 1.393776, Validation loss: 1.4425, lr: 0.0000\n",
      "Epoch: 916, Training loss: 1.350865, Validation loss: 1.3899, lr: 0.0000\n",
      "Epoch: 917, Training loss: 1.357771, Validation loss: 1.3791, lr: 0.0000\n",
      "Epoch: 918, Training loss: 1.373437, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 919, Training loss: 1.350954, Validation loss: 1.3691, lr: 0.0000\n",
      "Epoch: 920, Training loss: 1.384500, Validation loss: 1.3782, lr: 0.0000\n",
      "Epoch: 921, Training loss: 1.376319, Validation loss: 1.3316, lr: 0.0000\n",
      "Epoch: 922, Training loss: 1.327163, Validation loss: 1.3881, lr: 0.0000\n",
      "Epoch: 923, Training loss: 1.367791, Validation loss: 1.4025, lr: 0.0000\n",
      "Epoch: 924, Training loss: 1.356172, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 925, Training loss: 1.354862, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 926, Training loss: 1.364654, Validation loss: 1.3880, lr: 0.0000\n",
      "Epoch: 927, Training loss: 1.370923, Validation loss: 1.3888, lr: 0.0000\n",
      "Epoch: 928, Training loss: 1.371867, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 929, Training loss: 1.378672, Validation loss: 1.3797, lr: 0.0000\n",
      "Epoch: 930, Training loss: 1.370131, Validation loss: 1.3976, lr: 0.0000\n",
      "Epoch: 931, Training loss: 1.335579, Validation loss: 1.3536, lr: 0.0000\n",
      "Epoch: 932, Training loss: 1.367908, Validation loss: 1.3767, lr: 0.0000\n",
      "Epoch: 933, Training loss: 1.496467, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 934, Training loss: 1.346371, Validation loss: 1.3737, lr: 0.0000\n",
      "Epoch: 935, Training loss: 1.367861, Validation loss: 1.3754, lr: 0.0000\n",
      "Epoch: 936, Training loss: 1.389912, Validation loss: 1.3480, lr: 0.0000\n",
      "Epoch: 937, Training loss: 1.374443, Validation loss: 1.3775, lr: 0.0000\n",
      "Epoch: 938, Training loss: 1.366024, Validation loss: 1.3649, lr: 0.0000\n",
      "Epoch: 939, Training loss: 1.405952, Validation loss: 1.4050, lr: 0.0000\n",
      "Epoch: 940, Training loss: 1.375119, Validation loss: 1.3796, lr: 0.0000\n",
      "Epoch: 941, Training loss: 1.359488, Validation loss: 1.3593, lr: 0.0000\n",
      "Epoch: 942, Training loss: 1.359318, Validation loss: 1.3785, lr: 0.0000\n",
      "Epoch: 943, Training loss: 1.363555, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 944, Training loss: 1.380476, Validation loss: 1.3894, lr: 0.0000\n",
      "Epoch: 945, Training loss: 1.388274, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 946, Training loss: 1.367363, Validation loss: 1.3732, lr: 0.0000\n",
      "Epoch: 947, Training loss: 1.363625, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 948, Training loss: 1.366535, Validation loss: 1.4084, lr: 0.0000\n",
      "Epoch: 949, Training loss: 1.361993, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 950, Training loss: 1.360264, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 951, Training loss: 1.360532, Validation loss: 1.3764, lr: 0.0000\n",
      "Epoch: 952, Training loss: 1.374839, Validation loss: 1.3788, lr: 0.0000\n",
      "Epoch: 953, Training loss: 1.379403, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 954, Training loss: 1.366755, Validation loss: 1.3784, lr: 0.0000\n",
      "Epoch: 955, Training loss: 1.364025, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 956, Training loss: 1.365692, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 957, Training loss: 1.381284, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 958, Training loss: 1.368353, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 959, Training loss: 1.351045, Validation loss: 1.3882, lr: 0.0000\n",
      "Epoch: 960, Training loss: 1.355643, Validation loss: 1.3769, lr: 0.0000\n",
      "Epoch: 961, Training loss: 1.363819, Validation loss: 1.3448, lr: 0.0000\n",
      "Epoch: 962, Training loss: 1.386510, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 963, Training loss: 1.363716, Validation loss: 1.3393, lr: 0.0000\n",
      "Epoch: 964, Training loss: 1.381335, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 965, Training loss: 1.363832, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 966, Training loss: 1.364363, Validation loss: 1.3765, lr: 0.0000\n",
      "Epoch: 967, Training loss: 1.352036, Validation loss: 1.3621, lr: 0.0000\n",
      "Epoch: 968, Training loss: 1.373221, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 969, Training loss: 1.369810, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 970, Training loss: 1.399859, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 971, Training loss: 1.379732, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 972, Training loss: 1.383889, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 973, Training loss: 1.356913, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 974, Training loss: 1.376703, Validation loss: 1.3531, lr: 0.0000\n",
      "Epoch: 975, Training loss: 1.389347, Validation loss: 1.3797, lr: 0.0000\n",
      "Epoch: 976, Training loss: 1.362434, Validation loss: 1.3657, lr: 0.0000\n",
      "Epoch: 977, Training loss: 1.362206, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 978, Training loss: 1.368796, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 979, Training loss: 1.371783, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 980, Training loss: 1.378711, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 981, Training loss: 1.346559, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 982, Training loss: 1.352103, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 983, Training loss: 1.356536, Validation loss: 1.3647, lr: 0.0000\n",
      "Epoch: 984, Training loss: 1.445310, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 985, Training loss: 1.384131, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 986, Training loss: 1.374078, Validation loss: 1.3803, lr: 0.0000\n",
      "Epoch: 987, Training loss: 1.373760, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 988, Training loss: 1.376045, Validation loss: 1.3891, lr: 0.0000\n",
      "Epoch: 989, Training loss: 1.351702, Validation loss: 1.4549, lr: 0.0000\n",
      "Epoch: 990, Training loss: 1.365554, Validation loss: 1.3776, lr: 0.0000\n",
      "Epoch: 991, Training loss: 1.362047, Validation loss: 1.3482, lr: 0.0000\n",
      "Epoch: 992, Training loss: 1.355502, Validation loss: 1.3790, lr: 0.0000\n",
      "Epoch: 993, Training loss: 1.358404, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 994, Training loss: 1.363439, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 995, Training loss: 1.360046, Validation loss: 1.4222, lr: 0.0000\n",
      "Epoch: 996, Training loss: 1.357806, Validation loss: 1.3799, lr: 0.0000\n",
      "Epoch: 997, Training loss: 1.352933, Validation loss: 1.4620, lr: 0.0000\n",
      "Epoch: 998, Training loss: 1.345203, Validation loss: 1.3799, lr: 0.0000\n",
      "Epoch: 999, Training loss: 1.365621, Validation loss: 1.3448, lr: 0.0000\n",
      "Final test loss: 1.3825\n",
      "=== Run 07/10 ===\n",
      "\n",
      "---- Settings: \n",
      "\n",
      "epochs : 1000\n",
      "hidden_channels : [32]\n",
      "out_channels : 10\n",
      "inner_product_features : False\n",
      "batch_size : 64\n",
      "lr : 0.01\n",
      "momentum : 0.9\n",
      "dropout : 0.0\n",
      "batch_norm : batch_norm\n",
      "bias : True\n",
      "order : 2\n",
      "diffusion : True\n",
      "frac_sampled_nb : -1\n",
      "include_positions : False\n",
      "include_self : True\n",
      "vec_norm : False\n",
      "emb_norm : False\n",
      "seed : 0\n",
      "dim_signal : 100\n",
      "dim_emb : 100\n",
      "n_sampled_nb : -1\n",
      "\n",
      "---- Number of features to pass to the MLP:  1010100\n",
      "---- Total number of parameters:  32323627\n",
      "\n",
      "Using device cuda:0\n",
      "\n",
      "---- Training network ...\n",
      "\n",
      "---- Timestamp: 20250614-144943\n",
      "\n",
      " *och: 0, Training loss: 1.464928, Validation loss: 2.4962, lr: 0.0100\n",
      " *och: 1, Training loss: 1.359722, Validation loss: 1.3673, lr: 0.0100\n",
      "Epoch: 2, Training loss: 1.427556, Validation loss: 1.3756, lr: 0.0100\n",
      "Epoch: 3, Training loss: 1.402263, Validation loss: 1.3816, lr: 0.0100\n",
      "Epoch: 4, Training loss: 1.461493, Validation loss: 1.3955, lr: 0.0100\n",
      "Epoch: 5, Training loss: 1.386295, Validation loss: 1.3848, lr: 0.0100\n",
      "Epoch: 6, Training loss: 1.398168, Validation loss: 1.3711, lr: 0.0100\n",
      "Epoch: 7, Training loss: 1.362723, Validation loss: 1.3777, lr: 0.0100\n",
      "Epoch: 8, Training loss: 1.385490, Validation loss: 1.3802, lr: 0.0100\n",
      "Epoch: 9, Training loss: 1.362670, Validation loss: 1.3850, lr: 0.0100\n",
      " *och: 10, Training loss: 1.409322, Validation loss: 1.3660, lr: 0.0100\n",
      "Epoch: 11, Training loss: 1.367381, Validation loss: 1.3809, lr: 0.0100\n",
      "Epoch: 12, Training loss: 1.388061, Validation loss: 1.3803, lr: 0.0010\n",
      "Epoch: 13, Training loss: 1.379386, Validation loss: 1.3726, lr: 0.0010\n",
      "Epoch: 14, Training loss: 1.383786, Validation loss: 1.3769, lr: 0.0010\n",
      "Epoch: 15, Training loss: 1.403776, Validation loss: 1.3792, lr: 0.0010\n",
      "Epoch: 16, Training loss: 1.406289, Validation loss: 1.3697, lr: 0.0010\n",
      "Epoch: 17, Training loss: 1.368394, Validation loss: 1.4337, lr: 0.0010\n",
      "Epoch: 18, Training loss: 1.379452, Validation loss: 1.3845, lr: 0.0010\n",
      "Epoch: 19, Training loss: 1.414158, Validation loss: 1.3860, lr: 0.0010\n",
      "Epoch: 20, Training loss: 1.492304, Validation loss: 1.3867, lr: 0.0010\n",
      "Epoch: 21, Training loss: 1.431445, Validation loss: 1.3846, lr: 0.0010\n",
      "Epoch: 22, Training loss: 1.363200, Validation loss: 1.3815, lr: 0.0010\n",
      "Epoch: 23, Training loss: 1.369300, Validation loss: 1.3816, lr: 0.0001\n",
      "Epoch: 24, Training loss: 1.385165, Validation loss: 1.3859, lr: 0.0001\n",
      "Epoch: 25, Training loss: 1.366239, Validation loss: 1.3792, lr: 0.0001\n",
      " *och: 26, Training loss: 1.375854, Validation loss: 1.3609, lr: 0.0001\n",
      "Epoch: 27, Training loss: 1.394882, Validation loss: 1.3865, lr: 0.0001\n",
      "Epoch: 28, Training loss: 1.355331, Validation loss: 1.3892, lr: 0.0001\n",
      "Epoch: 29, Training loss: 1.360128, Validation loss: 1.3627, lr: 0.0001\n",
      "Epoch: 30, Training loss: 1.359194, Validation loss: 1.3819, lr: 0.0001\n",
      "Epoch: 31, Training loss: 1.399895, Validation loss: 1.3873, lr: 0.0001\n",
      "Epoch: 32, Training loss: 1.380197, Validation loss: 1.3829, lr: 0.0001\n",
      "Epoch: 33, Training loss: 1.361327, Validation loss: 1.3855, lr: 0.0001\n",
      "Epoch: 34, Training loss: 1.431615, Validation loss: 1.3770, lr: 0.0001\n",
      "Epoch: 35, Training loss: 1.363918, Validation loss: 1.3654, lr: 0.0001\n",
      "Epoch: 36, Training loss: 1.380052, Validation loss: 1.3831, lr: 0.0001\n",
      "Epoch: 37, Training loss: 1.374403, Validation loss: 1.3831, lr: 0.0001\n",
      "Epoch: 38, Training loss: 1.373993, Validation loss: 1.3821, lr: 0.0001\n",
      "Epoch: 39, Training loss: 1.397789, Validation loss: 1.3786, lr: 0.0000\n",
      "Epoch: 40, Training loss: 1.381597, Validation loss: 1.3788, lr: 0.0000\n",
      "Epoch: 41, Training loss: 1.372497, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 42, Training loss: 1.381012, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 43, Training loss: 1.465584, Validation loss: 1.3917, lr: 0.0000\n",
      "Epoch: 44, Training loss: 1.406368, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 45, Training loss: 1.410653, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 46, Training loss: 1.366102, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 47, Training loss: 1.465070, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 48, Training loss: 1.367606, Validation loss: 1.4255, lr: 0.0000\n",
      "Epoch: 49, Training loss: 1.377332, Validation loss: 1.4084, lr: 0.0000\n",
      "Epoch: 50, Training loss: 1.386272, Validation loss: 1.3803, lr: 0.0000\n",
      "Epoch: 51, Training loss: 1.393630, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 52, Training loss: 1.407710, Validation loss: 1.3728, lr: 0.0000\n",
      "Epoch: 53, Training loss: 1.402797, Validation loss: 1.3779, lr: 0.0000\n",
      "Epoch: 54, Training loss: 1.359412, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 55, Training loss: 1.375591, Validation loss: 1.3778, lr: 0.0000\n",
      "Epoch: 56, Training loss: 1.361549, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 57, Training loss: 1.489182, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 58, Training loss: 1.371825, Validation loss: 1.3744, lr: 0.0000\n",
      "Epoch: 59, Training loss: 1.362723, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 60, Training loss: 1.397255, Validation loss: 1.3889, lr: 0.0000\n",
      "Epoch: 61, Training loss: 1.366580, Validation loss: 1.3921, lr: 0.0000\n",
      "Epoch: 62, Training loss: 1.395516, Validation loss: 1.3690, lr: 0.0000\n",
      "Epoch: 63, Training loss: 1.374565, Validation loss: 1.3893, lr: 0.0000\n",
      "Epoch: 64, Training loss: 1.424001, Validation loss: 1.3783, lr: 0.0000\n",
      "Epoch: 65, Training loss: 1.389313, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 66, Training loss: 1.377498, Validation loss: 1.3906, lr: 0.0000\n",
      "Epoch: 67, Training loss: 1.378889, Validation loss: 1.3809, lr: 0.0000\n",
      "Epoch: 68, Training loss: 1.375915, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 69, Training loss: 1.359223, Validation loss: 1.3784, lr: 0.0000\n",
      " *och: 70, Training loss: 1.384633, Validation loss: 1.3595, lr: 0.0000\n",
      "Epoch: 71, Training loss: 1.358386, Validation loss: 1.3792, lr: 0.0000\n",
      "Epoch: 72, Training loss: 1.373035, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 73, Training loss: 1.358175, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 74, Training loss: 1.387259, Validation loss: 1.3783, lr: 0.0000\n",
      "Epoch: 75, Training loss: 1.406814, Validation loss: 1.4131, lr: 0.0000\n",
      "Epoch: 76, Training loss: 1.354354, Validation loss: 1.3754, lr: 0.0000\n",
      "Epoch: 77, Training loss: 1.386338, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 78, Training loss: 1.378691, Validation loss: 1.3965, lr: 0.0000\n",
      "Epoch: 79, Training loss: 1.377304, Validation loss: 1.3902, lr: 0.0000\n",
      "Epoch: 80, Training loss: 1.389209, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 81, Training loss: 1.355611, Validation loss: 1.3762, lr: 0.0000\n",
      "Epoch: 82, Training loss: 1.424182, Validation loss: 1.3946, lr: 0.0000\n",
      "Epoch: 83, Training loss: 1.378957, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 84, Training loss: 1.384583, Validation loss: 1.3744, lr: 0.0000\n",
      "Epoch: 85, Training loss: 1.392742, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 86, Training loss: 1.397387, Validation loss: 1.3905, lr: 0.0000\n",
      "Epoch: 87, Training loss: 1.368280, Validation loss: 1.3965, lr: 0.0000\n",
      "Epoch: 88, Training loss: 1.404664, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 89, Training loss: 1.380540, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 90, Training loss: 1.428701, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 91, Training loss: 1.372226, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 92, Training loss: 1.406406, Validation loss: 1.3787, lr: 0.0000\n",
      "Epoch: 93, Training loss: 1.444754, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 94, Training loss: 1.422257, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 95, Training loss: 1.371284, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 96, Training loss: 1.360626, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 97, Training loss: 1.386595, Validation loss: 1.3900, lr: 0.0000\n",
      "Epoch: 98, Training loss: 1.350935, Validation loss: 1.3793, lr: 0.0000\n",
      " *och: 99, Training loss: 1.380379, Validation loss: 1.3433, lr: 0.0000\n",
      "Epoch: 100, Training loss: 1.400535, Validation loss: 1.3739, lr: 0.0000\n",
      "Epoch: 101, Training loss: 1.375318, Validation loss: 1.4127, lr: 0.0000\n",
      "Epoch: 102, Training loss: 1.410841, Validation loss: 1.5696, lr: 0.0000\n",
      "Epoch: 103, Training loss: 1.405191, Validation loss: 1.3791, lr: 0.0000\n",
      "Epoch: 104, Training loss: 1.359107, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 105, Training loss: 1.359552, Validation loss: 1.3716, lr: 0.0000\n",
      "Epoch: 106, Training loss: 1.399292, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 107, Training loss: 1.370398, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 108, Training loss: 1.394295, Validation loss: 1.3798, lr: 0.0000\n",
      "Epoch: 109, Training loss: 1.390867, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 110, Training loss: 1.367841, Validation loss: 1.3550, lr: 0.0000\n",
      "Epoch: 111, Training loss: 1.373125, Validation loss: 1.3798, lr: 0.0000\n",
      "Epoch: 112, Training loss: 1.383276, Validation loss: 1.3492, lr: 0.0000\n",
      "Epoch: 113, Training loss: 1.346540, Validation loss: 1.4112, lr: 0.0000\n",
      "Epoch: 114, Training loss: 1.398131, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 115, Training loss: 1.368767, Validation loss: 1.3899, lr: 0.0000\n",
      "Epoch: 116, Training loss: 1.364312, Validation loss: 1.3785, lr: 0.0000\n",
      "Epoch: 117, Training loss: 1.368118, Validation loss: 1.3795, lr: 0.0000\n",
      "Epoch: 118, Training loss: 1.385838, Validation loss: 1.4038, lr: 0.0000\n",
      "Epoch: 119, Training loss: 1.388397, Validation loss: 1.3704, lr: 0.0000\n",
      "Epoch: 120, Training loss: 1.383111, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 121, Training loss: 1.370104, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 122, Training loss: 1.386452, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 123, Training loss: 1.377008, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 124, Training loss: 1.392987, Validation loss: 1.3940, lr: 0.0000\n",
      "Epoch: 125, Training loss: 1.402198, Validation loss: 1.3875, lr: 0.0000\n",
      "Epoch: 126, Training loss: 1.410701, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 127, Training loss: 1.440061, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 128, Training loss: 1.408154, Validation loss: 1.3633, lr: 0.0000\n",
      "Epoch: 129, Training loss: 1.375607, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 130, Training loss: 1.382004, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 131, Training loss: 1.389937, Validation loss: 1.3687, lr: 0.0000\n",
      "Epoch: 132, Training loss: 1.366696, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 133, Training loss: 1.370821, Validation loss: 1.4196, lr: 0.0000\n",
      "Epoch: 134, Training loss: 1.383501, Validation loss: 1.3928, lr: 0.0000\n",
      "Epoch: 135, Training loss: 1.374481, Validation loss: 1.4258, lr: 0.0000\n",
      "Epoch: 136, Training loss: 1.366499, Validation loss: 1.3873, lr: 0.0000\n",
      "Epoch: 137, Training loss: 1.363697, Validation loss: 1.3783, lr: 0.0000\n",
      "Epoch: 138, Training loss: 1.377660, Validation loss: 1.3673, lr: 0.0000\n",
      "Epoch: 139, Training loss: 1.355658, Validation loss: 1.3680, lr: 0.0000\n",
      "Epoch: 140, Training loss: 1.399089, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 141, Training loss: 1.365363, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 142, Training loss: 1.378105, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 143, Training loss: 1.387418, Validation loss: 1.3698, lr: 0.0000\n",
      "Epoch: 144, Training loss: 1.376485, Validation loss: 1.3888, lr: 0.0000\n",
      "Epoch: 145, Training loss: 1.381160, Validation loss: 1.3796, lr: 0.0000\n",
      "Epoch: 146, Training loss: 1.369258, Validation loss: 1.3768, lr: 0.0000\n",
      "Epoch: 147, Training loss: 1.387625, Validation loss: 1.3730, lr: 0.0000\n",
      "Epoch: 148, Training loss: 1.363786, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 149, Training loss: 1.380110, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 150, Training loss: 1.371790, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 151, Training loss: 1.380855, Validation loss: 1.3877, lr: 0.0000\n",
      "Epoch: 152, Training loss: 1.367357, Validation loss: 1.4030, lr: 0.0000\n",
      "Epoch: 153, Training loss: 1.393343, Validation loss: 1.3878, lr: 0.0000\n",
      "Epoch: 154, Training loss: 1.394134, Validation loss: 1.3894, lr: 0.0000\n",
      "Epoch: 155, Training loss: 1.367592, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 156, Training loss: 1.382660, Validation loss: 1.3705, lr: 0.0000\n",
      "Epoch: 157, Training loss: 1.384906, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 158, Training loss: 1.374390, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 159, Training loss: 1.380535, Validation loss: 1.3769, lr: 0.0000\n",
      "Epoch: 160, Training loss: 1.386890, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 161, Training loss: 1.384656, Validation loss: 1.3523, lr: 0.0000\n",
      "Epoch: 162, Training loss: 1.390209, Validation loss: 1.3746, lr: 0.0000\n",
      "Epoch: 163, Training loss: 1.386068, Validation loss: 1.3798, lr: 0.0000\n",
      "Epoch: 164, Training loss: 1.380885, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 165, Training loss: 1.362760, Validation loss: 1.3674, lr: 0.0000\n",
      "Epoch: 166, Training loss: 1.373007, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 167, Training loss: 1.366937, Validation loss: 1.3776, lr: 0.0000\n",
      "Epoch: 168, Training loss: 1.379267, Validation loss: 1.3769, lr: 0.0000\n",
      "Epoch: 169, Training loss: 1.371818, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 170, Training loss: 1.371658, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 171, Training loss: 1.375765, Validation loss: 1.3787, lr: 0.0000\n",
      "Epoch: 172, Training loss: 1.357395, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 173, Training loss: 1.383541, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 174, Training loss: 1.407792, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 175, Training loss: 1.381751, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 176, Training loss: 1.400554, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 177, Training loss: 1.386819, Validation loss: 1.3532, lr: 0.0000\n",
      "Epoch: 178, Training loss: 1.379636, Validation loss: 1.3877, lr: 0.0000\n",
      "Epoch: 179, Training loss: 1.380121, Validation loss: 1.3752, lr: 0.0000\n",
      "Epoch: 180, Training loss: 1.369143, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 181, Training loss: 1.375572, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 182, Training loss: 1.453943, Validation loss: 1.3790, lr: 0.0000\n",
      "Epoch: 183, Training loss: 1.354733, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 184, Training loss: 1.401048, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 185, Training loss: 1.395853, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 186, Training loss: 1.406800, Validation loss: 1.3803, lr: 0.0000\n",
      " *och: 187, Training loss: 1.434732, Validation loss: 1.3365, lr: 0.0000\n",
      "Epoch: 188, Training loss: 1.373424, Validation loss: 1.3931, lr: 0.0000\n",
      "Epoch: 189, Training loss: 1.378781, Validation loss: 1.3893, lr: 0.0000\n",
      "Epoch: 190, Training loss: 1.355836, Validation loss: 1.3789, lr: 0.0000\n",
      "Epoch: 191, Training loss: 1.383519, Validation loss: 1.3727, lr: 0.0000\n",
      "Epoch: 192, Training loss: 1.467190, Validation loss: 1.3781, lr: 0.0000\n",
      "Epoch: 193, Training loss: 1.385963, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 194, Training loss: 1.380436, Validation loss: 1.3889, lr: 0.0000\n",
      "Epoch: 195, Training loss: 1.378062, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 196, Training loss: 1.496273, Validation loss: 1.3910, lr: 0.0000\n",
      "Epoch: 197, Training loss: 1.379779, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 198, Training loss: 1.408909, Validation loss: 1.4015, lr: 0.0000\n",
      "Epoch: 199, Training loss: 1.362726, Validation loss: 1.3590, lr: 0.0000\n",
      "Epoch: 200, Training loss: 1.375398, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 201, Training loss: 1.377727, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 202, Training loss: 1.379793, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 203, Training loss: 1.383618, Validation loss: 1.3946, lr: 0.0000\n",
      "Epoch: 204, Training loss: 1.390388, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 205, Training loss: 1.374626, Validation loss: 1.3772, lr: 0.0000\n",
      "Epoch: 206, Training loss: 1.375589, Validation loss: 1.3706, lr: 0.0000\n",
      "Epoch: 207, Training loss: 1.390250, Validation loss: 1.3871, lr: 0.0000\n",
      "Epoch: 208, Training loss: 1.373477, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 209, Training loss: 1.383681, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 210, Training loss: 1.366546, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 211, Training loss: 1.374902, Validation loss: 1.3799, lr: 0.0000\n",
      "Epoch: 212, Training loss: 1.374953, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 213, Training loss: 1.373555, Validation loss: 1.3795, lr: 0.0000\n",
      "Epoch: 214, Training loss: 1.374080, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 215, Training loss: 1.378997, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 216, Training loss: 1.356530, Validation loss: 1.3644, lr: 0.0000\n",
      "Epoch: 217, Training loss: 1.404570, Validation loss: 1.3872, lr: 0.0000\n",
      "Epoch: 218, Training loss: 1.376502, Validation loss: 1.3919, lr: 0.0000\n",
      "Epoch: 219, Training loss: 1.389257, Validation loss: 1.3659, lr: 0.0000\n",
      "Epoch: 220, Training loss: 1.380786, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 221, Training loss: 1.363965, Validation loss: 1.4016, lr: 0.0000\n",
      "Epoch: 222, Training loss: 1.382197, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 223, Training loss: 1.361868, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 224, Training loss: 1.383309, Validation loss: 1.3747, lr: 0.0000\n",
      "Epoch: 225, Training loss: 1.451721, Validation loss: 1.3745, lr: 0.0000\n",
      "Epoch: 226, Training loss: 1.385988, Validation loss: 1.3895, lr: 0.0000\n",
      "Epoch: 227, Training loss: 1.381452, Validation loss: 1.3920, lr: 0.0000\n",
      "Epoch: 228, Training loss: 1.370828, Validation loss: 1.3657, lr: 0.0000\n",
      "Epoch: 229, Training loss: 1.377748, Validation loss: 1.3888, lr: 0.0000\n",
      "Epoch: 230, Training loss: 1.362068, Validation loss: 1.4081, lr: 0.0000\n",
      "Epoch: 231, Training loss: 1.430966, Validation loss: 1.3871, lr: 0.0000\n",
      "Epoch: 232, Training loss: 1.368484, Validation loss: 1.3777, lr: 0.0000\n",
      "Epoch: 233, Training loss: 1.363978, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 234, Training loss: 1.365774, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 235, Training loss: 1.376245, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 236, Training loss: 1.390773, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 237, Training loss: 1.375353, Validation loss: 1.3635, lr: 0.0000\n",
      "Epoch: 238, Training loss: 1.375936, Validation loss: 1.3783, lr: 0.0000\n",
      "Epoch: 239, Training loss: 1.395054, Validation loss: 1.3888, lr: 0.0000\n",
      "Epoch: 240, Training loss: 1.371354, Validation loss: 1.3659, lr: 0.0000\n",
      "Epoch: 241, Training loss: 1.362145, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 242, Training loss: 1.386019, Validation loss: 1.3787, lr: 0.0000\n",
      "Epoch: 243, Training loss: 1.366142, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 244, Training loss: 1.380265, Validation loss: 1.3755, lr: 0.0000\n",
      "Epoch: 245, Training loss: 1.365368, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 246, Training loss: 1.399671, Validation loss: 1.3764, lr: 0.0000\n",
      "Epoch: 247, Training loss: 1.352243, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 248, Training loss: 1.380759, Validation loss: 1.3872, lr: 0.0000\n",
      "Epoch: 249, Training loss: 1.365728, Validation loss: 1.4010, lr: 0.0000\n",
      "Epoch: 250, Training loss: 1.363473, Validation loss: 1.3737, lr: 0.0000\n",
      "Epoch: 251, Training loss: 1.367027, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 252, Training loss: 1.409428, Validation loss: 1.3908, lr: 0.0000\n",
      "Epoch: 253, Training loss: 1.392788, Validation loss: 1.3573, lr: 0.0000\n",
      "Epoch: 254, Training loss: 1.408092, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 255, Training loss: 1.397491, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 256, Training loss: 1.387616, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 257, Training loss: 1.371826, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 258, Training loss: 1.368230, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 259, Training loss: 1.360051, Validation loss: 1.3911, lr: 0.0000\n",
      "Epoch: 260, Training loss: 1.391077, Validation loss: 1.3871, lr: 0.0000\n",
      "Epoch: 261, Training loss: 1.377409, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 262, Training loss: 1.362082, Validation loss: 1.3756, lr: 0.0000\n",
      "Epoch: 263, Training loss: 1.395258, Validation loss: 1.3871, lr: 0.0000\n",
      "Epoch: 264, Training loss: 1.371479, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 265, Training loss: 1.411735, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 266, Training loss: 1.350304, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 267, Training loss: 1.379562, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 268, Training loss: 1.373692, Validation loss: 1.3514, lr: 0.0000\n",
      "Epoch: 269, Training loss: 1.376400, Validation loss: 1.4373, lr: 0.0000\n",
      "Epoch: 270, Training loss: 1.371985, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 271, Training loss: 1.401492, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 272, Training loss: 1.379200, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 273, Training loss: 1.376245, Validation loss: 1.3997, lr: 0.0000\n",
      "Epoch: 274, Training loss: 1.379453, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 275, Training loss: 1.382929, Validation loss: 1.3772, lr: 0.0000\n",
      "Epoch: 276, Training loss: 1.383994, Validation loss: 1.3888, lr: 0.0000\n",
      "Epoch: 277, Training loss: 1.368792, Validation loss: 1.3960, lr: 0.0000\n",
      "Epoch: 278, Training loss: 1.390526, Validation loss: 1.3686, lr: 0.0000\n",
      "Epoch: 279, Training loss: 1.376484, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 280, Training loss: 1.386460, Validation loss: 1.3436, lr: 0.0000\n",
      "Epoch: 281, Training loss: 1.365905, Validation loss: 1.3785, lr: 0.0000\n",
      "Epoch: 282, Training loss: 1.365882, Validation loss: 1.3728, lr: 0.0000\n",
      "Epoch: 283, Training loss: 1.382649, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 284, Training loss: 1.367928, Validation loss: 1.3696, lr: 0.0000\n",
      "Epoch: 285, Training loss: 1.362199, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 286, Training loss: 1.362555, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 287, Training loss: 1.403316, Validation loss: 1.3790, lr: 0.0000\n",
      "Epoch: 288, Training loss: 1.385779, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 289, Training loss: 1.407335, Validation loss: 1.3791, lr: 0.0000\n",
      "Epoch: 290, Training loss: 1.387293, Validation loss: 1.3725, lr: 0.0000\n",
      "Epoch: 291, Training loss: 1.378057, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 292, Training loss: 1.373549, Validation loss: 1.3803, lr: 0.0000\n",
      "Epoch: 293, Training loss: 1.391397, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 294, Training loss: 1.361533, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 295, Training loss: 1.398417, Validation loss: 1.3872, lr: 0.0000\n",
      "Epoch: 296, Training loss: 1.390309, Validation loss: 1.3871, lr: 0.0000\n",
      "Epoch: 297, Training loss: 1.386664, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 298, Training loss: 1.368133, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 299, Training loss: 1.381597, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 300, Training loss: 1.393803, Validation loss: 1.3468, lr: 0.0000\n",
      "Epoch: 301, Training loss: 1.382165, Validation loss: 1.3392, lr: 0.0000\n",
      "Epoch: 302, Training loss: 1.383139, Validation loss: 1.3912, lr: 0.0000\n",
      "Epoch: 303, Training loss: 1.376973, Validation loss: 1.3770, lr: 0.0000\n",
      "Epoch: 304, Training loss: 1.368981, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 305, Training loss: 1.398417, Validation loss: 1.3712, lr: 0.0000\n",
      "Epoch: 306, Training loss: 1.374092, Validation loss: 1.3787, lr: 0.0000\n",
      "Epoch: 307, Training loss: 1.363735, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 308, Training loss: 1.354595, Validation loss: 1.3769, lr: 0.0000\n",
      "Epoch: 309, Training loss: 1.376073, Validation loss: 1.3771, lr: 0.0000\n",
      "Epoch: 310, Training loss: 1.373254, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 311, Training loss: 1.396680, Validation loss: 1.4041, lr: 0.0000\n",
      "Epoch: 312, Training loss: 1.439939, Validation loss: 1.3784, lr: 0.0000\n",
      "Epoch: 313, Training loss: 1.430121, Validation loss: 1.3708, lr: 0.0000\n",
      "Epoch: 314, Training loss: 1.372206, Validation loss: 1.3942, lr: 0.0000\n",
      "Epoch: 315, Training loss: 1.419163, Validation loss: 1.3654, lr: 0.0000\n",
      "Epoch: 316, Training loss: 1.381555, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 317, Training loss: 1.374590, Validation loss: 1.3782, lr: 0.0000\n",
      "Epoch: 318, Training loss: 1.368801, Validation loss: 1.3754, lr: 0.0000\n",
      "Epoch: 319, Training loss: 1.364337, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 320, Training loss: 1.378103, Validation loss: 1.3759, lr: 0.0000\n",
      "Epoch: 321, Training loss: 1.404103, Validation loss: 1.4079, lr: 0.0000\n",
      "Epoch: 322, Training loss: 1.423904, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 323, Training loss: 1.394709, Validation loss: 1.3795, lr: 0.0000\n",
      "Epoch: 324, Training loss: 1.384609, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 325, Training loss: 1.373853, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 326, Training loss: 1.383113, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 327, Training loss: 1.374547, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 328, Training loss: 1.379063, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 329, Training loss: 1.360997, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 330, Training loss: 1.395009, Validation loss: 1.3950, lr: 0.0000\n",
      "Epoch: 331, Training loss: 1.370836, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 332, Training loss: 1.365088, Validation loss: 1.3788, lr: 0.0000\n",
      "Epoch: 333, Training loss: 1.372215, Validation loss: 1.3880, lr: 0.0000\n",
      "Epoch: 334, Training loss: 1.369584, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 335, Training loss: 1.397270, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 336, Training loss: 1.363856, Validation loss: 1.3794, lr: 0.0000\n",
      "Epoch: 337, Training loss: 1.392082, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 338, Training loss: 1.383491, Validation loss: 1.3782, lr: 0.0000\n",
      "Epoch: 339, Training loss: 1.361162, Validation loss: 1.3872, lr: 0.0000\n",
      "Epoch: 340, Training loss: 1.369976, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 341, Training loss: 1.384087, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 342, Training loss: 1.438002, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 343, Training loss: 1.364059, Validation loss: 1.3698, lr: 0.0000\n",
      "Epoch: 344, Training loss: 1.383056, Validation loss: 1.4351, lr: 0.0000\n",
      "Epoch: 345, Training loss: 1.381735, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 346, Training loss: 1.365014, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 347, Training loss: 1.385912, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 348, Training loss: 1.388899, Validation loss: 1.3726, lr: 0.0000\n",
      "Epoch: 349, Training loss: 1.388284, Validation loss: 1.3876, lr: 0.0000\n",
      "Epoch: 350, Training loss: 1.391653, Validation loss: 1.4044, lr: 0.0000\n",
      "Epoch: 351, Training loss: 1.380138, Validation loss: 1.3702, lr: 0.0000\n",
      "Epoch: 352, Training loss: 1.370550, Validation loss: 1.3756, lr: 0.0000\n",
      "Epoch: 353, Training loss: 1.386968, Validation loss: 1.3757, lr: 0.0000\n",
      "Epoch: 354, Training loss: 1.379977, Validation loss: 1.3924, lr: 0.0000\n",
      "Epoch: 355, Training loss: 1.419883, Validation loss: 1.3881, lr: 0.0000\n",
      "Epoch: 356, Training loss: 1.418826, Validation loss: 1.3800, lr: 0.0000\n",
      "Epoch: 357, Training loss: 1.415142, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 358, Training loss: 1.385753, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 359, Training loss: 1.387724, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 360, Training loss: 1.382633, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 361, Training loss: 1.370481, Validation loss: 1.3771, lr: 0.0000\n",
      "Epoch: 362, Training loss: 1.387084, Validation loss: 1.3900, lr: 0.0000\n",
      "Epoch: 363, Training loss: 1.400884, Validation loss: 1.3993, lr: 0.0000\n",
      "Epoch: 364, Training loss: 1.391012, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 365, Training loss: 1.397595, Validation loss: 1.3726, lr: 0.0000\n",
      "Epoch: 366, Training loss: 1.372757, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 367, Training loss: 1.411530, Validation loss: 1.3785, lr: 0.0000\n",
      "Epoch: 368, Training loss: 1.379339, Validation loss: 1.3873, lr: 0.0000\n",
      "Epoch: 369, Training loss: 1.385697, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 370, Training loss: 1.379180, Validation loss: 1.3713, lr: 0.0000\n",
      "Epoch: 371, Training loss: 1.374884, Validation loss: 1.4460, lr: 0.0000\n",
      "Epoch: 372, Training loss: 1.373169, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 373, Training loss: 1.380350, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 374, Training loss: 1.457540, Validation loss: 1.3772, lr: 0.0000\n",
      "Epoch: 375, Training loss: 1.373439, Validation loss: 1.3783, lr: 0.0000\n",
      "Epoch: 376, Training loss: 1.403508, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 377, Training loss: 1.416796, Validation loss: 1.3703, lr: 0.0000\n",
      "Epoch: 378, Training loss: 1.375074, Validation loss: 1.3773, lr: 0.0000\n",
      "Epoch: 379, Training loss: 1.389574, Validation loss: 1.3876, lr: 0.0000\n",
      "Epoch: 380, Training loss: 1.378822, Validation loss: 1.3781, lr: 0.0000\n",
      "Epoch: 381, Training loss: 1.366351, Validation loss: 1.3717, lr: 0.0000\n",
      "Epoch: 382, Training loss: 1.443868, Validation loss: 1.3789, lr: 0.0000\n",
      "Epoch: 383, Training loss: 1.379697, Validation loss: 1.3981, lr: 0.0000\n",
      "Epoch: 384, Training loss: 1.359740, Validation loss: 1.4405, lr: 0.0000\n",
      "Epoch: 385, Training loss: 1.379503, Validation loss: 1.3759, lr: 0.0000\n",
      "Epoch: 386, Training loss: 1.391263, Validation loss: 1.3755, lr: 0.0000\n",
      "Epoch: 387, Training loss: 1.370946, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 388, Training loss: 1.390595, Validation loss: 1.3790, lr: 0.0000\n",
      "Epoch: 389, Training loss: 1.374246, Validation loss: 1.3751, lr: 0.0000\n",
      "Epoch: 390, Training loss: 1.385458, Validation loss: 1.4026, lr: 0.0000\n",
      "Epoch: 391, Training loss: 1.393578, Validation loss: 1.3576, lr: 0.0000\n",
      "Epoch: 392, Training loss: 1.375824, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 393, Training loss: 1.380934, Validation loss: 1.3642, lr: 0.0000\n",
      "Epoch: 394, Training loss: 1.370693, Validation loss: 1.3775, lr: 0.0000\n",
      "Epoch: 395, Training loss: 1.356188, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 396, Training loss: 1.380225, Validation loss: 1.3666, lr: 0.0000\n",
      "Epoch: 397, Training loss: 1.376325, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 398, Training loss: 1.390022, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 399, Training loss: 1.389588, Validation loss: 1.3976, lr: 0.0000\n",
      "Epoch: 400, Training loss: 1.408224, Validation loss: 1.3752, lr: 0.0000\n",
      "Epoch: 401, Training loss: 1.403241, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 402, Training loss: 1.363808, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 403, Training loss: 1.471517, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 404, Training loss: 1.382624, Validation loss: 1.3731, lr: 0.0000\n",
      "Epoch: 405, Training loss: 1.395614, Validation loss: 1.3755, lr: 0.0000\n",
      "Epoch: 406, Training loss: 1.388147, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 407, Training loss: 1.391417, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 408, Training loss: 1.390696, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 409, Training loss: 1.443072, Validation loss: 1.3761, lr: 0.0000\n",
      "Epoch: 410, Training loss: 1.356800, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 411, Training loss: 1.374710, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 412, Training loss: 1.372469, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 413, Training loss: 1.402973, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 414, Training loss: 1.356575, Validation loss: 1.3917, lr: 0.0000\n",
      "Epoch: 415, Training loss: 1.367021, Validation loss: 1.3737, lr: 0.0000\n",
      "Epoch: 416, Training loss: 1.377298, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 417, Training loss: 1.413944, Validation loss: 1.4108, lr: 0.0000\n",
      "Epoch: 418, Training loss: 1.389062, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 419, Training loss: 1.377040, Validation loss: 1.3737, lr: 0.0000\n",
      "Epoch: 420, Training loss: 1.384966, Validation loss: 1.3608, lr: 0.0000\n",
      "Epoch: 421, Training loss: 1.368353, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 422, Training loss: 1.371400, Validation loss: 1.3702, lr: 0.0000\n",
      "Epoch: 423, Training loss: 1.357756, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 424, Training loss: 1.390626, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 425, Training loss: 1.342990, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 426, Training loss: 1.366479, Validation loss: 1.3725, lr: 0.0000\n",
      "Epoch: 427, Training loss: 1.397023, Validation loss: 1.3766, lr: 0.0000\n",
      "Epoch: 428, Training loss: 1.382976, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 429, Training loss: 1.401493, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 430, Training loss: 1.398043, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 431, Training loss: 1.392177, Validation loss: 1.4107, lr: 0.0000\n",
      "Epoch: 432, Training loss: 1.452577, Validation loss: 1.3892, lr: 0.0000\n",
      "Epoch: 433, Training loss: 1.397461, Validation loss: 1.3789, lr: 0.0000\n",
      "Epoch: 434, Training loss: 1.391071, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 435, Training loss: 1.372282, Validation loss: 1.3901, lr: 0.0000\n",
      "Epoch: 436, Training loss: 1.389132, Validation loss: 1.3800, lr: 0.0000\n",
      "Epoch: 437, Training loss: 1.366539, Validation loss: 1.5899, lr: 0.0000\n",
      "Epoch: 438, Training loss: 1.391148, Validation loss: 1.3750, lr: 0.0000\n",
      "Epoch: 439, Training loss: 1.395645, Validation loss: 1.3692, lr: 0.0000\n",
      "Epoch: 440, Training loss: 1.381401, Validation loss: 1.3936, lr: 0.0000\n",
      "Epoch: 441, Training loss: 1.398333, Validation loss: 1.3620, lr: 0.0000\n",
      "Epoch: 442, Training loss: 1.356297, Validation loss: 1.3642, lr: 0.0000\n",
      "Epoch: 443, Training loss: 1.372297, Validation loss: 1.4060, lr: 0.0000\n",
      "Epoch: 444, Training loss: 1.366760, Validation loss: 1.3714, lr: 0.0000\n",
      "Epoch: 445, Training loss: 1.399906, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 446, Training loss: 1.394554, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 447, Training loss: 1.356068, Validation loss: 1.3876, lr: 0.0000\n",
      "Epoch: 448, Training loss: 1.367800, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 449, Training loss: 1.369937, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 450, Training loss: 1.379053, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 451, Training loss: 1.379832, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 452, Training loss: 1.391287, Validation loss: 1.3789, lr: 0.0000\n",
      "Epoch: 453, Training loss: 1.413443, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 454, Training loss: 1.368628, Validation loss: 1.3876, lr: 0.0000\n",
      "Epoch: 455, Training loss: 1.382689, Validation loss: 1.3865, lr: 0.0000\n",
      " *och: 456, Training loss: 1.394148, Validation loss: 1.3315, lr: 0.0000\n",
      "Epoch: 457, Training loss: 1.351507, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 458, Training loss: 1.385846, Validation loss: 1.4003, lr: 0.0000\n",
      "Epoch: 459, Training loss: 1.394319, Validation loss: 1.4381, lr: 0.0000\n",
      "Epoch: 460, Training loss: 1.360482, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 461, Training loss: 1.394787, Validation loss: 1.3589, lr: 0.0000\n",
      "Epoch: 462, Training loss: 1.406757, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 463, Training loss: 1.367567, Validation loss: 1.3791, lr: 0.0000\n",
      "Epoch: 464, Training loss: 1.364917, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 465, Training loss: 1.375910, Validation loss: 1.3774, lr: 0.0000\n",
      "Epoch: 466, Training loss: 1.400096, Validation loss: 1.3775, lr: 0.0000\n",
      "Epoch: 467, Training loss: 1.376172, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 468, Training loss: 1.407159, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 469, Training loss: 1.387986, Validation loss: 1.5260, lr: 0.0000\n",
      "Epoch: 470, Training loss: 1.408494, Validation loss: 1.3783, lr: 0.0000\n",
      "Epoch: 471, Training loss: 1.381460, Validation loss: 1.3778, lr: 0.0000\n",
      "Epoch: 472, Training loss: 1.361640, Validation loss: 1.3790, lr: 0.0000\n",
      "Epoch: 473, Training loss: 1.420963, Validation loss: 1.3910, lr: 0.0000\n",
      "Epoch: 474, Training loss: 1.388602, Validation loss: 1.3879, lr: 0.0000\n",
      "Epoch: 475, Training loss: 1.430927, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 476, Training loss: 1.360771, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 477, Training loss: 1.403583, Validation loss: 1.3771, lr: 0.0000\n",
      "Epoch: 478, Training loss: 1.362908, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 479, Training loss: 1.381312, Validation loss: 1.3924, lr: 0.0000\n",
      "Epoch: 480, Training loss: 1.373805, Validation loss: 1.3642, lr: 0.0000\n",
      "Epoch: 481, Training loss: 1.380685, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 482, Training loss: 1.380711, Validation loss: 1.3733, lr: 0.0000\n",
      "Epoch: 483, Training loss: 1.375053, Validation loss: 1.3781, lr: 0.0000\n",
      "Epoch: 484, Training loss: 1.389538, Validation loss: 1.3964, lr: 0.0000\n",
      "Epoch: 485, Training loss: 1.398060, Validation loss: 1.3773, lr: 0.0000\n",
      "Epoch: 486, Training loss: 1.376316, Validation loss: 1.3674, lr: 0.0000\n",
      "Epoch: 487, Training loss: 1.378568, Validation loss: 1.3904, lr: 0.0000\n",
      "Epoch: 488, Training loss: 1.363424, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 489, Training loss: 1.380548, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 490, Training loss: 1.386535, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 491, Training loss: 1.414928, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 492, Training loss: 1.375881, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 493, Training loss: 1.403364, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 494, Training loss: 1.378429, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 495, Training loss: 1.383616, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 496, Training loss: 1.378756, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 497, Training loss: 1.389671, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 498, Training loss: 1.363625, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 499, Training loss: 1.400538, Validation loss: 1.3746, lr: 0.0000\n",
      "Epoch: 500, Training loss: 1.388839, Validation loss: 1.3921, lr: 0.0000\n",
      "Epoch: 501, Training loss: 1.480968, Validation loss: 1.3879, lr: 0.0000\n",
      "Epoch: 502, Training loss: 1.342096, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 503, Training loss: 1.371626, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 504, Training loss: 1.366342, Validation loss: 1.3782, lr: 0.0000\n",
      "Epoch: 505, Training loss: 1.384675, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 506, Training loss: 1.385929, Validation loss: 1.3738, lr: 0.0000\n",
      "Epoch: 507, Training loss: 1.368983, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 508, Training loss: 1.363823, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 509, Training loss: 1.382001, Validation loss: 1.5050, lr: 0.0000\n",
      "Epoch: 510, Training loss: 1.361344, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 511, Training loss: 1.413918, Validation loss: 1.3914, lr: 0.0000\n",
      "Epoch: 512, Training loss: 1.369385, Validation loss: 1.3890, lr: 0.0000\n",
      "Epoch: 513, Training loss: 1.461162, Validation loss: 1.3783, lr: 0.0000\n",
      "Epoch: 514, Training loss: 1.383470, Validation loss: 1.3773, lr: 0.0000\n",
      "Epoch: 515, Training loss: 1.381731, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 516, Training loss: 1.396023, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 517, Training loss: 1.389598, Validation loss: 1.3904, lr: 0.0000\n",
      "Epoch: 518, Training loss: 1.381978, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 519, Training loss: 1.355842, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 520, Training loss: 1.387647, Validation loss: 1.3797, lr: 0.0000\n",
      "Epoch: 521, Training loss: 1.378391, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 522, Training loss: 1.390923, Validation loss: 1.3956, lr: 0.0000\n",
      "Epoch: 523, Training loss: 1.390972, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 524, Training loss: 1.371077, Validation loss: 1.3786, lr: 0.0000\n",
      "Epoch: 525, Training loss: 1.393556, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 526, Training loss: 1.358539, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 527, Training loss: 1.362009, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 528, Training loss: 1.385531, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 529, Training loss: 1.363360, Validation loss: 1.3367, lr: 0.0000\n",
      "Epoch: 530, Training loss: 1.413812, Validation loss: 1.3785, lr: 0.0000\n",
      "Epoch: 531, Training loss: 1.366225, Validation loss: 1.3783, lr: 0.0000\n",
      "Epoch: 532, Training loss: 1.383734, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 533, Training loss: 1.372953, Validation loss: 1.3725, lr: 0.0000\n",
      "Epoch: 534, Training loss: 1.428943, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 535, Training loss: 1.383826, Validation loss: 1.3622, lr: 0.0000\n",
      "Epoch: 536, Training loss: 1.373817, Validation loss: 1.3772, lr: 0.0000\n",
      "Epoch: 537, Training loss: 1.375435, Validation loss: 1.3727, lr: 0.0000\n",
      "Epoch: 538, Training loss: 1.364000, Validation loss: 1.3628, lr: 0.0000\n",
      "Epoch: 539, Training loss: 1.378459, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 540, Training loss: 1.398106, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 541, Training loss: 1.381184, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 542, Training loss: 1.424160, Validation loss: 1.3782, lr: 0.0000\n",
      "Epoch: 543, Training loss: 1.371715, Validation loss: 1.3797, lr: 0.0000\n",
      "Epoch: 544, Training loss: 1.418473, Validation loss: 1.3894, lr: 0.0000\n",
      "Epoch: 545, Training loss: 1.383818, Validation loss: 1.3882, lr: 0.0000\n",
      "Epoch: 546, Training loss: 1.377899, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 547, Training loss: 1.377466, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 548, Training loss: 1.367831, Validation loss: 1.3674, lr: 0.0000\n",
      "Epoch: 549, Training loss: 1.388742, Validation loss: 1.3912, lr: 0.0000\n",
      "Epoch: 550, Training loss: 1.394116, Validation loss: 1.3750, lr: 0.0000\n",
      "Epoch: 551, Training loss: 1.393016, Validation loss: 1.3702, lr: 0.0000\n",
      "Epoch: 552, Training loss: 1.381681, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 553, Training loss: 1.382432, Validation loss: 1.3762, lr: 0.0000\n",
      "Epoch: 554, Training loss: 1.356930, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 555, Training loss: 1.379058, Validation loss: 1.3943, lr: 0.0000\n",
      "Epoch: 556, Training loss: 1.377217, Validation loss: 1.3642, lr: 0.0000\n",
      "Epoch: 557, Training loss: 1.376469, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 558, Training loss: 1.402545, Validation loss: 1.3962, lr: 0.0000\n",
      "Epoch: 559, Training loss: 1.402291, Validation loss: 1.3554, lr: 0.0000\n",
      "Epoch: 560, Training loss: 1.375863, Validation loss: 1.3523, lr: 0.0000\n",
      "Epoch: 561, Training loss: 1.380813, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 562, Training loss: 1.353440, Validation loss: 1.4349, lr: 0.0000\n",
      "Epoch: 563, Training loss: 1.380542, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 564, Training loss: 1.369532, Validation loss: 1.3877, lr: 0.0000\n",
      "Epoch: 565, Training loss: 1.378177, Validation loss: 1.4227, lr: 0.0000\n",
      "Epoch: 566, Training loss: 1.369265, Validation loss: 1.3565, lr: 0.0000\n",
      "Epoch: 567, Training loss: 1.376298, Validation loss: 1.3713, lr: 0.0000\n",
      "Epoch: 568, Training loss: 1.379539, Validation loss: 1.3776, lr: 0.0000\n",
      "Epoch: 569, Training loss: 1.423038, Validation loss: 1.3871, lr: 0.0000\n",
      "Epoch: 570, Training loss: 1.374127, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 571, Training loss: 1.391015, Validation loss: 1.4930, lr: 0.0000\n",
      "Epoch: 572, Training loss: 1.382276, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 573, Training loss: 1.383883, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 574, Training loss: 1.367190, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 575, Training loss: 1.366658, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 576, Training loss: 1.384274, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 577, Training loss: 1.374522, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 578, Training loss: 1.378091, Validation loss: 1.3789, lr: 0.0000\n",
      "Epoch: 579, Training loss: 1.398786, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 580, Training loss: 1.376280, Validation loss: 1.3744, lr: 0.0000\n",
      "Epoch: 581, Training loss: 1.425745, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 582, Training loss: 1.367055, Validation loss: 1.3797, lr: 0.0000\n",
      "Epoch: 583, Training loss: 1.397200, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 584, Training loss: 1.364988, Validation loss: 1.3917, lr: 0.0000\n",
      "Epoch: 585, Training loss: 1.394522, Validation loss: 1.3758, lr: 0.0000\n",
      "Epoch: 586, Training loss: 1.379441, Validation loss: 1.3756, lr: 0.0000\n",
      "Epoch: 587, Training loss: 1.347450, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 588, Training loss: 1.376594, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 589, Training loss: 1.366660, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 590, Training loss: 1.380371, Validation loss: 1.3895, lr: 0.0000\n",
      "Epoch: 591, Training loss: 1.423426, Validation loss: 1.3875, lr: 0.0000\n",
      "Epoch: 592, Training loss: 1.392584, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 593, Training loss: 1.359409, Validation loss: 1.3781, lr: 0.0000\n",
      "Epoch: 594, Training loss: 1.372835, Validation loss: 1.3749, lr: 0.0000\n",
      "Epoch: 595, Training loss: 1.380291, Validation loss: 1.3928, lr: 0.0000\n",
      "Epoch: 596, Training loss: 1.381621, Validation loss: 1.3635, lr: 0.0000\n",
      "Epoch: 597, Training loss: 1.383653, Validation loss: 1.3742, lr: 0.0000\n",
      "Epoch: 598, Training loss: 1.401703, Validation loss: 1.3753, lr: 0.0000\n",
      "Epoch: 599, Training loss: 1.366099, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 600, Training loss: 1.373628, Validation loss: 1.3544, lr: 0.0000\n",
      "Epoch: 601, Training loss: 1.378540, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 602, Training loss: 1.366089, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 603, Training loss: 1.385205, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 604, Training loss: 1.430146, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 605, Training loss: 1.408625, Validation loss: 1.3878, lr: 0.0000\n",
      "Epoch: 606, Training loss: 1.387614, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 607, Training loss: 1.433140, Validation loss: 1.3917, lr: 0.0000\n",
      "Epoch: 608, Training loss: 1.425478, Validation loss: 1.3795, lr: 0.0000\n",
      "Epoch: 609, Training loss: 1.377513, Validation loss: 1.3914, lr: 0.0000\n",
      "Epoch: 610, Training loss: 1.388720, Validation loss: 1.3790, lr: 0.0000\n",
      "Epoch: 611, Training loss: 1.424835, Validation loss: 1.3875, lr: 0.0000\n",
      "Epoch: 612, Training loss: 1.375455, Validation loss: 1.4691, lr: 0.0000\n",
      "Epoch: 613, Training loss: 1.397890, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 614, Training loss: 1.365594, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 615, Training loss: 1.358731, Validation loss: 1.3713, lr: 0.0000\n",
      "Epoch: 616, Training loss: 1.406920, Validation loss: 1.3671, lr: 0.0000\n",
      "Epoch: 617, Training loss: 1.385253, Validation loss: 1.3766, lr: 0.0000\n",
      "Epoch: 618, Training loss: 1.369908, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 619, Training loss: 1.379510, Validation loss: 1.3784, lr: 0.0000\n",
      "Epoch: 620, Training loss: 1.378952, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 621, Training loss: 1.381111, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 622, Training loss: 1.376203, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 623, Training loss: 1.376988, Validation loss: 1.3707, lr: 0.0000\n",
      "Epoch: 624, Training loss: 1.395434, Validation loss: 1.4513, lr: 0.0000\n",
      "Epoch: 625, Training loss: 1.382308, Validation loss: 1.3799, lr: 0.0000\n",
      "Epoch: 626, Training loss: 1.382351, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 627, Training loss: 1.380769, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 628, Training loss: 1.368345, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 629, Training loss: 1.377080, Validation loss: 1.4224, lr: 0.0000\n",
      "Epoch: 630, Training loss: 1.364372, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 631, Training loss: 1.394227, Validation loss: 1.3524, lr: 0.0000\n",
      "Epoch: 632, Training loss: 1.386482, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 633, Training loss: 1.379473, Validation loss: 1.3798, lr: 0.0000\n",
      "Epoch: 634, Training loss: 1.419042, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 635, Training loss: 1.376301, Validation loss: 1.3401, lr: 0.0000\n",
      "Epoch: 636, Training loss: 1.371192, Validation loss: 1.3713, lr: 0.0000\n",
      "Epoch: 637, Training loss: 1.410993, Validation loss: 1.3872, lr: 0.0000\n",
      "Epoch: 638, Training loss: 1.368861, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 639, Training loss: 1.382323, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 640, Training loss: 1.388625, Validation loss: 1.3768, lr: 0.0000\n",
      "Epoch: 641, Training loss: 1.371380, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 642, Training loss: 1.362453, Validation loss: 1.3724, lr: 0.0000\n",
      "Epoch: 643, Training loss: 1.373956, Validation loss: 1.3902, lr: 0.0000\n",
      "Epoch: 644, Training loss: 1.377402, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 645, Training loss: 1.394486, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 646, Training loss: 1.373409, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 647, Training loss: 1.393065, Validation loss: 1.3772, lr: 0.0000\n",
      "Epoch: 648, Training loss: 1.379870, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 649, Training loss: 1.383180, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 650, Training loss: 1.390469, Validation loss: 1.3769, lr: 0.0000\n",
      "Epoch: 651, Training loss: 1.384080, Validation loss: 1.4026, lr: 0.0000\n",
      "Epoch: 652, Training loss: 1.379412, Validation loss: 1.3594, lr: 0.0000\n",
      "Epoch: 653, Training loss: 1.367466, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 654, Training loss: 1.385552, Validation loss: 1.3666, lr: 0.0000\n",
      "Epoch: 655, Training loss: 1.365434, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 656, Training loss: 1.375743, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 657, Training loss: 1.374064, Validation loss: 1.3913, lr: 0.0000\n",
      "Epoch: 658, Training loss: 1.368314, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 659, Training loss: 1.365079, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 660, Training loss: 1.374013, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 661, Training loss: 1.366669, Validation loss: 1.3651, lr: 0.0000\n",
      "Epoch: 662, Training loss: 1.384549, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 663, Training loss: 1.377949, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 664, Training loss: 1.374642, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 665, Training loss: 1.398900, Validation loss: 1.3911, lr: 0.0000\n",
      "Epoch: 666, Training loss: 1.385170, Validation loss: 1.8416, lr: 0.0000\n",
      "Epoch: 667, Training loss: 1.499143, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 668, Training loss: 1.395516, Validation loss: 1.3760, lr: 0.0000\n",
      "Epoch: 669, Training loss: 1.367126, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 670, Training loss: 1.379340, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 671, Training loss: 1.366847, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 672, Training loss: 1.372203, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 673, Training loss: 1.374890, Validation loss: 1.3774, lr: 0.0000\n",
      "Epoch: 674, Training loss: 1.383195, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 675, Training loss: 1.364796, Validation loss: 1.3803, lr: 0.0000\n",
      "Epoch: 676, Training loss: 1.378161, Validation loss: 1.3762, lr: 0.0000\n",
      "Epoch: 677, Training loss: 1.370781, Validation loss: 1.3882, lr: 0.0000\n",
      "Epoch: 678, Training loss: 1.364001, Validation loss: 1.3743, lr: 0.0000\n",
      "Epoch: 679, Training loss: 1.375001, Validation loss: 1.3738, lr: 0.0000\n",
      "Epoch: 680, Training loss: 1.384247, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 681, Training loss: 1.391681, Validation loss: 1.3898, lr: 0.0000\n",
      "Epoch: 682, Training loss: 1.426084, Validation loss: 1.3697, lr: 0.0000\n",
      "Epoch: 683, Training loss: 1.399585, Validation loss: 1.3962, lr: 0.0000\n",
      "Epoch: 684, Training loss: 1.389312, Validation loss: 1.3792, lr: 0.0000\n",
      "Epoch: 685, Training loss: 1.364237, Validation loss: 1.3787, lr: 0.0000\n",
      "Epoch: 686, Training loss: 1.402695, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 687, Training loss: 1.388482, Validation loss: 1.3796, lr: 0.0000\n",
      "Epoch: 688, Training loss: 1.524214, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 689, Training loss: 1.420959, Validation loss: 1.4018, lr: 0.0000\n",
      "Epoch: 690, Training loss: 1.379737, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 691, Training loss: 1.386541, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 692, Training loss: 1.368267, Validation loss: 1.3771, lr: 0.0000\n",
      "Epoch: 693, Training loss: 1.390575, Validation loss: 1.3547, lr: 0.0000\n",
      "Epoch: 694, Training loss: 1.367795, Validation loss: 1.3774, lr: 0.0000\n",
      "Epoch: 695, Training loss: 1.368675, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 696, Training loss: 1.397233, Validation loss: 1.3788, lr: 0.0000\n",
      "Epoch: 697, Training loss: 1.405802, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 698, Training loss: 1.386014, Validation loss: 1.3571, lr: 0.0000\n",
      "Epoch: 699, Training loss: 1.376786, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 700, Training loss: 1.375481, Validation loss: 1.3873, lr: 0.0000\n",
      "Epoch: 701, Training loss: 1.395246, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 702, Training loss: 1.379891, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 703, Training loss: 1.383726, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 704, Training loss: 1.392787, Validation loss: 1.3772, lr: 0.0000\n",
      "Epoch: 705, Training loss: 1.390111, Validation loss: 1.3789, lr: 0.0000\n",
      "Epoch: 706, Training loss: 1.371019, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 707, Training loss: 1.388640, Validation loss: 1.3659, lr: 0.0000\n",
      "Epoch: 708, Training loss: 1.355527, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 709, Training loss: 1.397992, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 710, Training loss: 1.408533, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 711, Training loss: 1.376936, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 712, Training loss: 1.375569, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 713, Training loss: 1.375091, Validation loss: 1.3789, lr: 0.0000\n",
      "Epoch: 714, Training loss: 1.352589, Validation loss: 1.3647, lr: 0.0000\n",
      "Epoch: 715, Training loss: 1.369392, Validation loss: 1.3716, lr: 0.0000\n",
      "Epoch: 716, Training loss: 1.386299, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 717, Training loss: 1.372000, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 718, Training loss: 1.353012, Validation loss: 1.3783, lr: 0.0000\n",
      "Epoch: 719, Training loss: 1.395259, Validation loss: 1.3754, lr: 0.0000\n",
      "Epoch: 720, Training loss: 1.371317, Validation loss: 1.3879, lr: 0.0000\n",
      "Epoch: 721, Training loss: 1.405811, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 722, Training loss: 1.400322, Validation loss: 1.3927, lr: 0.0000\n",
      "Epoch: 723, Training loss: 1.372540, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 724, Training loss: 1.410679, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 725, Training loss: 1.382447, Validation loss: 1.3902, lr: 0.0000\n",
      "Epoch: 726, Training loss: 1.406488, Validation loss: 1.3727, lr: 0.0000\n",
      "Epoch: 727, Training loss: 1.377907, Validation loss: 1.3768, lr: 0.0000\n",
      "Epoch: 728, Training loss: 1.405677, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 729, Training loss: 1.383882, Validation loss: 1.3802, lr: 0.0000\n",
      "Epoch: 730, Training loss: 1.369176, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 731, Training loss: 1.373046, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 732, Training loss: 1.368422, Validation loss: 1.3799, lr: 0.0000\n",
      "Epoch: 733, Training loss: 1.373129, Validation loss: 1.3887, lr: 0.0000\n",
      "Epoch: 734, Training loss: 1.376384, Validation loss: 1.3696, lr: 0.0000\n",
      "Epoch: 735, Training loss: 1.382260, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 736, Training loss: 1.383325, Validation loss: 1.4250, lr: 0.0000\n",
      "Epoch: 737, Training loss: 1.408629, Validation loss: 1.3790, lr: 0.0000\n",
      "Epoch: 738, Training loss: 1.361335, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 739, Training loss: 1.381480, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 740, Training loss: 1.368603, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 741, Training loss: 1.389832, Validation loss: 1.6258, lr: 0.0000\n",
      "Epoch: 742, Training loss: 1.422873, Validation loss: 1.3779, lr: 0.0000\n",
      "Epoch: 743, Training loss: 1.389758, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 744, Training loss: 1.396115, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 745, Training loss: 1.429829, Validation loss: 1.3765, lr: 0.0000\n",
      "Epoch: 746, Training loss: 1.410443, Validation loss: 1.3642, lr: 0.0000\n",
      "Epoch: 747, Training loss: 1.370555, Validation loss: 1.3722, lr: 0.0000\n",
      "Epoch: 748, Training loss: 1.382408, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 749, Training loss: 1.364886, Validation loss: 1.3713, lr: 0.0000\n",
      "Epoch: 750, Training loss: 1.390403, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 751, Training loss: 1.356729, Validation loss: 1.3717, lr: 0.0000\n",
      "Epoch: 752, Training loss: 1.378526, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 753, Training loss: 1.378227, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 754, Training loss: 1.377478, Validation loss: 1.4230, lr: 0.0000\n",
      "Epoch: 755, Training loss: 1.379061, Validation loss: 1.3988, lr: 0.0000\n",
      "Epoch: 756, Training loss: 1.477794, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 757, Training loss: 1.361769, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 758, Training loss: 1.363435, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 759, Training loss: 1.366211, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 760, Training loss: 1.374550, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 761, Training loss: 1.388516, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 762, Training loss: 1.364258, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 763, Training loss: 1.402199, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 764, Training loss: 1.470663, Validation loss: 1.3634, lr: 0.0000\n",
      "Epoch: 765, Training loss: 1.389168, Validation loss: 1.3785, lr: 0.0000\n",
      "Epoch: 766, Training loss: 1.377731, Validation loss: 1.3796, lr: 0.0000\n",
      "Epoch: 767, Training loss: 1.368236, Validation loss: 1.3786, lr: 0.0000\n",
      "Epoch: 768, Training loss: 1.363513, Validation loss: 1.3979, lr: 0.0000\n",
      "Epoch: 769, Training loss: 1.379350, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 770, Training loss: 1.355740, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 771, Training loss: 1.346831, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 772, Training loss: 1.368929, Validation loss: 1.3756, lr: 0.0000\n",
      "Epoch: 773, Training loss: 1.384069, Validation loss: 1.4739, lr: 0.0000\n",
      "Epoch: 774, Training loss: 1.365032, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 775, Training loss: 1.361799, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 776, Training loss: 1.352044, Validation loss: 1.3792, lr: 0.0000\n",
      "Epoch: 777, Training loss: 1.369461, Validation loss: 1.3872, lr: 0.0000\n",
      "Epoch: 778, Training loss: 1.359796, Validation loss: 1.3726, lr: 0.0000\n",
      "Epoch: 779, Training loss: 1.387426, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 780, Training loss: 1.383624, Validation loss: 1.4448, lr: 0.0000\n",
      "Epoch: 781, Training loss: 1.380919, Validation loss: 1.3944, lr: 0.0000\n",
      "Epoch: 782, Training loss: 1.370300, Validation loss: 1.3699, lr: 0.0000\n",
      "Epoch: 783, Training loss: 1.369342, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 784, Training loss: 1.397909, Validation loss: 1.3791, lr: 0.0000\n",
      "Epoch: 785, Training loss: 1.368135, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 786, Training loss: 1.368466, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 787, Training loss: 1.381579, Validation loss: 1.3877, lr: 0.0000\n",
      "Epoch: 788, Training loss: 1.385504, Validation loss: 1.4004, lr: 0.0000\n",
      "Epoch: 789, Training loss: 1.377335, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 790, Training loss: 1.374984, Validation loss: 1.3740, lr: 0.0000\n",
      "Epoch: 791, Training loss: 1.413211, Validation loss: 1.3756, lr: 0.0000\n",
      "Epoch: 792, Training loss: 1.376046, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 793, Training loss: 1.368695, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 794, Training loss: 1.407590, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 795, Training loss: 1.369642, Validation loss: 1.3915, lr: 0.0000\n",
      "Epoch: 796, Training loss: 1.393202, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 797, Training loss: 1.356979, Validation loss: 1.3581, lr: 0.0000\n",
      "Epoch: 798, Training loss: 1.429718, Validation loss: 1.3751, lr: 0.0000\n",
      "Epoch: 799, Training loss: 1.380993, Validation loss: 1.3724, lr: 0.0000\n",
      "Epoch: 800, Training loss: 1.403463, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 801, Training loss: 1.387652, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 802, Training loss: 1.384397, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 803, Training loss: 1.373078, Validation loss: 1.3872, lr: 0.0000\n",
      "Epoch: 804, Training loss: 1.378051, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 805, Training loss: 1.381730, Validation loss: 1.3738, lr: 0.0000\n",
      "Epoch: 806, Training loss: 1.385601, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 807, Training loss: 1.358151, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 808, Training loss: 1.391106, Validation loss: 1.3877, lr: 0.0000\n",
      "Epoch: 809, Training loss: 1.379391, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 810, Training loss: 1.412195, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 811, Training loss: 1.396052, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 812, Training loss: 1.363606, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 813, Training loss: 1.393995, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 814, Training loss: 1.356929, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 815, Training loss: 1.408566, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 816, Training loss: 1.378483, Validation loss: 1.3939, lr: 0.0000\n",
      "Epoch: 817, Training loss: 1.376209, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 818, Training loss: 1.363368, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 819, Training loss: 1.373487, Validation loss: 1.3660, lr: 0.0000\n",
      "Epoch: 820, Training loss: 1.411658, Validation loss: 1.4246, lr: 0.0000\n",
      "Epoch: 821, Training loss: 1.362979, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 822, Training loss: 1.354609, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 823, Training loss: 1.370902, Validation loss: 1.3917, lr: 0.0000\n",
      "Epoch: 824, Training loss: 1.375176, Validation loss: 1.3792, lr: 0.0000\n",
      "Epoch: 825, Training loss: 1.405119, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 826, Training loss: 1.364992, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 827, Training loss: 1.385274, Validation loss: 1.4164, lr: 0.0000\n",
      "Epoch: 828, Training loss: 1.375781, Validation loss: 1.3651, lr: 0.0000\n",
      "Epoch: 829, Training loss: 1.371198, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 830, Training loss: 1.380455, Validation loss: 1.3752, lr: 0.0000\n",
      "Epoch: 831, Training loss: 1.366154, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 832, Training loss: 1.372779, Validation loss: 1.3920, lr: 0.0000\n",
      "Epoch: 833, Training loss: 1.374485, Validation loss: 1.4664, lr: 0.0000\n",
      "Epoch: 834, Training loss: 1.379250, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 835, Training loss: 1.387772, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 836, Training loss: 1.374723, Validation loss: 1.3739, lr: 0.0000\n",
      "Epoch: 837, Training loss: 1.389564, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 838, Training loss: 1.405094, Validation loss: 1.3928, lr: 0.0000\n",
      "Epoch: 839, Training loss: 1.382519, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 840, Training loss: 1.397830, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 841, Training loss: 1.380510, Validation loss: 1.3615, lr: 0.0000\n",
      "Epoch: 842, Training loss: 1.379747, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 843, Training loss: 1.361247, Validation loss: 1.3774, lr: 0.0000\n",
      "Epoch: 844, Training loss: 1.383737, Validation loss: 1.3718, lr: 0.0000\n",
      "Epoch: 845, Training loss: 1.389555, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 846, Training loss: 1.365820, Validation loss: 1.3756, lr: 0.0000\n",
      "Epoch: 847, Training loss: 1.390222, Validation loss: 1.3910, lr: 0.0000\n",
      "Epoch: 848, Training loss: 1.379739, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 849, Training loss: 1.372430, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 850, Training loss: 1.381849, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 851, Training loss: 1.385307, Validation loss: 1.3784, lr: 0.0000\n",
      "Epoch: 852, Training loss: 1.399807, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 853, Training loss: 1.394828, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 854, Training loss: 1.399846, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 855, Training loss: 1.357618, Validation loss: 1.3786, lr: 0.0000\n",
      "Epoch: 856, Training loss: 1.447785, Validation loss: 1.3520, lr: 0.0000\n",
      "Epoch: 857, Training loss: 1.375829, Validation loss: 1.3879, lr: 0.0000\n",
      "Epoch: 858, Training loss: 1.374998, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 859, Training loss: 1.375993, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 860, Training loss: 1.389895, Validation loss: 1.3883, lr: 0.0000\n",
      "Epoch: 861, Training loss: 1.368831, Validation loss: 1.3795, lr: 0.0000\n",
      "Epoch: 862, Training loss: 1.371656, Validation loss: 1.3754, lr: 0.0000\n",
      "Epoch: 863, Training loss: 1.374672, Validation loss: 1.3766, lr: 0.0000\n",
      "Epoch: 864, Training loss: 1.372390, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 865, Training loss: 1.371788, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 866, Training loss: 1.397365, Validation loss: 1.3997, lr: 0.0000\n",
      "Epoch: 867, Training loss: 1.372190, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 868, Training loss: 1.364650, Validation loss: 1.6166, lr: 0.0000\n",
      "Epoch: 869, Training loss: 1.392077, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 870, Training loss: 1.402115, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 871, Training loss: 1.364899, Validation loss: 1.3917, lr: 0.0000\n",
      "Epoch: 872, Training loss: 1.369529, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 873, Training loss: 1.410258, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 874, Training loss: 1.388290, Validation loss: 1.3795, lr: 0.0000\n",
      "Epoch: 875, Training loss: 1.408957, Validation loss: 1.3893, lr: 0.0000\n",
      "Epoch: 876, Training loss: 1.366141, Validation loss: 1.3802, lr: 0.0000\n",
      "Epoch: 877, Training loss: 1.377587, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 878, Training loss: 1.398848, Validation loss: 1.3726, lr: 0.0000\n",
      "Epoch: 879, Training loss: 1.381037, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 880, Training loss: 1.392855, Validation loss: 1.3781, lr: 0.0000\n",
      "Epoch: 881, Training loss: 1.373719, Validation loss: 1.3767, lr: 0.0000\n",
      "Epoch: 882, Training loss: 1.421831, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 883, Training loss: 1.398290, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 884, Training loss: 1.371530, Validation loss: 1.3936, lr: 0.0000\n",
      "Epoch: 885, Training loss: 1.428636, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 886, Training loss: 1.367291, Validation loss: 1.3681, lr: 0.0000\n",
      "Epoch: 887, Training loss: 1.421446, Validation loss: 1.3920, lr: 0.0000\n",
      "Epoch: 888, Training loss: 1.406483, Validation loss: 1.3798, lr: 0.0000\n",
      "Epoch: 889, Training loss: 1.363936, Validation loss: 1.4039, lr: 0.0000\n",
      "Epoch: 890, Training loss: 1.388792, Validation loss: 1.3711, lr: 0.0000\n",
      "Epoch: 891, Training loss: 1.375084, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 892, Training loss: 1.384384, Validation loss: 1.3754, lr: 0.0000\n",
      "Epoch: 893, Training loss: 1.358554, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 894, Training loss: 1.368467, Validation loss: 1.3790, lr: 0.0000\n",
      "Epoch: 895, Training loss: 1.357798, Validation loss: 1.3591, lr: 0.0000\n",
      "Epoch: 896, Training loss: 1.415048, Validation loss: 1.3670, lr: 0.0000\n",
      "Epoch: 897, Training loss: 1.446823, Validation loss: 1.3780, lr: 0.0000\n",
      "Epoch: 898, Training loss: 1.375825, Validation loss: 1.3921, lr: 0.0000\n",
      "Epoch: 899, Training loss: 1.468168, Validation loss: 1.3735, lr: 0.0000\n",
      "Epoch: 900, Training loss: 1.391741, Validation loss: 1.3952, lr: 0.0000\n",
      "Epoch: 901, Training loss: 1.380099, Validation loss: 1.3651, lr: 0.0000\n",
      "Epoch: 902, Training loss: 1.443362, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 903, Training loss: 1.387479, Validation loss: 1.3790, lr: 0.0000\n",
      "Epoch: 904, Training loss: 1.448413, Validation loss: 1.3879, lr: 0.0000\n",
      "Epoch: 905, Training loss: 1.369446, Validation loss: 1.3643, lr: 0.0000\n",
      "Epoch: 906, Training loss: 1.375944, Validation loss: 1.3756, lr: 0.0000\n",
      "Epoch: 907, Training loss: 1.392496, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 908, Training loss: 1.365914, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 909, Training loss: 1.374231, Validation loss: 1.3798, lr: 0.0000\n",
      "Epoch: 910, Training loss: 1.362647, Validation loss: 1.3700, lr: 0.0000\n",
      "Epoch: 911, Training loss: 1.358889, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 912, Training loss: 1.393975, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 913, Training loss: 1.368268, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 914, Training loss: 1.373975, Validation loss: 1.3399, lr: 0.0000\n",
      "Epoch: 915, Training loss: 1.377440, Validation loss: 1.3789, lr: 0.0000\n",
      "Epoch: 916, Training loss: 1.395005, Validation loss: 1.3785, lr: 0.0000\n",
      "Epoch: 917, Training loss: 1.410191, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 918, Training loss: 1.447225, Validation loss: 1.3567, lr: 0.0000\n",
      "Epoch: 919, Training loss: 1.375829, Validation loss: 1.3750, lr: 0.0000\n",
      "Epoch: 920, Training loss: 1.375125, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 921, Training loss: 1.406220, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 922, Training loss: 1.351699, Validation loss: 1.3874, lr: 0.0000\n",
      "Epoch: 923, Training loss: 1.403488, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 924, Training loss: 1.426517, Validation loss: 1.3877, lr: 0.0000\n",
      "Epoch: 925, Training loss: 1.363216, Validation loss: 1.3665, lr: 0.0000\n",
      "Epoch: 926, Training loss: 1.354633, Validation loss: 1.3759, lr: 0.0000\n",
      "Epoch: 927, Training loss: 1.378790, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 928, Training loss: 1.428936, Validation loss: 1.3730, lr: 0.0000\n",
      "Epoch: 929, Training loss: 1.388849, Validation loss: 1.3789, lr: 0.0000\n",
      "Epoch: 930, Training loss: 1.362779, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 931, Training loss: 1.358061, Validation loss: 1.4851, lr: 0.0000\n",
      "Epoch: 932, Training loss: 1.412704, Validation loss: 1.4479, lr: 0.0000\n",
      "Epoch: 933, Training loss: 1.380039, Validation loss: 1.3776, lr: 0.0000\n",
      "Epoch: 934, Training loss: 1.485072, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 935, Training loss: 1.389886, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 936, Training loss: 1.389140, Validation loss: 1.3874, lr: 0.0000\n",
      "Epoch: 937, Training loss: 1.383409, Validation loss: 1.4040, lr: 0.0000\n",
      "Epoch: 938, Training loss: 1.399742, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 939, Training loss: 1.380453, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 940, Training loss: 1.361127, Validation loss: 1.6623, lr: 0.0000\n",
      "Epoch: 941, Training loss: 1.400443, Validation loss: 2.5123, lr: 0.0000\n",
      "Epoch: 942, Training loss: 1.443056, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 943, Training loss: 1.390555, Validation loss: 1.3744, lr: 0.0000\n",
      "Epoch: 944, Training loss: 1.381601, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 945, Training loss: 1.382829, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 946, Training loss: 1.389156, Validation loss: 1.3696, lr: 0.0000\n",
      "Epoch: 947, Training loss: 1.385458, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 948, Training loss: 1.385441, Validation loss: 1.3794, lr: 0.0000\n",
      "Epoch: 949, Training loss: 1.380401, Validation loss: 1.3725, lr: 0.0000\n",
      "Epoch: 950, Training loss: 1.364870, Validation loss: 1.3906, lr: 0.0000\n",
      "Epoch: 951, Training loss: 1.371429, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 952, Training loss: 1.382730, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 953, Training loss: 1.401912, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 954, Training loss: 1.402310, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 955, Training loss: 1.380310, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 956, Training loss: 1.398221, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 957, Training loss: 1.378792, Validation loss: 1.3875, lr: 0.0000\n",
      "Epoch: 958, Training loss: 1.400484, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 959, Training loss: 1.376673, Validation loss: 1.3561, lr: 0.0000\n",
      "Epoch: 960, Training loss: 1.400096, Validation loss: 1.3625, lr: 0.0000\n",
      "Epoch: 961, Training loss: 1.381140, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 962, Training loss: 1.346033, Validation loss: 1.3598, lr: 0.0000\n",
      "Epoch: 963, Training loss: 1.365246, Validation loss: 1.3738, lr: 0.0000\n",
      "Epoch: 964, Training loss: 1.479631, Validation loss: 1.3803, lr: 0.0000\n",
      "Epoch: 965, Training loss: 1.435653, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 966, Training loss: 1.372167, Validation loss: 1.3882, lr: 0.0000\n",
      "Epoch: 967, Training loss: 1.398002, Validation loss: 1.3903, lr: 0.0000\n",
      "Epoch: 968, Training loss: 1.384775, Validation loss: 1.3781, lr: 0.0000\n",
      "Epoch: 969, Training loss: 1.375128, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 970, Training loss: 1.396285, Validation loss: 1.3797, lr: 0.0000\n",
      "Epoch: 971, Training loss: 1.394613, Validation loss: 1.4348, lr: 0.0000\n",
      "Epoch: 972, Training loss: 1.374811, Validation loss: 1.3923, lr: 0.0000\n",
      "Epoch: 973, Training loss: 1.362535, Validation loss: 1.3642, lr: 0.0000\n",
      "Epoch: 974, Training loss: 1.393992, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 975, Training loss: 1.385781, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 976, Training loss: 1.366697, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 977, Training loss: 1.406082, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 978, Training loss: 1.383875, Validation loss: 1.3904, lr: 0.0000\n",
      "Epoch: 979, Training loss: 1.369665, Validation loss: 1.3772, lr: 0.0000\n",
      "Epoch: 980, Training loss: 1.392205, Validation loss: 1.3684, lr: 0.0000\n",
      "Epoch: 981, Training loss: 1.363249, Validation loss: 1.3802, lr: 0.0000\n",
      "Epoch: 982, Training loss: 1.386851, Validation loss: 1.3915, lr: 0.0000\n",
      "Epoch: 983, Training loss: 1.386176, Validation loss: 1.3719, lr: 0.0000\n",
      "Epoch: 984, Training loss: 1.391133, Validation loss: 1.3780, lr: 0.0000\n",
      "Epoch: 985, Training loss: 1.361490, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 986, Training loss: 1.385424, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 987, Training loss: 1.368459, Validation loss: 1.3785, lr: 0.0000\n",
      "Epoch: 988, Training loss: 1.408158, Validation loss: 1.3727, lr: 0.0000\n",
      "Epoch: 989, Training loss: 1.380487, Validation loss: 1.3887, lr: 0.0000\n",
      "Epoch: 990, Training loss: 1.382222, Validation loss: 1.3984, lr: 0.0000\n",
      "Epoch: 991, Training loss: 1.365605, Validation loss: 1.3705, lr: 0.0000\n",
      "Epoch: 992, Training loss: 1.349054, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 993, Training loss: 1.375879, Validation loss: 1.3627, lr: 0.0000\n",
      "Epoch: 994, Training loss: 1.393284, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 995, Training loss: 1.379964, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 996, Training loss: 1.359563, Validation loss: 1.3511, lr: 0.0000\n",
      "Epoch: 997, Training loss: 1.419004, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 998, Training loss: 1.376259, Validation loss: 1.3789, lr: 0.0000\n",
      "Epoch: 999, Training loss: 1.395036, Validation loss: 1.3804, lr: 0.0000\n",
      "Final test loss: 1.3723\n",
      "=== Run 08/10 ===\n",
      "\n",
      "---- Settings: \n",
      "\n",
      "epochs : 1000\n",
      "hidden_channels : [32]\n",
      "out_channels : 10\n",
      "inner_product_features : False\n",
      "batch_size : 64\n",
      "lr : 0.01\n",
      "momentum : 0.9\n",
      "dropout : 0.0\n",
      "batch_norm : batch_norm\n",
      "bias : True\n",
      "order : 2\n",
      "diffusion : True\n",
      "frac_sampled_nb : -1\n",
      "include_positions : False\n",
      "include_self : True\n",
      "vec_norm : False\n",
      "emb_norm : False\n",
      "seed : 0\n",
      "dim_signal : 100\n",
      "dim_emb : 100\n",
      "n_sampled_nb : -1\n",
      "\n",
      "---- Number of features to pass to the MLP:  1010100\n",
      "---- Total number of parameters:  32323627\n",
      "\n",
      "Using device cuda:0\n",
      "\n",
      "---- Training network ...\n",
      "\n",
      "---- Timestamp: 20250614-160140\n",
      "\n",
      " *och: 0, Training loss: 1.405445, Validation loss: 1.3356, lr: 0.0100\n",
      "Epoch: 1, Training loss: 1.396365, Validation loss: 1.3786, lr: 0.0100\n",
      "Epoch: 2, Training loss: 1.384691, Validation loss: 1.3789, lr: 0.0100\n",
      "Epoch: 3, Training loss: 1.425178, Validation loss: 1.3769, lr: 0.0100\n",
      "Epoch: 4, Training loss: 1.433893, Validation loss: 1.3861, lr: 0.0100\n",
      "Epoch: 5, Training loss: 1.433284, Validation loss: 1.3830, lr: 0.0100\n",
      "Epoch: 6, Training loss: 1.398398, Validation loss: 1.3737, lr: 0.0100\n",
      " *och: 7, Training loss: 1.382025, Validation loss: 1.3307, lr: 0.0100\n",
      "Epoch: 8, Training loss: 1.388793, Validation loss: 1.3828, lr: 0.0100\n",
      "Epoch: 9, Training loss: 1.436177, Validation loss: 1.3817, lr: 0.0100\n",
      "Epoch: 10, Training loss: 1.375389, Validation loss: 1.3491, lr: 0.0100\n",
      "Epoch: 11, Training loss: 1.404025, Validation loss: 1.3819, lr: 0.0100\n",
      "Epoch: 12, Training loss: 1.378820, Validation loss: 1.3773, lr: 0.0100\n",
      "Epoch: 13, Training loss: 1.363782, Validation loss: 1.3831, lr: 0.0100\n",
      "Epoch: 14, Training loss: 1.365108, Validation loss: 1.3849, lr: 0.0100\n",
      "Epoch: 15, Training loss: 1.388068, Validation loss: 1.4103, lr: 0.0100\n",
      "Epoch: 16, Training loss: 1.386688, Validation loss: 1.3795, lr: 0.0100\n",
      "Epoch: 17, Training loss: 1.370632, Validation loss: 1.3821, lr: 0.0100\n",
      "Epoch: 18, Training loss: 1.378716, Validation loss: 1.3809, lr: 0.0100\n",
      "Epoch: 19, Training loss: 1.374540, Validation loss: 1.3800, lr: 0.0100\n",
      "Epoch: 20, Training loss: 1.523969, Validation loss: 1.3865, lr: 0.0100\n",
      "Epoch: 21, Training loss: 1.416115, Validation loss: 1.3904, lr: 0.0100\n",
      "Epoch: 22, Training loss: 1.393746, Validation loss: 1.3855, lr: 0.0100\n",
      "Epoch: 23, Training loss: 1.361041, Validation loss: 1.3843, lr: 0.0100\n",
      "Epoch: 24, Training loss: 1.385049, Validation loss: 1.3758, lr: 0.0100\n",
      "Epoch: 25, Training loss: 1.375905, Validation loss: 1.3542, lr: 0.0100\n",
      "Epoch: 26, Training loss: 1.384366, Validation loss: 1.3478, lr: 0.0100\n",
      "Epoch: 27, Training loss: 1.368725, Validation loss: 1.3980, lr: 0.0100\n",
      "Epoch: 28, Training loss: 1.360272, Validation loss: 1.3785, lr: 0.0100\n",
      "Epoch: 29, Training loss: 1.376999, Validation loss: 1.8872, lr: 0.0100\n",
      " *och: 30, Training loss: 1.383987, Validation loss: 1.3101, lr: 0.0100\n",
      "Epoch: 31, Training loss: 1.356609, Validation loss: 1.3759, lr: 0.0100\n",
      "Epoch: 32, Training loss: 1.365742, Validation loss: 1.3872, lr: 0.0100\n",
      "Epoch: 33, Training loss: 1.386985, Validation loss: 1.3872, lr: 0.0100\n",
      "Epoch: 34, Training loss: 1.348765, Validation loss: 1.3762, lr: 0.0100\n",
      "Epoch: 35, Training loss: 1.369640, Validation loss: 1.3866, lr: 0.0100\n",
      "Epoch: 36, Training loss: 1.343771, Validation loss: 1.3838, lr: 0.0100\n",
      "Epoch: 37, Training loss: 1.375950, Validation loss: 1.3849, lr: 0.0100\n",
      "Epoch: 38, Training loss: 1.379791, Validation loss: 1.3767, lr: 0.0100\n",
      "Epoch: 39, Training loss: 1.347421, Validation loss: 1.3462, lr: 0.0100\n",
      "Epoch: 40, Training loss: 1.393203, Validation loss: 1.3526, lr: 0.0100\n",
      "Epoch: 41, Training loss: 1.386281, Validation loss: 1.3946, lr: 0.0100\n",
      "Epoch: 42, Training loss: 1.364463, Validation loss: 1.3643, lr: 0.0100\n",
      "Epoch: 43, Training loss: 1.366052, Validation loss: 1.3424, lr: 0.0100\n",
      "Epoch: 44, Training loss: 1.405407, Validation loss: 1.3900, lr: 0.0100\n",
      "Epoch: 45, Training loss: 1.367608, Validation loss: 1.3572, lr: 0.0100\n",
      "Epoch: 46, Training loss: 1.369292, Validation loss: 1.3662, lr: 0.0100\n",
      "Epoch: 47, Training loss: 1.382446, Validation loss: 1.3767, lr: 0.0010\n",
      "Epoch: 48, Training loss: 1.342420, Validation loss: 1.3662, lr: 0.0010\n",
      "Epoch: 49, Training loss: 1.363866, Validation loss: 1.3770, lr: 0.0010\n",
      "Epoch: 50, Training loss: 1.341989, Validation loss: 1.3612, lr: 0.0010\n",
      "Epoch: 51, Training loss: 1.360014, Validation loss: 1.3643, lr: 0.0010\n",
      "Epoch: 52, Training loss: 1.370847, Validation loss: 1.3649, lr: 0.0010\n",
      "Epoch: 53, Training loss: 1.405199, Validation loss: 1.3586, lr: 0.0010\n",
      "Epoch: 54, Training loss: 1.411410, Validation loss: 1.3746, lr: 0.0010\n",
      "Epoch: 55, Training loss: 1.381422, Validation loss: 1.3714, lr: 0.0010\n",
      "Epoch: 56, Training loss: 1.336892, Validation loss: 1.3761, lr: 0.0010\n",
      "Epoch: 57, Training loss: 1.361078, Validation loss: 1.3708, lr: 0.0010\n",
      "Epoch: 58, Training loss: 1.373146, Validation loss: 1.3713, lr: 0.0010\n",
      "Epoch: 59, Training loss: 1.350303, Validation loss: 1.3368, lr: 0.0010\n",
      "Epoch: 60, Training loss: 1.417380, Validation loss: 1.3869, lr: 0.0010\n",
      "Epoch: 61, Training loss: 1.370641, Validation loss: 1.3822, lr: 0.0010\n",
      "Epoch: 62, Training loss: 1.339691, Validation loss: 1.3717, lr: 0.0010\n",
      "Epoch: 63, Training loss: 1.348928, Validation loss: 1.3646, lr: 0.0010\n",
      "Epoch: 64, Training loss: 1.337633, Validation loss: 1.3577, lr: 0.0010\n",
      " *och: 65, Training loss: 1.345423, Validation loss: 1.3051, lr: 0.0010\n",
      "Epoch: 66, Training loss: 1.370739, Validation loss: 1.3974, lr: 0.0010\n",
      "Epoch: 67, Training loss: 1.376824, Validation loss: 1.3823, lr: 0.0001\n",
      "Epoch: 68, Training loss: 1.338307, Validation loss: 1.3497, lr: 0.0001\n",
      "Epoch: 69, Training loss: 1.340889, Validation loss: 1.3593, lr: 0.0001\n",
      "Epoch: 70, Training loss: 1.331331, Validation loss: 1.3450, lr: 0.0001\n",
      "Epoch: 71, Training loss: 1.330537, Validation loss: 1.3692, lr: 0.0001\n",
      "Epoch: 72, Training loss: 1.377647, Validation loss: 1.3696, lr: 0.0001\n",
      "Epoch: 73, Training loss: 1.425346, Validation loss: 1.3144, lr: 0.0001\n",
      "Epoch: 74, Training loss: 1.347805, Validation loss: 1.3795, lr: 0.0001\n",
      "Epoch: 75, Training loss: 1.386441, Validation loss: 1.3607, lr: 0.0001\n",
      "Epoch: 76, Training loss: 1.412106, Validation loss: 1.3722, lr: 0.0001\n",
      "Epoch: 77, Training loss: 1.383308, Validation loss: 1.3866, lr: 0.0001\n",
      "Epoch: 78, Training loss: 1.361683, Validation loss: 1.3333, lr: 0.0001\n",
      "Epoch: 79, Training loss: 1.346799, Validation loss: 1.3719, lr: 0.0001\n",
      "Epoch: 80, Training loss: 1.336932, Validation loss: 1.3796, lr: 0.0001\n",
      "Epoch: 81, Training loss: 1.330194, Validation loss: 1.3770, lr: 0.0001\n",
      "Epoch: 82, Training loss: 1.369013, Validation loss: 1.3802, lr: 0.0001\n",
      "Epoch: 83, Training loss: 1.370108, Validation loss: 1.3772, lr: 0.0001\n",
      "Epoch: 84, Training loss: 1.388569, Validation loss: 1.3743, lr: 0.0001\n",
      "Epoch: 85, Training loss: 1.344456, Validation loss: 1.3720, lr: 0.0001\n",
      "Epoch: 86, Training loss: 1.376607, Validation loss: 1.3726, lr: 0.0001\n",
      "Epoch: 87, Training loss: 1.419804, Validation loss: 1.3662, lr: 0.0001\n",
      "Epoch: 88, Training loss: 1.351884, Validation loss: 1.3505, lr: 0.0001\n",
      "Epoch: 89, Training loss: 1.330389, Validation loss: 1.3721, lr: 0.0001\n",
      "Epoch: 90, Training loss: 1.327422, Validation loss: 1.3727, lr: 0.0001\n",
      "Epoch: 91, Training loss: 1.345356, Validation loss: 1.3624, lr: 0.0001\n",
      "Epoch: 92, Training loss: 1.325376, Validation loss: 1.3688, lr: 0.0001\n",
      " *och: 93, Training loss: 1.351158, Validation loss: 1.2603, lr: 0.0001\n",
      "Epoch: 94, Training loss: 1.355277, Validation loss: 1.3724, lr: 0.0001\n",
      "Epoch: 95, Training loss: 1.371916, Validation loss: 1.3650, lr: 0.0001\n",
      "Epoch: 96, Training loss: 1.336788, Validation loss: 1.9081, lr: 0.0001\n",
      "Epoch: 97, Training loss: 1.351228, Validation loss: 1.3700, lr: 0.0001\n",
      "Epoch: 98, Training loss: 1.382265, Validation loss: 1.3677, lr: 0.0001\n",
      "Epoch: 99, Training loss: 1.360687, Validation loss: 1.3551, lr: 0.0001\n",
      "Epoch: 100, Training loss: 1.374174, Validation loss: 1.3761, lr: 0.0001\n",
      "Epoch: 101, Training loss: 1.385695, Validation loss: 1.3653, lr: 0.0001\n",
      "Epoch: 102, Training loss: 1.394995, Validation loss: 1.3775, lr: 0.0001\n",
      "Epoch: 103, Training loss: 1.354201, Validation loss: 1.3725, lr: 0.0000\n",
      "Epoch: 104, Training loss: 1.347615, Validation loss: 1.3752, lr: 0.0000\n",
      "Epoch: 105, Training loss: 1.363528, Validation loss: 1.3533, lr: 0.0000\n",
      "Epoch: 106, Training loss: 1.350846, Validation loss: 1.3584, lr: 0.0000\n",
      "Epoch: 107, Training loss: 1.347841, Validation loss: 1.3983, lr: 0.0000\n",
      "Epoch: 108, Training loss: 1.365991, Validation loss: 1.3445, lr: 0.0000\n",
      "Epoch: 109, Training loss: 1.357331, Validation loss: 1.6851, lr: 0.0000\n",
      "Epoch: 110, Training loss: 1.352519, Validation loss: 1.4476, lr: 0.0000\n",
      "Epoch: 111, Training loss: 1.359306, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 112, Training loss: 1.377895, Validation loss: 1.3688, lr: 0.0000\n",
      "Epoch: 113, Training loss: 1.343016, Validation loss: 1.3528, lr: 0.0000\n",
      "Epoch: 114, Training loss: 1.362127, Validation loss: 1.3692, lr: 0.0000\n",
      "Epoch: 115, Training loss: 1.390528, Validation loss: 1.3762, lr: 0.0000\n",
      "Epoch: 116, Training loss: 1.338616, Validation loss: 1.3711, lr: 0.0000\n",
      "Epoch: 117, Training loss: 1.331576, Validation loss: 1.3377, lr: 0.0000\n",
      "Epoch: 118, Training loss: 1.323723, Validation loss: 1.3697, lr: 0.0000\n",
      "Epoch: 119, Training loss: 1.403254, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 120, Training loss: 1.392934, Validation loss: 1.3638, lr: 0.0000\n",
      "Epoch: 121, Training loss: 1.329988, Validation loss: 1.3444, lr: 0.0000\n",
      "Epoch: 122, Training loss: 1.361023, Validation loss: 1.3790, lr: 0.0000\n",
      "Epoch: 123, Training loss: 1.383308, Validation loss: 1.3467, lr: 0.0000\n",
      "Epoch: 124, Training loss: 1.360327, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 125, Training loss: 1.344144, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 126, Training loss: 1.347182, Validation loss: 1.3797, lr: 0.0000\n",
      "Epoch: 127, Training loss: 1.371488, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 128, Training loss: 1.330003, Validation loss: 1.3672, lr: 0.0000\n",
      "Epoch: 129, Training loss: 1.349743, Validation loss: 1.3798, lr: 0.0000\n",
      "Epoch: 130, Training loss: 1.390865, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 131, Training loss: 1.332409, Validation loss: 1.3782, lr: 0.0000\n",
      "Epoch: 132, Training loss: 1.356331, Validation loss: 1.3727, lr: 0.0000\n",
      "Epoch: 133, Training loss: 1.336998, Validation loss: 1.3800, lr: 0.0000\n",
      "Epoch: 134, Training loss: 1.367518, Validation loss: 1.3662, lr: 0.0000\n",
      "Epoch: 135, Training loss: 1.355796, Validation loss: 1.3728, lr: 0.0000\n",
      "Epoch: 136, Training loss: 1.377020, Validation loss: 1.3449, lr: 0.0000\n",
      "Epoch: 137, Training loss: 1.367391, Validation loss: 1.3660, lr: 0.0000\n",
      "Epoch: 138, Training loss: 1.344993, Validation loss: 1.3554, lr: 0.0000\n",
      "Epoch: 139, Training loss: 1.372285, Validation loss: 1.3493, lr: 0.0000\n",
      "Epoch: 140, Training loss: 1.438438, Validation loss: 1.3766, lr: 0.0000\n",
      "Epoch: 141, Training loss: 1.344994, Validation loss: 1.3765, lr: 0.0000\n",
      "Epoch: 142, Training loss: 1.336489, Validation loss: 1.3651, lr: 0.0000\n",
      "Epoch: 143, Training loss: 1.373342, Validation loss: 1.3771, lr: 0.0000\n",
      "Epoch: 144, Training loss: 1.433091, Validation loss: 1.3422, lr: 0.0000\n",
      "Epoch: 145, Training loss: 1.351816, Validation loss: 1.3874, lr: 0.0000\n",
      "Epoch: 146, Training loss: 1.361661, Validation loss: 1.3718, lr: 0.0000\n",
      "Epoch: 147, Training loss: 1.377315, Validation loss: 1.3354, lr: 0.0000\n",
      "Epoch: 148, Training loss: 1.342309, Validation loss: 1.3769, lr: 0.0000\n",
      "Epoch: 149, Training loss: 1.387555, Validation loss: 1.3605, lr: 0.0000\n",
      "Epoch: 150, Training loss: 1.334336, Validation loss: 1.3731, lr: 0.0000\n",
      "Epoch: 151, Training loss: 1.353079, Validation loss: 1.3675, lr: 0.0000\n",
      "Epoch: 152, Training loss: 1.344971, Validation loss: 1.3710, lr: 0.0000\n",
      "Epoch: 153, Training loss: 1.363291, Validation loss: 1.3544, lr: 0.0000\n",
      "Epoch: 154, Training loss: 1.361508, Validation loss: 1.3736, lr: 0.0000\n",
      "Epoch: 155, Training loss: 1.377427, Validation loss: 1.3702, lr: 0.0000\n",
      "Epoch: 156, Training loss: 1.335713, Validation loss: 1.3128, lr: 0.0000\n",
      "Epoch: 157, Training loss: 1.332784, Validation loss: 1.3631, lr: 0.0000\n",
      "Epoch: 158, Training loss: 1.329323, Validation loss: 1.3681, lr: 0.0000\n",
      "Epoch: 159, Training loss: 1.358584, Validation loss: 1.3793, lr: 0.0000\n",
      "Epoch: 160, Training loss: 1.389028, Validation loss: 1.3503, lr: 0.0000\n",
      "Epoch: 161, Training loss: 1.402887, Validation loss: 1.3701, lr: 0.0000\n",
      "Epoch: 162, Training loss: 1.370199, Validation loss: 1.3741, lr: 0.0000\n",
      "Epoch: 163, Training loss: 1.429076, Validation loss: 1.3577, lr: 0.0000\n",
      "Epoch: 164, Training loss: 1.374129, Validation loss: 1.3650, lr: 0.0000\n",
      "Epoch: 165, Training loss: 1.331526, Validation loss: 1.3764, lr: 0.0000\n",
      "Epoch: 166, Training loss: 1.337076, Validation loss: 1.3686, lr: 0.0000\n",
      "Epoch: 167, Training loss: 1.361144, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 168, Training loss: 1.394179, Validation loss: 1.3437, lr: 0.0000\n",
      "Epoch: 169, Training loss: 1.461254, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 170, Training loss: 1.358846, Validation loss: 1.3791, lr: 0.0000\n",
      "Epoch: 171, Training loss: 1.372886, Validation loss: 1.3738, lr: 0.0000\n",
      "Epoch: 172, Training loss: 1.324036, Validation loss: 1.3799, lr: 0.0000\n",
      "Epoch: 173, Training loss: 1.316629, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 174, Training loss: 1.331329, Validation loss: 1.3640, lr: 0.0000\n",
      "Epoch: 175, Training loss: 1.377793, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 176, Training loss: 1.366593, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 177, Training loss: 1.364308, Validation loss: 1.3778, lr: 0.0000\n",
      "Epoch: 178, Training loss: 1.358829, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 179, Training loss: 1.468406, Validation loss: 1.3768, lr: 0.0000\n",
      "Epoch: 180, Training loss: 1.352608, Validation loss: 1.3718, lr: 0.0000\n",
      "Epoch: 181, Training loss: 1.400226, Validation loss: 1.3894, lr: 0.0000\n",
      "Epoch: 182, Training loss: 1.344911, Validation loss: 1.3234, lr: 0.0000\n",
      "Epoch: 183, Training loss: 1.355887, Validation loss: 1.3889, lr: 0.0000\n",
      "Epoch: 184, Training loss: 1.328962, Validation loss: 1.3739, lr: 0.0000\n",
      "Epoch: 185, Training loss: 1.392777, Validation loss: 1.4205, lr: 0.0000\n",
      "Epoch: 186, Training loss: 1.359303, Validation loss: 1.3765, lr: 0.0000\n",
      "Epoch: 187, Training loss: 1.354142, Validation loss: 1.3727, lr: 0.0000\n",
      "Epoch: 188, Training loss: 1.355263, Validation loss: 1.3692, lr: 0.0000\n",
      "Epoch: 189, Training loss: 1.333742, Validation loss: 1.3369, lr: 0.0000\n",
      "Epoch: 190, Training loss: 1.334931, Validation loss: 1.3574, lr: 0.0000\n",
      "Epoch: 191, Training loss: 1.427732, Validation loss: 1.3779, lr: 0.0000\n",
      "Epoch: 192, Training loss: 1.324897, Validation loss: 1.3567, lr: 0.0000\n",
      "Epoch: 193, Training loss: 1.338574, Validation loss: 1.3727, lr: 0.0000\n",
      "Epoch: 194, Training loss: 1.330250, Validation loss: 1.3712, lr: 0.0000\n",
      "Epoch: 195, Training loss: 1.404775, Validation loss: 1.4775, lr: 0.0000\n",
      "Epoch: 196, Training loss: 1.384880, Validation loss: 1.3914, lr: 0.0000\n",
      "Epoch: 197, Training loss: 1.341645, Validation loss: 1.3220, lr: 0.0000\n",
      "Epoch: 198, Training loss: 1.322020, Validation loss: 1.3747, lr: 0.0000\n",
      "Epoch: 199, Training loss: 1.377214, Validation loss: 1.3553, lr: 0.0000\n",
      "Epoch: 200, Training loss: 1.361944, Validation loss: 1.4735, lr: 0.0000\n",
      "Epoch: 201, Training loss: 1.414989, Validation loss: 1.3938, lr: 0.0000\n",
      "Epoch: 202, Training loss: 1.327374, Validation loss: 1.3641, lr: 0.0000\n",
      "Epoch: 203, Training loss: 1.456455, Validation loss: 1.3512, lr: 0.0000\n",
      "Epoch: 204, Training loss: 1.332829, Validation loss: 1.3779, lr: 0.0000\n",
      "Epoch: 205, Training loss: 1.356385, Validation loss: 1.3491, lr: 0.0000\n",
      "Epoch: 206, Training loss: 1.363262, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 207, Training loss: 1.382085, Validation loss: 1.3711, lr: 0.0000\n",
      "Epoch: 208, Training loss: 1.400374, Validation loss: 1.3569, lr: 0.0000\n",
      "Epoch: 209, Training loss: 1.348715, Validation loss: 1.3708, lr: 0.0000\n",
      "Epoch: 210, Training loss: 1.335396, Validation loss: 1.3765, lr: 0.0000\n",
      "Epoch: 211, Training loss: 1.541562, Validation loss: 1.3484, lr: 0.0000\n",
      "Epoch: 212, Training loss: 1.373367, Validation loss: 1.3766, lr: 0.0000\n",
      "Epoch: 213, Training loss: 1.390200, Validation loss: 1.3676, lr: 0.0000\n",
      "Epoch: 214, Training loss: 1.375394, Validation loss: 1.3740, lr: 0.0000\n",
      "Epoch: 215, Training loss: 1.356423, Validation loss: 1.3746, lr: 0.0000\n",
      "Epoch: 216, Training loss: 1.351841, Validation loss: 1.3794, lr: 0.0000\n",
      "Epoch: 217, Training loss: 1.345517, Validation loss: 1.3739, lr: 0.0000\n",
      "Epoch: 218, Training loss: 1.341468, Validation loss: 1.3690, lr: 0.0000\n",
      "Epoch: 219, Training loss: 1.358557, Validation loss: 1.3251, lr: 0.0000\n",
      "Epoch: 220, Training loss: 1.352008, Validation loss: 1.3648, lr: 0.0000\n",
      "Epoch: 221, Training loss: 1.338708, Validation loss: 1.3643, lr: 0.0000\n",
      "Epoch: 222, Training loss: 1.342397, Validation loss: 1.3645, lr: 0.0000\n",
      "Epoch: 223, Training loss: 1.338925, Validation loss: 1.3631, lr: 0.0000\n",
      "Epoch: 224, Training loss: 1.340815, Validation loss: 1.3449, lr: 0.0000\n",
      "Epoch: 225, Training loss: 1.338993, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 226, Training loss: 1.352102, Validation loss: 1.3620, lr: 0.0000\n",
      "Epoch: 227, Training loss: 1.339769, Validation loss: 1.3681, lr: 0.0000\n",
      "Epoch: 228, Training loss: 1.355133, Validation loss: 1.3748, lr: 0.0000\n",
      "Epoch: 229, Training loss: 1.491226, Validation loss: 1.3744, lr: 0.0000\n",
      "Epoch: 230, Training loss: 1.330190, Validation loss: 1.3376, lr: 0.0000\n",
      "Epoch: 231, Training loss: 1.347062, Validation loss: 1.3776, lr: 0.0000\n",
      "Epoch: 232, Training loss: 1.387090, Validation loss: 1.3788, lr: 0.0000\n",
      "Epoch: 233, Training loss: 1.344199, Validation loss: 1.3763, lr: 0.0000\n",
      "Epoch: 234, Training loss: 1.330679, Validation loss: 1.3499, lr: 0.0000\n",
      "Epoch: 235, Training loss: 1.350440, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 236, Training loss: 1.367780, Validation loss: 1.3732, lr: 0.0000\n",
      "Epoch: 237, Training loss: 1.332025, Validation loss: 1.3730, lr: 0.0000\n",
      "Epoch: 238, Training loss: 1.382030, Validation loss: 1.3683, lr: 0.0000\n",
      "Epoch: 239, Training loss: 1.349410, Validation loss: 1.3527, lr: 0.0000\n",
      "Epoch: 240, Training loss: 1.336013, Validation loss: 1.3701, lr: 0.0000\n",
      "Epoch: 241, Training loss: 1.359487, Validation loss: 1.3548, lr: 0.0000\n",
      "Epoch: 242, Training loss: 1.308722, Validation loss: 1.4227, lr: 0.0000\n",
      "Epoch: 243, Training loss: 1.355761, Validation loss: 1.3347, lr: 0.0000\n",
      "Epoch: 244, Training loss: 1.364164, Validation loss: 1.3734, lr: 0.0000\n",
      "Epoch: 245, Training loss: 1.362249, Validation loss: 1.3778, lr: 0.0000\n",
      "Epoch: 246, Training loss: 1.376927, Validation loss: 1.3758, lr: 0.0000\n",
      "Epoch: 247, Training loss: 1.354924, Validation loss: 1.3690, lr: 0.0000\n",
      "Epoch: 248, Training loss: 1.382345, Validation loss: 1.3789, lr: 0.0000\n",
      "Epoch: 249, Training loss: 1.350070, Validation loss: 1.3615, lr: 0.0000\n",
      "Epoch: 250, Training loss: 1.357944, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 251, Training loss: 1.390450, Validation loss: 1.3783, lr: 0.0000\n",
      "Epoch: 252, Training loss: 1.338641, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 253, Training loss: 1.455771, Validation loss: 1.3576, lr: 0.0000\n",
      "Epoch: 254, Training loss: 1.348845, Validation loss: 1.3647, lr: 0.0000\n",
      "Epoch: 255, Training loss: 1.374474, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 256, Training loss: 1.342417, Validation loss: 1.3566, lr: 0.0000\n",
      "Epoch: 257, Training loss: 1.352864, Validation loss: 1.3735, lr: 0.0000\n",
      "Epoch: 258, Training loss: 1.354260, Validation loss: 1.3426, lr: 0.0000\n",
      "Epoch: 259, Training loss: 1.364834, Validation loss: 1.3682, lr: 0.0000\n",
      "Epoch: 260, Training loss: 1.330943, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 261, Training loss: 1.374965, Validation loss: 1.3761, lr: 0.0000\n",
      "Epoch: 262, Training loss: 1.345452, Validation loss: 1.3780, lr: 0.0000\n",
      "Epoch: 263, Training loss: 1.338494, Validation loss: 1.3613, lr: 0.0000\n",
      "Epoch: 264, Training loss: 1.355976, Validation loss: 1.3770, lr: 0.0000\n",
      "Epoch: 265, Training loss: 1.374222, Validation loss: 1.3667, lr: 0.0000\n",
      "Epoch: 266, Training loss: 1.330904, Validation loss: 1.3644, lr: 0.0000\n",
      "Epoch: 267, Training loss: 1.339899, Validation loss: 1.3782, lr: 0.0000\n",
      "Epoch: 268, Training loss: 1.358155, Validation loss: 1.3683, lr: 0.0000\n",
      "Epoch: 269, Training loss: 1.351325, Validation loss: 1.4582, lr: 0.0000\n",
      "Epoch: 270, Training loss: 1.357424, Validation loss: 1.3495, lr: 0.0000\n",
      "Epoch: 271, Training loss: 1.345658, Validation loss: 1.3800, lr: 0.0000\n",
      "Epoch: 272, Training loss: 1.339837, Validation loss: 1.3240, lr: 0.0000\n",
      "Epoch: 273, Training loss: 1.363421, Validation loss: 1.3449, lr: 0.0000\n",
      "Epoch: 274, Training loss: 1.336787, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 275, Training loss: 1.357083, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 276, Training loss: 1.355155, Validation loss: 1.3496, lr: 0.0000\n",
      "Epoch: 277, Training loss: 1.351032, Validation loss: 1.3619, lr: 0.0000\n",
      "Epoch: 278, Training loss: 1.362548, Validation loss: 1.3313, lr: 0.0000\n",
      "Epoch: 279, Training loss: 1.346142, Validation loss: 1.3767, lr: 0.0000\n",
      "Epoch: 280, Training loss: 1.342333, Validation loss: 1.3658, lr: 0.0000\n",
      "Epoch: 281, Training loss: 1.513821, Validation loss: 1.3714, lr: 0.0000\n",
      "Epoch: 282, Training loss: 1.342028, Validation loss: 1.3636, lr: 0.0000\n",
      "Epoch: 283, Training loss: 1.332194, Validation loss: 1.3646, lr: 0.0000\n",
      "Epoch: 284, Training loss: 1.360808, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 285, Training loss: 1.354585, Validation loss: 1.3443, lr: 0.0000\n",
      "Epoch: 286, Training loss: 1.343471, Validation loss: 1.3294, lr: 0.0000\n",
      "Epoch: 287, Training loss: 1.322794, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 288, Training loss: 1.346986, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 289, Training loss: 1.326723, Validation loss: 1.3683, lr: 0.0000\n",
      "Epoch: 290, Training loss: 1.356839, Validation loss: 1.3415, lr: 0.0000\n",
      "Epoch: 291, Training loss: 1.352738, Validation loss: 1.3758, lr: 0.0000\n",
      "Epoch: 292, Training loss: 1.366450, Validation loss: 1.3573, lr: 0.0000\n",
      "Epoch: 293, Training loss: 1.390003, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 294, Training loss: 1.316033, Validation loss: 1.3797, lr: 0.0000\n",
      "Epoch: 295, Training loss: 1.347401, Validation loss: 1.3641, lr: 0.0000\n",
      "Epoch: 296, Training loss: 1.382503, Validation loss: 1.3557, lr: 0.0000\n",
      "Epoch: 297, Training loss: 1.357680, Validation loss: 1.3624, lr: 0.0000\n",
      "Epoch: 298, Training loss: 1.450474, Validation loss: 1.3783, lr: 0.0000\n",
      "Epoch: 299, Training loss: 1.345058, Validation loss: 1.3756, lr: 0.0000\n",
      "Epoch: 300, Training loss: 1.347419, Validation loss: 1.3692, lr: 0.0000\n",
      "Epoch: 301, Training loss: 1.408602, Validation loss: 1.3720, lr: 0.0000\n",
      "Epoch: 302, Training loss: 1.378458, Validation loss: 1.3471, lr: 0.0000\n",
      "Epoch: 303, Training loss: 1.394435, Validation loss: 1.3263, lr: 0.0000\n",
      "Epoch: 304, Training loss: 1.338995, Validation loss: 1.3785, lr: 0.0000\n",
      "Epoch: 305, Training loss: 1.398439, Validation loss: 1.3685, lr: 0.0000\n",
      "Epoch: 306, Training loss: 1.358929, Validation loss: 1.3736, lr: 0.0000\n",
      "Epoch: 307, Training loss: 1.366972, Validation loss: 1.3461, lr: 0.0000\n",
      "Epoch: 308, Training loss: 1.363024, Validation loss: 1.3531, lr: 0.0000\n",
      "Epoch: 309, Training loss: 1.351628, Validation loss: 1.3670, lr: 0.0000\n",
      "Epoch: 310, Training loss: 1.346172, Validation loss: 1.3659, lr: 0.0000\n",
      "Epoch: 311, Training loss: 1.364732, Validation loss: 1.3570, lr: 0.0000\n",
      "Epoch: 312, Training loss: 1.339048, Validation loss: 1.3214, lr: 0.0000\n",
      "Epoch: 313, Training loss: 1.394180, Validation loss: 1.3698, lr: 0.0000\n",
      "Epoch: 314, Training loss: 1.353834, Validation loss: 1.3736, lr: 0.0000\n",
      "Epoch: 315, Training loss: 1.375963, Validation loss: 1.3498, lr: 0.0000\n",
      "Epoch: 316, Training loss: 1.352726, Validation loss: 1.3539, lr: 0.0000\n",
      "Epoch: 317, Training loss: 1.356002, Validation loss: 1.3332, lr: 0.0000\n",
      "Epoch: 318, Training loss: 1.372343, Validation loss: 1.3794, lr: 0.0000\n",
      "Epoch: 319, Training loss: 1.362566, Validation loss: 1.3739, lr: 0.0000\n",
      "Epoch: 320, Training loss: 1.355027, Validation loss: 1.3727, lr: 0.0000\n",
      "Epoch: 321, Training loss: 1.417916, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 322, Training loss: 1.332961, Validation loss: 1.3637, lr: 0.0000\n",
      "Epoch: 323, Training loss: 1.462637, Validation loss: 1.3635, lr: 0.0000\n",
      "Epoch: 324, Training loss: 1.352199, Validation loss: 1.4099, lr: 0.0000\n",
      "Epoch: 325, Training loss: 1.360201, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 326, Training loss: 1.362190, Validation loss: 1.3740, lr: 0.0000\n",
      "Epoch: 327, Training loss: 1.355728, Validation loss: 1.3729, lr: 0.0000\n",
      "Epoch: 328, Training loss: 1.355638, Validation loss: 1.3752, lr: 0.0000\n",
      "Epoch: 329, Training loss: 1.345591, Validation loss: 1.3760, lr: 0.0000\n",
      "Epoch: 330, Training loss: 1.386119, Validation loss: 1.3556, lr: 0.0000\n",
      "Epoch: 331, Training loss: 1.337751, Validation loss: 1.3689, lr: 0.0000\n",
      "Epoch: 332, Training loss: 1.363841, Validation loss: 1.3941, lr: 0.0000\n",
      "Epoch: 333, Training loss: 1.351792, Validation loss: 1.3703, lr: 0.0000\n",
      "Epoch: 334, Training loss: 1.375993, Validation loss: 1.3773, lr: 0.0000\n",
      "Epoch: 335, Training loss: 1.354314, Validation loss: 1.3651, lr: 0.0000\n",
      "Epoch: 336, Training loss: 1.347955, Validation loss: 1.4035, lr: 0.0000\n",
      "Epoch: 337, Training loss: 1.329823, Validation loss: 1.3601, lr: 0.0000\n",
      "Epoch: 338, Training loss: 1.354204, Validation loss: 1.3642, lr: 0.0000\n",
      "Epoch: 339, Training loss: 1.381461, Validation loss: 1.3559, lr: 0.0000\n",
      "Epoch: 340, Training loss: 1.396070, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 341, Training loss: 1.344307, Validation loss: 1.3439, lr: 0.0000\n",
      "Epoch: 342, Training loss: 1.362741, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 343, Training loss: 1.362268, Validation loss: 1.3677, lr: 0.0000\n",
      "Epoch: 344, Training loss: 1.377865, Validation loss: 1.3680, lr: 0.0000\n",
      "Epoch: 345, Training loss: 1.367084, Validation loss: 1.3534, lr: 0.0000\n",
      "Epoch: 346, Training loss: 1.348068, Validation loss: 1.3758, lr: 0.0000\n",
      "Epoch: 347, Training loss: 1.344107, Validation loss: 1.3554, lr: 0.0000\n",
      "Epoch: 348, Training loss: 1.341032, Validation loss: 1.3703, lr: 0.0000\n",
      "Epoch: 349, Training loss: 1.352424, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 350, Training loss: 1.398698, Validation loss: 1.3799, lr: 0.0000\n",
      "Epoch: 351, Training loss: 1.424901, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 352, Training loss: 1.333648, Validation loss: 1.3633, lr: 0.0000\n",
      "Epoch: 353, Training loss: 1.348854, Validation loss: 1.3803, lr: 0.0000\n",
      "Epoch: 354, Training loss: 1.313845, Validation loss: 1.3771, lr: 0.0000\n",
      "Epoch: 355, Training loss: 1.350162, Validation loss: 1.3267, lr: 0.0000\n",
      "Epoch: 356, Training loss: 1.345304, Validation loss: 1.3565, lr: 0.0000\n",
      "Epoch: 357, Training loss: 1.403802, Validation loss: 1.3458, lr: 0.0000\n",
      "Epoch: 358, Training loss: 1.356472, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 359, Training loss: 1.339393, Validation loss: 1.3462, lr: 0.0000\n",
      "Epoch: 360, Training loss: 1.352037, Validation loss: 1.3946, lr: 0.0000\n",
      "Epoch: 361, Training loss: 1.340085, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 362, Training loss: 1.386721, Validation loss: 1.3690, lr: 0.0000\n",
      "Epoch: 363, Training loss: 1.359653, Validation loss: 1.3322, lr: 0.0000\n",
      "Epoch: 364, Training loss: 1.334425, Validation loss: 1.3606, lr: 0.0000\n",
      "Epoch: 365, Training loss: 1.340988, Validation loss: 1.3687, lr: 0.0000\n",
      "Epoch: 366, Training loss: 1.361784, Validation loss: 1.6687, lr: 0.0000\n",
      "Epoch: 367, Training loss: 1.352617, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 368, Training loss: 1.359684, Validation loss: 1.3586, lr: 0.0000\n",
      "Epoch: 369, Training loss: 1.356352, Validation loss: 1.3534, lr: 0.0000\n",
      "Epoch: 370, Training loss: 1.343178, Validation loss: 1.3716, lr: 0.0000\n",
      "Epoch: 371, Training loss: 1.342739, Validation loss: 1.3763, lr: 0.0000\n",
      "Epoch: 372, Training loss: 1.365447, Validation loss: 1.3694, lr: 0.0000\n",
      "Epoch: 373, Training loss: 1.359470, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 374, Training loss: 1.339770, Validation loss: 1.3666, lr: 0.0000\n",
      "Epoch: 375, Training loss: 1.383395, Validation loss: 1.3686, lr: 0.0000\n",
      "Epoch: 376, Training loss: 1.344956, Validation loss: 1.3782, lr: 0.0000\n",
      "Epoch: 377, Training loss: 1.372547, Validation loss: 1.3614, lr: 0.0000\n",
      "Epoch: 378, Training loss: 1.350741, Validation loss: 1.3635, lr: 0.0000\n",
      "Epoch: 379, Training loss: 1.338012, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 380, Training loss: 1.363036, Validation loss: 1.3955, lr: 0.0000\n",
      "Epoch: 381, Training loss: 1.324503, Validation loss: 1.3738, lr: 0.0000\n",
      "Epoch: 382, Training loss: 1.379074, Validation loss: 1.3742, lr: 0.0000\n",
      "Epoch: 383, Training loss: 1.352060, Validation loss: 1.3774, lr: 0.0000\n",
      "Epoch: 384, Training loss: 1.372833, Validation loss: 1.3245, lr: 0.0000\n",
      "Epoch: 385, Training loss: 1.426699, Validation loss: 1.3688, lr: 0.0000\n",
      "Epoch: 386, Training loss: 1.334107, Validation loss: 1.3504, lr: 0.0000\n",
      "Epoch: 387, Training loss: 1.354879, Validation loss: 1.3655, lr: 0.0000\n",
      "Epoch: 388, Training loss: 1.394283, Validation loss: 1.3751, lr: 0.0000\n",
      "Epoch: 389, Training loss: 1.372255, Validation loss: 1.3708, lr: 0.0000\n",
      "Epoch: 390, Training loss: 1.370899, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 391, Training loss: 1.341922, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 392, Training loss: 1.390054, Validation loss: 1.3705, lr: 0.0000\n",
      "Epoch: 393, Training loss: 1.343897, Validation loss: 1.3713, lr: 0.0000\n",
      "Epoch: 394, Training loss: 1.349661, Validation loss: 1.3751, lr: 0.0000\n",
      "Epoch: 395, Training loss: 1.367159, Validation loss: 1.3776, lr: 0.0000\n",
      "Epoch: 396, Training loss: 1.350786, Validation loss: 1.3710, lr: 0.0000\n",
      "Epoch: 397, Training loss: 1.340586, Validation loss: 1.3550, lr: 0.0000\n",
      "Epoch: 398, Training loss: 1.387408, Validation loss: 1.3731, lr: 0.0000\n",
      "Epoch: 399, Training loss: 1.362719, Validation loss: 1.3738, lr: 0.0000\n",
      "Epoch: 400, Training loss: 1.367664, Validation loss: 1.3691, lr: 0.0000\n",
      "Epoch: 401, Training loss: 1.333039, Validation loss: 1.3611, lr: 0.0000\n",
      "Epoch: 402, Training loss: 1.330484, Validation loss: 1.3746, lr: 0.0000\n",
      "Epoch: 403, Training loss: 1.362848, Validation loss: 1.3696, lr: 0.0000\n",
      "Epoch: 404, Training loss: 1.409527, Validation loss: 1.3712, lr: 0.0000\n",
      "Epoch: 405, Training loss: 1.372266, Validation loss: 1.3736, lr: 0.0000\n",
      "Epoch: 406, Training loss: 1.357873, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 407, Training loss: 1.397235, Validation loss: 1.3719, lr: 0.0000\n",
      "Epoch: 408, Training loss: 1.380792, Validation loss: 1.3573, lr: 0.0000\n",
      "Epoch: 409, Training loss: 1.354095, Validation loss: 1.3715, lr: 0.0000\n",
      "Epoch: 410, Training loss: 1.365719, Validation loss: 1.3719, lr: 0.0000\n",
      "Epoch: 411, Training loss: 1.360851, Validation loss: 1.3802, lr: 0.0000\n",
      "Epoch: 412, Training loss: 1.333069, Validation loss: 1.3683, lr: 0.0000\n",
      "Epoch: 413, Training loss: 1.331533, Validation loss: 1.3512, lr: 0.0000\n",
      "Epoch: 414, Training loss: 1.348738, Validation loss: 1.3894, lr: 0.0000\n",
      "Epoch: 415, Training loss: 1.321639, Validation loss: 1.3700, lr: 0.0000\n",
      "Epoch: 416, Training loss: 1.328161, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 417, Training loss: 1.335760, Validation loss: 1.4055, lr: 0.0000\n",
      "Epoch: 418, Training loss: 1.387804, Validation loss: 1.3564, lr: 0.0000\n",
      "Epoch: 419, Training loss: 1.390728, Validation loss: 1.3684, lr: 0.0000\n",
      "Epoch: 420, Training loss: 1.328976, Validation loss: 1.3573, lr: 0.0000\n",
      "Epoch: 421, Training loss: 1.357532, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 422, Training loss: 1.329252, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 423, Training loss: 1.375360, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 424, Training loss: 1.349873, Validation loss: 1.3632, lr: 0.0000\n",
      "Epoch: 425, Training loss: 1.327770, Validation loss: 1.3723, lr: 0.0000\n",
      "Epoch: 426, Training loss: 1.354044, Validation loss: 1.3614, lr: 0.0000\n",
      "Epoch: 427, Training loss: 1.399599, Validation loss: 1.4001, lr: 0.0000\n",
      "Epoch: 428, Training loss: 1.365415, Validation loss: 1.3809, lr: 0.0000\n",
      "Epoch: 429, Training loss: 1.362797, Validation loss: 1.3679, lr: 0.0000\n",
      "Epoch: 430, Training loss: 1.362831, Validation loss: 1.3782, lr: 0.0000\n",
      "Epoch: 431, Training loss: 1.351187, Validation loss: 1.3788, lr: 0.0000\n",
      "Epoch: 432, Training loss: 1.364695, Validation loss: 1.3727, lr: 0.0000\n",
      "Epoch: 433, Training loss: 1.324853, Validation loss: 1.3722, lr: 0.0000\n",
      "Epoch: 434, Training loss: 1.368828, Validation loss: 1.3308, lr: 0.0000\n",
      "Epoch: 435, Training loss: 1.347168, Validation loss: 1.3776, lr: 0.0000\n",
      "Epoch: 436, Training loss: 1.309886, Validation loss: 1.3622, lr: 0.0000\n",
      "Epoch: 437, Training loss: 1.345099, Validation loss: 1.3534, lr: 0.0000\n",
      "Epoch: 438, Training loss: 1.341478, Validation loss: 1.3441, lr: 0.0000\n",
      "Epoch: 439, Training loss: 1.375961, Validation loss: 1.3624, lr: 0.0000\n",
      "Epoch: 440, Training loss: 1.346084, Validation loss: 1.3353, lr: 0.0000\n",
      "Epoch: 441, Training loss: 1.334771, Validation loss: 1.3911, lr: 0.0000\n",
      "Epoch: 442, Training loss: 1.339025, Validation loss: 1.3642, lr: 0.0000\n",
      "Epoch: 443, Training loss: 1.372850, Validation loss: 1.3766, lr: 0.0000\n",
      "Epoch: 444, Training loss: 1.360979, Validation loss: 1.3727, lr: 0.0000\n",
      "Epoch: 445, Training loss: 1.369107, Validation loss: 1.3551, lr: 0.0000\n",
      "Epoch: 446, Training loss: 1.369947, Validation loss: 1.3778, lr: 0.0000\n",
      "Epoch: 447, Training loss: 1.340392, Validation loss: 1.3486, lr: 0.0000\n",
      "Epoch: 448, Training loss: 1.351177, Validation loss: 1.3439, lr: 0.0000\n",
      "Epoch: 449, Training loss: 1.339357, Validation loss: 1.3543, lr: 0.0000\n",
      "Epoch: 450, Training loss: 1.336750, Validation loss: 1.3509, lr: 0.0000\n",
      "Epoch: 451, Training loss: 1.346828, Validation loss: 1.3920, lr: 0.0000\n",
      "Epoch: 452, Training loss: 1.353183, Validation loss: 1.3534, lr: 0.0000\n",
      "Epoch: 453, Training loss: 1.366217, Validation loss: 1.3725, lr: 0.0000\n",
      "Epoch: 454, Training loss: 1.317973, Validation loss: 1.3737, lr: 0.0000\n",
      "Epoch: 455, Training loss: 1.331661, Validation loss: 1.3131, lr: 0.0000\n",
      "Epoch: 456, Training loss: 1.357894, Validation loss: 1.3759, lr: 0.0000\n",
      "Epoch: 457, Training loss: 1.348077, Validation loss: 1.3725, lr: 0.0000\n",
      "Epoch: 458, Training loss: 1.366983, Validation loss: 1.3472, lr: 0.0000\n",
      "Epoch: 459, Training loss: 1.339396, Validation loss: 1.3653, lr: 0.0000\n",
      "Epoch: 460, Training loss: 1.353377, Validation loss: 1.5144, lr: 0.0000\n",
      "Epoch: 461, Training loss: 1.339002, Validation loss: 1.3786, lr: 0.0000\n",
      "Epoch: 462, Training loss: 1.357297, Validation loss: 1.3540, lr: 0.0000\n",
      "Epoch: 463, Training loss: 1.336574, Validation loss: 1.3305, lr: 0.0000\n",
      "Epoch: 464, Training loss: 1.345058, Validation loss: 1.3472, lr: 0.0000\n",
      "Epoch: 465, Training loss: 1.350782, Validation loss: 1.5226, lr: 0.0000\n",
      "Epoch: 466, Training loss: 1.367098, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 467, Training loss: 1.319853, Validation loss: 1.4121, lr: 0.0000\n",
      "Epoch: 468, Training loss: 1.341395, Validation loss: 1.3529, lr: 0.0000\n",
      "Epoch: 469, Training loss: 1.383471, Validation loss: 1.3541, lr: 0.0000\n",
      "Epoch: 470, Training loss: 1.376828, Validation loss: 1.3679, lr: 0.0000\n",
      "Epoch: 471, Training loss: 1.358026, Validation loss: 1.3671, lr: 0.0000\n",
      "Epoch: 472, Training loss: 1.345700, Validation loss: 1.3546, lr: 0.0000\n",
      "Epoch: 473, Training loss: 1.355588, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 474, Training loss: 1.346364, Validation loss: 1.5514, lr: 0.0000\n",
      "Epoch: 475, Training loss: 1.368840, Validation loss: 1.3603, lr: 0.0000\n",
      "Epoch: 476, Training loss: 1.385299, Validation loss: 1.3614, lr: 0.0000\n",
      "Epoch: 477, Training loss: 1.322596, Validation loss: 1.3683, lr: 0.0000\n",
      "Epoch: 478, Training loss: 1.352763, Validation loss: 1.3769, lr: 0.0000\n",
      "Epoch: 479, Training loss: 1.367254, Validation loss: 1.3771, lr: 0.0000\n",
      "Epoch: 480, Training loss: 1.359249, Validation loss: 1.3664, lr: 0.0000\n",
      "Epoch: 481, Training loss: 1.326189, Validation loss: 1.3718, lr: 0.0000\n",
      "Epoch: 482, Training loss: 1.361247, Validation loss: 1.3314, lr: 0.0000\n",
      "Epoch: 483, Training loss: 1.346081, Validation loss: 1.3982, lr: 0.0000\n",
      "Epoch: 484, Training loss: 1.362544, Validation loss: 1.3714, lr: 0.0000\n",
      "Epoch: 485, Training loss: 1.349831, Validation loss: 1.3703, lr: 0.0000\n",
      "Epoch: 486, Training loss: 1.359230, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 487, Training loss: 1.371862, Validation loss: 1.3708, lr: 0.0000\n",
      "Epoch: 488, Training loss: 1.352866, Validation loss: 1.3743, lr: 0.0000\n",
      "Epoch: 489, Training loss: 1.369176, Validation loss: 1.3689, lr: 0.0000\n",
      "Epoch: 490, Training loss: 1.328454, Validation loss: 1.3663, lr: 0.0000\n",
      "Epoch: 491, Training loss: 1.394151, Validation loss: 1.3961, lr: 0.0000\n",
      "Epoch: 492, Training loss: 1.349449, Validation loss: 1.3720, lr: 0.0000\n",
      "Epoch: 493, Training loss: 1.329176, Validation loss: 1.3455, lr: 0.0000\n",
      "Epoch: 494, Training loss: 1.373897, Validation loss: 1.3740, lr: 0.0000\n",
      "Epoch: 495, Training loss: 1.344013, Validation loss: 1.3724, lr: 0.0000\n",
      "Epoch: 496, Training loss: 1.349686, Validation loss: 1.3761, lr: 0.0000\n",
      "Epoch: 497, Training loss: 1.369525, Validation loss: 1.3667, lr: 0.0000\n",
      "Epoch: 498, Training loss: 1.392020, Validation loss: 1.3720, lr: 0.0000\n",
      "Epoch: 499, Training loss: 1.415178, Validation loss: 1.3720, lr: 0.0000\n",
      "Epoch: 500, Training loss: 1.352112, Validation loss: 1.3656, lr: 0.0000\n",
      "Epoch: 501, Training loss: 1.390902, Validation loss: 1.3742, lr: 0.0000\n",
      "Epoch: 502, Training loss: 1.361746, Validation loss: 1.3789, lr: 0.0000\n",
      "Epoch: 503, Training loss: 1.395917, Validation loss: 1.3620, lr: 0.0000\n",
      "Epoch: 504, Training loss: 1.309032, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 505, Training loss: 1.356264, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 506, Training loss: 1.353075, Validation loss: 1.3776, lr: 0.0000\n",
      "Epoch: 507, Training loss: 1.343868, Validation loss: 1.3393, lr: 0.0000\n",
      "Epoch: 508, Training loss: 1.351628, Validation loss: 1.3772, lr: 0.0000\n",
      "Epoch: 509, Training loss: 1.353100, Validation loss: 1.3148, lr: 0.0000\n",
      "Epoch: 510, Training loss: 1.358677, Validation loss: 1.3590, lr: 0.0000\n",
      "Epoch: 511, Training loss: 1.394232, Validation loss: 1.3672, lr: 0.0000\n",
      "Epoch: 512, Training loss: 1.351701, Validation loss: 1.3697, lr: 0.0000\n",
      "Epoch: 513, Training loss: 1.370473, Validation loss: 1.3769, lr: 0.0000\n",
      "Epoch: 514, Training loss: 1.357779, Validation loss: 1.3147, lr: 0.0000\n",
      "Epoch: 515, Training loss: 1.355015, Validation loss: 1.3773, lr: 0.0000\n",
      "Epoch: 516, Training loss: 1.342608, Validation loss: 1.3552, lr: 0.0000\n",
      "Epoch: 517, Training loss: 1.334428, Validation loss: 1.3676, lr: 0.0000\n",
      "Epoch: 518, Training loss: 1.348463, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 519, Training loss: 1.323375, Validation loss: 1.3514, lr: 0.0000\n",
      "Epoch: 520, Training loss: 1.375839, Validation loss: 1.3707, lr: 0.0000\n",
      "Epoch: 521, Training loss: 1.346928, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 522, Training loss: 1.398239, Validation loss: 1.3519, lr: 0.0000\n",
      "Epoch: 523, Training loss: 1.340402, Validation loss: 1.3510, lr: 0.0000\n",
      "Epoch: 524, Training loss: 1.350097, Validation loss: 1.3676, lr: 0.0000\n",
      "Epoch: 525, Training loss: 1.360616, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 526, Training loss: 1.351397, Validation loss: 1.3752, lr: 0.0000\n",
      "Epoch: 527, Training loss: 1.353619, Validation loss: 1.3679, lr: 0.0000\n",
      "Epoch: 528, Training loss: 1.352283, Validation loss: 1.3786, lr: 0.0000\n",
      "Epoch: 529, Training loss: 1.354930, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 530, Training loss: 1.361582, Validation loss: 1.3703, lr: 0.0000\n",
      "Epoch: 531, Training loss: 1.360902, Validation loss: 1.3947, lr: 0.0000\n",
      "Epoch: 532, Training loss: 1.335967, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 533, Training loss: 1.341522, Validation loss: 1.3592, lr: 0.0000\n",
      "Epoch: 534, Training loss: 1.353769, Validation loss: 1.4120, lr: 0.0000\n",
      "Epoch: 535, Training loss: 1.359653, Validation loss: 1.3802, lr: 0.0000\n",
      "Epoch: 536, Training loss: 1.380909, Validation loss: 1.3795, lr: 0.0000\n",
      "Epoch: 537, Training loss: 1.356808, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 538, Training loss: 1.363066, Validation loss: 1.3711, lr: 0.0000\n",
      "Epoch: 539, Training loss: 1.429845, Validation loss: 1.3789, lr: 0.0000\n",
      "Epoch: 540, Training loss: 1.350595, Validation loss: 1.3777, lr: 0.0000\n",
      "Epoch: 541, Training loss: 1.387008, Validation loss: 1.3755, lr: 0.0000\n",
      "Epoch: 542, Training loss: 1.353315, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 543, Training loss: 1.385695, Validation loss: 1.3685, lr: 0.0000\n",
      "Epoch: 544, Training loss: 1.338148, Validation loss: 1.3775, lr: 0.0000\n",
      "Epoch: 545, Training loss: 1.341997, Validation loss: 1.3747, lr: 0.0000\n",
      "Epoch: 546, Training loss: 1.356676, Validation loss: 1.4814, lr: 0.0000\n",
      "Epoch: 547, Training loss: 1.352100, Validation loss: 1.3316, lr: 0.0000\n",
      "Epoch: 548, Training loss: 1.359173, Validation loss: 1.3694, lr: 0.0000\n",
      "Epoch: 549, Training loss: 1.402910, Validation loss: 1.3480, lr: 0.0000\n",
      "Epoch: 550, Training loss: 1.395130, Validation loss: 1.3396, lr: 0.0000\n",
      "Epoch: 551, Training loss: 1.420739, Validation loss: 1.3685, lr: 0.0000\n",
      "Epoch: 552, Training loss: 1.349704, Validation loss: 1.4392, lr: 0.0000\n",
      "Epoch: 553, Training loss: 1.352913, Validation loss: 1.3510, lr: 0.0000\n",
      "Epoch: 554, Training loss: 1.344699, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 555, Training loss: 1.328353, Validation loss: 1.3646, lr: 0.0000\n",
      "Epoch: 556, Training loss: 1.419619, Validation loss: 1.3792, lr: 0.0000\n",
      "Epoch: 557, Training loss: 1.350220, Validation loss: 1.3633, lr: 0.0000\n",
      "Epoch: 558, Training loss: 1.348725, Validation loss: 1.3626, lr: 0.0000\n",
      "Epoch: 559, Training loss: 1.363679, Validation loss: 1.3745, lr: 0.0000\n",
      "Epoch: 560, Training loss: 1.363013, Validation loss: 1.3957, lr: 0.0000\n",
      "Epoch: 561, Training loss: 1.349161, Validation loss: 1.3654, lr: 0.0000\n",
      "Epoch: 562, Training loss: 1.321527, Validation loss: 1.3563, lr: 0.0000\n",
      "Epoch: 563, Training loss: 1.356094, Validation loss: 1.3691, lr: 0.0000\n",
      "Epoch: 564, Training loss: 1.348106, Validation loss: 1.3753, lr: 0.0000\n",
      "Epoch: 565, Training loss: 1.349946, Validation loss: 1.3555, lr: 0.0000\n",
      "Epoch: 566, Training loss: 1.359851, Validation loss: 1.3703, lr: 0.0000\n",
      "Epoch: 567, Training loss: 1.331533, Validation loss: 1.3650, lr: 0.0000\n",
      "Epoch: 568, Training loss: 1.334815, Validation loss: 1.3698, lr: 0.0000\n",
      "Epoch: 569, Training loss: 1.380404, Validation loss: 1.4127, lr: 0.0000\n",
      "Epoch: 570, Training loss: 1.367047, Validation loss: 1.3705, lr: 0.0000\n",
      "Epoch: 571, Training loss: 1.332733, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 572, Training loss: 1.354113, Validation loss: 1.3363, lr: 0.0000\n",
      "Epoch: 573, Training loss: 1.368996, Validation loss: 1.3748, lr: 0.0000\n",
      "Epoch: 574, Training loss: 1.356537, Validation loss: 1.3625, lr: 0.0000\n",
      "Epoch: 575, Training loss: 1.344919, Validation loss: 1.3560, lr: 0.0000\n",
      "Epoch: 576, Training loss: 1.347904, Validation loss: 1.3667, lr: 0.0000\n",
      "Epoch: 577, Training loss: 1.347245, Validation loss: 1.4220, lr: 0.0000\n",
      "Epoch: 578, Training loss: 1.390090, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 579, Training loss: 1.355906, Validation loss: 1.3572, lr: 0.0000\n",
      "Epoch: 580, Training loss: 1.383087, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 581, Training loss: 1.366047, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 582, Training loss: 1.354584, Validation loss: 1.3664, lr: 0.0000\n",
      "Epoch: 583, Training loss: 1.366541, Validation loss: 1.3772, lr: 0.0000\n",
      "Epoch: 584, Training loss: 1.357403, Validation loss: 1.3769, lr: 0.0000\n",
      "Epoch: 585, Training loss: 1.359489, Validation loss: 1.3757, lr: 0.0000\n",
      "Epoch: 586, Training loss: 1.336433, Validation loss: 1.3676, lr: 0.0000\n",
      "Epoch: 587, Training loss: 1.365718, Validation loss: 1.3922, lr: 0.0000\n",
      "Epoch: 588, Training loss: 1.343048, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 589, Training loss: 1.352838, Validation loss: 1.4009, lr: 0.0000\n",
      "Epoch: 590, Training loss: 1.366088, Validation loss: 1.3539, lr: 0.0000\n",
      "Epoch: 591, Training loss: 1.348804, Validation loss: 1.3497, lr: 0.0000\n",
      "Epoch: 592, Training loss: 1.341999, Validation loss: 1.3788, lr: 0.0000\n",
      "Epoch: 593, Training loss: 1.397140, Validation loss: 1.3563, lr: 0.0000\n",
      "Epoch: 594, Training loss: 1.362954, Validation loss: 1.3683, lr: 0.0000\n",
      "Epoch: 595, Training loss: 1.349414, Validation loss: 1.3648, lr: 0.0000\n",
      "Epoch: 596, Training loss: 1.325415, Validation loss: 1.3671, lr: 0.0000\n",
      "Epoch: 597, Training loss: 1.339739, Validation loss: 1.3571, lr: 0.0000\n",
      "Epoch: 598, Training loss: 1.353766, Validation loss: 1.3732, lr: 0.0000\n",
      "Epoch: 599, Training loss: 1.338619, Validation loss: 1.3499, lr: 0.0000\n",
      "Epoch: 600, Training loss: 1.344994, Validation loss: 1.3618, lr: 0.0000\n",
      "Epoch: 601, Training loss: 1.398938, Validation loss: 1.3975, lr: 0.0000\n",
      "Epoch: 602, Training loss: 1.358722, Validation loss: 1.3776, lr: 0.0000\n",
      "Epoch: 603, Training loss: 1.342444, Validation loss: 1.3734, lr: 0.0000\n",
      "Epoch: 604, Training loss: 1.358671, Validation loss: 1.3614, lr: 0.0000\n",
      "Epoch: 605, Training loss: 1.357295, Validation loss: 1.3769, lr: 0.0000\n",
      "Epoch: 606, Training loss: 1.363143, Validation loss: 1.3809, lr: 0.0000\n",
      "Epoch: 607, Training loss: 1.339997, Validation loss: 1.3762, lr: 0.0000\n",
      "Epoch: 608, Training loss: 1.348283, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 609, Training loss: 1.338913, Validation loss: 1.3593, lr: 0.0000\n",
      "Epoch: 610, Training loss: 1.324789, Validation loss: 1.3769, lr: 0.0000\n",
      "Epoch: 611, Training loss: 1.349529, Validation loss: 1.3515, lr: 0.0000\n",
      "Epoch: 612, Training loss: 1.364275, Validation loss: 1.3742, lr: 0.0000\n",
      "Epoch: 613, Training loss: 1.379013, Validation loss: 1.3579, lr: 0.0000\n",
      "Epoch: 614, Training loss: 1.367331, Validation loss: 1.3661, lr: 0.0000\n",
      "Epoch: 615, Training loss: 1.351612, Validation loss: 1.3508, lr: 0.0000\n",
      "Epoch: 616, Training loss: 1.340082, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 617, Training loss: 1.387400, Validation loss: 1.3566, lr: 0.0000\n",
      "Epoch: 618, Training loss: 1.388421, Validation loss: 1.3741, lr: 0.0000\n",
      "Epoch: 619, Training loss: 1.344716, Validation loss: 1.3545, lr: 0.0000\n",
      "Epoch: 620, Training loss: 1.355284, Validation loss: 1.3760, lr: 0.0000\n",
      "Epoch: 621, Training loss: 1.423694, Validation loss: 1.3709, lr: 0.0000\n",
      "Epoch: 622, Training loss: 1.349440, Validation loss: 1.3718, lr: 0.0000\n",
      "Epoch: 623, Training loss: 1.359080, Validation loss: 1.3661, lr: 0.0000\n",
      "Epoch: 624, Training loss: 1.352872, Validation loss: 1.3557, lr: 0.0000\n",
      "Epoch: 625, Training loss: 1.370875, Validation loss: 1.3499, lr: 0.0000\n",
      "Epoch: 626, Training loss: 1.364673, Validation loss: 1.3722, lr: 0.0000\n",
      "Epoch: 627, Training loss: 1.342821, Validation loss: 1.3774, lr: 0.0000\n",
      "Epoch: 628, Training loss: 1.366788, Validation loss: 1.3696, lr: 0.0000\n",
      "Epoch: 629, Training loss: 1.349089, Validation loss: 1.3638, lr: 0.0000\n",
      "Epoch: 630, Training loss: 1.373470, Validation loss: 1.3620, lr: 0.0000\n",
      "Epoch: 631, Training loss: 1.364124, Validation loss: 1.3756, lr: 0.0000\n",
      "Epoch: 632, Training loss: 1.346069, Validation loss: 1.3809, lr: 0.0000\n",
      "Epoch: 633, Training loss: 1.398086, Validation loss: 1.3731, lr: 0.0000\n",
      "Epoch: 634, Training loss: 1.378239, Validation loss: 1.3670, lr: 0.0000\n",
      "Epoch: 635, Training loss: 1.345540, Validation loss: 1.3447, lr: 0.0000\n",
      "Epoch: 636, Training loss: 1.387505, Validation loss: 1.3786, lr: 0.0000\n",
      "Epoch: 637, Training loss: 1.441347, Validation loss: 1.3634, lr: 0.0000\n",
      "Epoch: 638, Training loss: 1.354795, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 639, Training loss: 1.400585, Validation loss: 1.3708, lr: 0.0000\n",
      "Epoch: 640, Training loss: 1.350410, Validation loss: 1.3716, lr: 0.0000\n",
      "Epoch: 641, Training loss: 1.356031, Validation loss: 1.3654, lr: 0.0000\n",
      "Epoch: 642, Training loss: 1.348113, Validation loss: 1.3521, lr: 0.0000\n",
      "Epoch: 643, Training loss: 1.420312, Validation loss: 1.3504, lr: 0.0000\n",
      "Epoch: 644, Training loss: 1.332039, Validation loss: 1.3682, lr: 0.0000\n",
      "Epoch: 645, Training loss: 1.356334, Validation loss: 1.3777, lr: 0.0000\n",
      "Epoch: 646, Training loss: 1.402671, Validation loss: 1.3660, lr: 0.0000\n",
      "Epoch: 647, Training loss: 1.357928, Validation loss: 1.3790, lr: 0.0000\n",
      "Epoch: 648, Training loss: 1.415469, Validation loss: 1.3760, lr: 0.0000\n",
      "Epoch: 649, Training loss: 1.341075, Validation loss: 1.3677, lr: 0.0000\n",
      "Epoch: 650, Training loss: 1.355813, Validation loss: 1.3650, lr: 0.0000\n",
      "Epoch: 651, Training loss: 1.374532, Validation loss: 1.3787, lr: 0.0000\n",
      "Epoch: 652, Training loss: 1.367714, Validation loss: 1.3522, lr: 0.0000\n",
      "Epoch: 653, Training loss: 1.358633, Validation loss: 1.3473, lr: 0.0000\n",
      "Epoch: 654, Training loss: 1.376749, Validation loss: 1.3796, lr: 0.0000\n",
      "Epoch: 655, Training loss: 1.351177, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 656, Training loss: 1.323163, Validation loss: 1.3585, lr: 0.0000\n",
      "Epoch: 657, Training loss: 1.308293, Validation loss: 1.3670, lr: 0.0000\n",
      "Epoch: 658, Training loss: 1.357511, Validation loss: 1.3092, lr: 0.0000\n",
      "Epoch: 659, Training loss: 1.402189, Validation loss: 1.3569, lr: 0.0000\n",
      "Epoch: 660, Training loss: 1.357133, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 661, Training loss: 1.337169, Validation loss: 1.3624, lr: 0.0000\n",
      "Epoch: 662, Training loss: 1.353842, Validation loss: 1.3122, lr: 0.0000\n",
      "Epoch: 663, Training loss: 1.372123, Validation loss: 1.3730, lr: 0.0000\n",
      "Epoch: 664, Training loss: 1.338583, Validation loss: 1.3893, lr: 0.0000\n",
      "Epoch: 665, Training loss: 1.378942, Validation loss: 1.3638, lr: 0.0000\n",
      "Epoch: 666, Training loss: 1.413327, Validation loss: 1.3737, lr: 0.0000\n",
      "Epoch: 667, Training loss: 1.414294, Validation loss: 1.3610, lr: 0.0000\n",
      "Epoch: 668, Training loss: 1.347497, Validation loss: 1.3549, lr: 0.0000\n",
      "Epoch: 669, Training loss: 1.337740, Validation loss: 1.3708, lr: 0.0000\n",
      "Epoch: 670, Training loss: 1.338518, Validation loss: 1.3775, lr: 0.0000\n",
      "Epoch: 671, Training loss: 1.357905, Validation loss: 1.3692, lr: 0.0000\n",
      "Epoch: 672, Training loss: 1.398863, Validation loss: 1.3874, lr: 0.0000\n",
      "Epoch: 673, Training loss: 1.383766, Validation loss: 1.3404, lr: 0.0000\n",
      "Epoch: 674, Training loss: 1.347187, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 675, Training loss: 1.359502, Validation loss: 1.3757, lr: 0.0000\n",
      "Epoch: 676, Training loss: 1.354233, Validation loss: 1.3566, lr: 0.0000\n",
      "Epoch: 677, Training loss: 1.347560, Validation loss: 1.3313, lr: 0.0000\n",
      "Epoch: 678, Training loss: 1.378182, Validation loss: 1.3644, lr: 0.0000\n",
      "Epoch: 679, Training loss: 1.410599, Validation loss: 1.3672, lr: 0.0000\n",
      "Epoch: 680, Training loss: 1.318028, Validation loss: 1.3726, lr: 0.0000\n",
      "Epoch: 681, Training loss: 1.413462, Validation loss: 1.3523, lr: 0.0000\n",
      "Epoch: 682, Training loss: 1.350347, Validation loss: 1.3910, lr: 0.0000\n",
      "Epoch: 683, Training loss: 1.345186, Validation loss: 1.3544, lr: 0.0000\n",
      "Epoch: 684, Training loss: 1.346009, Validation loss: 1.3790, lr: 0.0000\n",
      "Epoch: 685, Training loss: 1.399404, Validation loss: 1.3786, lr: 0.0000\n",
      "Epoch: 686, Training loss: 1.350514, Validation loss: 1.3345, lr: 0.0000\n",
      "Epoch: 687, Training loss: 1.330516, Validation loss: 1.3973, lr: 0.0000\n",
      "Epoch: 688, Training loss: 1.377267, Validation loss: 1.3705, lr: 0.0000\n",
      "Epoch: 689, Training loss: 1.510113, Validation loss: 1.3798, lr: 0.0000\n",
      "Epoch: 690, Training loss: 1.355057, Validation loss: 1.3705, lr: 0.0000\n",
      "Epoch: 691, Training loss: 1.334580, Validation loss: 1.3744, lr: 0.0000\n",
      "Epoch: 692, Training loss: 1.353595, Validation loss: 1.3745, lr: 0.0000\n",
      "Epoch: 693, Training loss: 1.329767, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 694, Training loss: 1.355512, Validation loss: 1.3725, lr: 0.0000\n",
      "Epoch: 695, Training loss: 1.347450, Validation loss: 1.3709, lr: 0.0000\n",
      "Epoch: 696, Training loss: 1.369745, Validation loss: 1.3718, lr: 0.0000\n",
      "Epoch: 697, Training loss: 1.354866, Validation loss: 1.3688, lr: 0.0000\n",
      "Epoch: 698, Training loss: 1.399199, Validation loss: 1.3675, lr: 0.0000\n",
      "Epoch: 699, Training loss: 1.429739, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 700, Training loss: 1.335406, Validation loss: 1.3935, lr: 0.0000\n",
      "Epoch: 701, Training loss: 1.342679, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 702, Training loss: 1.346577, Validation loss: 1.3795, lr: 0.0000\n",
      "Epoch: 703, Training loss: 1.364632, Validation loss: 1.3556, lr: 0.0000\n",
      "Epoch: 704, Training loss: 1.352023, Validation loss: 1.3506, lr: 0.0000\n",
      "Epoch: 705, Training loss: 1.308263, Validation loss: 1.3449, lr: 0.0000\n",
      "Epoch: 706, Training loss: 1.349197, Validation loss: 1.3785, lr: 0.0000\n",
      "Epoch: 707, Training loss: 1.373792, Validation loss: 1.3409, lr: 0.0000\n",
      "Epoch: 708, Training loss: 1.353476, Validation loss: 1.3729, lr: 0.0000\n",
      "Epoch: 709, Training loss: 1.343338, Validation loss: 1.4207, lr: 0.0000\n",
      "Epoch: 710, Training loss: 1.334029, Validation loss: 1.3786, lr: 0.0000\n",
      "Epoch: 711, Training loss: 1.347358, Validation loss: 1.3372, lr: 0.0000\n",
      "Epoch: 712, Training loss: 1.356660, Validation loss: 1.3787, lr: 0.0000\n",
      "Epoch: 713, Training loss: 1.346160, Validation loss: 1.5985, lr: 0.0000\n",
      "Epoch: 714, Training loss: 1.377481, Validation loss: 1.3695, lr: 0.0000\n",
      "Epoch: 715, Training loss: 1.341688, Validation loss: 1.3662, lr: 0.0000\n",
      "Epoch: 716, Training loss: 1.375758, Validation loss: 1.3464, lr: 0.0000\n",
      "Epoch: 717, Training loss: 1.346565, Validation loss: 1.3717, lr: 0.0000\n",
      "Epoch: 718, Training loss: 1.324033, Validation loss: 1.3674, lr: 0.0000\n",
      "Epoch: 719, Training loss: 1.338121, Validation loss: 1.3626, lr: 0.0000\n",
      "Epoch: 720, Training loss: 1.387861, Validation loss: 1.3142, lr: 0.0000\n",
      "Epoch: 721, Training loss: 1.361198, Validation loss: 1.3695, lr: 0.0000\n",
      "Epoch: 722, Training loss: 1.326149, Validation loss: 1.3733, lr: 0.0000\n",
      "Epoch: 723, Training loss: 1.372409, Validation loss: 1.3622, lr: 0.0000\n",
      "Epoch: 724, Training loss: 1.352840, Validation loss: 1.6301, lr: 0.0000\n",
      "Epoch: 725, Training loss: 1.367660, Validation loss: 1.3765, lr: 0.0000\n",
      "Epoch: 726, Training loss: 1.351966, Validation loss: 1.3741, lr: 0.0000\n",
      "Epoch: 727, Training loss: 1.329495, Validation loss: 1.3779, lr: 0.0000\n",
      "Epoch: 728, Training loss: 1.359763, Validation loss: 1.3661, lr: 0.0000\n",
      "Epoch: 729, Training loss: 1.351657, Validation loss: 1.3717, lr: 0.0000\n",
      "Epoch: 730, Training loss: 1.347248, Validation loss: 1.3783, lr: 0.0000\n",
      "Epoch: 731, Training loss: 1.313702, Validation loss: 1.3215, lr: 0.0000\n",
      "Epoch: 732, Training loss: 1.342153, Validation loss: 1.3318, lr: 0.0000\n",
      "Epoch: 733, Training loss: 1.354622, Validation loss: 1.3344, lr: 0.0000\n",
      "Epoch: 734, Training loss: 1.377972, Validation loss: 1.3921, lr: 0.0000\n",
      "Epoch: 735, Training loss: 1.385040, Validation loss: 1.3698, lr: 0.0000\n",
      "Epoch: 736, Training loss: 1.415861, Validation loss: 1.3593, lr: 0.0000\n",
      "Epoch: 737, Training loss: 1.351220, Validation loss: 1.3689, lr: 0.0000\n",
      "Epoch: 738, Training loss: 1.326873, Validation loss: 1.3788, lr: 0.0000\n",
      "Epoch: 739, Training loss: 1.364125, Validation loss: 1.3483, lr: 0.0000\n",
      "Epoch: 740, Training loss: 1.391131, Validation loss: 1.3624, lr: 0.0000\n",
      "Epoch: 741, Training loss: 1.334612, Validation loss: 1.3695, lr: 0.0000\n",
      "Epoch: 742, Training loss: 1.336804, Validation loss: 1.3426, lr: 0.0000\n",
      "Epoch: 743, Training loss: 1.357963, Validation loss: 1.3724, lr: 0.0000\n",
      "Epoch: 744, Training loss: 1.337014, Validation loss: 1.3633, lr: 0.0000\n",
      "Epoch: 745, Training loss: 1.376923, Validation loss: 1.3652, lr: 0.0000\n",
      "Epoch: 746, Training loss: 1.355625, Validation loss: 1.3700, lr: 0.0000\n",
      "Epoch: 747, Training loss: 1.345138, Validation loss: 1.3766, lr: 0.0000\n",
      "Epoch: 748, Training loss: 1.350330, Validation loss: 1.3658, lr: 0.0000\n",
      "Epoch: 749, Training loss: 1.400907, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 750, Training loss: 1.379715, Validation loss: 1.3758, lr: 0.0000\n",
      "Epoch: 751, Training loss: 1.356289, Validation loss: 1.3534, lr: 0.0000\n",
      "Epoch: 752, Training loss: 1.338537, Validation loss: 1.3709, lr: 0.0000\n",
      "Epoch: 753, Training loss: 1.353728, Validation loss: 1.3628, lr: 0.0000\n",
      "Epoch: 754, Training loss: 1.345156, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 755, Training loss: 1.389931, Validation loss: 1.3512, lr: 0.0000\n",
      "Epoch: 756, Training loss: 1.377971, Validation loss: 1.3742, lr: 0.0000\n",
      "Epoch: 757, Training loss: 1.338319, Validation loss: 1.3672, lr: 0.0000\n",
      "Epoch: 758, Training loss: 1.343131, Validation loss: 1.3654, lr: 0.0000\n",
      "Epoch: 759, Training loss: 1.376967, Validation loss: 1.3487, lr: 0.0000\n",
      "Epoch: 760, Training loss: 1.334532, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 761, Training loss: 1.381289, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 762, Training loss: 1.394691, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 763, Training loss: 1.341613, Validation loss: 1.3590, lr: 0.0000\n",
      "Epoch: 764, Training loss: 1.352512, Validation loss: 1.3595, lr: 0.0000\n",
      "Epoch: 765, Training loss: 1.361605, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 766, Training loss: 1.338488, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 767, Training loss: 1.365004, Validation loss: 1.3382, lr: 0.0000\n",
      "Epoch: 768, Training loss: 1.341227, Validation loss: 1.3457, lr: 0.0000\n",
      "Epoch: 769, Training loss: 1.351507, Validation loss: 1.3642, lr: 0.0000\n",
      "Epoch: 770, Training loss: 1.406641, Validation loss: 1.3780, lr: 0.0000\n",
      "Epoch: 771, Training loss: 1.392419, Validation loss: 1.3783, lr: 0.0000\n",
      "Epoch: 772, Training loss: 1.377184, Validation loss: 1.3619, lr: 0.0000\n",
      "Epoch: 773, Training loss: 1.378786, Validation loss: 1.3676, lr: 0.0000\n",
      "Epoch: 774, Training loss: 1.416307, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 775, Training loss: 1.389561, Validation loss: 1.3696, lr: 0.0000\n",
      "Epoch: 776, Training loss: 1.338621, Validation loss: 1.3800, lr: 0.0000\n",
      "Epoch: 777, Training loss: 1.359423, Validation loss: 1.3626, lr: 0.0000\n",
      "Epoch: 778, Training loss: 1.366780, Validation loss: 1.3541, lr: 0.0000\n",
      "Epoch: 779, Training loss: 1.367091, Validation loss: 1.3642, lr: 0.0000\n",
      "Epoch: 780, Training loss: 1.335765, Validation loss: 1.3714, lr: 0.0000\n",
      "Epoch: 781, Training loss: 1.342478, Validation loss: 1.3200, lr: 0.0000\n",
      "Epoch: 782, Training loss: 1.374677, Validation loss: 1.3787, lr: 0.0000\n",
      "Epoch: 783, Training loss: 1.332009, Validation loss: 1.3524, lr: 0.0000\n",
      "Epoch: 784, Training loss: 1.320673, Validation loss: 1.3323, lr: 0.0000\n",
      "Epoch: 785, Training loss: 1.351262, Validation loss: 1.3717, lr: 0.0000\n",
      "Epoch: 786, Training loss: 1.336012, Validation loss: 1.3661, lr: 0.0000\n",
      "Epoch: 787, Training loss: 1.353441, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 788, Training loss: 1.349460, Validation loss: 1.3584, lr: 0.0000\n",
      "Epoch: 789, Training loss: 1.382926, Validation loss: 1.3461, lr: 0.0000\n",
      "Epoch: 790, Training loss: 1.372871, Validation loss: 1.3609, lr: 0.0000\n",
      "Epoch: 791, Training loss: 1.351931, Validation loss: 1.3599, lr: 0.0000\n",
      "Epoch: 792, Training loss: 1.346653, Validation loss: 1.3764, lr: 0.0000\n",
      "Epoch: 793, Training loss: 1.391722, Validation loss: 1.3626, lr: 0.0000\n",
      "Epoch: 794, Training loss: 1.349344, Validation loss: 1.3735, lr: 0.0000\n",
      "Epoch: 795, Training loss: 1.443946, Validation loss: 1.3991, lr: 0.0000\n",
      "Epoch: 796, Training loss: 1.385026, Validation loss: 1.3543, lr: 0.0000\n",
      "Epoch: 797, Training loss: 1.376003, Validation loss: 1.3769, lr: 0.0000\n",
      "Epoch: 798, Training loss: 1.358318, Validation loss: 1.3500, lr: 0.0000\n",
      "Epoch: 799, Training loss: 1.368171, Validation loss: 1.3655, lr: 0.0000\n",
      "Epoch: 800, Training loss: 1.346324, Validation loss: 1.3406, lr: 0.0000\n",
      "Epoch: 801, Training loss: 1.347653, Validation loss: 1.3596, lr: 0.0000\n",
      "Epoch: 802, Training loss: 1.442335, Validation loss: 1.3711, lr: 0.0000\n",
      "Epoch: 803, Training loss: 1.335455, Validation loss: 1.3502, lr: 0.0000\n",
      "Epoch: 804, Training loss: 1.411278, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 805, Training loss: 1.369814, Validation loss: 1.3511, lr: 0.0000\n",
      "Epoch: 806, Training loss: 1.432964, Validation loss: 1.3504, lr: 0.0000\n",
      "Epoch: 807, Training loss: 1.379973, Validation loss: 1.3780, lr: 0.0000\n",
      "Epoch: 808, Training loss: 1.385205, Validation loss: 1.3795, lr: 0.0000\n",
      "Epoch: 809, Training loss: 1.358977, Validation loss: 1.3725, lr: 0.0000\n",
      "Epoch: 810, Training loss: 1.357570, Validation loss: 1.3747, lr: 0.0000\n",
      "Epoch: 811, Training loss: 1.374684, Validation loss: 1.3501, lr: 0.0000\n",
      "Epoch: 812, Training loss: 1.371974, Validation loss: 1.3517, lr: 0.0000\n",
      "Epoch: 813, Training loss: 1.341388, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 814, Training loss: 1.405428, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 815, Training loss: 1.328782, Validation loss: 1.3651, lr: 0.0000\n",
      "Epoch: 816, Training loss: 1.349216, Validation loss: 1.3734, lr: 0.0000\n",
      "Epoch: 817, Training loss: 1.321404, Validation loss: 1.3735, lr: 0.0000\n",
      "Epoch: 818, Training loss: 1.373455, Validation loss: 1.3716, lr: 0.0000\n",
      "Epoch: 819, Training loss: 1.385518, Validation loss: 1.3609, lr: 0.0000\n",
      "Epoch: 820, Training loss: 1.338757, Validation loss: 1.3534, lr: 0.0000\n",
      "Epoch: 821, Training loss: 1.332201, Validation loss: 1.4062, lr: 0.0000\n",
      "Epoch: 822, Training loss: 1.330501, Validation loss: 1.3742, lr: 0.0000\n",
      "Epoch: 823, Training loss: 1.352999, Validation loss: 1.3716, lr: 0.0000\n",
      "Epoch: 824, Training loss: 1.329364, Validation loss: 1.3554, lr: 0.0000\n",
      "Epoch: 825, Training loss: 1.352031, Validation loss: 1.3269, lr: 0.0000\n",
      "Epoch: 826, Training loss: 1.439788, Validation loss: 1.3588, lr: 0.0000\n",
      "Epoch: 827, Training loss: 1.353585, Validation loss: 1.3771, lr: 0.0000\n",
      "Epoch: 828, Training loss: 1.355891, Validation loss: 1.3728, lr: 0.0000\n",
      "Epoch: 829, Training loss: 1.380096, Validation loss: 1.3798, lr: 0.0000\n",
      "Epoch: 830, Training loss: 1.380616, Validation loss: 1.3775, lr: 0.0000\n",
      "Epoch: 831, Training loss: 1.347129, Validation loss: 1.3757, lr: 0.0000\n",
      "Epoch: 832, Training loss: 1.333372, Validation loss: 1.3495, lr: 0.0000\n",
      "Epoch: 833, Training loss: 1.336403, Validation loss: 1.3562, lr: 0.0000\n",
      "Epoch: 834, Training loss: 1.349926, Validation loss: 1.3386, lr: 0.0000\n",
      "Epoch: 835, Training loss: 1.340191, Validation loss: 1.3476, lr: 0.0000\n",
      "Epoch: 836, Training loss: 1.341128, Validation loss: 1.3423, lr: 0.0000\n",
      "Epoch: 837, Training loss: 1.371508, Validation loss: 1.3750, lr: 0.0000\n",
      "Epoch: 838, Training loss: 1.375756, Validation loss: 1.4233, lr: 0.0000\n",
      "Epoch: 839, Training loss: 1.343851, Validation loss: 1.3752, lr: 0.0000\n",
      "Epoch: 840, Training loss: 1.388090, Validation loss: 1.3671, lr: 0.0000\n",
      "Epoch: 841, Training loss: 1.390550, Validation loss: 1.3713, lr: 0.0000\n",
      "Epoch: 842, Training loss: 1.350428, Validation loss: 1.3740, lr: 0.0000\n",
      "Epoch: 843, Training loss: 1.340338, Validation loss: 1.3788, lr: 0.0000\n",
      "Epoch: 844, Training loss: 1.383323, Validation loss: 1.3627, lr: 0.0000\n",
      "Epoch: 845, Training loss: 1.354986, Validation loss: 1.3721, lr: 0.0000\n",
      "Epoch: 846, Training loss: 1.350437, Validation loss: 1.3783, lr: 0.0000\n",
      "Epoch: 847, Training loss: 1.330279, Validation loss: 1.3694, lr: 0.0000\n",
      "Epoch: 848, Training loss: 1.403920, Validation loss: 1.3466, lr: 0.0000\n",
      "Epoch: 849, Training loss: 1.391211, Validation loss: 1.3657, lr: 0.0000\n",
      "Epoch: 850, Training loss: 1.360008, Validation loss: 1.3456, lr: 0.0000\n",
      "Epoch: 851, Training loss: 1.377420, Validation loss: 1.3660, lr: 0.0000\n",
      "Epoch: 852, Training loss: 1.382389, Validation loss: 1.3735, lr: 0.0000\n",
      "Epoch: 853, Training loss: 1.362295, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 854, Training loss: 1.355280, Validation loss: 1.3577, lr: 0.0000\n",
      "Epoch: 855, Training loss: 1.357333, Validation loss: 1.3789, lr: 0.0000\n",
      "Epoch: 856, Training loss: 1.372084, Validation loss: 1.3648, lr: 0.0000\n",
      "Epoch: 857, Training loss: 1.453185, Validation loss: 1.3672, lr: 0.0000\n",
      "Epoch: 858, Training loss: 1.366118, Validation loss: 1.3611, lr: 0.0000\n",
      "Epoch: 859, Training loss: 1.358623, Validation loss: 1.3634, lr: 0.0000\n",
      "Epoch: 860, Training loss: 1.361039, Validation loss: 1.3758, lr: 0.0000\n",
      "Epoch: 861, Training loss: 1.377208, Validation loss: 1.3747, lr: 0.0000\n",
      "Epoch: 862, Training loss: 1.364764, Validation loss: 1.3666, lr: 0.0000\n",
      "Epoch: 863, Training loss: 1.364964, Validation loss: 1.3501, lr: 0.0000\n",
      "Epoch: 864, Training loss: 1.349777, Validation loss: 1.3545, lr: 0.0000\n",
      "Epoch: 865, Training loss: 1.346352, Validation loss: 1.3727, lr: 0.0000\n",
      "Epoch: 866, Training loss: 1.364564, Validation loss: 1.3938, lr: 0.0000\n",
      "Epoch: 867, Training loss: 1.363426, Validation loss: 1.3756, lr: 0.0000\n",
      "Epoch: 868, Training loss: 1.376303, Validation loss: 1.3753, lr: 0.0000\n",
      "Epoch: 869, Training loss: 1.310219, Validation loss: 1.3764, lr: 0.0000\n",
      "Epoch: 870, Training loss: 1.399727, Validation loss: 1.3671, lr: 0.0000\n",
      "Epoch: 871, Training loss: 1.331056, Validation loss: 1.3732, lr: 0.0000\n",
      "Epoch: 872, Training loss: 1.352576, Validation loss: 1.3411, lr: 0.0000\n",
      "Epoch: 873, Training loss: 1.325116, Validation loss: 1.3766, lr: 0.0000\n",
      "Epoch: 874, Training loss: 1.340778, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 875, Training loss: 1.360306, Validation loss: 1.3700, lr: 0.0000\n",
      "Epoch: 876, Training loss: 1.331109, Validation loss: 1.3727, lr: 0.0000\n",
      "Epoch: 877, Training loss: 1.330396, Validation loss: 1.3729, lr: 0.0000\n",
      "Epoch: 878, Training loss: 1.368159, Validation loss: 1.3195, lr: 0.0000\n",
      "Epoch: 879, Training loss: 1.332897, Validation loss: 1.3787, lr: 0.0000\n",
      "Epoch: 880, Training loss: 1.334654, Validation loss: 1.3322, lr: 0.0000\n",
      "Epoch: 881, Training loss: 1.334878, Validation loss: 1.3942, lr: 0.0000\n",
      "Epoch: 882, Training loss: 1.385843, Validation loss: 1.3659, lr: 0.0000\n",
      "Epoch: 883, Training loss: 1.344078, Validation loss: 1.4263, lr: 0.0000\n",
      "Epoch: 884, Training loss: 1.349546, Validation loss: 1.3764, lr: 0.0000\n",
      "Epoch: 885, Training loss: 1.363315, Validation loss: 1.3388, lr: 0.0000\n",
      "Epoch: 886, Training loss: 1.354641, Validation loss: 1.3437, lr: 0.0000\n",
      "Epoch: 887, Training loss: 1.390535, Validation loss: 1.3531, lr: 0.0000\n",
      "Epoch: 888, Training loss: 1.319934, Validation loss: 1.3704, lr: 0.0000\n",
      "Epoch: 889, Training loss: 1.357423, Validation loss: 1.3220, lr: 0.0000\n",
      "Epoch: 890, Training loss: 1.347067, Validation loss: 1.3748, lr: 0.0000\n",
      "Epoch: 891, Training loss: 1.360239, Validation loss: 1.3736, lr: 0.0000\n",
      "Epoch: 892, Training loss: 1.398979, Validation loss: 1.3789, lr: 0.0000\n",
      "Epoch: 893, Training loss: 1.358145, Validation loss: 1.3708, lr: 0.0000\n",
      "Epoch: 894, Training loss: 1.470083, Validation loss: 1.3653, lr: 0.0000\n",
      "Epoch: 895, Training loss: 1.320967, Validation loss: 1.4314, lr: 0.0000\n",
      "Epoch: 896, Training loss: 1.329946, Validation loss: 1.3686, lr: 0.0000\n",
      "Epoch: 897, Training loss: 1.358945, Validation loss: 1.3607, lr: 0.0000\n",
      "Epoch: 898, Training loss: 1.320068, Validation loss: 1.3792, lr: 0.0000\n",
      "Epoch: 899, Training loss: 1.361086, Validation loss: 1.3038, lr: 0.0000\n",
      "Epoch: 900, Training loss: 1.336756, Validation loss: 2.1761, lr: 0.0000\n",
      "Epoch: 901, Training loss: 1.345993, Validation loss: 1.3585, lr: 0.0000\n",
      "Epoch: 902, Training loss: 1.346675, Validation loss: 1.3710, lr: 0.0000\n",
      "Epoch: 903, Training loss: 1.363157, Validation loss: 1.4430, lr: 0.0000\n",
      "Epoch: 904, Training loss: 1.360972, Validation loss: 1.3713, lr: 0.0000\n",
      "Epoch: 905, Training loss: 1.358281, Validation loss: 1.3588, lr: 0.0000\n",
      "Epoch: 906, Training loss: 1.390845, Validation loss: 1.3725, lr: 0.0000\n",
      "Epoch: 907, Training loss: 1.342861, Validation loss: 1.3784, lr: 0.0000\n",
      "Epoch: 908, Training loss: 1.370416, Validation loss: 1.3518, lr: 0.0000\n",
      "Epoch: 909, Training loss: 1.361533, Validation loss: 1.3909, lr: 0.0000\n",
      "Epoch: 910, Training loss: 1.310035, Validation loss: 1.3355, lr: 0.0000\n",
      "Epoch: 911, Training loss: 1.354092, Validation loss: 1.3702, lr: 0.0000\n",
      "Epoch: 912, Training loss: 1.345370, Validation loss: 1.3796, lr: 0.0000\n",
      "Epoch: 913, Training loss: 1.346296, Validation loss: 1.3755, lr: 0.0000\n",
      "Epoch: 914, Training loss: 1.359952, Validation loss: 1.3574, lr: 0.0000\n",
      "Epoch: 915, Training loss: 1.372253, Validation loss: 1.3696, lr: 0.0000\n",
      "Epoch: 916, Training loss: 1.382840, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 917, Training loss: 1.386495, Validation loss: 1.3772, lr: 0.0000\n",
      "Epoch: 918, Training loss: 1.361230, Validation loss: 1.3287, lr: 0.0000\n",
      "Epoch: 919, Training loss: 1.352855, Validation loss: 1.3684, lr: 0.0000\n",
      "Epoch: 920, Training loss: 1.353558, Validation loss: 1.3561, lr: 0.0000\n",
      "Epoch: 921, Training loss: 1.380806, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 922, Training loss: 1.319863, Validation loss: 1.3281, lr: 0.0000\n",
      "Epoch: 923, Training loss: 1.376301, Validation loss: 1.3873, lr: 0.0000\n",
      "Epoch: 924, Training loss: 1.363426, Validation loss: 1.3560, lr: 0.0000\n",
      "Epoch: 925, Training loss: 1.396344, Validation loss: 1.3719, lr: 0.0000\n",
      "Epoch: 926, Training loss: 1.384623, Validation loss: 1.3719, lr: 0.0000\n",
      "Epoch: 927, Training loss: 1.340510, Validation loss: 1.3525, lr: 0.0000\n",
      "Epoch: 928, Training loss: 1.346664, Validation loss: 1.3769, lr: 0.0000\n",
      "Epoch: 929, Training loss: 1.350052, Validation loss: 1.3576, lr: 0.0000\n",
      "Epoch: 930, Training loss: 1.319650, Validation loss: 1.4207, lr: 0.0000\n",
      "Epoch: 931, Training loss: 1.340134, Validation loss: 1.3711, lr: 0.0000\n",
      "Epoch: 932, Training loss: 1.369127, Validation loss: 1.3751, lr: 0.0000\n",
      "Epoch: 933, Training loss: 1.365001, Validation loss: 1.3448, lr: 0.0000\n",
      "Epoch: 934, Training loss: 1.391686, Validation loss: 1.3617, lr: 0.0000\n",
      "Epoch: 935, Training loss: 1.360488, Validation loss: 1.3337, lr: 0.0000\n",
      "Epoch: 936, Training loss: 1.386586, Validation loss: 1.3439, lr: 0.0000\n",
      "Epoch: 937, Training loss: 1.346636, Validation loss: 1.3695, lr: 0.0000\n",
      "Epoch: 938, Training loss: 1.391860, Validation loss: 1.3706, lr: 0.0000\n",
      "Epoch: 939, Training loss: 1.376329, Validation loss: 1.4603, lr: 0.0000\n",
      "Epoch: 940, Training loss: 1.380225, Validation loss: 1.3428, lr: 0.0000\n",
      "Epoch: 941, Training loss: 1.484692, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 942, Training loss: 1.319814, Validation loss: 1.3695, lr: 0.0000\n",
      "Epoch: 943, Training loss: 1.343867, Validation loss: 1.3779, lr: 0.0000\n",
      "Epoch: 944, Training loss: 1.374833, Validation loss: 1.3878, lr: 0.0000\n",
      "Epoch: 945, Training loss: 1.379991, Validation loss: 1.3689, lr: 0.0000\n",
      "Epoch: 946, Training loss: 1.339333, Validation loss: 1.3799, lr: 0.0000\n",
      "Epoch: 947, Training loss: 1.382458, Validation loss: 1.4051, lr: 0.0000\n",
      "Epoch: 948, Training loss: 1.354548, Validation loss: 1.3730, lr: 0.0000\n",
      "Epoch: 949, Training loss: 1.335388, Validation loss: 1.3898, lr: 0.0000\n",
      "Epoch: 950, Training loss: 1.349101, Validation loss: 1.3638, lr: 0.0000\n",
      "Epoch: 951, Training loss: 1.370804, Validation loss: 1.3746, lr: 0.0000\n",
      "Epoch: 952, Training loss: 1.358513, Validation loss: 1.3560, lr: 0.0000\n",
      "Epoch: 953, Training loss: 1.337318, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 954, Training loss: 1.334471, Validation loss: 1.3779, lr: 0.0000\n",
      "Epoch: 955, Training loss: 1.333223, Validation loss: 1.3996, lr: 0.0000\n",
      "Epoch: 956, Training loss: 1.360909, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 957, Training loss: 1.367724, Validation loss: 1.3761, lr: 0.0000\n",
      "Epoch: 958, Training loss: 1.326062, Validation loss: 1.3593, lr: 0.0000\n",
      "Epoch: 959, Training loss: 1.347394, Validation loss: 1.3580, lr: 0.0000\n",
      "Epoch: 960, Training loss: 1.345121, Validation loss: 1.3424, lr: 0.0000\n",
      "Epoch: 961, Training loss: 1.341792, Validation loss: 1.3790, lr: 0.0000\n",
      "Epoch: 962, Training loss: 1.361460, Validation loss: 1.3938, lr: 0.0000\n",
      "Epoch: 963, Training loss: 1.356667, Validation loss: 1.3504, lr: 0.0000\n",
      "Epoch: 964, Training loss: 1.335685, Validation loss: 1.3595, lr: 0.0000\n",
      "Epoch: 965, Training loss: 1.372964, Validation loss: 1.3720, lr: 0.0000\n",
      "Epoch: 966, Training loss: 1.350380, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 967, Training loss: 1.421900, Validation loss: 1.3542, lr: 0.0000\n",
      "Epoch: 968, Training loss: 1.329328, Validation loss: 1.3701, lr: 0.0000\n",
      "Epoch: 969, Training loss: 1.408948, Validation loss: 1.3745, lr: 0.0000\n",
      "Epoch: 970, Training loss: 1.326656, Validation loss: 1.3151, lr: 0.0000\n",
      "Epoch: 971, Training loss: 1.554990, Validation loss: 1.3670, lr: 0.0000\n",
      "Epoch: 972, Training loss: 1.349202, Validation loss: 1.3760, lr: 0.0000\n",
      "Epoch: 973, Training loss: 1.356570, Validation loss: 1.3924, lr: 0.0000\n",
      "Epoch: 974, Training loss: 1.338734, Validation loss: 1.3910, lr: 0.0000\n",
      "Epoch: 975, Training loss: 1.367158, Validation loss: 1.3419, lr: 0.0000\n",
      "Epoch: 976, Training loss: 1.345825, Validation loss: 1.3803, lr: 0.0000\n",
      "Epoch: 977, Training loss: 1.369416, Validation loss: 1.3658, lr: 0.0000\n",
      "Epoch: 978, Training loss: 1.356530, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 979, Training loss: 1.329980, Validation loss: 1.3550, lr: 0.0000\n",
      "Epoch: 980, Training loss: 1.361414, Validation loss: 1.3566, lr: 0.0000\n",
      "Epoch: 981, Training loss: 1.336411, Validation loss: 1.3761, lr: 0.0000\n",
      "Epoch: 982, Training loss: 1.339755, Validation loss: 1.3701, lr: 0.0000\n",
      "Epoch: 983, Training loss: 1.368407, Validation loss: 1.3668, lr: 0.0000\n",
      "Epoch: 984, Training loss: 1.344897, Validation loss: 1.2991, lr: 0.0000\n",
      "Epoch: 985, Training loss: 1.351030, Validation loss: 1.3682, lr: 0.0000\n",
      "Epoch: 986, Training loss: 1.337622, Validation loss: 1.3735, lr: 0.0000\n",
      "Epoch: 987, Training loss: 1.351274, Validation loss: 1.3776, lr: 0.0000\n",
      "Epoch: 988, Training loss: 1.343807, Validation loss: 1.3661, lr: 0.0000\n",
      "Epoch: 989, Training loss: 1.328083, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 990, Training loss: 1.347507, Validation loss: 1.3635, lr: 0.0000\n",
      "Epoch: 991, Training loss: 1.322704, Validation loss: 1.3620, lr: 0.0000\n",
      "Epoch: 992, Training loss: 1.380926, Validation loss: 1.3579, lr: 0.0000\n",
      "Epoch: 993, Training loss: 1.328320, Validation loss: 1.3796, lr: 0.0000\n",
      "Epoch: 994, Training loss: 1.353809, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 995, Training loss: 1.345534, Validation loss: 1.3796, lr: 0.0000\n",
      "Epoch: 996, Training loss: 1.355279, Validation loss: 1.3565, lr: 0.0000\n",
      "Epoch: 997, Training loss: 1.393677, Validation loss: 1.3379, lr: 0.0000\n",
      "Epoch: 998, Training loss: 1.346428, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 999, Training loss: 1.351757, Validation loss: 1.3657, lr: 0.0000\n",
      "Final test loss: 1.3673\n",
      "=== Run 09/10 ===\n",
      "\n",
      "---- Settings: \n",
      "\n",
      "epochs : 1000\n",
      "hidden_channels : [32]\n",
      "out_channels : 10\n",
      "inner_product_features : False\n",
      "batch_size : 64\n",
      "lr : 0.01\n",
      "momentum : 0.9\n",
      "dropout : 0.0\n",
      "batch_norm : batch_norm\n",
      "bias : True\n",
      "order : 2\n",
      "diffusion : True\n",
      "frac_sampled_nb : -1\n",
      "include_positions : False\n",
      "include_self : True\n",
      "vec_norm : False\n",
      "emb_norm : False\n",
      "seed : 0\n",
      "dim_signal : 100\n",
      "dim_emb : 100\n",
      "n_sampled_nb : -1\n",
      "\n",
      "---- Number of features to pass to the MLP:  1010100\n",
      "---- Total number of parameters:  32323627\n",
      "\n",
      "Using device cuda:0\n",
      "\n",
      "---- Training network ...\n",
      "\n",
      "---- Timestamp: 20250614-171321\n",
      "\n",
      " *och: 0, Training loss: 1.495717, Validation loss: 2.0858, lr: 0.0100\n",
      " *och: 1, Training loss: 1.394743, Validation loss: 1.3149, lr: 0.0100\n",
      "Epoch: 2, Training loss: 1.366523, Validation loss: 1.3776, lr: 0.0100\n",
      "Epoch: 3, Training loss: 1.435412, Validation loss: 1.5177, lr: 0.0100\n",
      "Epoch: 4, Training loss: 1.406885, Validation loss: 1.3821, lr: 0.0100\n",
      "Epoch: 5, Training loss: 1.386058, Validation loss: 1.3855, lr: 0.0100\n",
      "Epoch: 6, Training loss: 1.460672, Validation loss: 1.3832, lr: 0.0100\n",
      "Epoch: 7, Training loss: 1.375124, Validation loss: 1.3838, lr: 0.0100\n",
      "Epoch: 8, Training loss: 1.412022, Validation loss: 1.3976, lr: 0.0100\n",
      "Epoch: 9, Training loss: 1.379463, Validation loss: 1.3812, lr: 0.0100\n",
      "Epoch: 10, Training loss: 1.379852, Validation loss: 1.3820, lr: 0.0100\n",
      "Epoch: 11, Training loss: 1.392372, Validation loss: 1.3706, lr: 0.0100\n",
      "Epoch: 12, Training loss: 1.407585, Validation loss: 1.3984, lr: 0.0100\n",
      "Epoch: 13, Training loss: 1.383517, Validation loss: 1.3620, lr: 0.0010\n",
      "Epoch: 14, Training loss: 1.373211, Validation loss: 1.3881, lr: 0.0010\n",
      "Epoch: 15, Training loss: 1.360838, Validation loss: 1.3729, lr: 0.0010\n",
      "Epoch: 16, Training loss: 1.403057, Validation loss: 1.3852, lr: 0.0010\n",
      "Epoch: 17, Training loss: 1.397932, Validation loss: 1.3916, lr: 0.0010\n",
      "Epoch: 18, Training loss: 1.384376, Validation loss: 1.3847, lr: 0.0010\n",
      "Epoch: 19, Training loss: 1.399338, Validation loss: 1.3797, lr: 0.0010\n",
      "Epoch: 20, Training loss: 1.382990, Validation loss: 1.3851, lr: 0.0010\n",
      "Epoch: 21, Training loss: 1.378107, Validation loss: 1.3834, lr: 0.0010\n",
      "Epoch: 22, Training loss: 1.416622, Validation loss: 1.3860, lr: 0.0010\n",
      "Epoch: 23, Training loss: 1.365673, Validation loss: 1.3719, lr: 0.0010\n",
      "Epoch: 24, Training loss: 1.401366, Validation loss: 1.3790, lr: 0.0010\n",
      "Epoch: 25, Training loss: 1.428255, Validation loss: 1.3890, lr: 0.0010\n",
      "Epoch: 26, Training loss: 1.389015, Validation loss: 1.3826, lr: 0.0001\n",
      "Epoch: 27, Training loss: 1.370564, Validation loss: 1.3843, lr: 0.0001\n",
      "Epoch: 28, Training loss: 1.395710, Validation loss: 1.3893, lr: 0.0001\n",
      "Epoch: 29, Training loss: 1.366142, Validation loss: 1.3651, lr: 0.0001\n",
      "Epoch: 30, Training loss: 1.399426, Validation loss: 1.3804, lr: 0.0001\n",
      "Epoch: 31, Training loss: 1.358843, Validation loss: 1.3700, lr: 0.0001\n",
      "Epoch: 32, Training loss: 1.399281, Validation loss: 1.4032, lr: 0.0001\n",
      "Epoch: 33, Training loss: 1.360157, Validation loss: 1.3789, lr: 0.0001\n",
      "Epoch: 34, Training loss: 1.397878, Validation loss: 1.3626, lr: 0.0001\n",
      "Epoch: 35, Training loss: 1.391157, Validation loss: 1.3788, lr: 0.0001\n",
      "Epoch: 36, Training loss: 1.373103, Validation loss: 1.3790, lr: 0.0001\n",
      "Epoch: 37, Training loss: 1.385973, Validation loss: 1.3868, lr: 0.0001\n",
      "Epoch: 38, Training loss: 1.382600, Validation loss: 1.3621, lr: 0.0001\n",
      "Epoch: 39, Training loss: 1.372434, Validation loss: 1.3818, lr: 0.0001\n",
      "Epoch: 40, Training loss: 1.386998, Validation loss: 1.3841, lr: 0.0001\n",
      "Epoch: 41, Training loss: 1.375745, Validation loss: 1.3760, lr: 0.0001\n",
      "Epoch: 42, Training loss: 1.369524, Validation loss: 1.3672, lr: 0.0000\n",
      "Epoch: 43, Training loss: 1.389808, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 44, Training loss: 1.395825, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 45, Training loss: 1.381443, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 46, Training loss: 1.386904, Validation loss: 1.3684, lr: 0.0000\n",
      "Epoch: 47, Training loss: 1.365523, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 48, Training loss: 1.384508, Validation loss: 1.3920, lr: 0.0000\n",
      "Epoch: 49, Training loss: 1.360497, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 50, Training loss: 1.375166, Validation loss: 1.3674, lr: 0.0000\n",
      "Epoch: 51, Training loss: 1.365640, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 52, Training loss: 1.383744, Validation loss: 1.3878, lr: 0.0000\n",
      "Epoch: 53, Training loss: 1.399579, Validation loss: 1.3549, lr: 0.0000\n",
      "Epoch: 54, Training loss: 1.371231, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 55, Training loss: 1.381352, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 56, Training loss: 1.378330, Validation loss: 1.3765, lr: 0.0000\n",
      "Epoch: 57, Training loss: 1.391486, Validation loss: 1.3685, lr: 0.0000\n",
      "Epoch: 58, Training loss: 1.394392, Validation loss: 1.3690, lr: 0.0000\n",
      "Epoch: 59, Training loss: 1.385364, Validation loss: 1.5305, lr: 0.0000\n",
      "Epoch: 60, Training loss: 1.409664, Validation loss: 1.4271, lr: 0.0000\n",
      "Epoch: 61, Training loss: 1.367408, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 62, Training loss: 1.392071, Validation loss: 1.4064, lr: 0.0000\n",
      "Epoch: 63, Training loss: 1.563062, Validation loss: 1.3699, lr: 0.0000\n",
      "Epoch: 64, Training loss: 1.394677, Validation loss: 1.3752, lr: 0.0000\n",
      "Epoch: 65, Training loss: 1.371504, Validation loss: 1.3872, lr: 0.0000\n",
      "Epoch: 66, Training loss: 1.395724, Validation loss: 1.3906, lr: 0.0000\n",
      "Epoch: 67, Training loss: 1.371028, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 68, Training loss: 1.373394, Validation loss: 1.3754, lr: 0.0000\n",
      "Epoch: 69, Training loss: 1.407590, Validation loss: 1.3791, lr: 0.0000\n",
      "Epoch: 70, Training loss: 1.392553, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 71, Training loss: 1.381119, Validation loss: 1.3745, lr: 0.0000\n",
      "Epoch: 72, Training loss: 1.362210, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 73, Training loss: 1.374130, Validation loss: 1.3717, lr: 0.0000\n",
      "Epoch: 74, Training loss: 1.424128, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 75, Training loss: 1.374074, Validation loss: 1.3771, lr: 0.0000\n",
      "Epoch: 76, Training loss: 1.403685, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 77, Training loss: 1.368551, Validation loss: 5.7123, lr: 0.0000\n",
      "Epoch: 78, Training loss: 1.409046, Validation loss: 1.3664, lr: 0.0000\n",
      "Epoch: 79, Training loss: 1.359313, Validation loss: 1.3602, lr: 0.0000\n",
      "Epoch: 80, Training loss: 1.378858, Validation loss: 1.3783, lr: 0.0000\n",
      "Epoch: 81, Training loss: 1.418323, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 82, Training loss: 1.392924, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 83, Training loss: 1.390014, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 84, Training loss: 1.382816, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 85, Training loss: 1.386607, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 86, Training loss: 1.368863, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 87, Training loss: 1.366919, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 88, Training loss: 1.374577, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 89, Training loss: 1.436541, Validation loss: 1.3887, lr: 0.0000\n",
      "Epoch: 90, Training loss: 1.362232, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 91, Training loss: 1.436075, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 92, Training loss: 1.371854, Validation loss: 1.3893, lr: 0.0000\n",
      "Epoch: 93, Training loss: 1.399434, Validation loss: 1.3904, lr: 0.0000\n",
      "Epoch: 94, Training loss: 1.398594, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 95, Training loss: 1.369585, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 96, Training loss: 1.365604, Validation loss: 1.3789, lr: 0.0000\n",
      "Epoch: 97, Training loss: 1.367939, Validation loss: 1.3892, lr: 0.0000\n",
      "Epoch: 98, Training loss: 1.373502, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 99, Training loss: 1.392969, Validation loss: 1.3895, lr: 0.0000\n",
      "Epoch: 100, Training loss: 1.374928, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 101, Training loss: 1.379785, Validation loss: 1.3809, lr: 0.0000\n",
      "Epoch: 102, Training loss: 1.361758, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 103, Training loss: 1.374296, Validation loss: 1.3788, lr: 0.0000\n",
      "Epoch: 104, Training loss: 1.369505, Validation loss: 1.3744, lr: 0.0000\n",
      "Epoch: 105, Training loss: 1.383563, Validation loss: 1.3637, lr: 0.0000\n",
      "Epoch: 106, Training loss: 1.366428, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 107, Training loss: 1.393138, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 108, Training loss: 1.389328, Validation loss: 1.3774, lr: 0.0000\n",
      "Epoch: 109, Training loss: 1.363529, Validation loss: 1.3610, lr: 0.0000\n",
      "Epoch: 110, Training loss: 1.373836, Validation loss: 1.3902, lr: 0.0000\n",
      "Epoch: 111, Training loss: 1.420791, Validation loss: 1.3906, lr: 0.0000\n",
      "Epoch: 112, Training loss: 1.368131, Validation loss: 1.3756, lr: 0.0000\n",
      "Epoch: 113, Training loss: 1.359771, Validation loss: 1.3789, lr: 0.0000\n",
      "Epoch: 114, Training loss: 1.374116, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 115, Training loss: 1.389754, Validation loss: 1.3701, lr: 0.0000\n",
      "Epoch: 116, Training loss: 1.370614, Validation loss: 1.3872, lr: 0.0000\n",
      "Epoch: 117, Training loss: 1.382658, Validation loss: 1.3872, lr: 0.0000\n",
      "Epoch: 118, Training loss: 1.381467, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 119, Training loss: 1.424044, Validation loss: 1.3796, lr: 0.0000\n",
      "Epoch: 120, Training loss: 1.380739, Validation loss: 1.4791, lr: 0.0000\n",
      "Epoch: 121, Training loss: 1.385150, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 122, Training loss: 1.378234, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 123, Training loss: 1.387423, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 124, Training loss: 1.378480, Validation loss: 1.4095, lr: 0.0000\n",
      "Epoch: 125, Training loss: 1.385816, Validation loss: 1.3675, lr: 0.0000\n",
      "Epoch: 126, Training loss: 1.404743, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 127, Training loss: 1.448347, Validation loss: 1.3650, lr: 0.0000\n",
      "Epoch: 128, Training loss: 1.393730, Validation loss: 1.4408, lr: 0.0000\n",
      "Epoch: 129, Training loss: 1.377552, Validation loss: 1.3789, lr: 0.0000\n",
      "Epoch: 130, Training loss: 1.382960, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 131, Training loss: 1.383615, Validation loss: 1.3919, lr: 0.0000\n",
      "Epoch: 132, Training loss: 1.369497, Validation loss: 1.3971, lr: 0.0000\n",
      "Epoch: 133, Training loss: 1.381156, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 134, Training loss: 1.388929, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 135, Training loss: 1.360824, Validation loss: 1.3690, lr: 0.0000\n",
      "Epoch: 136, Training loss: 1.370928, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 137, Training loss: 1.446970, Validation loss: 1.3649, lr: 0.0000\n",
      "Epoch: 138, Training loss: 1.365796, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 139, Training loss: 1.375536, Validation loss: 1.3910, lr: 0.0000\n",
      "Epoch: 140, Training loss: 1.386970, Validation loss: 1.3790, lr: 0.0000\n",
      "Epoch: 141, Training loss: 1.369109, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 142, Training loss: 1.390636, Validation loss: 1.3877, lr: 0.0000\n",
      "Epoch: 143, Training loss: 1.389024, Validation loss: 1.3774, lr: 0.0000\n",
      "Epoch: 144, Training loss: 1.377942, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 145, Training loss: 1.444096, Validation loss: 1.3877, lr: 0.0000\n",
      "Epoch: 146, Training loss: 1.375738, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 147, Training loss: 1.376316, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 148, Training loss: 1.395550, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 149, Training loss: 1.356847, Validation loss: 1.3728, lr: 0.0000\n",
      "Epoch: 150, Training loss: 1.359401, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 151, Training loss: 1.375917, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 152, Training loss: 1.387451, Validation loss: 1.3700, lr: 0.0000\n",
      "Epoch: 153, Training loss: 1.398524, Validation loss: 1.3695, lr: 0.0000\n",
      "Epoch: 154, Training loss: 1.387411, Validation loss: 1.3740, lr: 0.0000\n",
      "Epoch: 155, Training loss: 1.374119, Validation loss: 1.3895, lr: 0.0000\n",
      "Epoch: 156, Training loss: 1.368257, Validation loss: 1.3606, lr: 0.0000\n",
      "Epoch: 157, Training loss: 1.383681, Validation loss: 1.3718, lr: 0.0000\n",
      "Epoch: 158, Training loss: 1.383185, Validation loss: 1.3915, lr: 0.0000\n",
      "Epoch: 159, Training loss: 1.390466, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 160, Training loss: 1.405531, Validation loss: 1.3802, lr: 0.0000\n",
      "Epoch: 161, Training loss: 1.383672, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 162, Training loss: 1.373451, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 163, Training loss: 1.412531, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 164, Training loss: 1.353658, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 165, Training loss: 1.369485, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 166, Training loss: 1.372126, Validation loss: 1.4103, lr: 0.0000\n",
      "Epoch: 167, Training loss: 1.386515, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 168, Training loss: 1.376107, Validation loss: 1.3907, lr: 0.0000\n",
      "Epoch: 169, Training loss: 1.380714, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 170, Training loss: 1.402432, Validation loss: 1.3934, lr: 0.0000\n",
      "Epoch: 171, Training loss: 1.377839, Validation loss: 1.3971, lr: 0.0000\n",
      "Epoch: 172, Training loss: 1.394623, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 173, Training loss: 1.383013, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 174, Training loss: 1.370252, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 175, Training loss: 1.364854, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 176, Training loss: 1.378466, Validation loss: 1.3927, lr: 0.0000\n",
      "Epoch: 177, Training loss: 1.367106, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 178, Training loss: 1.385389, Validation loss: 1.3774, lr: 0.0000\n",
      "Epoch: 179, Training loss: 1.368917, Validation loss: 1.3793, lr: 0.0000\n",
      "Epoch: 180, Training loss: 1.386600, Validation loss: 1.3891, lr: 0.0000\n",
      "Epoch: 181, Training loss: 1.362536, Validation loss: 1.3663, lr: 0.0000\n",
      "Epoch: 182, Training loss: 1.382795, Validation loss: 1.3879, lr: 0.0000\n",
      "Epoch: 183, Training loss: 1.373295, Validation loss: 1.3789, lr: 0.0000\n",
      "Epoch: 184, Training loss: 1.368371, Validation loss: 1.3704, lr: 0.0000\n",
      "Epoch: 185, Training loss: 1.365134, Validation loss: 1.3671, lr: 0.0000\n",
      "Epoch: 186, Training loss: 1.384596, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 187, Training loss: 1.438551, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 188, Training loss: 1.393866, Validation loss: 1.3565, lr: 0.0000\n",
      "Epoch: 189, Training loss: 1.376711, Validation loss: 1.3792, lr: 0.0000\n",
      "Epoch: 190, Training loss: 1.386955, Validation loss: 1.3547, lr: 0.0000\n",
      "Epoch: 191, Training loss: 1.387576, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 192, Training loss: 1.389559, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 193, Training loss: 1.379259, Validation loss: 1.3543, lr: 0.0000\n",
      "Epoch: 194, Training loss: 1.365606, Validation loss: 1.3771, lr: 0.0000\n",
      "Epoch: 195, Training loss: 1.376939, Validation loss: 1.3984, lr: 0.0000\n",
      "Epoch: 196, Training loss: 1.389694, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 197, Training loss: 1.392394, Validation loss: 1.3794, lr: 0.0000\n",
      "Epoch: 198, Training loss: 1.370424, Validation loss: 1.3752, lr: 0.0000\n",
      "Epoch: 199, Training loss: 1.372973, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 200, Training loss: 1.356734, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 201, Training loss: 1.377266, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 202, Training loss: 1.382554, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 203, Training loss: 1.368538, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 204, Training loss: 1.392482, Validation loss: 1.3701, lr: 0.0000\n",
      "Epoch: 205, Training loss: 1.370348, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 206, Training loss: 1.373636, Validation loss: 1.3768, lr: 0.0000\n",
      "Epoch: 207, Training loss: 1.402132, Validation loss: 1.3571, lr: 0.0000\n",
      "Epoch: 208, Training loss: 1.420300, Validation loss: 1.4014, lr: 0.0000\n",
      "Epoch: 209, Training loss: 1.383302, Validation loss: 1.3637, lr: 0.0000\n",
      "Epoch: 210, Training loss: 1.378657, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 211, Training loss: 1.367297, Validation loss: 1.3937, lr: 0.0000\n",
      "Epoch: 212, Training loss: 1.364911, Validation loss: 1.3935, lr: 0.0000\n",
      "Epoch: 213, Training loss: 1.369684, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 214, Training loss: 1.377730, Validation loss: 1.3783, lr: 0.0000\n",
      "Epoch: 215, Training loss: 1.355872, Validation loss: 1.3800, lr: 0.0000\n",
      "Epoch: 216, Training loss: 1.394112, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 217, Training loss: 1.375613, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 218, Training loss: 1.363732, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 219, Training loss: 1.389108, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 220, Training loss: 1.475246, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 221, Training loss: 1.402853, Validation loss: 1.3932, lr: 0.0000\n",
      "Epoch: 222, Training loss: 1.398655, Validation loss: 2.1866, lr: 0.0000\n",
      "Epoch: 223, Training loss: 1.385523, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 224, Training loss: 1.380526, Validation loss: 1.3603, lr: 0.0000\n",
      "Epoch: 225, Training loss: 1.370490, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 226, Training loss: 1.386870, Validation loss: 1.4055, lr: 0.0000\n",
      "Epoch: 227, Training loss: 1.374226, Validation loss: 1.3749, lr: 0.0000\n",
      "Epoch: 228, Training loss: 1.381217, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 229, Training loss: 1.451352, Validation loss: 1.3879, lr: 0.0000\n",
      "Epoch: 230, Training loss: 1.351377, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 231, Training loss: 1.395985, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 232, Training loss: 1.386433, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 233, Training loss: 1.372021, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 234, Training loss: 1.381925, Validation loss: 1.3784, lr: 0.0000\n",
      "Epoch: 235, Training loss: 1.421419, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 236, Training loss: 1.375127, Validation loss: 1.3678, lr: 0.0000\n",
      "Epoch: 237, Training loss: 1.400363, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 238, Training loss: 1.363400, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 239, Training loss: 1.362649, Validation loss: 1.3926, lr: 0.0000\n",
      "Epoch: 240, Training loss: 1.388139, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 241, Training loss: 1.423370, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 242, Training loss: 1.394322, Validation loss: 1.3871, lr: 0.0000\n",
      "Epoch: 243, Training loss: 1.386317, Validation loss: 1.3872, lr: 0.0000\n",
      "Epoch: 244, Training loss: 1.374875, Validation loss: 1.3911, lr: 0.0000\n",
      "Epoch: 245, Training loss: 1.381571, Validation loss: 1.3946, lr: 0.0000\n",
      "Epoch: 246, Training loss: 1.367300, Validation loss: 1.3752, lr: 0.0000\n",
      "Epoch: 247, Training loss: 1.382176, Validation loss: 1.3654, lr: 0.0000\n",
      "Epoch: 248, Training loss: 1.380630, Validation loss: 1.3747, lr: 0.0000\n",
      "Epoch: 249, Training loss: 1.388592, Validation loss: 1.3673, lr: 0.0000\n",
      "Epoch: 250, Training loss: 1.385399, Validation loss: 1.3764, lr: 0.0000\n",
      "Epoch: 251, Training loss: 1.376837, Validation loss: 1.3747, lr: 0.0000\n",
      "Epoch: 252, Training loss: 1.463292, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 253, Training loss: 1.378671, Validation loss: 1.3894, lr: 0.0000\n",
      "Epoch: 254, Training loss: 1.382247, Validation loss: 1.3771, lr: 0.0000\n",
      "Epoch: 255, Training loss: 1.373006, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 256, Training loss: 1.369825, Validation loss: 1.3873, lr: 0.0000\n",
      "Epoch: 257, Training loss: 1.361986, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 258, Training loss: 1.372012, Validation loss: 1.3787, lr: 0.0000\n",
      "Epoch: 259, Training loss: 1.397659, Validation loss: 1.3622, lr: 0.0000\n",
      "Epoch: 260, Training loss: 1.388116, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 261, Training loss: 1.410847, Validation loss: 1.3681, lr: 0.0000\n",
      "Epoch: 262, Training loss: 1.358591, Validation loss: 1.3792, lr: 0.0000\n",
      "Epoch: 263, Training loss: 1.383936, Validation loss: 1.3626, lr: 0.0000\n",
      "Epoch: 264, Training loss: 1.377718, Validation loss: 1.3889, lr: 0.0000\n",
      "Epoch: 265, Training loss: 1.386759, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 266, Training loss: 1.377863, Validation loss: 1.3752, lr: 0.0000\n",
      "Epoch: 267, Training loss: 1.376879, Validation loss: 1.3741, lr: 0.0000\n",
      "Epoch: 268, Training loss: 1.402256, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 269, Training loss: 1.351736, Validation loss: 1.3912, lr: 0.0000\n",
      "Epoch: 270, Training loss: 1.381885, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 271, Training loss: 1.417755, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 272, Training loss: 1.406005, Validation loss: 1.3669, lr: 0.0000\n",
      "Epoch: 273, Training loss: 1.360280, Validation loss: 1.3878, lr: 0.0000\n",
      "Epoch: 274, Training loss: 1.405400, Validation loss: 1.3733, lr: 0.0000\n",
      "Epoch: 275, Training loss: 1.383025, Validation loss: 1.3793, lr: 0.0000\n",
      "Epoch: 276, Training loss: 1.362334, Validation loss: 1.3389, lr: 0.0000\n",
      "Epoch: 277, Training loss: 1.413002, Validation loss: 1.3782, lr: 0.0000\n",
      "Epoch: 278, Training loss: 1.410429, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 279, Training loss: 1.404198, Validation loss: 1.3751, lr: 0.0000\n",
      "Epoch: 280, Training loss: 1.371698, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 281, Training loss: 1.371271, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 282, Training loss: 1.370794, Validation loss: 1.3978, lr: 0.0000\n",
      "Epoch: 283, Training loss: 1.384709, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 284, Training loss: 1.381474, Validation loss: 1.3706, lr: 0.0000\n",
      "Epoch: 285, Training loss: 1.388085, Validation loss: 1.3906, lr: 0.0000\n",
      "Epoch: 286, Training loss: 1.368595, Validation loss: 1.3871, lr: 0.0000\n",
      "Epoch: 287, Training loss: 1.414459, Validation loss: 1.4284, lr: 0.0000\n",
      "Epoch: 288, Training loss: 1.395407, Validation loss: 1.3761, lr: 0.0000\n",
      "Epoch: 289, Training loss: 1.373967, Validation loss: 1.3752, lr: 0.0000\n",
      "Epoch: 290, Training loss: 1.373091, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 291, Training loss: 1.377619, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 292, Training loss: 1.401962, Validation loss: 1.3935, lr: 0.0000\n",
      "Epoch: 293, Training loss: 1.381946, Validation loss: 1.3733, lr: 0.0000\n",
      "Epoch: 294, Training loss: 1.378249, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 295, Training loss: 1.392328, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 296, Training loss: 1.383876, Validation loss: 1.3799, lr: 0.0000\n",
      "Epoch: 297, Training loss: 1.368878, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 298, Training loss: 1.366029, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 299, Training loss: 1.365034, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 300, Training loss: 1.365991, Validation loss: 1.3725, lr: 0.0000\n",
      "Epoch: 301, Training loss: 1.372680, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 302, Training loss: 1.419291, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 303, Training loss: 1.377821, Validation loss: 1.3310, lr: 0.0000\n",
      "Epoch: 304, Training loss: 1.391166, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 305, Training loss: 1.373930, Validation loss: 1.3902, lr: 0.0000\n",
      "Epoch: 306, Training loss: 1.359657, Validation loss: 1.3708, lr: 0.0000\n",
      "Epoch: 307, Training loss: 1.389384, Validation loss: 1.3447, lr: 0.0000\n",
      "Epoch: 308, Training loss: 1.388957, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 309, Training loss: 1.362096, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 310, Training loss: 1.377858, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 311, Training loss: 1.394600, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 312, Training loss: 1.433190, Validation loss: 1.3719, lr: 0.0000\n",
      "Epoch: 313, Training loss: 1.407005, Validation loss: 1.3797, lr: 0.0000\n",
      "Epoch: 314, Training loss: 1.350602, Validation loss: 1.3757, lr: 0.0000\n",
      "Epoch: 315, Training loss: 1.363044, Validation loss: 1.3729, lr: 0.0000\n",
      "Epoch: 316, Training loss: 1.410353, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 317, Training loss: 1.398324, Validation loss: 1.3792, lr: 0.0000\n",
      "Epoch: 318, Training loss: 1.358555, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 319, Training loss: 1.388529, Validation loss: 1.3893, lr: 0.0000\n",
      "Epoch: 320, Training loss: 1.375077, Validation loss: 1.4074, lr: 0.0000\n",
      "Epoch: 321, Training loss: 1.372813, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 322, Training loss: 1.397809, Validation loss: 1.3744, lr: 0.0000\n",
      "Epoch: 323, Training loss: 1.363420, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 324, Training loss: 1.386399, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 325, Training loss: 1.385745, Validation loss: 1.3773, lr: 0.0000\n",
      "Epoch: 326, Training loss: 1.380261, Validation loss: 1.4224, lr: 0.0000\n",
      "Epoch: 327, Training loss: 1.391688, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 328, Training loss: 1.376109, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 329, Training loss: 1.431922, Validation loss: 1.3879, lr: 0.0000\n",
      "Epoch: 330, Training loss: 1.369587, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 331, Training loss: 1.397743, Validation loss: 1.3803, lr: 0.0000\n",
      "Epoch: 332, Training loss: 1.377520, Validation loss: 1.3800, lr: 0.0000\n",
      "Epoch: 333, Training loss: 1.366777, Validation loss: 1.3597, lr: 0.0000\n",
      "Epoch: 334, Training loss: 1.407269, Validation loss: 1.3721, lr: 0.0000\n",
      "Epoch: 335, Training loss: 1.405512, Validation loss: 1.3787, lr: 0.0000\n",
      "Epoch: 336, Training loss: 1.386481, Validation loss: 1.3665, lr: 0.0000\n",
      "Epoch: 337, Training loss: 1.377600, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 338, Training loss: 1.388659, Validation loss: 1.3734, lr: 0.0000\n",
      "Epoch: 339, Training loss: 1.373209, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 340, Training loss: 1.404825, Validation loss: 1.3666, lr: 0.0000\n",
      "Epoch: 341, Training loss: 1.367152, Validation loss: 1.3903, lr: 0.0000\n",
      "Epoch: 342, Training loss: 1.389598, Validation loss: 1.3898, lr: 0.0000\n",
      "Epoch: 343, Training loss: 1.382542, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 344, Training loss: 1.419824, Validation loss: 1.3722, lr: 0.0000\n",
      "Epoch: 345, Training loss: 1.357420, Validation loss: 1.3880, lr: 0.0000\n",
      "Epoch: 346, Training loss: 1.355525, Validation loss: 1.3744, lr: 0.0000\n",
      "Epoch: 347, Training loss: 1.368343, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 348, Training loss: 1.388970, Validation loss: 1.3908, lr: 0.0000\n",
      "Epoch: 349, Training loss: 1.361640, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 350, Training loss: 1.395110, Validation loss: 1.3896, lr: 0.0000\n",
      "Epoch: 351, Training loss: 1.380773, Validation loss: 1.4649, lr: 0.0000\n",
      "Epoch: 352, Training loss: 1.383523, Validation loss: 1.3938, lr: 0.0000\n",
      "Epoch: 353, Training loss: 1.378473, Validation loss: 1.3724, lr: 0.0000\n",
      "Epoch: 354, Training loss: 1.387651, Validation loss: 1.3792, lr: 0.0000\n",
      "Epoch: 355, Training loss: 1.369810, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 356, Training loss: 1.408311, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 357, Training loss: 1.407348, Validation loss: 1.3745, lr: 0.0000\n",
      "Epoch: 358, Training loss: 1.374892, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 359, Training loss: 1.363999, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 360, Training loss: 1.449187, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 361, Training loss: 1.359258, Validation loss: 1.3795, lr: 0.0000\n",
      "Epoch: 362, Training loss: 1.388421, Validation loss: 1.3734, lr: 0.0000\n",
      "Epoch: 363, Training loss: 1.362581, Validation loss: 1.3678, lr: 0.0000\n",
      "Epoch: 364, Training loss: 1.417083, Validation loss: 1.4766, lr: 0.0000\n",
      "Epoch: 365, Training loss: 1.367575, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 366, Training loss: 1.363582, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 367, Training loss: 1.397442, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 368, Training loss: 1.370133, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 369, Training loss: 1.410622, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 370, Training loss: 1.361329, Validation loss: 1.3873, lr: 0.0000\n",
      "Epoch: 371, Training loss: 1.374927, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 372, Training loss: 1.390430, Validation loss: 1.3761, lr: 0.0000\n",
      "Epoch: 373, Training loss: 1.390390, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 374, Training loss: 1.427074, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 375, Training loss: 1.377109, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 376, Training loss: 1.371842, Validation loss: 1.3722, lr: 0.0000\n",
      "Epoch: 377, Training loss: 1.384086, Validation loss: 1.3701, lr: 0.0000\n",
      " *och: 378, Training loss: 1.371823, Validation loss: 1.3080, lr: 0.0000\n",
      "Epoch: 379, Training loss: 1.410145, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 380, Training loss: 1.379304, Validation loss: 1.3735, lr: 0.0000\n",
      "Epoch: 381, Training loss: 1.350381, Validation loss: 1.4555, lr: 0.0000\n",
      "Epoch: 382, Training loss: 1.366255, Validation loss: 1.3892, lr: 0.0000\n",
      "Epoch: 383, Training loss: 1.370584, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 384, Training loss: 1.393510, Validation loss: 1.3679, lr: 0.0000\n",
      "Epoch: 385, Training loss: 1.378335, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 386, Training loss: 1.395055, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 387, Training loss: 1.360430, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 388, Training loss: 1.386848, Validation loss: 1.3717, lr: 0.0000\n",
      "Epoch: 389, Training loss: 1.383706, Validation loss: 1.4492, lr: 0.0000\n",
      "Epoch: 390, Training loss: 1.373743, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 391, Training loss: 1.388264, Validation loss: 1.3580, lr: 0.0000\n",
      "Epoch: 392, Training loss: 1.376591, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 393, Training loss: 1.370431, Validation loss: 1.3602, lr: 0.0000\n",
      "Epoch: 394, Training loss: 1.387082, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 395, Training loss: 1.374874, Validation loss: 1.3755, lr: 0.0000\n",
      "Epoch: 396, Training loss: 1.386696, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 397, Training loss: 1.383092, Validation loss: 1.3726, lr: 0.0000\n",
      "Epoch: 398, Training loss: 1.375749, Validation loss: 1.4990, lr: 0.0000\n",
      "Epoch: 399, Training loss: 1.380077, Validation loss: 1.3778, lr: 0.0000\n",
      "Epoch: 400, Training loss: 1.366772, Validation loss: 1.3759, lr: 0.0000\n",
      "Epoch: 401, Training loss: 1.389810, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 402, Training loss: 1.362101, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 403, Training loss: 1.371536, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 404, Training loss: 1.387031, Validation loss: 1.3720, lr: 0.0000\n",
      "Epoch: 405, Training loss: 1.435039, Validation loss: 1.3689, lr: 0.0000\n",
      "Epoch: 406, Training loss: 1.374770, Validation loss: 1.3740, lr: 0.0000\n",
      "Epoch: 407, Training loss: 1.356301, Validation loss: 1.3886, lr: 0.0000\n",
      "Epoch: 408, Training loss: 1.369650, Validation loss: 1.3744, lr: 0.0000\n",
      "Epoch: 409, Training loss: 1.368371, Validation loss: 1.4198, lr: 0.0000\n",
      "Epoch: 410, Training loss: 1.359479, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 411, Training loss: 1.386285, Validation loss: 1.3687, lr: 0.0000\n",
      "Epoch: 412, Training loss: 1.407615, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 413, Training loss: 1.380204, Validation loss: 1.4587, lr: 0.0000\n",
      "Epoch: 414, Training loss: 1.373961, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 415, Training loss: 1.358367, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 416, Training loss: 1.385271, Validation loss: 1.3680, lr: 0.0000\n",
      "Epoch: 417, Training loss: 1.382200, Validation loss: 1.3889, lr: 0.0000\n",
      "Epoch: 418, Training loss: 1.376562, Validation loss: 1.4080, lr: 0.0000\n",
      "Epoch: 419, Training loss: 1.377679, Validation loss: 1.3763, lr: 0.0000\n",
      "Epoch: 420, Training loss: 1.369170, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 421, Training loss: 1.375233, Validation loss: 1.3737, lr: 0.0000\n",
      "Epoch: 422, Training loss: 1.380263, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 423, Training loss: 1.387132, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 424, Training loss: 1.373985, Validation loss: 1.4211, lr: 0.0000\n",
      "Epoch: 425, Training loss: 1.405983, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 426, Training loss: 1.407634, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 427, Training loss: 1.376620, Validation loss: 1.3905, lr: 0.0000\n",
      "Epoch: 428, Training loss: 1.372465, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 429, Training loss: 1.375337, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 430, Training loss: 1.370796, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 431, Training loss: 1.393453, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 432, Training loss: 1.383043, Validation loss: 1.4395, lr: 0.0000\n",
      "Epoch: 433, Training loss: 1.370853, Validation loss: 1.3996, lr: 0.0000\n",
      "Epoch: 434, Training loss: 1.387369, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 435, Training loss: 1.357783, Validation loss: 1.3177, lr: 0.0000\n",
      "Epoch: 436, Training loss: 1.367735, Validation loss: 1.3569, lr: 0.0000\n",
      "Epoch: 437, Training loss: 1.389465, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 438, Training loss: 1.386605, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 439, Training loss: 1.376551, Validation loss: 1.3959, lr: 0.0000\n",
      "Epoch: 440, Training loss: 1.361133, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 441, Training loss: 1.367407, Validation loss: 1.4039, lr: 0.0000\n",
      "Epoch: 442, Training loss: 1.387784, Validation loss: 1.4231, lr: 0.0000\n",
      "Epoch: 443, Training loss: 1.393756, Validation loss: 1.3704, lr: 0.0000\n",
      "Epoch: 444, Training loss: 1.397986, Validation loss: 1.3746, lr: 0.0000\n",
      "Epoch: 445, Training loss: 1.387778, Validation loss: 1.3707, lr: 0.0000\n",
      "Epoch: 446, Training loss: 1.376485, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 447, Training loss: 1.371147, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 448, Training loss: 1.373854, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 449, Training loss: 1.378150, Validation loss: 1.3876, lr: 0.0000\n",
      "Epoch: 450, Training loss: 1.384327, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 451, Training loss: 1.352951, Validation loss: 1.3772, lr: 0.0000\n",
      "Epoch: 452, Training loss: 1.365130, Validation loss: 1.3738, lr: 0.0000\n",
      "Epoch: 453, Training loss: 1.405214, Validation loss: 1.3766, lr: 0.0000\n",
      "Epoch: 454, Training loss: 1.372156, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 455, Training loss: 1.363129, Validation loss: 1.3800, lr: 0.0000\n",
      "Epoch: 456, Training loss: 1.364055, Validation loss: 1.3789, lr: 0.0000\n",
      "Epoch: 457, Training loss: 1.379394, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 458, Training loss: 1.378117, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 459, Training loss: 1.383442, Validation loss: 1.3755, lr: 0.0000\n",
      "Epoch: 460, Training loss: 1.370929, Validation loss: 1.3709, lr: 0.0000\n",
      "Epoch: 461, Training loss: 1.387539, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 462, Training loss: 1.369963, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 463, Training loss: 1.366767, Validation loss: 1.3776, lr: 0.0000\n",
      "Epoch: 464, Training loss: 1.381695, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 465, Training loss: 1.411045, Validation loss: 1.3753, lr: 0.0000\n",
      "Epoch: 466, Training loss: 1.369287, Validation loss: 1.3679, lr: 0.0000\n",
      "Epoch: 467, Training loss: 1.372015, Validation loss: 1.3802, lr: 0.0000\n",
      "Epoch: 468, Training loss: 1.371577, Validation loss: 1.3762, lr: 0.0000\n",
      "Epoch: 469, Training loss: 1.394228, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 470, Training loss: 1.403245, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 471, Training loss: 1.381555, Validation loss: 1.3696, lr: 0.0000\n",
      "Epoch: 472, Training loss: 1.394123, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 473, Training loss: 1.373379, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 474, Training loss: 1.392732, Validation loss: 1.3762, lr: 0.0000\n",
      "Epoch: 475, Training loss: 1.404737, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 476, Training loss: 1.391118, Validation loss: 1.3771, lr: 0.0000\n",
      "Epoch: 477, Training loss: 1.363782, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 478, Training loss: 1.376544, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 479, Training loss: 1.356575, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 480, Training loss: 1.407511, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 481, Training loss: 1.367146, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 482, Training loss: 1.382112, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 483, Training loss: 1.360119, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 484, Training loss: 1.362360, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 485, Training loss: 1.378481, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 486, Training loss: 1.354532, Validation loss: 1.3610, lr: 0.0000\n",
      "Epoch: 487, Training loss: 1.382515, Validation loss: 1.3726, lr: 0.0000\n",
      "Epoch: 488, Training loss: 1.382653, Validation loss: 1.3879, lr: 0.0000\n",
      "Epoch: 489, Training loss: 1.380371, Validation loss: 1.4122, lr: 0.0000\n",
      "Epoch: 490, Training loss: 1.373337, Validation loss: 1.3802, lr: 0.0000\n",
      "Epoch: 491, Training loss: 1.390163, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 492, Training loss: 1.412556, Validation loss: 1.3926, lr: 0.0000\n",
      "Epoch: 493, Training loss: 1.426354, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 494, Training loss: 1.377396, Validation loss: 1.3880, lr: 0.0000\n",
      "Epoch: 495, Training loss: 1.395736, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 496, Training loss: 1.360718, Validation loss: 1.3971, lr: 0.0000\n",
      "Epoch: 497, Training loss: 1.369332, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 498, Training loss: 1.387001, Validation loss: 1.3891, lr: 0.0000\n",
      "Epoch: 499, Training loss: 1.388229, Validation loss: 1.3772, lr: 0.0000\n",
      "Epoch: 500, Training loss: 1.379253, Validation loss: 1.3634, lr: 0.0000\n",
      "Epoch: 501, Training loss: 1.444264, Validation loss: 1.3985, lr: 0.0000\n",
      "Epoch: 502, Training loss: 1.387989, Validation loss: 1.3795, lr: 0.0000\n",
      "Epoch: 503, Training loss: 1.367427, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 504, Training loss: 1.416902, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 505, Training loss: 1.395489, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 506, Training loss: 1.353535, Validation loss: 1.3721, lr: 0.0000\n",
      "Epoch: 507, Training loss: 1.401297, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 508, Training loss: 1.386444, Validation loss: 1.3721, lr: 0.0000\n",
      "Epoch: 509, Training loss: 1.395252, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 510, Training loss: 1.409108, Validation loss: 1.4130, lr: 0.0000\n",
      "Epoch: 511, Training loss: 1.393774, Validation loss: 1.3959, lr: 0.0000\n",
      "Epoch: 512, Training loss: 1.391467, Validation loss: 1.3511, lr: 0.0000\n",
      "Epoch: 513, Training loss: 1.390011, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 514, Training loss: 1.373909, Validation loss: 1.3697, lr: 0.0000\n",
      "Epoch: 515, Training loss: 1.385433, Validation loss: 1.3873, lr: 0.0000\n",
      "Epoch: 516, Training loss: 1.385793, Validation loss: 1.3557, lr: 0.0000\n",
      "Epoch: 517, Training loss: 1.396134, Validation loss: 1.3770, lr: 0.0000\n",
      "Epoch: 518, Training loss: 1.368508, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 519, Training loss: 1.348515, Validation loss: 1.3787, lr: 0.0000\n",
      "Epoch: 520, Training loss: 1.376510, Validation loss: 1.4008, lr: 0.0000\n",
      "Epoch: 521, Training loss: 1.385583, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 522, Training loss: 1.360822, Validation loss: 1.3758, lr: 0.0000\n",
      "Epoch: 523, Training loss: 1.383298, Validation loss: 1.3699, lr: 0.0000\n",
      "Epoch: 524, Training loss: 1.389419, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 525, Training loss: 1.398823, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 526, Training loss: 1.426852, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 527, Training loss: 1.374498, Validation loss: 1.3731, lr: 0.0000\n",
      "Epoch: 528, Training loss: 1.369357, Validation loss: 1.3790, lr: 0.0000\n",
      "Epoch: 529, Training loss: 1.379317, Validation loss: 1.3878, lr: 0.0000\n",
      "Epoch: 530, Training loss: 1.380437, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 531, Training loss: 1.393441, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 532, Training loss: 1.377309, Validation loss: 1.4133, lr: 0.0000\n",
      "Epoch: 533, Training loss: 1.401167, Validation loss: 1.3875, lr: 0.0000\n",
      "Epoch: 534, Training loss: 1.401054, Validation loss: 1.3701, lr: 0.0000\n",
      "Epoch: 535, Training loss: 1.373852, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 536, Training loss: 1.382506, Validation loss: 1.3765, lr: 0.0000\n",
      "Epoch: 537, Training loss: 1.400492, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 538, Training loss: 1.397902, Validation loss: 1.3783, lr: 0.0000\n",
      "Epoch: 539, Training loss: 1.363589, Validation loss: 1.3647, lr: 0.0000\n",
      "Epoch: 540, Training loss: 1.368819, Validation loss: 1.3878, lr: 0.0000\n",
      "Epoch: 541, Training loss: 1.392037, Validation loss: 1.3872, lr: 0.0000\n",
      "Epoch: 542, Training loss: 1.381753, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 543, Training loss: 1.382023, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 544, Training loss: 1.406092, Validation loss: 1.3937, lr: 0.0000\n",
      "Epoch: 545, Training loss: 1.377377, Validation loss: 1.3888, lr: 0.0000\n",
      "Epoch: 546, Training loss: 1.424410, Validation loss: 1.3892, lr: 0.0000\n",
      "Epoch: 547, Training loss: 1.396351, Validation loss: 1.3779, lr: 0.0000\n",
      "Epoch: 548, Training loss: 1.374763, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 549, Training loss: 1.370890, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 550, Training loss: 1.376372, Validation loss: 1.3765, lr: 0.0000\n",
      "Epoch: 551, Training loss: 1.408071, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 552, Training loss: 1.384609, Validation loss: 1.3698, lr: 0.0000\n",
      "Epoch: 553, Training loss: 1.383086, Validation loss: 1.3800, lr: 0.0000\n",
      "Epoch: 554, Training loss: 1.403434, Validation loss: 1.3876, lr: 0.0000\n",
      "Epoch: 555, Training loss: 1.447659, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 556, Training loss: 1.378807, Validation loss: 1.3875, lr: 0.0000\n",
      "Epoch: 557, Training loss: 1.404871, Validation loss: 1.3722, lr: 0.0000\n",
      "Epoch: 558, Training loss: 1.377022, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 559, Training loss: 1.384398, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 560, Training loss: 1.385560, Validation loss: 1.3795, lr: 0.0000\n",
      "Epoch: 561, Training loss: 1.364472, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 562, Training loss: 1.394978, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 563, Training loss: 1.390233, Validation loss: 1.3879, lr: 0.0000\n",
      "Epoch: 564, Training loss: 1.374783, Validation loss: 1.3471, lr: 0.0000\n",
      "Epoch: 565, Training loss: 1.373231, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 566, Training loss: 1.405957, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 567, Training loss: 1.377067, Validation loss: 1.3742, lr: 0.0000\n",
      "Epoch: 568, Training loss: 1.391743, Validation loss: 1.3894, lr: 0.0000\n",
      "Epoch: 569, Training loss: 1.384135, Validation loss: 1.3935, lr: 0.0000\n",
      "Epoch: 570, Training loss: 1.450390, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 571, Training loss: 1.406224, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 572, Training loss: 1.380066, Validation loss: 1.4026, lr: 0.0000\n",
      "Epoch: 573, Training loss: 1.379229, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 574, Training loss: 1.379400, Validation loss: 1.3911, lr: 0.0000\n",
      "Epoch: 575, Training loss: 1.378913, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 576, Training loss: 1.404655, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 577, Training loss: 1.369156, Validation loss: 1.3743, lr: 0.0000\n",
      "Epoch: 578, Training loss: 1.378498, Validation loss: 1.3733, lr: 0.0000\n",
      "Epoch: 579, Training loss: 1.379412, Validation loss: 1.3796, lr: 0.0000\n",
      "Epoch: 580, Training loss: 1.391218, Validation loss: 1.3760, lr: 0.0000\n",
      "Epoch: 581, Training loss: 1.379453, Validation loss: 1.3744, lr: 0.0000\n",
      "Epoch: 582, Training loss: 1.377621, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 583, Training loss: 1.370890, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 584, Training loss: 1.384449, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 585, Training loss: 1.395270, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 586, Training loss: 1.362687, Validation loss: 1.3721, lr: 0.0000\n",
      "Epoch: 587, Training loss: 1.369864, Validation loss: 1.3871, lr: 0.0000\n",
      "Epoch: 588, Training loss: 1.376244, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 589, Training loss: 1.377926, Validation loss: 1.3577, lr: 0.0000\n",
      "Epoch: 590, Training loss: 1.364076, Validation loss: 1.3796, lr: 0.0000\n",
      "Epoch: 591, Training loss: 1.366425, Validation loss: 1.3743, lr: 0.0000\n",
      "Epoch: 592, Training loss: 1.388425, Validation loss: 1.3642, lr: 0.0000\n",
      "Epoch: 593, Training loss: 1.368552, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 594, Training loss: 1.382141, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 595, Training loss: 1.389751, Validation loss: 1.3890, lr: 0.0000\n",
      "Epoch: 596, Training loss: 1.376486, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 597, Training loss: 1.370074, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 598, Training loss: 1.386006, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 599, Training loss: 1.371420, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 600, Training loss: 1.434796, Validation loss: 1.3696, lr: 0.0000\n",
      "Epoch: 601, Training loss: 1.386995, Validation loss: 1.3762, lr: 0.0000\n",
      "Epoch: 602, Training loss: 1.358454, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 603, Training loss: 1.376756, Validation loss: 1.3751, lr: 0.0000\n",
      "Epoch: 604, Training loss: 1.376852, Validation loss: 1.3635, lr: 0.0000\n",
      "Epoch: 605, Training loss: 1.372505, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 606, Training loss: 1.363290, Validation loss: 1.3720, lr: 0.0000\n",
      "Epoch: 607, Training loss: 1.374195, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 608, Training loss: 1.397231, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 609, Training loss: 1.362456, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 610, Training loss: 1.382197, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 611, Training loss: 1.388495, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 612, Training loss: 1.379400, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 613, Training loss: 1.370031, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 614, Training loss: 1.409411, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 615, Training loss: 1.386878, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 616, Training loss: 1.363769, Validation loss: 1.3719, lr: 0.0000\n",
      "Epoch: 617, Training loss: 1.392898, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 618, Training loss: 1.392024, Validation loss: 1.3766, lr: 0.0000\n",
      "Epoch: 619, Training loss: 1.458823, Validation loss: 1.3564, lr: 0.0000\n",
      "Epoch: 620, Training loss: 1.363606, Validation loss: 1.3750, lr: 0.0000\n",
      "Epoch: 621, Training loss: 1.374182, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 622, Training loss: 1.383753, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 623, Training loss: 1.395305, Validation loss: 1.3934, lr: 0.0000\n",
      "Epoch: 624, Training loss: 1.379999, Validation loss: 1.3716, lr: 0.0000\n",
      "Epoch: 625, Training loss: 1.398178, Validation loss: 1.3684, lr: 0.0000\n",
      "Epoch: 626, Training loss: 1.388207, Validation loss: 1.3707, lr: 0.0000\n",
      "Epoch: 627, Training loss: 1.345734, Validation loss: 1.3623, lr: 0.0000\n",
      "Epoch: 628, Training loss: 1.386693, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 629, Training loss: 1.392257, Validation loss: 1.3739, lr: 0.0000\n",
      "Epoch: 630, Training loss: 1.382992, Validation loss: 1.3545, lr: 0.0000\n",
      "Epoch: 631, Training loss: 1.384109, Validation loss: 1.3722, lr: 0.0000\n",
      "Epoch: 632, Training loss: 1.380184, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 633, Training loss: 1.385426, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 634, Training loss: 1.372687, Validation loss: 1.3730, lr: 0.0000\n",
      "Epoch: 635, Training loss: 1.366295, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 636, Training loss: 1.354189, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 637, Training loss: 1.369407, Validation loss: 1.3872, lr: 0.0000\n",
      "Epoch: 638, Training loss: 1.410145, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 639, Training loss: 1.364301, Validation loss: 1.3894, lr: 0.0000\n",
      "Epoch: 640, Training loss: 1.379132, Validation loss: 1.3891, lr: 0.0000\n",
      "Epoch: 641, Training loss: 1.378675, Validation loss: 1.3704, lr: 0.0000\n",
      "Epoch: 642, Training loss: 1.399743, Validation loss: 1.3599, lr: 0.0000\n",
      "Epoch: 643, Training loss: 1.401011, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 644, Training loss: 1.384431, Validation loss: 1.3556, lr: 0.0000\n",
      "Epoch: 645, Training loss: 1.362516, Validation loss: 1.3720, lr: 0.0000\n",
      "Epoch: 646, Training loss: 1.365833, Validation loss: 1.3770, lr: 0.0000\n",
      "Epoch: 647, Training loss: 1.386810, Validation loss: 1.3999, lr: 0.0000\n",
      "Epoch: 648, Training loss: 1.459987, Validation loss: 1.3886, lr: 0.0000\n",
      "Epoch: 649, Training loss: 1.362040, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 650, Training loss: 1.364006, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 651, Training loss: 1.378726, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 652, Training loss: 1.380262, Validation loss: 1.3780, lr: 0.0000\n",
      "Epoch: 653, Training loss: 1.412176, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 654, Training loss: 1.384512, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 655, Training loss: 1.368109, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 656, Training loss: 1.382342, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 657, Training loss: 1.369214, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 658, Training loss: 1.360156, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 659, Training loss: 1.382801, Validation loss: 1.3929, lr: 0.0000\n",
      "Epoch: 660, Training loss: 1.432698, Validation loss: 1.8200, lr: 0.0000\n",
      "Epoch: 661, Training loss: 1.357503, Validation loss: 1.3737, lr: 0.0000\n",
      "Epoch: 662, Training loss: 1.410483, Validation loss: 1.3878, lr: 0.0000\n",
      "Epoch: 663, Training loss: 1.364761, Validation loss: 1.3758, lr: 0.0000\n",
      "Epoch: 664, Training loss: 1.401413, Validation loss: 1.3799, lr: 0.0000\n",
      "Epoch: 665, Training loss: 1.364741, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 666, Training loss: 1.380938, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 667, Training loss: 1.398308, Validation loss: 1.4635, lr: 0.0000\n",
      "Epoch: 668, Training loss: 1.439711, Validation loss: 1.3791, lr: 0.0000\n",
      "Epoch: 669, Training loss: 1.384053, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 670, Training loss: 1.358820, Validation loss: 3.1839, lr: 0.0000\n",
      "Epoch: 671, Training loss: 1.395753, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 672, Training loss: 1.387345, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 673, Training loss: 1.373003, Validation loss: 1.3747, lr: 0.0000\n",
      "Epoch: 674, Training loss: 1.349592, Validation loss: 1.3786, lr: 0.0000\n",
      "Epoch: 675, Training loss: 1.371208, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 676, Training loss: 1.376149, Validation loss: 1.3697, lr: 0.0000\n",
      "Epoch: 677, Training loss: 1.390142, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 678, Training loss: 1.371794, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 679, Training loss: 1.434724, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 680, Training loss: 1.397805, Validation loss: 1.3795, lr: 0.0000\n",
      "Epoch: 681, Training loss: 1.390222, Validation loss: 1.3871, lr: 0.0000\n",
      "Epoch: 682, Training loss: 1.391279, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 683, Training loss: 1.412023, Validation loss: 1.4329, lr: 0.0000\n",
      "Epoch: 684, Training loss: 1.435281, Validation loss: 1.3737, lr: 0.0000\n",
      "Epoch: 685, Training loss: 1.354816, Validation loss: 1.3795, lr: 0.0000\n",
      "Epoch: 686, Training loss: 1.387572, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 687, Training loss: 1.377729, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 688, Training loss: 1.364075, Validation loss: 1.4026, lr: 0.0000\n",
      "Epoch: 689, Training loss: 1.381063, Validation loss: 1.3882, lr: 0.0000\n",
      "Epoch: 690, Training loss: 1.376087, Validation loss: 1.3790, lr: 0.0000\n",
      "Epoch: 691, Training loss: 1.374394, Validation loss: 1.3374, lr: 0.0000\n",
      "Epoch: 692, Training loss: 1.376478, Validation loss: 1.3670, lr: 0.0000\n",
      "Epoch: 693, Training loss: 1.388238, Validation loss: 1.3972, lr: 0.0000\n",
      "Epoch: 694, Training loss: 1.392473, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 695, Training loss: 1.364337, Validation loss: 1.3798, lr: 0.0000\n",
      "Epoch: 696, Training loss: 1.401252, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 697, Training loss: 1.367790, Validation loss: 1.3949, lr: 0.0000\n",
      "Epoch: 698, Training loss: 1.365399, Validation loss: 1.3384, lr: 0.0000\n",
      "Epoch: 699, Training loss: 1.386256, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 700, Training loss: 1.376686, Validation loss: 1.3732, lr: 0.0000\n",
      "Epoch: 701, Training loss: 1.366551, Validation loss: 1.3969, lr: 0.0000\n",
      "Epoch: 702, Training loss: 1.373246, Validation loss: 1.3798, lr: 0.0000\n",
      "Epoch: 703, Training loss: 1.364954, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 704, Training loss: 1.400804, Validation loss: 1.3743, lr: 0.0000\n",
      "Epoch: 705, Training loss: 1.378824, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 706, Training loss: 1.374553, Validation loss: 1.3719, lr: 0.0000\n",
      "Epoch: 707, Training loss: 1.420514, Validation loss: 1.3794, lr: 0.0000\n",
      "Epoch: 708, Training loss: 1.381233, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 709, Training loss: 1.370742, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 710, Training loss: 1.380386, Validation loss: 1.3694, lr: 0.0000\n",
      "Epoch: 711, Training loss: 1.382079, Validation loss: 1.3803, lr: 0.0000\n",
      "Epoch: 712, Training loss: 1.368996, Validation loss: 1.3747, lr: 0.0000\n",
      "Epoch: 713, Training loss: 1.380002, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 714, Training loss: 1.370679, Validation loss: 1.3497, lr: 0.0000\n",
      "Epoch: 715, Training loss: 1.392819, Validation loss: 1.3751, lr: 0.0000\n",
      "Epoch: 716, Training loss: 1.378211, Validation loss: 1.3775, lr: 0.0000\n",
      "Epoch: 717, Training loss: 1.370804, Validation loss: 1.3786, lr: 0.0000\n",
      "Epoch: 718, Training loss: 1.389799, Validation loss: 1.3798, lr: 0.0000\n",
      "Epoch: 719, Training loss: 1.417745, Validation loss: 1.3772, lr: 0.0000\n",
      "Epoch: 720, Training loss: 1.397191, Validation loss: 1.3797, lr: 0.0000\n",
      "Epoch: 721, Training loss: 1.393260, Validation loss: 1.3893, lr: 0.0000\n",
      "Epoch: 722, Training loss: 1.385362, Validation loss: 1.3727, lr: 0.0000\n",
      "Epoch: 723, Training loss: 1.372745, Validation loss: 1.3961, lr: 0.0000\n",
      "Epoch: 724, Training loss: 1.375281, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 725, Training loss: 1.371970, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 726, Training loss: 1.365553, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 727, Training loss: 1.367494, Validation loss: 1.3920, lr: 0.0000\n",
      "Epoch: 728, Training loss: 1.366382, Validation loss: 1.3809, lr: 0.0000\n",
      "Epoch: 729, Training loss: 1.389008, Validation loss: 1.3759, lr: 0.0000\n",
      "Epoch: 730, Training loss: 1.375991, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 731, Training loss: 1.396875, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 732, Training loss: 1.428313, Validation loss: 1.3770, lr: 0.0000\n",
      "Epoch: 733, Training loss: 1.445739, Validation loss: 1.3925, lr: 0.0000\n",
      "Epoch: 734, Training loss: 1.378304, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 735, Training loss: 1.372846, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 736, Training loss: 1.382643, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 737, Training loss: 1.378491, Validation loss: 1.3957, lr: 0.0000\n",
      "Epoch: 738, Training loss: 1.386546, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 739, Training loss: 1.367702, Validation loss: 1.3712, lr: 0.0000\n",
      "Epoch: 740, Training loss: 1.356001, Validation loss: 1.3624, lr: 0.0000\n",
      "Epoch: 741, Training loss: 1.360637, Validation loss: 1.3876, lr: 0.0000\n",
      "Epoch: 742, Training loss: 1.382038, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 743, Training loss: 1.377368, Validation loss: 1.3765, lr: 0.0000\n",
      "Epoch: 744, Training loss: 1.385442, Validation loss: 2.1210, lr: 0.0000\n",
      "Epoch: 745, Training loss: 1.392122, Validation loss: 1.3482, lr: 0.0000\n",
      "Epoch: 746, Training loss: 1.374607, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 747, Training loss: 1.369802, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 748, Training loss: 1.393701, Validation loss: 1.3892, lr: 0.0000\n",
      "Epoch: 749, Training loss: 1.361442, Validation loss: 1.3711, lr: 0.0000\n",
      "Epoch: 750, Training loss: 1.394648, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 751, Training loss: 1.386602, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 752, Training loss: 1.404388, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 753, Training loss: 1.388326, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 754, Training loss: 1.380366, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 755, Training loss: 1.382332, Validation loss: 1.3889, lr: 0.0000\n",
      "Epoch: 756, Training loss: 1.385547, Validation loss: 1.3762, lr: 0.0000\n",
      "Epoch: 757, Training loss: 1.437138, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 758, Training loss: 1.389171, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 759, Training loss: 1.362306, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 760, Training loss: 1.364753, Validation loss: 1.3875, lr: 0.0000\n",
      "Epoch: 761, Training loss: 1.359842, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 762, Training loss: 1.387951, Validation loss: 1.4262, lr: 0.0000\n",
      "Epoch: 763, Training loss: 1.399744, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 764, Training loss: 1.375136, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 765, Training loss: 1.387046, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 766, Training loss: 1.375553, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 767, Training loss: 1.436389, Validation loss: 1.4069, lr: 0.0000\n",
      "Epoch: 768, Training loss: 1.371644, Validation loss: 1.3927, lr: 0.0000\n",
      "Epoch: 769, Training loss: 1.394176, Validation loss: 1.3875, lr: 0.0000\n",
      "Epoch: 770, Training loss: 1.364774, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 771, Training loss: 1.375171, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 772, Training loss: 1.393653, Validation loss: 1.3636, lr: 0.0000\n",
      "Epoch: 773, Training loss: 1.376894, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 774, Training loss: 1.418146, Validation loss: 1.3912, lr: 0.0000\n",
      "Epoch: 775, Training loss: 1.369982, Validation loss: 1.3569, lr: 0.0000\n",
      "Epoch: 776, Training loss: 1.376983, Validation loss: 1.3795, lr: 0.0000\n",
      "Epoch: 777, Training loss: 1.384786, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 778, Training loss: 1.379306, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 779, Training loss: 1.372021, Validation loss: 1.3458, lr: 0.0000\n",
      "Epoch: 780, Training loss: 1.361932, Validation loss: 1.4347, lr: 0.0000\n",
      "Epoch: 781, Training loss: 1.373154, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 782, Training loss: 1.401383, Validation loss: 1.3743, lr: 0.0000\n",
      "Epoch: 783, Training loss: 1.453366, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 784, Training loss: 1.379153, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 785, Training loss: 1.428872, Validation loss: 1.3598, lr: 0.0000\n",
      "Epoch: 786, Training loss: 1.407249, Validation loss: 1.3757, lr: 0.0000\n",
      "Epoch: 787, Training loss: 1.434672, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 788, Training loss: 1.373645, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 789, Training loss: 1.376328, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 790, Training loss: 1.394097, Validation loss: 1.3748, lr: 0.0000\n",
      "Epoch: 791, Training loss: 1.378752, Validation loss: 1.3734, lr: 0.0000\n",
      "Epoch: 792, Training loss: 1.391070, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 793, Training loss: 1.421150, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 794, Training loss: 1.373929, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 795, Training loss: 1.390242, Validation loss: 1.3795, lr: 0.0000\n",
      "Epoch: 796, Training loss: 1.385968, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 797, Training loss: 1.376281, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 798, Training loss: 1.377565, Validation loss: 1.3749, lr: 0.0000\n",
      "Epoch: 799, Training loss: 1.423598, Validation loss: 1.3553, lr: 0.0000\n",
      "Epoch: 800, Training loss: 1.372156, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 801, Training loss: 1.398261, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 802, Training loss: 1.380119, Validation loss: 1.3934, lr: 0.0000\n",
      "Epoch: 803, Training loss: 1.399226, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 804, Training loss: 1.374910, Validation loss: 1.3799, lr: 0.0000\n",
      "Epoch: 805, Training loss: 1.396506, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 806, Training loss: 1.371836, Validation loss: 1.3803, lr: 0.0000\n",
      "Epoch: 807, Training loss: 1.384177, Validation loss: 1.3796, lr: 0.0000\n",
      "Epoch: 808, Training loss: 1.367824, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 809, Training loss: 1.368290, Validation loss: 1.3745, lr: 0.0000\n",
      "Epoch: 810, Training loss: 1.381935, Validation loss: 1.3693, lr: 0.0000\n",
      "Epoch: 811, Training loss: 1.395013, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 812, Training loss: 1.383700, Validation loss: 1.3746, lr: 0.0000\n",
      "Epoch: 813, Training loss: 1.386990, Validation loss: 1.3922, lr: 0.0000\n",
      "Epoch: 814, Training loss: 1.382977, Validation loss: 1.3722, lr: 0.0000\n",
      "Epoch: 815, Training loss: 1.340538, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 816, Training loss: 1.382969, Validation loss: 1.3556, lr: 0.0000\n",
      "Epoch: 817, Training loss: 1.378358, Validation loss: 1.3894, lr: 0.0000\n",
      "Epoch: 818, Training loss: 1.380352, Validation loss: 1.3892, lr: 0.0000\n",
      "Epoch: 819, Training loss: 1.466395, Validation loss: 1.3803, lr: 0.0000\n",
      "Epoch: 820, Training loss: 1.490309, Validation loss: 1.3742, lr: 0.0000\n",
      "Epoch: 821, Training loss: 1.382138, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 822, Training loss: 1.390750, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 823, Training loss: 1.382249, Validation loss: 1.3872, lr: 0.0000\n",
      "Epoch: 824, Training loss: 1.377010, Validation loss: 1.3764, lr: 0.0000\n",
      "Epoch: 825, Training loss: 1.383219, Validation loss: 1.3779, lr: 0.0000\n",
      "Epoch: 826, Training loss: 1.425230, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 827, Training loss: 1.364551, Validation loss: 1.3897, lr: 0.0000\n",
      "Epoch: 828, Training loss: 1.405653, Validation loss: 1.4554, lr: 0.0000\n",
      "Epoch: 829, Training loss: 1.393216, Validation loss: 1.3783, lr: 0.0000\n",
      "Epoch: 830, Training loss: 1.370783, Validation loss: 1.3776, lr: 0.0000\n",
      "Epoch: 831, Training loss: 1.376791, Validation loss: 1.3994, lr: 0.0000\n",
      "Epoch: 832, Training loss: 1.363436, Validation loss: 1.3928, lr: 0.0000\n",
      "Epoch: 833, Training loss: 1.480170, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 834, Training loss: 1.396505, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 835, Training loss: 1.416376, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 836, Training loss: 1.366862, Validation loss: 1.3794, lr: 0.0000\n",
      "Epoch: 837, Training loss: 1.360495, Validation loss: 1.3789, lr: 0.0000\n",
      "Epoch: 838, Training loss: 1.368093, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 839, Training loss: 1.387385, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 840, Training loss: 1.360791, Validation loss: 1.3880, lr: 0.0000\n",
      "Epoch: 841, Training loss: 1.363212, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 842, Training loss: 1.375312, Validation loss: 1.4856, lr: 0.0000\n",
      "Epoch: 843, Training loss: 1.385232, Validation loss: 1.3917, lr: 0.0000\n",
      "Epoch: 844, Training loss: 1.378775, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 845, Training loss: 1.420108, Validation loss: 1.3765, lr: 0.0000\n",
      "Epoch: 846, Training loss: 1.372788, Validation loss: 1.4098, lr: 0.0000\n",
      "Epoch: 847, Training loss: 1.375921, Validation loss: 1.3673, lr: 0.0000\n",
      "Epoch: 848, Training loss: 1.375493, Validation loss: 1.3781, lr: 0.0000\n",
      "Epoch: 849, Training loss: 1.440130, Validation loss: 1.3678, lr: 0.0000\n",
      "Epoch: 850, Training loss: 1.375611, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 851, Training loss: 1.365192, Validation loss: 1.3739, lr: 0.0000\n",
      "Epoch: 852, Training loss: 1.376861, Validation loss: 1.3771, lr: 0.0000\n",
      "Epoch: 853, Training loss: 1.384142, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 854, Training loss: 1.450272, Validation loss: 1.3933, lr: 0.0000\n",
      "Epoch: 855, Training loss: 1.366190, Validation loss: 1.3637, lr: 0.0000\n",
      "Epoch: 856, Training loss: 1.381571, Validation loss: 1.3800, lr: 0.0000\n",
      "Epoch: 857, Training loss: 1.430008, Validation loss: 1.3698, lr: 0.0000\n",
      "Epoch: 858, Training loss: 1.416271, Validation loss: 1.3716, lr: 0.0000\n",
      "Epoch: 859, Training loss: 1.382020, Validation loss: 1.3912, lr: 0.0000\n",
      "Epoch: 860, Training loss: 1.382153, Validation loss: 1.3685, lr: 0.0000\n",
      "Epoch: 861, Training loss: 1.360375, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 862, Training loss: 1.458268, Validation loss: 1.3775, lr: 0.0000\n",
      "Epoch: 863, Training loss: 1.380424, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 864, Training loss: 1.408526, Validation loss: 1.3735, lr: 0.0000\n",
      "Epoch: 865, Training loss: 1.384180, Validation loss: 1.3752, lr: 0.0000\n",
      "Epoch: 866, Training loss: 1.384550, Validation loss: 1.3774, lr: 0.0000\n",
      "Epoch: 867, Training loss: 1.377653, Validation loss: 1.3785, lr: 0.0000\n",
      "Epoch: 868, Training loss: 1.378252, Validation loss: 1.3726, lr: 0.0000\n",
      "Epoch: 869, Training loss: 1.377921, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 870, Training loss: 1.380314, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 871, Training loss: 1.367295, Validation loss: 1.4119, lr: 0.0000\n",
      "Epoch: 872, Training loss: 1.377812, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 873, Training loss: 1.378997, Validation loss: 1.3902, lr: 0.0000\n",
      "Epoch: 874, Training loss: 1.402469, Validation loss: 1.3526, lr: 0.0000\n",
      "Epoch: 875, Training loss: 1.362330, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 876, Training loss: 1.381361, Validation loss: 1.3539, lr: 0.0000\n",
      "Epoch: 877, Training loss: 1.367973, Validation loss: 1.3782, lr: 0.0000\n",
      "Epoch: 878, Training loss: 1.408177, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 879, Training loss: 1.378601, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 880, Training loss: 1.404940, Validation loss: 1.3714, lr: 0.0000\n",
      "Epoch: 881, Training loss: 1.371935, Validation loss: 1.3911, lr: 0.0000\n",
      "Epoch: 882, Training loss: 1.399722, Validation loss: 1.3663, lr: 0.0000\n",
      "Epoch: 883, Training loss: 1.371556, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 884, Training loss: 1.380068, Validation loss: 1.3900, lr: 0.0000\n",
      "Epoch: 885, Training loss: 1.372969, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 886, Training loss: 1.357744, Validation loss: 1.3445, lr: 0.0000\n",
      "Epoch: 887, Training loss: 1.400079, Validation loss: 1.3492, lr: 0.0000\n",
      "Epoch: 888, Training loss: 1.392631, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 889, Training loss: 1.375134, Validation loss: 1.3800, lr: 0.0000\n",
      "Epoch: 890, Training loss: 1.384099, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 891, Training loss: 1.394809, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 892, Training loss: 1.382242, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 893, Training loss: 1.387298, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 894, Training loss: 1.407538, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 895, Training loss: 1.375435, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 896, Training loss: 1.424078, Validation loss: 1.3708, lr: 0.0000\n",
      "Epoch: 897, Training loss: 1.384298, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 898, Training loss: 1.387498, Validation loss: 1.3670, lr: 0.0000\n",
      "Epoch: 899, Training loss: 1.367172, Validation loss: 1.3909, lr: 0.0000\n",
      "Epoch: 900, Training loss: 1.387735, Validation loss: 1.3756, lr: 0.0000\n",
      "Epoch: 901, Training loss: 1.380598, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 902, Training loss: 1.376341, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 903, Training loss: 1.378251, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 904, Training loss: 1.367903, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 905, Training loss: 1.368122, Validation loss: 1.3794, lr: 0.0000\n",
      "Epoch: 906, Training loss: 1.373235, Validation loss: 1.3889, lr: 0.0000\n",
      "Epoch: 907, Training loss: 1.405574, Validation loss: 1.3749, lr: 0.0000\n",
      "Epoch: 908, Training loss: 1.396705, Validation loss: 1.3766, lr: 0.0000\n",
      "Epoch: 909, Training loss: 1.383613, Validation loss: 1.3877, lr: 0.0000\n",
      "Epoch: 910, Training loss: 1.386228, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 911, Training loss: 1.362289, Validation loss: 1.3639, lr: 0.0000\n",
      "Epoch: 912, Training loss: 1.381252, Validation loss: 1.3926, lr: 0.0000\n",
      "Epoch: 913, Training loss: 1.380192, Validation loss: 1.3768, lr: 0.0000\n",
      "Epoch: 914, Training loss: 1.390782, Validation loss: 1.3706, lr: 0.0000\n",
      "Epoch: 915, Training loss: 1.360120, Validation loss: 1.3767, lr: 0.0000\n",
      "Epoch: 916, Training loss: 1.382538, Validation loss: 1.3623, lr: 0.0000\n",
      "Epoch: 917, Training loss: 1.375453, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 918, Training loss: 1.380385, Validation loss: 1.3742, lr: 0.0000\n",
      "Epoch: 919, Training loss: 1.371319, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 920, Training loss: 1.357223, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 921, Training loss: 1.384500, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 922, Training loss: 1.449258, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 923, Training loss: 1.397542, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 924, Training loss: 1.437323, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 925, Training loss: 1.399463, Validation loss: 1.3875, lr: 0.0000\n",
      "Epoch: 926, Training loss: 1.385605, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 927, Training loss: 1.372198, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 928, Training loss: 1.388621, Validation loss: 1.3731, lr: 0.0000\n",
      "Epoch: 929, Training loss: 1.384671, Validation loss: 1.3629, lr: 0.0000\n",
      "Epoch: 930, Training loss: 1.387647, Validation loss: 1.4000, lr: 0.0000\n",
      "Epoch: 931, Training loss: 1.410258, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 932, Training loss: 1.374495, Validation loss: 1.3629, lr: 0.0000\n",
      "Epoch: 933, Training loss: 1.390363, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 934, Training loss: 1.372879, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 935, Training loss: 1.383414, Validation loss: 1.3882, lr: 0.0000\n",
      "Epoch: 936, Training loss: 1.389569, Validation loss: 1.4239, lr: 0.0000\n",
      "Epoch: 937, Training loss: 1.381990, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 938, Training loss: 1.368838, Validation loss: 1.3624, lr: 0.0000\n",
      "Epoch: 939, Training loss: 1.390235, Validation loss: 1.3885, lr: 0.0000\n",
      "Epoch: 940, Training loss: 1.384278, Validation loss: 1.3772, lr: 0.0000\n",
      "Epoch: 941, Training loss: 1.385947, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 942, Training loss: 1.368180, Validation loss: 1.3539, lr: 0.0000\n",
      "Epoch: 943, Training loss: 1.385524, Validation loss: 1.3897, lr: 0.0000\n",
      "Epoch: 944, Training loss: 1.356723, Validation loss: 1.3891, lr: 0.0000\n",
      "Epoch: 945, Training loss: 1.363698, Validation loss: 1.3933, lr: 0.0000\n",
      "Epoch: 946, Training loss: 1.381978, Validation loss: 1.6621, lr: 0.0000\n",
      "Epoch: 947, Training loss: 1.393324, Validation loss: 1.3901, lr: 0.0000\n",
      "Epoch: 948, Training loss: 1.368410, Validation loss: 1.3875, lr: 0.0000\n",
      "Epoch: 949, Training loss: 1.351928, Validation loss: 1.3729, lr: 0.0000\n",
      "Epoch: 950, Training loss: 1.379756, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 951, Training loss: 1.371061, Validation loss: 1.3751, lr: 0.0000\n",
      "Epoch: 952, Training loss: 1.406745, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 953, Training loss: 1.393210, Validation loss: 1.3792, lr: 0.0000\n",
      "Epoch: 954, Training loss: 1.429889, Validation loss: 1.3772, lr: 0.0000\n",
      "Epoch: 955, Training loss: 1.388048, Validation loss: 1.3692, lr: 0.0000\n",
      "Epoch: 956, Training loss: 1.392070, Validation loss: 1.3714, lr: 0.0000\n",
      "Epoch: 957, Training loss: 1.379160, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 958, Training loss: 1.366114, Validation loss: 1.3896, lr: 0.0000\n",
      "Epoch: 959, Training loss: 1.440010, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 960, Training loss: 1.366034, Validation loss: 1.4231, lr: 0.0000\n",
      "Epoch: 961, Training loss: 1.397117, Validation loss: 1.3692, lr: 0.0000\n",
      "Epoch: 962, Training loss: 1.365631, Validation loss: 1.3594, lr: 0.0000\n",
      "Epoch: 963, Training loss: 1.357220, Validation loss: 1.3530, lr: 0.0000\n",
      "Epoch: 964, Training loss: 1.366561, Validation loss: 1.3876, lr: 0.0000\n",
      "Epoch: 965, Training loss: 1.378316, Validation loss: 1.3874, lr: 0.0000\n",
      "Epoch: 966, Training loss: 1.382351, Validation loss: 1.3786, lr: 0.0000\n",
      "Epoch: 967, Training loss: 1.368819, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 968, Training loss: 1.373082, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 969, Training loss: 1.344148, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 970, Training loss: 1.391818, Validation loss: 1.3784, lr: 0.0000\n",
      "Epoch: 971, Training loss: 1.392058, Validation loss: 1.4493, lr: 0.0000\n",
      "Epoch: 972, Training loss: 1.395259, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 973, Training loss: 1.354740, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 974, Training loss: 1.443564, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 975, Training loss: 1.372504, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 976, Training loss: 1.384017, Validation loss: 1.3742, lr: 0.0000\n",
      "Epoch: 977, Training loss: 1.403274, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 978, Training loss: 1.373115, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 979, Training loss: 1.368293, Validation loss: 1.3792, lr: 0.0000\n",
      "Epoch: 980, Training loss: 1.391455, Validation loss: 1.3995, lr: 0.0000\n",
      "Epoch: 981, Training loss: 1.383947, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 982, Training loss: 1.378262, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 983, Training loss: 1.383299, Validation loss: 1.3779, lr: 0.0000\n",
      "Epoch: 984, Training loss: 1.374573, Validation loss: 1.3663, lr: 0.0000\n",
      "Epoch: 985, Training loss: 1.383923, Validation loss: 1.4019, lr: 0.0000\n",
      "Epoch: 986, Training loss: 1.371243, Validation loss: 1.3795, lr: 0.0000\n",
      "Epoch: 987, Training loss: 1.374573, Validation loss: 1.3755, lr: 0.0000\n",
      "Epoch: 988, Training loss: 1.391423, Validation loss: 1.3737, lr: 0.0000\n",
      "Epoch: 989, Training loss: 1.381117, Validation loss: 1.3887, lr: 0.0000\n",
      "Epoch: 990, Training loss: 1.365581, Validation loss: 1.3894, lr: 0.0000\n",
      "Epoch: 991, Training loss: 1.380968, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 992, Training loss: 1.369291, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 993, Training loss: 1.376388, Validation loss: 1.3657, lr: 0.0000\n",
      "Epoch: 994, Training loss: 1.392046, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 995, Training loss: 1.393289, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 996, Training loss: 1.374546, Validation loss: 1.3943, lr: 0.0000\n",
      "Epoch: 997, Training loss: 1.454371, Validation loss: 1.3793, lr: 0.0000\n",
      "Epoch: 998, Training loss: 1.360077, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 999, Training loss: 1.368548, Validation loss: 1.3849, lr: 0.0000\n",
      "Final test loss: 1.3930\n",
      "=== Run 10/10 ===\n",
      "\n",
      "---- Settings: \n",
      "\n",
      "epochs : 1000\n",
      "hidden_channels : [32]\n",
      "out_channels : 10\n",
      "inner_product_features : False\n",
      "batch_size : 64\n",
      "lr : 0.01\n",
      "momentum : 0.9\n",
      "dropout : 0.0\n",
      "batch_norm : batch_norm\n",
      "bias : True\n",
      "order : 2\n",
      "diffusion : True\n",
      "frac_sampled_nb : -1\n",
      "include_positions : False\n",
      "include_self : True\n",
      "vec_norm : False\n",
      "emb_norm : False\n",
      "seed : 0\n",
      "dim_signal : 100\n",
      "dim_emb : 100\n",
      "n_sampled_nb : -1\n",
      "\n",
      "---- Number of features to pass to the MLP:  1010100\n",
      "---- Total number of parameters:  32323627\n",
      "\n",
      "Using device cuda:0\n",
      "\n",
      "---- Training network ...\n",
      "\n",
      "---- Timestamp: 20250614-182451\n",
      "\n",
      " *och: 0, Training loss: 1.574291, Validation loss: 1.3603, lr: 0.0100\n",
      "Epoch: 1, Training loss: 1.394976, Validation loss: 1.3719, lr: 0.0100\n",
      "Epoch: 2, Training loss: 1.371138, Validation loss: 1.3681, lr: 0.0100\n",
      "Epoch: 3, Training loss: 1.368883, Validation loss: 1.5815, lr: 0.0100\n",
      "Epoch: 4, Training loss: 1.381719, Validation loss: 1.3697, lr: 0.0100\n",
      "Epoch: 5, Training loss: 1.379715, Validation loss: 1.3647, lr: 0.0100\n",
      "Epoch: 6, Training loss: 1.402395, Validation loss: 1.3705, lr: 0.0100\n",
      "Epoch: 7, Training loss: 1.387970, Validation loss: 1.4196, lr: 0.0100\n",
      "Epoch: 8, Training loss: 1.417790, Validation loss: 1.3649, lr: 0.0100\n",
      "Epoch: 9, Training loss: 1.393347, Validation loss: 1.3851, lr: 0.0100\n",
      "Epoch: 10, Training loss: 1.403845, Validation loss: 1.3855, lr: 0.0100\n",
      "Epoch: 11, Training loss: 1.375329, Validation loss: 1.3708, lr: 0.0100\n",
      "Epoch: 12, Training loss: 1.385468, Validation loss: 1.3892, lr: 0.0100\n",
      "Epoch: 13, Training loss: 1.402304, Validation loss: 1.3984, lr: 0.0100\n",
      "Epoch: 14, Training loss: 1.415456, Validation loss: 1.3774, lr: 0.0010\n",
      "Epoch: 15, Training loss: 1.356692, Validation loss: 1.3693, lr: 0.0010\n",
      "Epoch: 16, Training loss: 1.397876, Validation loss: 1.3797, lr: 0.0010\n",
      "Epoch: 17, Training loss: 1.361627, Validation loss: 1.3795, lr: 0.0010\n",
      "Epoch: 18, Training loss: 1.378872, Validation loss: 1.3843, lr: 0.0010\n",
      "Epoch: 19, Training loss: 1.361269, Validation loss: 1.3872, lr: 0.0010\n",
      "Epoch: 20, Training loss: 1.359616, Validation loss: 1.3798, lr: 0.0010\n",
      "Epoch: 21, Training loss: 1.426082, Validation loss: 1.3650, lr: 0.0010\n",
      "Epoch: 22, Training loss: 1.380420, Validation loss: 1.3817, lr: 0.0010\n",
      "Epoch: 23, Training loss: 1.384543, Validation loss: 1.3804, lr: 0.0010\n",
      "Epoch: 24, Training loss: 1.380747, Validation loss: 1.3742, lr: 0.0010\n",
      " *och: 25, Training loss: 1.390370, Validation loss: 1.3480, lr: 0.0010\n",
      "Epoch: 26, Training loss: 1.393080, Validation loss: 1.3868, lr: 0.0001\n",
      "Epoch: 27, Training loss: 1.370402, Validation loss: 1.3877, lr: 0.0001\n",
      "Epoch: 28, Training loss: 1.363534, Validation loss: 1.3830, lr: 0.0001\n",
      "Epoch: 29, Training loss: 1.373516, Validation loss: 1.3882, lr: 0.0001\n",
      "Epoch: 30, Training loss: 1.373997, Validation loss: 1.3806, lr: 0.0001\n",
      "Epoch: 31, Training loss: 1.366534, Validation loss: 1.3851, lr: 0.0001\n",
      "Epoch: 32, Training loss: 1.376341, Validation loss: 1.3852, lr: 0.0001\n",
      "Epoch: 33, Training loss: 1.420636, Validation loss: 1.4241, lr: 0.0001\n",
      "Epoch: 34, Training loss: 1.390672, Validation loss: 1.3785, lr: 0.0001\n",
      "Epoch: 35, Training loss: 1.371067, Validation loss: 1.3967, lr: 0.0001\n",
      "Epoch: 36, Training loss: 1.371212, Validation loss: 1.3823, lr: 0.0001\n",
      "Epoch: 37, Training loss: 1.405198, Validation loss: 1.3659, lr: 0.0000\n",
      "Epoch: 38, Training loss: 1.396014, Validation loss: 1.3657, lr: 0.0000\n",
      "Epoch: 39, Training loss: 1.374376, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 40, Training loss: 1.377054, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 41, Training loss: 1.367950, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 42, Training loss: 1.408669, Validation loss: 1.3777, lr: 0.0000\n",
      "Epoch: 43, Training loss: 1.353774, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 44, Training loss: 1.378614, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 45, Training loss: 1.378155, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 46, Training loss: 1.372657, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 47, Training loss: 1.370356, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 48, Training loss: 1.431423, Validation loss: 1.3899, lr: 0.0000\n",
      "Epoch: 49, Training loss: 1.367705, Validation loss: 1.3893, lr: 0.0000\n",
      "Epoch: 50, Training loss: 1.343247, Validation loss: 1.3900, lr: 0.0000\n",
      "Epoch: 51, Training loss: 1.377940, Validation loss: 1.3893, lr: 0.0000\n",
      "Epoch: 52, Training loss: 1.388102, Validation loss: 1.3708, lr: 0.0000\n",
      "Epoch: 53, Training loss: 1.402348, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 54, Training loss: 1.378517, Validation loss: 1.3629, lr: 0.0000\n",
      "Epoch: 55, Training loss: 1.361419, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 56, Training loss: 1.382452, Validation loss: 1.3876, lr: 0.0000\n",
      "Epoch: 57, Training loss: 1.371184, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 58, Training loss: 1.395163, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 59, Training loss: 1.388182, Validation loss: 1.3960, lr: 0.0000\n",
      "Epoch: 60, Training loss: 1.377958, Validation loss: 1.3731, lr: 0.0000\n",
      "Epoch: 61, Training loss: 1.357144, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 62, Training loss: 1.380722, Validation loss: 1.3743, lr: 0.0000\n",
      "Epoch: 63, Training loss: 1.357768, Validation loss: 1.4282, lr: 0.0000\n",
      "Epoch: 64, Training loss: 1.377358, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 65, Training loss: 1.371939, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 66, Training loss: 1.402744, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 67, Training loss: 1.373687, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 68, Training loss: 1.373211, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 69, Training loss: 1.384070, Validation loss: 1.3871, lr: 0.0000\n",
      "Epoch: 70, Training loss: 1.403545, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 71, Training loss: 1.367277, Validation loss: 1.3954, lr: 0.0000\n",
      "Epoch: 72, Training loss: 1.385594, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 73, Training loss: 1.368016, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 74, Training loss: 1.379135, Validation loss: 1.3785, lr: 0.0000\n",
      "Epoch: 75, Training loss: 1.381263, Validation loss: 1.3693, lr: 0.0000\n",
      "Epoch: 76, Training loss: 1.392444, Validation loss: 1.3786, lr: 0.0000\n",
      "Epoch: 77, Training loss: 1.381834, Validation loss: 1.3763, lr: 0.0000\n",
      "Epoch: 78, Training loss: 1.383399, Validation loss: 1.3794, lr: 0.0000\n",
      "Epoch: 79, Training loss: 1.369080, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 80, Training loss: 1.371478, Validation loss: 1.3876, lr: 0.0000\n",
      "Epoch: 81, Training loss: 1.371563, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 82, Training loss: 1.390226, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 83, Training loss: 1.418935, Validation loss: 1.3906, lr: 0.0000\n",
      "Epoch: 84, Training loss: 1.364187, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 85, Training loss: 1.369639, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 86, Training loss: 1.389046, Validation loss: 1.3787, lr: 0.0000\n",
      "Epoch: 87, Training loss: 1.356519, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 88, Training loss: 1.363796, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 89, Training loss: 1.370271, Validation loss: 1.3797, lr: 0.0000\n",
      "Epoch: 90, Training loss: 1.357269, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 91, Training loss: 1.375848, Validation loss: 1.3701, lr: 0.0000\n",
      "Epoch: 92, Training loss: 1.389027, Validation loss: 1.3873, lr: 0.0000\n",
      "Epoch: 93, Training loss: 1.358108, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 94, Training loss: 1.412515, Validation loss: 1.3586, lr: 0.0000\n",
      "Epoch: 95, Training loss: 1.368938, Validation loss: 1.3917, lr: 0.0000\n",
      "Epoch: 96, Training loss: 1.390989, Validation loss: 1.3637, lr: 0.0000\n",
      "Epoch: 97, Training loss: 1.370967, Validation loss: 1.3706, lr: 0.0000\n",
      "Epoch: 98, Training loss: 1.388185, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 99, Training loss: 1.369605, Validation loss: 1.3779, lr: 0.0000\n",
      "Epoch: 100, Training loss: 1.367812, Validation loss: 1.3875, lr: 0.0000\n",
      "Epoch: 101, Training loss: 1.366071, Validation loss: 1.3688, lr: 0.0000\n",
      "Epoch: 102, Training loss: 1.380369, Validation loss: 1.3790, lr: 0.0000\n",
      "Epoch: 103, Training loss: 1.375720, Validation loss: 1.3792, lr: 0.0000\n",
      "Epoch: 104, Training loss: 1.362461, Validation loss: 1.3882, lr: 0.0000\n",
      "Epoch: 105, Training loss: 1.375757, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 106, Training loss: 1.372822, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 107, Training loss: 1.369940, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 108, Training loss: 1.356310, Validation loss: 1.3917, lr: 0.0000\n",
      "Epoch: 109, Training loss: 1.404797, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 110, Training loss: 1.375251, Validation loss: 1.3742, lr: 0.0000\n",
      "Epoch: 111, Training loss: 1.392180, Validation loss: 1.3901, lr: 0.0000\n",
      "Epoch: 112, Training loss: 1.376625, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 113, Training loss: 1.369828, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 114, Training loss: 1.381398, Validation loss: 1.3710, lr: 0.0000\n",
      "Epoch: 115, Training loss: 1.372407, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 116, Training loss: 1.361946, Validation loss: 1.4049, lr: 0.0000\n",
      "Epoch: 117, Training loss: 1.387298, Validation loss: 1.3894, lr: 0.0000\n",
      "Epoch: 118, Training loss: 1.363735, Validation loss: 1.3790, lr: 0.0000\n",
      "Epoch: 119, Training loss: 1.358644, Validation loss: 1.3904, lr: 0.0000\n",
      "Epoch: 120, Training loss: 1.367969, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 121, Training loss: 1.388438, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 122, Training loss: 1.387067, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 123, Training loss: 1.388516, Validation loss: 1.3880, lr: 0.0000\n",
      "Epoch: 124, Training loss: 1.379044, Validation loss: 1.3513, lr: 0.0000\n",
      "Epoch: 125, Training loss: 1.353833, Validation loss: 1.3701, lr: 0.0000\n",
      "Epoch: 126, Training loss: 1.369643, Validation loss: 1.3999, lr: 0.0000\n",
      "Epoch: 127, Training loss: 1.354029, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 128, Training loss: 1.367223, Validation loss: 1.3651, lr: 0.0000\n",
      "Epoch: 129, Training loss: 1.373103, Validation loss: 1.3894, lr: 0.0000\n",
      "Epoch: 130, Training loss: 1.368770, Validation loss: 1.3897, lr: 0.0000\n",
      "Epoch: 131, Training loss: 1.383105, Validation loss: 1.3890, lr: 0.0000\n",
      "Epoch: 132, Training loss: 1.384661, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 133, Training loss: 1.365707, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 134, Training loss: 1.356248, Validation loss: 1.3797, lr: 0.0000\n",
      "Epoch: 135, Training loss: 1.364763, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 136, Training loss: 1.374541, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 137, Training loss: 1.377356, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 138, Training loss: 1.393284, Validation loss: 1.3876, lr: 0.0000\n",
      "Epoch: 139, Training loss: 1.376282, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 140, Training loss: 1.394260, Validation loss: 1.3893, lr: 0.0000\n",
      "Epoch: 141, Training loss: 1.400255, Validation loss: 1.3893, lr: 0.0000\n",
      "Epoch: 142, Training loss: 1.379108, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 143, Training loss: 1.370134, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 144, Training loss: 1.352590, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 145, Training loss: 1.384735, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 146, Training loss: 1.383963, Validation loss: 1.3789, lr: 0.0000\n",
      "Epoch: 147, Training loss: 1.382451, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 148, Training loss: 1.362528, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 149, Training loss: 1.420261, Validation loss: 1.3950, lr: 0.0000\n",
      "Epoch: 150, Training loss: 1.385633, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 151, Training loss: 1.365516, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 152, Training loss: 1.377052, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 153, Training loss: 1.373471, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 154, Training loss: 1.389523, Validation loss: 1.3789, lr: 0.0000\n",
      "Epoch: 155, Training loss: 1.394382, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 156, Training loss: 1.356901, Validation loss: 1.3745, lr: 0.0000\n",
      "Epoch: 157, Training loss: 1.371361, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 158, Training loss: 1.369863, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 159, Training loss: 1.378649, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 160, Training loss: 1.387049, Validation loss: 1.4615, lr: 0.0000\n",
      "Epoch: 161, Training loss: 1.368950, Validation loss: 1.3773, lr: 0.0000\n",
      "Epoch: 162, Training loss: 1.385673, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 163, Training loss: 1.383233, Validation loss: 1.4043, lr: 0.0000\n",
      "Epoch: 164, Training loss: 1.362247, Validation loss: 1.3738, lr: 0.0000\n",
      "Epoch: 165, Training loss: 1.377128, Validation loss: 1.3677, lr: 0.0000\n",
      "Epoch: 166, Training loss: 1.378803, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 167, Training loss: 1.364210, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 168, Training loss: 1.370927, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 169, Training loss: 1.415468, Validation loss: 1.3629, lr: 0.0000\n",
      "Epoch: 170, Training loss: 1.397848, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 171, Training loss: 1.378979, Validation loss: 1.3782, lr: 0.0000\n",
      "Epoch: 172, Training loss: 1.370986, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 173, Training loss: 1.366497, Validation loss: 1.3703, lr: 0.0000\n",
      "Epoch: 174, Training loss: 1.412800, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 175, Training loss: 1.407318, Validation loss: 1.3913, lr: 0.0000\n",
      "Epoch: 176, Training loss: 1.383770, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 177, Training loss: 1.364207, Validation loss: 1.3754, lr: 0.0000\n",
      "Epoch: 178, Training loss: 1.380695, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 179, Training loss: 1.354744, Validation loss: 1.3917, lr: 0.0000\n",
      "Epoch: 180, Training loss: 1.373634, Validation loss: 1.3911, lr: 0.0000\n",
      "Epoch: 181, Training loss: 1.354183, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 182, Training loss: 1.385365, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 183, Training loss: 1.361718, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 184, Training loss: 1.376059, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 185, Training loss: 1.376446, Validation loss: 1.3717, lr: 0.0000\n",
      "Epoch: 186, Training loss: 1.366857, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 187, Training loss: 1.379030, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 188, Training loss: 1.379628, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 189, Training loss: 1.384995, Validation loss: 1.3787, lr: 0.0000\n",
      "Epoch: 190, Training loss: 1.368275, Validation loss: 1.3755, lr: 0.0000\n",
      "Epoch: 191, Training loss: 1.370765, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 192, Training loss: 1.389568, Validation loss: 1.3896, lr: 0.0000\n",
      "Epoch: 193, Training loss: 1.388699, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 194, Training loss: 1.378466, Validation loss: 1.3727, lr: 0.0000\n",
      "Epoch: 195, Training loss: 1.391068, Validation loss: 1.3682, lr: 0.0000\n",
      "Epoch: 196, Training loss: 1.380310, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 197, Training loss: 1.367077, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 198, Training loss: 1.356122, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 199, Training loss: 1.385591, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 200, Training loss: 1.375124, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 201, Training loss: 1.365797, Validation loss: 1.3928, lr: 0.0000\n",
      "Epoch: 202, Training loss: 1.368853, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 203, Training loss: 1.356711, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 204, Training loss: 1.372197, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 205, Training loss: 1.416783, Validation loss: 1.5673, lr: 0.0000\n",
      "Epoch: 206, Training loss: 1.370519, Validation loss: 1.3685, lr: 0.0000\n",
      "Epoch: 207, Training loss: 1.350906, Validation loss: 1.3709, lr: 0.0000\n",
      "Epoch: 208, Training loss: 1.371208, Validation loss: 1.3699, lr: 0.0000\n",
      "Epoch: 209, Training loss: 1.375801, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 210, Training loss: 1.354307, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 211, Training loss: 1.363763, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 212, Training loss: 1.381564, Validation loss: 1.3753, lr: 0.0000\n",
      "Epoch: 213, Training loss: 1.364159, Validation loss: 1.3881, lr: 0.0000\n",
      "Epoch: 214, Training loss: 1.421751, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 215, Training loss: 1.384606, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 216, Training loss: 1.380862, Validation loss: 1.3646, lr: 0.0000\n",
      "Epoch: 217, Training loss: 1.379562, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 218, Training loss: 1.379957, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 219, Training loss: 1.382388, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 220, Training loss: 1.382843, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 221, Training loss: 1.365962, Validation loss: 1.3709, lr: 0.0000\n",
      "Epoch: 222, Training loss: 1.395207, Validation loss: 1.3753, lr: 0.0000\n",
      "Epoch: 223, Training loss: 1.427041, Validation loss: 1.3886, lr: 0.0000\n",
      "Epoch: 224, Training loss: 1.388657, Validation loss: 1.3641, lr: 0.0000\n",
      "Epoch: 225, Training loss: 1.363825, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 226, Training loss: 1.383716, Validation loss: 1.3798, lr: 0.0000\n",
      "Epoch: 227, Training loss: 1.387975, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 228, Training loss: 1.389599, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 229, Training loss: 1.377865, Validation loss: 1.3765, lr: 0.0000\n",
      "Epoch: 230, Training loss: 1.357680, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 231, Training loss: 1.380281, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 232, Training loss: 1.372836, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 233, Training loss: 1.404106, Validation loss: 1.3795, lr: 0.0000\n",
      "Epoch: 234, Training loss: 1.360567, Validation loss: 1.3788, lr: 0.0000\n",
      "Epoch: 235, Training loss: 1.380101, Validation loss: 1.3905, lr: 0.0000\n",
      "Epoch: 236, Training loss: 1.375841, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 237, Training loss: 1.367733, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 238, Training loss: 1.377013, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 239, Training loss: 1.418719, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 240, Training loss: 1.392510, Validation loss: 1.4163, lr: 0.0000\n",
      "Epoch: 241, Training loss: 1.390989, Validation loss: 1.3721, lr: 0.0000\n",
      "Epoch: 242, Training loss: 1.378463, Validation loss: 1.3793, lr: 0.0000\n",
      "Epoch: 243, Training loss: 1.374706, Validation loss: 1.4495, lr: 0.0000\n",
      "Epoch: 244, Training loss: 1.375036, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 245, Training loss: 1.359490, Validation loss: 1.3901, lr: 0.0000\n",
      "Epoch: 246, Training loss: 1.380755, Validation loss: 1.3922, lr: 0.0000\n",
      "Epoch: 247, Training loss: 1.370542, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 248, Training loss: 1.368223, Validation loss: 1.3961, lr: 0.0000\n",
      "Epoch: 249, Training loss: 1.394785, Validation loss: 1.3789, lr: 0.0000\n",
      "Epoch: 250, Training loss: 1.361409, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 251, Training loss: 1.368341, Validation loss: 1.3764, lr: 0.0000\n",
      "Epoch: 252, Training loss: 1.374211, Validation loss: 1.3951, lr: 0.0000\n",
      "Epoch: 253, Training loss: 1.392746, Validation loss: 1.3792, lr: 0.0000\n",
      "Epoch: 254, Training loss: 1.398257, Validation loss: 1.3962, lr: 0.0000\n",
      "Epoch: 255, Training loss: 1.378212, Validation loss: 1.3666, lr: 0.0000\n",
      "Epoch: 256, Training loss: 1.373446, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 257, Training loss: 1.410694, Validation loss: 1.3785, lr: 0.0000\n",
      "Epoch: 258, Training loss: 1.359994, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 259, Training loss: 1.384547, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 260, Training loss: 1.383037, Validation loss: 1.4127, lr: 0.0000\n",
      "Epoch: 261, Training loss: 1.355448, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 262, Training loss: 1.389528, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 263, Training loss: 1.373445, Validation loss: 1.3786, lr: 0.0000\n",
      "Epoch: 264, Training loss: 1.384481, Validation loss: 1.3622, lr: 0.0000\n",
      "Epoch: 265, Training loss: 1.387289, Validation loss: 1.3739, lr: 0.0000\n",
      "Epoch: 266, Training loss: 1.381490, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 267, Training loss: 1.384774, Validation loss: 1.3732, lr: 0.0000\n",
      "Epoch: 268, Training loss: 1.374997, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 269, Training loss: 1.369402, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 270, Training loss: 1.377568, Validation loss: 1.3832, lr: 0.0000\n",
      " *och: 271, Training loss: 1.381914, Validation loss: 1.3132, lr: 0.0000\n",
      "Epoch: 272, Training loss: 1.395615, Validation loss: 1.9461, lr: 0.0000\n",
      "Epoch: 273, Training loss: 1.378685, Validation loss: 1.3798, lr: 0.0000\n",
      "Epoch: 274, Training loss: 1.375093, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 275, Training loss: 1.392278, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 276, Training loss: 1.384476, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 277, Training loss: 1.369900, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 278, Training loss: 1.365642, Validation loss: 1.3879, lr: 0.0000\n",
      "Epoch: 279, Training loss: 1.364015, Validation loss: 1.3809, lr: 0.0000\n",
      "Epoch: 280, Training loss: 1.481562, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 281, Training loss: 1.372473, Validation loss: 1.3759, lr: 0.0000\n",
      "Epoch: 282, Training loss: 1.392343, Validation loss: 1.3781, lr: 0.0000\n",
      "Epoch: 283, Training loss: 1.380250, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 284, Training loss: 1.424385, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 285, Training loss: 1.377283, Validation loss: 1.3771, lr: 0.0000\n",
      "Epoch: 286, Training loss: 1.367214, Validation loss: 1.3684, lr: 0.0000\n",
      "Epoch: 287, Training loss: 1.379173, Validation loss: 1.3894, lr: 0.0000\n",
      "Epoch: 288, Training loss: 1.378965, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 289, Training loss: 1.398996, Validation loss: 1.3915, lr: 0.0000\n",
      "Epoch: 290, Training loss: 1.367923, Validation loss: 1.4052, lr: 0.0000\n",
      "Epoch: 291, Training loss: 1.404798, Validation loss: 1.3685, lr: 0.0000\n",
      "Epoch: 292, Training loss: 1.368633, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 293, Training loss: 1.381317, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 294, Training loss: 1.374151, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 295, Training loss: 1.367563, Validation loss: 1.3876, lr: 0.0000\n",
      "Epoch: 296, Training loss: 1.369697, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 297, Training loss: 1.372508, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 298, Training loss: 1.378154, Validation loss: 1.3788, lr: 0.0000\n",
      "Epoch: 299, Training loss: 1.376989, Validation loss: 1.3800, lr: 0.0000\n",
      "Epoch: 300, Training loss: 1.386240, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 301, Training loss: 1.367138, Validation loss: 1.3922, lr: 0.0000\n",
      "Epoch: 302, Training loss: 1.385529, Validation loss: 1.3879, lr: 0.0000\n",
      "Epoch: 303, Training loss: 1.398530, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 304, Training loss: 1.375740, Validation loss: 1.3671, lr: 0.0000\n",
      "Epoch: 305, Training loss: 1.378803, Validation loss: 1.3631, lr: 0.0000\n",
      "Epoch: 306, Training loss: 1.383872, Validation loss: 1.3686, lr: 0.0000\n",
      "Epoch: 307, Training loss: 1.386385, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 308, Training loss: 1.362965, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 309, Training loss: 1.376729, Validation loss: 1.3769, lr: 0.0000\n",
      "Epoch: 310, Training loss: 1.371496, Validation loss: 1.3974, lr: 0.0000\n",
      "Epoch: 311, Training loss: 1.372844, Validation loss: 1.3916, lr: 0.0000\n",
      "Epoch: 312, Training loss: 1.371759, Validation loss: 1.3883, lr: 0.0000\n",
      "Epoch: 313, Training loss: 1.386491, Validation loss: 1.3886, lr: 0.0000\n",
      "Epoch: 314, Training loss: 1.388888, Validation loss: 1.3724, lr: 0.0000\n",
      "Epoch: 315, Training loss: 1.365686, Validation loss: 1.3890, lr: 0.0000\n",
      "Epoch: 316, Training loss: 1.364242, Validation loss: 1.4161, lr: 0.0000\n",
      "Epoch: 317, Training loss: 1.381836, Validation loss: 1.3904, lr: 0.0000\n",
      "Epoch: 318, Training loss: 1.374711, Validation loss: 1.3873, lr: 0.0000\n",
      "Epoch: 319, Training loss: 1.378383, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 320, Training loss: 1.394514, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 321, Training loss: 1.376559, Validation loss: 1.3736, lr: 0.0000\n",
      "Epoch: 322, Training loss: 1.370753, Validation loss: 1.3751, lr: 0.0000\n",
      "Epoch: 323, Training loss: 1.516423, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 324, Training loss: 1.372297, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 325, Training loss: 1.414239, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 326, Training loss: 1.383812, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 327, Training loss: 1.373092, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 328, Training loss: 1.372708, Validation loss: 1.3935, lr: 0.0000\n",
      "Epoch: 329, Training loss: 1.368066, Validation loss: 1.3981, lr: 0.0000\n",
      "Epoch: 330, Training loss: 1.389877, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 331, Training loss: 1.388878, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 332, Training loss: 1.401489, Validation loss: 1.3900, lr: 0.0000\n",
      "Epoch: 333, Training loss: 1.371846, Validation loss: 1.3926, lr: 0.0000\n",
      "Epoch: 334, Training loss: 1.374255, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 335, Training loss: 1.379395, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 336, Training loss: 1.375864, Validation loss: 1.3949, lr: 0.0000\n",
      "Epoch: 337, Training loss: 1.369055, Validation loss: 1.3938, lr: 0.0000\n",
      "Epoch: 338, Training loss: 1.383355, Validation loss: 1.4063, lr: 0.0000\n",
      "Epoch: 339, Training loss: 1.381711, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 340, Training loss: 1.371890, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 341, Training loss: 1.402520, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 342, Training loss: 1.368645, Validation loss: 1.3774, lr: 0.0000\n",
      "Epoch: 343, Training loss: 1.381974, Validation loss: 1.3659, lr: 0.0000\n",
      "Epoch: 344, Training loss: 1.384732, Validation loss: 1.3803, lr: 0.0000\n",
      "Epoch: 345, Training loss: 1.369978, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 346, Training loss: 1.362973, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 347, Training loss: 1.369812, Validation loss: 1.3912, lr: 0.0000\n",
      "Epoch: 348, Training loss: 1.379205, Validation loss: 1.3878, lr: 0.0000\n",
      "Epoch: 349, Training loss: 1.383356, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 350, Training loss: 1.385396, Validation loss: 1.3778, lr: 0.0000\n",
      "Epoch: 351, Training loss: 1.360726, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 352, Training loss: 1.383151, Validation loss: 1.3679, lr: 0.0000\n",
      "Epoch: 353, Training loss: 1.368359, Validation loss: 1.3670, lr: 0.0000\n",
      "Epoch: 354, Training loss: 1.371189, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 355, Training loss: 1.381650, Validation loss: 1.3890, lr: 0.0000\n",
      "Epoch: 356, Training loss: 1.361638, Validation loss: 1.3335, lr: 0.0000\n",
      "Epoch: 357, Training loss: 1.364542, Validation loss: 1.3888, lr: 0.0000\n",
      "Epoch: 358, Training loss: 1.386630, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 359, Training loss: 1.382381, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 360, Training loss: 1.370793, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 361, Training loss: 1.388915, Validation loss: 1.5620, lr: 0.0000\n",
      "Epoch: 362, Training loss: 1.397631, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 363, Training loss: 1.398730, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 364, Training loss: 1.382395, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 365, Training loss: 1.378107, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 366, Training loss: 1.387121, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 367, Training loss: 1.360516, Validation loss: 1.3778, lr: 0.0000\n",
      "Epoch: 368, Training loss: 1.387290, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 369, Training loss: 1.367784, Validation loss: 1.3668, lr: 0.0000\n",
      "Epoch: 370, Training loss: 1.382130, Validation loss: 1.3792, lr: 0.0000\n",
      "Epoch: 371, Training loss: 1.394540, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 372, Training loss: 1.387288, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 373, Training loss: 1.363542, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 374, Training loss: 1.392957, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 375, Training loss: 1.374821, Validation loss: 1.3667, lr: 0.0000\n",
      "Epoch: 376, Training loss: 1.383787, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 377, Training loss: 1.379654, Validation loss: 1.3646, lr: 0.0000\n",
      "Epoch: 378, Training loss: 1.364840, Validation loss: 1.3666, lr: 0.0000\n",
      "Epoch: 379, Training loss: 1.370727, Validation loss: 1.3729, lr: 0.0000\n",
      "Epoch: 380, Training loss: 1.428491, Validation loss: 1.3754, lr: 0.0000\n",
      "Epoch: 381, Training loss: 1.459652, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 382, Training loss: 1.372051, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 383, Training loss: 1.395272, Validation loss: 1.3718, lr: 0.0000\n",
      "Epoch: 384, Training loss: 1.383716, Validation loss: 1.3787, lr: 0.0000\n",
      "Epoch: 385, Training loss: 1.385759, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 386, Training loss: 1.369860, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 387, Training loss: 1.350902, Validation loss: 1.4048, lr: 0.0000\n",
      "Epoch: 388, Training loss: 1.370774, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 389, Training loss: 1.399096, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 390, Training loss: 1.369158, Validation loss: 1.3770, lr: 0.0000\n",
      "Epoch: 391, Training loss: 1.377320, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 392, Training loss: 1.363036, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 393, Training loss: 1.407763, Validation loss: 1.4087, lr: 0.0000\n",
      "Epoch: 394, Training loss: 1.356527, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 395, Training loss: 1.355864, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 396, Training loss: 1.375264, Validation loss: 1.3974, lr: 0.0000\n",
      "Epoch: 397, Training loss: 1.360215, Validation loss: 1.3680, lr: 0.0000\n",
      "Epoch: 398, Training loss: 1.371804, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 399, Training loss: 1.368567, Validation loss: 1.3809, lr: 0.0000\n",
      "Epoch: 400, Training loss: 1.379928, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 401, Training loss: 1.360314, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 402, Training loss: 1.371420, Validation loss: 1.3651, lr: 0.0000\n",
      "Epoch: 403, Training loss: 1.371450, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 404, Training loss: 1.389445, Validation loss: 1.3778, lr: 0.0000\n",
      "Epoch: 405, Training loss: 1.398211, Validation loss: 1.3873, lr: 0.0000\n",
      "Epoch: 406, Training loss: 1.380549, Validation loss: 1.3773, lr: 0.0000\n",
      "Epoch: 407, Training loss: 1.367962, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 408, Training loss: 1.370364, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 409, Training loss: 1.382163, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 410, Training loss: 1.373794, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 411, Training loss: 1.362547, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 412, Training loss: 1.375570, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 413, Training loss: 1.380597, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 414, Training loss: 1.374463, Validation loss: 1.3880, lr: 0.0000\n",
      "Epoch: 415, Training loss: 1.368771, Validation loss: 1.3895, lr: 0.0000\n",
      "Epoch: 416, Training loss: 1.371539, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 417, Training loss: 1.370821, Validation loss: 1.3981, lr: 0.0000\n",
      "Epoch: 418, Training loss: 1.385564, Validation loss: 1.4089, lr: 0.0000\n",
      "Epoch: 419, Training loss: 1.377027, Validation loss: 1.3779, lr: 0.0000\n",
      "Epoch: 420, Training loss: 1.386185, Validation loss: 1.3956, lr: 0.0000\n",
      "Epoch: 421, Training loss: 1.385850, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 422, Training loss: 1.371378, Validation loss: 1.3780, lr: 0.0000\n",
      "Epoch: 423, Training loss: 1.390550, Validation loss: 1.3900, lr: 0.0000\n",
      "Epoch: 424, Training loss: 1.389775, Validation loss: 1.3911, lr: 0.0000\n",
      "Epoch: 425, Training loss: 1.372475, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 426, Training loss: 1.372939, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 427, Training loss: 1.381835, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 428, Training loss: 1.355507, Validation loss: 1.3791, lr: 0.0000\n",
      "Epoch: 429, Training loss: 1.374692, Validation loss: 1.3872, lr: 0.0000\n",
      "Epoch: 430, Training loss: 1.385119, Validation loss: 1.3794, lr: 0.0000\n",
      "Epoch: 431, Training loss: 1.393631, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 432, Training loss: 1.374868, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 433, Training loss: 1.380763, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 434, Training loss: 1.377417, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 435, Training loss: 1.360985, Validation loss: 1.3796, lr: 0.0000\n",
      "Epoch: 436, Training loss: 1.383878, Validation loss: 1.3887, lr: 0.0000\n",
      "Epoch: 437, Training loss: 1.370368, Validation loss: 1.3752, lr: 0.0000\n",
      "Epoch: 438, Training loss: 1.373276, Validation loss: 1.3890, lr: 0.0000\n",
      "Epoch: 439, Training loss: 1.378246, Validation loss: 1.3724, lr: 0.0000\n",
      "Epoch: 440, Training loss: 1.364811, Validation loss: 1.3890, lr: 0.0000\n",
      "Epoch: 441, Training loss: 1.378205, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 442, Training loss: 1.384031, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 443, Training loss: 1.403948, Validation loss: 1.3780, lr: 0.0000\n",
      "Epoch: 444, Training loss: 1.373778, Validation loss: 1.3876, lr: 0.0000\n",
      "Epoch: 445, Training loss: 1.389673, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 446, Training loss: 1.384877, Validation loss: 1.3731, lr: 0.0000\n",
      "Epoch: 447, Training loss: 1.361934, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 448, Training loss: 1.355089, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 449, Training loss: 1.394276, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 450, Training loss: 1.377505, Validation loss: 2.7592, lr: 0.0000\n",
      "Epoch: 451, Training loss: 1.379575, Validation loss: 1.3790, lr: 0.0000\n",
      "Epoch: 452, Training loss: 1.350202, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 453, Training loss: 1.384210, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 454, Training loss: 1.377002, Validation loss: 1.3773, lr: 0.0000\n",
      "Epoch: 455, Training loss: 1.369811, Validation loss: 1.3713, lr: 0.0000\n",
      "Epoch: 456, Training loss: 1.387666, Validation loss: 1.3784, lr: 0.0000\n",
      "Epoch: 457, Training loss: 1.374310, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 458, Training loss: 1.357636, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 459, Training loss: 1.378696, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 460, Training loss: 1.387442, Validation loss: 1.3793, lr: 0.0000\n",
      "Epoch: 461, Training loss: 1.366047, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 462, Training loss: 1.423013, Validation loss: 1.3789, lr: 0.0000\n",
      "Epoch: 463, Training loss: 1.371796, Validation loss: 1.4159, lr: 0.0000\n",
      "Epoch: 464, Training loss: 1.367824, Validation loss: 1.3724, lr: 0.0000\n",
      "Epoch: 465, Training loss: 1.386857, Validation loss: 1.3759, lr: 0.0000\n",
      "Epoch: 466, Training loss: 1.383423, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 467, Training loss: 1.377719, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 468, Training loss: 1.365204, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 469, Training loss: 1.402632, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 470, Training loss: 1.377519, Validation loss: 1.3754, lr: 0.0000\n",
      "Epoch: 471, Training loss: 1.363852, Validation loss: 1.3904, lr: 0.0000\n",
      "Epoch: 472, Training loss: 1.407225, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 473, Training loss: 1.388114, Validation loss: 1.3796, lr: 0.0000\n",
      "Epoch: 474, Training loss: 1.378576, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 475, Training loss: 1.396590, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 476, Training loss: 1.389994, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 477, Training loss: 1.377265, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 478, Training loss: 1.391701, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 479, Training loss: 1.380272, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 480, Training loss: 1.374701, Validation loss: 1.3871, lr: 0.0000\n",
      "Epoch: 481, Training loss: 1.376891, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 482, Training loss: 1.373063, Validation loss: 1.3879, lr: 0.0000\n",
      "Epoch: 483, Training loss: 1.379152, Validation loss: 1.3580, lr: 0.0000\n",
      "Epoch: 484, Training loss: 1.393818, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 485, Training loss: 1.388719, Validation loss: 1.3926, lr: 0.0000\n",
      "Epoch: 486, Training loss: 1.373591, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 487, Training loss: 1.377782, Validation loss: 1.3890, lr: 0.0000\n",
      "Epoch: 488, Training loss: 1.382071, Validation loss: 1.3527, lr: 0.0000\n",
      "Epoch: 489, Training loss: 1.363002, Validation loss: 1.4020, lr: 0.0000\n",
      "Epoch: 490, Training loss: 1.374699, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 491, Training loss: 1.377404, Validation loss: 1.4145, lr: 0.0000\n",
      "Epoch: 492, Training loss: 1.374338, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 493, Training loss: 1.384526, Validation loss: 1.3875, lr: 0.0000\n",
      "Epoch: 494, Training loss: 1.378734, Validation loss: 1.3969, lr: 0.0000\n",
      "Epoch: 495, Training loss: 1.373278, Validation loss: 1.3879, lr: 0.0000\n",
      "Epoch: 496, Training loss: 1.381629, Validation loss: 1.3754, lr: 0.0000\n",
      "Epoch: 497, Training loss: 1.376291, Validation loss: 1.4012, lr: 0.0000\n",
      "Epoch: 498, Training loss: 1.372963, Validation loss: 1.4325, lr: 0.0000\n",
      "Epoch: 499, Training loss: 1.392735, Validation loss: 1.4020, lr: 0.0000\n",
      "Epoch: 500, Training loss: 1.393710, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 501, Training loss: 1.457700, Validation loss: 1.3782, lr: 0.0000\n",
      "Epoch: 502, Training loss: 1.369993, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 503, Training loss: 1.378088, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 504, Training loss: 1.369912, Validation loss: 1.3718, lr: 0.0000\n",
      "Epoch: 505, Training loss: 1.404422, Validation loss: 1.3912, lr: 0.0000\n",
      "Epoch: 506, Training loss: 1.383656, Validation loss: 1.3797, lr: 0.0000\n",
      "Epoch: 507, Training loss: 1.393055, Validation loss: 1.3943, lr: 0.0000\n",
      "Epoch: 508, Training loss: 1.385852, Validation loss: 1.3626, lr: 0.0000\n",
      "Epoch: 509, Training loss: 1.388163, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 510, Training loss: 1.381695, Validation loss: 1.3769, lr: 0.0000\n",
      "Epoch: 511, Training loss: 1.384540, Validation loss: 1.3898, lr: 0.0000\n",
      "Epoch: 512, Training loss: 1.387066, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 513, Training loss: 1.386394, Validation loss: 1.3683, lr: 0.0000\n",
      "Epoch: 514, Training loss: 1.392239, Validation loss: 1.3957, lr: 0.0000\n",
      "Epoch: 515, Training loss: 1.372037, Validation loss: 1.3786, lr: 0.0000\n",
      "Epoch: 516, Training loss: 1.374058, Validation loss: 1.3608, lr: 0.0000\n",
      "Epoch: 517, Training loss: 1.355920, Validation loss: 1.4075, lr: 0.0000\n",
      "Epoch: 518, Training loss: 1.392157, Validation loss: 1.3873, lr: 0.0000\n",
      "Epoch: 519, Training loss: 1.381301, Validation loss: 1.3684, lr: 0.0000\n",
      "Epoch: 520, Training loss: 1.374574, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 521, Training loss: 1.369945, Validation loss: 1.3745, lr: 0.0000\n",
      "Epoch: 522, Training loss: 1.373012, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 523, Training loss: 1.387344, Validation loss: 1.3738, lr: 0.0000\n",
      "Epoch: 524, Training loss: 1.383505, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 525, Training loss: 1.358852, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 526, Training loss: 1.368289, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 527, Training loss: 1.367430, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 528, Training loss: 1.357189, Validation loss: 1.4123, lr: 0.0000\n",
      "Epoch: 529, Training loss: 1.381246, Validation loss: 1.4048, lr: 0.0000\n",
      "Epoch: 530, Training loss: 1.379678, Validation loss: 1.3787, lr: 0.0000\n",
      "Epoch: 531, Training loss: 1.371393, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 532, Training loss: 1.381914, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 533, Training loss: 1.392960, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 534, Training loss: 1.379661, Validation loss: 1.3876, lr: 0.0000\n",
      "Epoch: 535, Training loss: 1.369820, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 536, Training loss: 1.394368, Validation loss: 1.3888, lr: 0.0000\n",
      "Epoch: 537, Training loss: 1.365648, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 538, Training loss: 1.381382, Validation loss: 1.3959, lr: 0.0000\n",
      "Epoch: 539, Training loss: 1.376473, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 540, Training loss: 1.375323, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 541, Training loss: 1.382169, Validation loss: 1.3792, lr: 0.0000\n",
      "Epoch: 542, Training loss: 1.361828, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 543, Training loss: 1.368813, Validation loss: 1.3666, lr: 0.0000\n",
      "Epoch: 544, Training loss: 1.394685, Validation loss: 1.3712, lr: 0.0000\n",
      "Epoch: 545, Training loss: 1.376708, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 546, Training loss: 1.376004, Validation loss: 1.3991, lr: 0.0000\n",
      "Epoch: 547, Training loss: 1.362707, Validation loss: 1.3932, lr: 0.0000\n",
      "Epoch: 548, Training loss: 1.391808, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 549, Training loss: 1.366327, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 550, Training loss: 1.370246, Validation loss: 1.3795, lr: 0.0000\n",
      "Epoch: 551, Training loss: 1.357228, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 552, Training loss: 1.411380, Validation loss: 1.3929, lr: 0.0000\n",
      "Epoch: 553, Training loss: 1.406581, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 554, Training loss: 1.375392, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 555, Training loss: 1.370853, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 556, Training loss: 1.381790, Validation loss: 1.3754, lr: 0.0000\n",
      "Epoch: 557, Training loss: 1.388701, Validation loss: 1.3754, lr: 0.0000\n",
      "Epoch: 558, Training loss: 1.359301, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 559, Training loss: 1.372133, Validation loss: 1.3878, lr: 0.0000\n",
      "Epoch: 560, Training loss: 1.375241, Validation loss: 1.3746, lr: 0.0000\n",
      "Epoch: 561, Training loss: 1.374151, Validation loss: 1.3707, lr: 0.0000\n",
      "Epoch: 562, Training loss: 1.377165, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 563, Training loss: 1.386995, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 564, Training loss: 1.375763, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 565, Training loss: 1.369648, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 566, Training loss: 1.403992, Validation loss: 1.3881, lr: 0.0000\n",
      "Epoch: 567, Training loss: 1.371047, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 568, Training loss: 1.365957, Validation loss: 1.3883, lr: 0.0000\n",
      "Epoch: 569, Training loss: 1.376800, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 570, Training loss: 1.388779, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 571, Training loss: 1.388049, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 572, Training loss: 1.349028, Validation loss: 1.3871, lr: 0.0000\n",
      "Epoch: 573, Training loss: 1.379036, Validation loss: 1.3770, lr: 0.0000\n",
      "Epoch: 574, Training loss: 1.399458, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 575, Training loss: 1.367965, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 576, Training loss: 1.394622, Validation loss: 1.3878, lr: 0.0000\n",
      "Epoch: 577, Training loss: 1.370589, Validation loss: 1.3932, lr: 0.0000\n",
      "Epoch: 578, Training loss: 1.363968, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 579, Training loss: 1.396403, Validation loss: 1.3896, lr: 0.0000\n",
      "Epoch: 580, Training loss: 1.382556, Validation loss: 1.3889, lr: 0.0000\n",
      "Epoch: 581, Training loss: 1.372116, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 582, Training loss: 1.382995, Validation loss: 1.3781, lr: 0.0000\n",
      "Epoch: 583, Training loss: 1.368956, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 584, Training loss: 1.402713, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 585, Training loss: 1.356063, Validation loss: 1.5368, lr: 0.0000\n",
      "Epoch: 586, Training loss: 1.391737, Validation loss: 1.3788, lr: 0.0000\n",
      "Epoch: 587, Training loss: 1.388463, Validation loss: 1.3673, lr: 0.0000\n",
      "Epoch: 588, Training loss: 1.377196, Validation loss: 1.3761, lr: 0.0000\n",
      "Epoch: 589, Training loss: 1.382578, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 590, Training loss: 1.369921, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 591, Training loss: 1.355957, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 592, Training loss: 1.372194, Validation loss: 1.3613, lr: 0.0000\n",
      "Epoch: 593, Training loss: 1.367919, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 594, Training loss: 1.367225, Validation loss: 1.3685, lr: 0.0000\n",
      "Epoch: 595, Training loss: 1.384956, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 596, Training loss: 1.400974, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 597, Training loss: 1.390114, Validation loss: 1.3969, lr: 0.0000\n",
      "Epoch: 598, Training loss: 1.382643, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 599, Training loss: 1.370595, Validation loss: 1.3770, lr: 0.0000\n",
      "Epoch: 600, Training loss: 1.358061, Validation loss: 1.3950, lr: 0.0000\n",
      "Epoch: 601, Training loss: 1.370291, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 602, Training loss: 1.365038, Validation loss: 1.3873, lr: 0.0000\n",
      "Epoch: 603, Training loss: 1.360776, Validation loss: 1.3876, lr: 0.0000\n",
      "Epoch: 604, Training loss: 1.369859, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 605, Training loss: 1.366337, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 606, Training loss: 1.376301, Validation loss: 1.4044, lr: 0.0000\n",
      "Epoch: 607, Training loss: 1.381695, Validation loss: 1.3908, lr: 0.0000\n",
      "Epoch: 608, Training loss: 1.382302, Validation loss: 1.3780, lr: 0.0000\n",
      "Epoch: 609, Training loss: 1.370901, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 610, Training loss: 1.410463, Validation loss: 1.3922, lr: 0.0000\n",
      "Epoch: 611, Training loss: 1.369989, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 612, Training loss: 1.390530, Validation loss: 1.3759, lr: 0.0000\n",
      "Epoch: 613, Training loss: 1.376209, Validation loss: 1.3755, lr: 0.0000\n",
      "Epoch: 614, Training loss: 1.370332, Validation loss: 1.3766, lr: 0.0000\n",
      "Epoch: 615, Training loss: 1.457653, Validation loss: 1.3907, lr: 0.0000\n",
      "Epoch: 616, Training loss: 1.364460, Validation loss: 1.3773, lr: 0.0000\n",
      "Epoch: 617, Training loss: 1.371465, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 618, Training loss: 1.361852, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 619, Training loss: 1.369191, Validation loss: 1.3781, lr: 0.0000\n",
      "Epoch: 620, Training loss: 1.387184, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 621, Training loss: 1.370522, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 622, Training loss: 1.368650, Validation loss: 1.3922, lr: 0.0000\n",
      "Epoch: 623, Training loss: 1.396324, Validation loss: 1.3988, lr: 0.0000\n",
      "Epoch: 624, Training loss: 1.365496, Validation loss: 1.3882, lr: 0.0000\n",
      "Epoch: 625, Training loss: 1.374361, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 626, Training loss: 1.478224, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 627, Training loss: 1.403665, Validation loss: 1.3713, lr: 0.0000\n",
      "Epoch: 628, Training loss: 1.365784, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 629, Training loss: 1.377664, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 630, Training loss: 1.370633, Validation loss: 1.3684, lr: 0.0000\n",
      "Epoch: 631, Training loss: 1.379641, Validation loss: 1.3906, lr: 0.0000\n",
      "Epoch: 632, Training loss: 1.377580, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 633, Training loss: 1.395471, Validation loss: 1.3782, lr: 0.0000\n",
      "Epoch: 634, Training loss: 1.389398, Validation loss: 1.3692, lr: 0.0000\n",
      "Epoch: 635, Training loss: 1.368563, Validation loss: 1.3894, lr: 0.0000\n",
      "Epoch: 636, Training loss: 1.369927, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 637, Training loss: 1.381831, Validation loss: 1.3751, lr: 0.0000\n",
      "Epoch: 638, Training loss: 1.492938, Validation loss: 1.3766, lr: 0.0000\n",
      "Epoch: 639, Training loss: 1.381060, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 640, Training loss: 1.365467, Validation loss: 1.3470, lr: 0.0000\n",
      "Epoch: 641, Training loss: 1.351621, Validation loss: 1.3735, lr: 0.0000\n",
      "Epoch: 642, Training loss: 1.381369, Validation loss: 1.3889, lr: 0.0000\n",
      "Epoch: 643, Training loss: 1.383337, Validation loss: 1.3712, lr: 0.0000\n",
      "Epoch: 644, Training loss: 1.382827, Validation loss: 1.3774, lr: 0.0000\n",
      "Epoch: 645, Training loss: 1.371641, Validation loss: 1.4696, lr: 0.0000\n",
      "Epoch: 646, Training loss: 1.375597, Validation loss: 1.3722, lr: 0.0000\n",
      "Epoch: 647, Training loss: 1.374735, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 648, Training loss: 1.373240, Validation loss: 1.3798, lr: 0.0000\n",
      "Epoch: 649, Training loss: 1.385636, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 650, Training loss: 1.379919, Validation loss: 1.3908, lr: 0.0000\n",
      "Epoch: 651, Training loss: 1.364072, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 652, Training loss: 1.367183, Validation loss: 1.3763, lr: 0.0000\n",
      "Epoch: 653, Training loss: 1.383407, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 654, Training loss: 1.383909, Validation loss: 1.3885, lr: 0.0000\n",
      "Epoch: 655, Training loss: 1.402826, Validation loss: 1.3724, lr: 0.0000\n",
      "Epoch: 656, Training loss: 1.363169, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 657, Training loss: 1.412579, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 658, Training loss: 1.374460, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 659, Training loss: 1.387696, Validation loss: 1.3883, lr: 0.0000\n",
      "Epoch: 660, Training loss: 1.371577, Validation loss: 1.3735, lr: 0.0000\n",
      "Epoch: 661, Training loss: 1.376419, Validation loss: 1.4529, lr: 0.0000\n",
      "Epoch: 662, Training loss: 1.391779, Validation loss: 1.3780, lr: 0.0000\n",
      "Epoch: 663, Training loss: 1.374965, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 664, Training loss: 1.358339, Validation loss: 1.3896, lr: 0.0000\n",
      "Epoch: 665, Training loss: 1.375330, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 666, Training loss: 1.371616, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 667, Training loss: 1.388208, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 668, Training loss: 1.377842, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 669, Training loss: 1.381466, Validation loss: 1.3709, lr: 0.0000\n",
      "Epoch: 670, Training loss: 1.396119, Validation loss: 1.3761, lr: 0.0000\n",
      "Epoch: 671, Training loss: 1.389800, Validation loss: 1.3711, lr: 0.0000\n",
      "Epoch: 672, Training loss: 1.372536, Validation loss: 1.3797, lr: 0.0000\n",
      "Epoch: 673, Training loss: 1.386258, Validation loss: 1.3476, lr: 0.0000\n",
      "Epoch: 674, Training loss: 1.400985, Validation loss: 1.3738, lr: 0.0000\n",
      "Epoch: 675, Training loss: 1.361097, Validation loss: 1.4392, lr: 0.0000\n",
      "Epoch: 676, Training loss: 1.447735, Validation loss: 1.3768, lr: 0.0000\n",
      "Epoch: 677, Training loss: 1.495491, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 678, Training loss: 1.363085, Validation loss: 1.3809, lr: 0.0000\n",
      "Epoch: 679, Training loss: 1.365888, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 680, Training loss: 1.371688, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 681, Training loss: 1.386677, Validation loss: 1.3755, lr: 0.0000\n",
      "Epoch: 682, Training loss: 1.376266, Validation loss: 1.3727, lr: 0.0000\n",
      "Epoch: 683, Training loss: 1.365972, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 684, Training loss: 1.374417, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 685, Training loss: 1.368616, Validation loss: 1.3781, lr: 0.0000\n",
      "Epoch: 686, Training loss: 1.364006, Validation loss: 1.3708, lr: 0.0000\n",
      "Epoch: 687, Training loss: 1.360847, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 688, Training loss: 1.370680, Validation loss: 1.3961, lr: 0.0000\n",
      "Epoch: 689, Training loss: 1.378454, Validation loss: 1.4060, lr: 0.0000\n",
      "Epoch: 690, Training loss: 1.362515, Validation loss: 1.3739, lr: 0.0000\n",
      "Epoch: 691, Training loss: 1.373474, Validation loss: 1.3873, lr: 0.0000\n",
      "Epoch: 692, Training loss: 1.371664, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 693, Training loss: 1.412264, Validation loss: 1.3872, lr: 0.0000\n",
      "Epoch: 694, Training loss: 1.380462, Validation loss: 1.3975, lr: 0.0000\n",
      "Epoch: 695, Training loss: 1.380346, Validation loss: 1.3784, lr: 0.0000\n",
      "Epoch: 696, Training loss: 1.383166, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 697, Training loss: 1.384588, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 698, Training loss: 1.376745, Validation loss: 1.3938, lr: 0.0000\n",
      "Epoch: 699, Training loss: 1.367688, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 700, Training loss: 1.389532, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 701, Training loss: 1.381847, Validation loss: 1.3683, lr: 0.0000\n",
      "Epoch: 702, Training loss: 1.378790, Validation loss: 1.3756, lr: 0.0000\n",
      "Epoch: 703, Training loss: 1.369103, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 704, Training loss: 1.372080, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 705, Training loss: 1.364676, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 706, Training loss: 1.379237, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 707, Training loss: 1.364913, Validation loss: 1.3789, lr: 0.0000\n",
      "Epoch: 708, Training loss: 1.363253, Validation loss: 1.3687, lr: 0.0000\n",
      "Epoch: 709, Training loss: 1.381128, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 710, Training loss: 1.387098, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 711, Training loss: 1.366207, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 712, Training loss: 1.399380, Validation loss: 1.3882, lr: 0.0000\n",
      "Epoch: 713, Training loss: 1.364768, Validation loss: 1.4149, lr: 0.0000\n",
      "Epoch: 714, Training loss: 1.388283, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 715, Training loss: 1.381218, Validation loss: 1.3595, lr: 0.0000\n",
      "Epoch: 716, Training loss: 1.371879, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 717, Training loss: 1.379981, Validation loss: 1.3727, lr: 0.0000\n",
      "Epoch: 718, Training loss: 1.381834, Validation loss: 1.3777, lr: 0.0000\n",
      "Epoch: 719, Training loss: 1.380862, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 720, Training loss: 1.392793, Validation loss: 1.3720, lr: 0.0000\n",
      "Epoch: 721, Training loss: 1.381547, Validation loss: 1.3982, lr: 0.0000\n",
      "Epoch: 722, Training loss: 1.372330, Validation loss: 1.3695, lr: 0.0000\n",
      "Epoch: 723, Training loss: 1.362516, Validation loss: 1.4213, lr: 0.0000\n",
      "Epoch: 724, Training loss: 1.385030, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 725, Training loss: 1.360086, Validation loss: 1.4316, lr: 0.0000\n",
      "Epoch: 726, Training loss: 1.368325, Validation loss: 1.3726, lr: 0.0000\n",
      "Epoch: 727, Training loss: 1.383768, Validation loss: 1.3725, lr: 0.0000\n",
      "Epoch: 728, Training loss: 1.378483, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 729, Training loss: 1.382883, Validation loss: 1.3748, lr: 0.0000\n",
      "Epoch: 730, Training loss: 1.375166, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 731, Training loss: 1.367382, Validation loss: 1.4030, lr: 0.0000\n",
      "Epoch: 732, Training loss: 1.388072, Validation loss: 1.3788, lr: 0.0000\n",
      "Epoch: 733, Training loss: 1.371121, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 734, Training loss: 1.362147, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 735, Training loss: 1.370496, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 736, Training loss: 1.386401, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 737, Training loss: 1.408399, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 738, Training loss: 1.381152, Validation loss: 1.3743, lr: 0.0000\n",
      "Epoch: 739, Training loss: 1.391331, Validation loss: 1.3875, lr: 0.0000\n",
      "Epoch: 740, Training loss: 1.371794, Validation loss: 1.3886, lr: 0.0000\n",
      "Epoch: 741, Training loss: 1.405803, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 742, Training loss: 1.383001, Validation loss: 1.3775, lr: 0.0000\n",
      "Epoch: 743, Training loss: 1.388396, Validation loss: 1.3782, lr: 0.0000\n",
      "Epoch: 744, Training loss: 1.368340, Validation loss: 1.3727, lr: 0.0000\n",
      "Epoch: 745, Training loss: 1.373469, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 746, Training loss: 1.383577, Validation loss: 1.3549, lr: 0.0000\n",
      "Epoch: 747, Training loss: 1.399122, Validation loss: 1.3872, lr: 0.0000\n",
      "Epoch: 748, Training loss: 1.371767, Validation loss: 1.3803, lr: 0.0000\n",
      "Epoch: 749, Training loss: 1.379571, Validation loss: 1.3796, lr: 0.0000\n",
      "Epoch: 750, Training loss: 1.368331, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 751, Training loss: 1.379696, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 752, Training loss: 1.377956, Validation loss: 1.3773, lr: 0.0000\n",
      "Epoch: 753, Training loss: 1.450884, Validation loss: 1.3744, lr: 0.0000\n",
      "Epoch: 754, Training loss: 1.371497, Validation loss: 1.3923, lr: 0.0000\n",
      "Epoch: 755, Training loss: 1.366834, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 756, Training loss: 1.366831, Validation loss: 1.3809, lr: 0.0000\n",
      "Epoch: 757, Training loss: 1.374649, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 758, Training loss: 1.382399, Validation loss: 1.3795, lr: 0.0000\n",
      "Epoch: 759, Training loss: 1.377694, Validation loss: 1.3677, lr: 0.0000\n",
      "Epoch: 760, Training loss: 1.377255, Validation loss: 1.3886, lr: 0.0000\n",
      "Epoch: 761, Training loss: 1.386260, Validation loss: 1.3796, lr: 0.0000\n",
      "Epoch: 762, Training loss: 1.370052, Validation loss: 1.3802, lr: 0.0000\n",
      "Epoch: 763, Training loss: 1.362074, Validation loss: 1.4211, lr: 0.0000\n",
      "Epoch: 764, Training loss: 1.376413, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 765, Training loss: 1.379117, Validation loss: 1.3907, lr: 0.0000\n",
      "Epoch: 766, Training loss: 1.382752, Validation loss: 1.3874, lr: 0.0000\n",
      "Epoch: 767, Training loss: 1.372792, Validation loss: 1.3759, lr: 0.0000\n",
      "Epoch: 768, Training loss: 1.377457, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 769, Training loss: 1.389103, Validation loss: 1.3886, lr: 0.0000\n",
      "Epoch: 770, Training loss: 1.391090, Validation loss: 1.3803, lr: 0.0000\n",
      "Epoch: 771, Training loss: 1.386944, Validation loss: 1.3368, lr: 0.0000\n",
      "Epoch: 772, Training loss: 1.369196, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 773, Training loss: 1.372027, Validation loss: 1.3935, lr: 0.0000\n",
      "Epoch: 774, Training loss: 1.384279, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 775, Training loss: 1.361549, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 776, Training loss: 1.368535, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 777, Training loss: 1.376533, Validation loss: 1.3929, lr: 0.0000\n",
      "Epoch: 778, Training loss: 1.372918, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 779, Training loss: 1.395075, Validation loss: 1.3776, lr: 0.0000\n",
      "Epoch: 780, Training loss: 1.368983, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 781, Training loss: 1.386262, Validation loss: 1.3687, lr: 0.0000\n",
      "Epoch: 782, Training loss: 1.367779, Validation loss: 1.3928, lr: 0.0000\n",
      "Epoch: 783, Training loss: 1.387377, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 784, Training loss: 1.372466, Validation loss: 1.3779, lr: 0.0000\n",
      "Epoch: 785, Training loss: 1.350898, Validation loss: 1.3787, lr: 0.0000\n",
      "Epoch: 786, Training loss: 1.396444, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 787, Training loss: 1.366834, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 788, Training loss: 1.365456, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 789, Training loss: 1.375178, Validation loss: 1.3958, lr: 0.0000\n",
      "Epoch: 790, Training loss: 1.368027, Validation loss: 1.3878, lr: 0.0000\n",
      "Epoch: 791, Training loss: 1.372083, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 792, Training loss: 1.474596, Validation loss: 1.4048, lr: 0.0000\n",
      "Epoch: 793, Training loss: 1.383571, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 794, Training loss: 1.365271, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 795, Training loss: 1.369531, Validation loss: 1.3793, lr: 0.0000\n",
      "Epoch: 796, Training loss: 1.372770, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 797, Training loss: 1.386445, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 798, Training loss: 1.374638, Validation loss: 1.3784, lr: 0.0000\n",
      "Epoch: 799, Training loss: 1.374909, Validation loss: 1.4073, lr: 0.0000\n",
      "Epoch: 800, Training loss: 1.361391, Validation loss: 1.3625, lr: 0.0000\n",
      "Epoch: 801, Training loss: 1.370577, Validation loss: 1.4131, lr: 0.0000\n",
      "Epoch: 802, Training loss: 1.388823, Validation loss: 1.3769, lr: 0.0000\n",
      "Epoch: 803, Training loss: 1.370497, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 804, Training loss: 1.370210, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 805, Training loss: 1.370112, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 806, Training loss: 1.364518, Validation loss: 1.3893, lr: 0.0000\n",
      "Epoch: 807, Training loss: 1.383055, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 808, Training loss: 1.379917, Validation loss: 1.3685, lr: 0.0000\n",
      "Epoch: 809, Training loss: 1.368304, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 810, Training loss: 1.410479, Validation loss: 1.3882, lr: 0.0000\n",
      "Epoch: 811, Training loss: 1.385595, Validation loss: 1.3767, lr: 0.0000\n",
      "Epoch: 812, Training loss: 1.376485, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 813, Training loss: 1.385730, Validation loss: 1.3908, lr: 0.0000\n",
      "Epoch: 814, Training loss: 1.378105, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 815, Training loss: 1.376386, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 816, Training loss: 1.369416, Validation loss: 1.3755, lr: 0.0000\n",
      "Epoch: 817, Training loss: 1.379632, Validation loss: 1.3881, lr: 0.0000\n",
      "Epoch: 818, Training loss: 1.361391, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 819, Training loss: 1.367995, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 820, Training loss: 1.377167, Validation loss: 1.4143, lr: 0.0000\n",
      "Epoch: 821, Training loss: 1.369206, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 822, Training loss: 1.361078, Validation loss: 1.3763, lr: 0.0000\n",
      "Epoch: 823, Training loss: 1.357877, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 824, Training loss: 1.369160, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 825, Training loss: 1.370763, Validation loss: 1.3904, lr: 0.0000\n",
      "Epoch: 826, Training loss: 1.378188, Validation loss: 1.3766, lr: 0.0000\n",
      "Epoch: 827, Training loss: 1.364621, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 828, Training loss: 1.385278, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 829, Training loss: 1.400188, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 830, Training loss: 1.393807, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 831, Training loss: 1.370106, Validation loss: 1.3708, lr: 0.0000\n",
      "Epoch: 832, Training loss: 1.363156, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 833, Training loss: 1.375238, Validation loss: 1.3665, lr: 0.0000\n",
      "Epoch: 834, Training loss: 1.383275, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 835, Training loss: 1.375839, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 836, Training loss: 1.363444, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 837, Training loss: 1.373585, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 838, Training loss: 1.380009, Validation loss: 1.3800, lr: 0.0000\n",
      "Epoch: 839, Training loss: 1.472362, Validation loss: 1.3756, lr: 0.0000\n",
      "Epoch: 840, Training loss: 1.384759, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 841, Training loss: 1.396677, Validation loss: 1.3873, lr: 0.0000\n",
      "Epoch: 842, Training loss: 1.366867, Validation loss: 1.3885, lr: 0.0000\n",
      "Epoch: 843, Training loss: 1.378803, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 844, Training loss: 1.364202, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 845, Training loss: 1.408066, Validation loss: 1.3778, lr: 0.0000\n",
      "Epoch: 846, Training loss: 1.374318, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 847, Training loss: 1.388245, Validation loss: 1.3722, lr: 0.0000\n",
      "Epoch: 848, Training loss: 1.395108, Validation loss: 1.4476, lr: 0.0000\n",
      "Epoch: 849, Training loss: 1.382785, Validation loss: 1.3771, lr: 0.0000\n",
      "Epoch: 850, Training loss: 1.367975, Validation loss: 1.3809, lr: 0.0000\n",
      "Epoch: 851, Training loss: 1.381406, Validation loss: 1.3775, lr: 0.0000\n",
      "Epoch: 852, Training loss: 1.365296, Validation loss: 1.4052, lr: 0.0000\n",
      "Epoch: 853, Training loss: 1.361327, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 854, Training loss: 1.369163, Validation loss: 1.4140, lr: 0.0000\n",
      "Epoch: 855, Training loss: 1.390973, Validation loss: 1.3896, lr: 0.0000\n",
      "Epoch: 856, Training loss: 1.366578, Validation loss: 1.3591, lr: 0.0000\n",
      "Epoch: 857, Training loss: 1.371031, Validation loss: 1.5136, lr: 0.0000\n",
      "Epoch: 858, Training loss: 1.446434, Validation loss: 1.3723, lr: 0.0000\n",
      "Epoch: 859, Training loss: 1.356137, Validation loss: 1.3890, lr: 0.0000\n",
      "Epoch: 860, Training loss: 1.395439, Validation loss: 1.3659, lr: 0.0000\n",
      "Epoch: 861, Training loss: 1.390062, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 862, Training loss: 1.354744, Validation loss: 1.4878, lr: 0.0000\n",
      "Epoch: 863, Training loss: 1.364107, Validation loss: 1.3748, lr: 0.0000\n",
      "Epoch: 864, Training loss: 1.385404, Validation loss: 1.3772, lr: 0.0000\n",
      "Epoch: 865, Training loss: 1.381580, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 866, Training loss: 1.382487, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 867, Training loss: 1.439956, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 868, Training loss: 1.370903, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 869, Training loss: 1.363415, Validation loss: 1.3981, lr: 0.0000\n",
      "Epoch: 870, Training loss: 1.390335, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 871, Training loss: 1.393394, Validation loss: 1.4031, lr: 0.0000\n",
      "Epoch: 872, Training loss: 1.351691, Validation loss: 1.3792, lr: 0.0000\n",
      "Epoch: 873, Training loss: 1.406129, Validation loss: 1.3895, lr: 0.0000\n",
      "Epoch: 874, Training loss: 1.400394, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 875, Training loss: 1.373817, Validation loss: 1.3475, lr: 0.0000\n",
      "Epoch: 876, Training loss: 1.378161, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 877, Training loss: 1.375902, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 878, Training loss: 1.369438, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 879, Training loss: 1.358356, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 880, Training loss: 1.379528, Validation loss: 1.3577, lr: 0.0000\n",
      "Epoch: 881, Training loss: 1.374435, Validation loss: 1.3888, lr: 0.0000\n",
      "Epoch: 882, Training loss: 1.390085, Validation loss: 1.3899, lr: 0.0000\n",
      "Epoch: 883, Training loss: 1.422053, Validation loss: 1.3803, lr: 0.0000\n",
      "Epoch: 884, Training loss: 1.370573, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 885, Training loss: 1.380095, Validation loss: 1.3755, lr: 0.0000\n",
      "Epoch: 886, Training loss: 1.385091, Validation loss: 1.3797, lr: 0.0000\n",
      "Epoch: 887, Training loss: 1.388518, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 888, Training loss: 1.382195, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 889, Training loss: 1.379074, Validation loss: 1.3934, lr: 0.0000\n",
      "Epoch: 890, Training loss: 1.385889, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 891, Training loss: 1.398254, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 892, Training loss: 1.371600, Validation loss: 1.3791, lr: 0.0000\n",
      "Epoch: 893, Training loss: 1.371953, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 894, Training loss: 1.378582, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 895, Training loss: 1.382673, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 896, Training loss: 1.376626, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 897, Training loss: 1.428243, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 898, Training loss: 1.380802, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 899, Training loss: 1.373443, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 900, Training loss: 1.382731, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 901, Training loss: 1.370261, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 902, Training loss: 1.374727, Validation loss: 1.3889, lr: 0.0000\n",
      "Epoch: 903, Training loss: 1.366019, Validation loss: 1.3645, lr: 0.0000\n",
      "Epoch: 904, Training loss: 1.383122, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 905, Training loss: 1.386786, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 906, Training loss: 1.483034, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 907, Training loss: 1.366699, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 908, Training loss: 1.396680, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 909, Training loss: 1.385622, Validation loss: 1.3891, lr: 0.0000\n",
      "Epoch: 910, Training loss: 1.373696, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 911, Training loss: 1.365491, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 912, Training loss: 1.372265, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 913, Training loss: 1.363393, Validation loss: 1.3888, lr: 0.0000\n",
      "Epoch: 914, Training loss: 1.373824, Validation loss: 1.4063, lr: 0.0000\n",
      "Epoch: 915, Training loss: 1.378880, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 916, Training loss: 1.395445, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 917, Training loss: 1.374353, Validation loss: 1.3886, lr: 0.0000\n",
      "Epoch: 918, Training loss: 1.366189, Validation loss: 1.4023, lr: 0.0000\n",
      "Epoch: 919, Training loss: 1.383609, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 920, Training loss: 1.375720, Validation loss: 1.3881, lr: 0.0000\n",
      "Epoch: 921, Training loss: 1.378885, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 922, Training loss: 1.366224, Validation loss: 1.3793, lr: 0.0000\n",
      "Epoch: 923, Training loss: 1.377372, Validation loss: 1.3874, lr: 0.0000\n",
      "Epoch: 924, Training loss: 1.395911, Validation loss: 1.4045, lr: 0.0000\n",
      "Epoch: 925, Training loss: 1.372617, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 926, Training loss: 1.362681, Validation loss: 1.3735, lr: 0.0000\n",
      "Epoch: 927, Training loss: 1.364607, Validation loss: 1.3892, lr: 0.0000\n",
      "Epoch: 928, Training loss: 1.377281, Validation loss: 1.3736, lr: 0.0000\n",
      "Epoch: 929, Training loss: 1.374840, Validation loss: 1.3748, lr: 0.0000\n",
      "Epoch: 930, Training loss: 1.378804, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 931, Training loss: 1.377529, Validation loss: 1.3696, lr: 0.0000\n",
      "Epoch: 932, Training loss: 1.385852, Validation loss: 1.3771, lr: 0.0000\n",
      "Epoch: 933, Training loss: 1.368964, Validation loss: 1.3883, lr: 0.0000\n",
      "Epoch: 934, Training loss: 1.398171, Validation loss: 1.3979, lr: 0.0000\n",
      "Epoch: 935, Training loss: 1.362935, Validation loss: 1.3896, lr: 0.0000\n",
      "Epoch: 936, Training loss: 1.378354, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 937, Training loss: 1.382998, Validation loss: 1.3921, lr: 0.0000\n",
      "Epoch: 938, Training loss: 1.386181, Validation loss: 1.5000, lr: 0.0000\n",
      "Epoch: 939, Training loss: 1.388979, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 940, Training loss: 1.380723, Validation loss: 1.3871, lr: 0.0000\n",
      "Epoch: 941, Training loss: 1.392383, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 942, Training loss: 1.366127, Validation loss: 1.3776, lr: 0.0000\n",
      "Epoch: 943, Training loss: 1.375314, Validation loss: 1.3892, lr: 0.0000\n",
      "Epoch: 944, Training loss: 1.360982, Validation loss: 1.3683, lr: 0.0000\n",
      "Epoch: 945, Training loss: 1.372742, Validation loss: 1.3876, lr: 0.0000\n",
      "Epoch: 946, Training loss: 1.356822, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 947, Training loss: 1.375829, Validation loss: 1.4096, lr: 0.0000\n",
      "Epoch: 948, Training loss: 1.370171, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 949, Training loss: 1.381318, Validation loss: 1.3710, lr: 0.0000\n",
      "Epoch: 950, Training loss: 1.390722, Validation loss: 1.3874, lr: 0.0000\n",
      "Epoch: 951, Training loss: 1.380873, Validation loss: 1.3689, lr: 0.0000\n",
      "Epoch: 952, Training loss: 1.372450, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 953, Training loss: 1.380337, Validation loss: 1.3706, lr: 0.0000\n",
      "Epoch: 954, Training loss: 1.390328, Validation loss: 1.3913, lr: 0.0000\n",
      "Epoch: 955, Training loss: 1.389782, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 956, Training loss: 1.367381, Validation loss: 1.3876, lr: 0.0000\n",
      "Epoch: 957, Training loss: 1.371769, Validation loss: 1.3874, lr: 0.0000\n",
      "Epoch: 958, Training loss: 1.369214, Validation loss: 1.3915, lr: 0.0000\n",
      "Epoch: 959, Training loss: 1.380278, Validation loss: 1.3735, lr: 0.0000\n",
      "Epoch: 960, Training loss: 1.364136, Validation loss: 1.3772, lr: 0.0000\n",
      "Epoch: 961, Training loss: 1.386751, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 962, Training loss: 1.381925, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 963, Training loss: 1.381244, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 964, Training loss: 1.405256, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 965, Training loss: 1.383172, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 966, Training loss: 1.383815, Validation loss: 1.3642, lr: 0.0000\n",
      "Epoch: 967, Training loss: 1.366266, Validation loss: 1.3698, lr: 0.0000\n",
      "Epoch: 968, Training loss: 1.371645, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 969, Training loss: 1.375618, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 970, Training loss: 1.399298, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 971, Training loss: 1.360592, Validation loss: 1.3793, lr: 0.0000\n",
      "Epoch: 972, Training loss: 1.389620, Validation loss: 1.3889, lr: 0.0000\n",
      "Epoch: 973, Training loss: 1.391286, Validation loss: 1.3773, lr: 0.0000\n",
      "Epoch: 974, Training loss: 1.366659, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 975, Training loss: 1.354441, Validation loss: 1.3528, lr: 0.0000\n",
      "Epoch: 976, Training loss: 1.373091, Validation loss: 1.3896, lr: 0.0000\n",
      "Epoch: 977, Training loss: 1.382209, Validation loss: 1.3897, lr: 0.0000\n",
      "Epoch: 978, Training loss: 1.384090, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 979, Training loss: 1.390061, Validation loss: 1.3749, lr: 0.0000\n",
      "Epoch: 980, Training loss: 1.379996, Validation loss: 1.5267, lr: 0.0000\n",
      "Epoch: 981, Training loss: 1.365665, Validation loss: 1.3765, lr: 0.0000\n",
      "Epoch: 982, Training loss: 1.368872, Validation loss: 1.3692, lr: 0.0000\n",
      "Epoch: 983, Training loss: 1.369226, Validation loss: 1.3603, lr: 0.0000\n",
      "Epoch: 984, Training loss: 1.387763, Validation loss: 1.3880, lr: 0.0000\n",
      "Epoch: 985, Training loss: 1.376142, Validation loss: 1.3710, lr: 0.0000\n",
      "Epoch: 986, Training loss: 1.344109, Validation loss: 1.3900, lr: 0.0000\n",
      "Epoch: 987, Training loss: 1.372074, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 988, Training loss: 1.364791, Validation loss: 1.3888, lr: 0.0000\n",
      "Epoch: 989, Training loss: 1.379967, Validation loss: 1.3900, lr: 0.0000\n",
      "Epoch: 990, Training loss: 1.365718, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 991, Training loss: 1.386355, Validation loss: 1.3765, lr: 0.0000\n",
      "Epoch: 992, Training loss: 1.406367, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 993, Training loss: 1.386998, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 994, Training loss: 1.368040, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 995, Training loss: 1.369786, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 996, Training loss: 1.387627, Validation loss: 1.3791, lr: 0.0000\n",
      "Epoch: 997, Training loss: 1.365081, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 998, Training loss: 1.390813, Validation loss: 1.4226, lr: 0.0000\n",
      "Epoch: 999, Training loss: 1.373054, Validation loss: 1.3893, lr: 0.0000\n",
      "Final test loss: 1.3784\n",
      "\n",
      "---- Embedding dimension: 100\n",
      "---- Signal dimension: 100\n",
      "---- Computing kernels ... \n",
      "---- Computing full spectrum ...\n",
      "              (if this takes too long, then run construct_dataset()\n",
      "              with number_of_eigenvectors specified) \n",
      "---- Embedding dimension: 100\n",
      "---- Signal dimension: 100\n",
      "---- Computing kernels ... \n",
      "---- Computing full spectrum ...\n",
      "              (if this takes too long, then run construct_dataset()\n",
      "=== Run 01/10 ===h number_of_eigenvectors specified) \n",
      "\n",
      "---- Settings: \n",
      "\n",
      "epochs : 1000\n",
      "hidden_channels : [32]\n",
      "out_channels : 10\n",
      "inner_product_features : False\n",
      "batch_size : 64\n",
      "lr : 0.01\n",
      "momentum : 0.9\n",
      "dropout : 0.0\n",
      "batch_norm : batch_norm\n",
      "bias : True\n",
      "order : 2\n",
      "diffusion : True\n",
      "frac_sampled_nb : -1\n",
      "include_positions : False\n",
      "include_self : True\n",
      "vec_norm : False\n",
      "emb_norm : False\n",
      "seed : 0\n",
      "dim_signal : 100\n",
      "dim_emb : 100\n",
      "n_sampled_nb : -1\n",
      "\n",
      "---- Number of features to pass to the MLP:  1010100\n",
      "---- Total number of parameters:  32323627\n",
      "\n",
      "Using device cuda:0\n",
      "\n",
      "---- Training network ...\n",
      "\n",
      "---- Timestamp: 20250614-193628\n",
      "\n",
      " *och: 0, Training loss: 1.487620, Validation loss: 1.4878, lr: 0.0100\n",
      "Epoch: 1, Training loss: 1.437237, Validation loss: 1.5442, lr: 0.0100\n",
      " *och: 2, Training loss: 1.425814, Validation loss: 1.3850, lr: 0.0100\n",
      "Epoch: 3, Training loss: 1.376547, Validation loss: 1.4019, lr: 0.0100\n",
      " *och: 4, Training loss: 1.440593, Validation loss: 1.3815, lr: 0.0100\n",
      "Epoch: 5, Training loss: 1.411069, Validation loss: 1.3846, lr: 0.0100\n",
      " *och: 6, Training loss: 1.375311, Validation loss: 1.3692, lr: 0.0100\n",
      "Epoch: 7, Training loss: 1.368585, Validation loss: 1.3850, lr: 0.0100\n",
      "Epoch: 8, Training loss: 1.404240, Validation loss: 1.3858, lr: 0.0100\n",
      "Epoch: 9, Training loss: 1.421784, Validation loss: 1.3768, lr: 0.0100\n",
      "Epoch: 10, Training loss: 1.373997, Validation loss: 1.3764, lr: 0.0100\n",
      "Epoch: 11, Training loss: 1.376212, Validation loss: 1.3806, lr: 0.0100\n",
      "Epoch: 12, Training loss: 1.370841, Validation loss: 1.3837, lr: 0.0100\n",
      "Epoch: 13, Training loss: 1.364412, Validation loss: 1.3801, lr: 0.0100\n",
      "Epoch: 14, Training loss: 1.376500, Validation loss: 1.3848, lr: 0.0100\n",
      "Epoch: 15, Training loss: 1.377581, Validation loss: 1.3751, lr: 0.0100\n",
      "Epoch: 16, Training loss: 1.494447, Validation loss: 1.3830, lr: 0.0100\n",
      "Epoch: 17, Training loss: 1.381870, Validation loss: 1.3770, lr: 0.0100\n",
      "Epoch: 18, Training loss: 1.366699, Validation loss: 1.3863, lr: 0.0100\n",
      "Epoch: 19, Training loss: 1.385559, Validation loss: 1.3824, lr: 0.0100\n",
      "Epoch: 20, Training loss: 1.361025, Validation loss: 1.3754, lr: 0.0100\n",
      "Epoch: 21, Training loss: 1.364651, Validation loss: 1.4210, lr: 0.0100\n",
      "Epoch: 22, Training loss: 1.363213, Validation loss: 1.3803, lr: 0.0100\n",
      "Epoch: 23, Training loss: 1.364590, Validation loss: 1.3864, lr: 0.0100\n",
      " *och: 24, Training loss: 1.378259, Validation loss: 1.3542, lr: 0.0100\n",
      "Epoch: 25, Training loss: 1.365674, Validation loss: 1.3797, lr: 0.0100\n",
      "Epoch: 26, Training loss: 1.381883, Validation loss: 1.3808, lr: 0.0100\n",
      "Epoch: 27, Training loss: 1.407262, Validation loss: 1.3828, lr: 0.0100\n",
      "Epoch: 28, Training loss: 1.372449, Validation loss: 1.3854, lr: 0.0100\n",
      "Epoch: 29, Training loss: 1.354345, Validation loss: 1.3818, lr: 0.0100\n",
      " *och: 30, Training loss: 1.396891, Validation loss: 1.3514, lr: 0.0100\n",
      "Epoch: 31, Training loss: 1.378638, Validation loss: 1.3833, lr: 0.0100\n",
      "Epoch: 32, Training loss: 1.365087, Validation loss: 1.3653, lr: 0.0100\n",
      "Epoch: 33, Training loss: 1.366381, Validation loss: 1.3710, lr: 0.0100\n",
      "Epoch: 34, Training loss: 1.363276, Validation loss: 1.3807, lr: 0.0100\n",
      "Epoch: 35, Training loss: 1.373497, Validation loss: 1.3757, lr: 0.0100\n",
      "Epoch: 36, Training loss: 1.362393, Validation loss: 1.9722, lr: 0.0100\n",
      "Epoch: 37, Training loss: 1.371153, Validation loss: 1.3808, lr: 0.0100\n",
      "Epoch: 38, Training loss: 1.369367, Validation loss: 1.3711, lr: 0.0100\n",
      "Epoch: 39, Training loss: 1.367746, Validation loss: 1.3726, lr: 0.0100\n",
      "Epoch: 40, Training loss: 1.381342, Validation loss: 1.3702, lr: 0.0010\n",
      "Epoch: 41, Training loss: 1.409532, Validation loss: 1.3753, lr: 0.0010\n",
      "Epoch: 42, Training loss: 1.359151, Validation loss: 1.3866, lr: 0.0010\n",
      "Epoch: 43, Training loss: 1.474123, Validation loss: 1.3742, lr: 0.0010\n",
      "Epoch: 44, Training loss: 1.364424, Validation loss: 1.3852, lr: 0.0010\n",
      "Epoch: 45, Training loss: 1.377305, Validation loss: 1.3704, lr: 0.0010\n",
      "Epoch: 46, Training loss: 1.342201, Validation loss: 1.3556, lr: 0.0010\n",
      "Epoch: 47, Training loss: 1.393123, Validation loss: 1.3801, lr: 0.0010\n",
      "Epoch: 48, Training loss: 1.372208, Validation loss: 1.3883, lr: 0.0010\n",
      "Epoch: 49, Training loss: 1.371395, Validation loss: 1.3728, lr: 0.0010\n",
      "Epoch: 50, Training loss: 1.380772, Validation loss: 1.4147, lr: 0.0010\n",
      "Epoch: 51, Training loss: 1.370200, Validation loss: 1.3615, lr: 0.0010\n",
      "Epoch: 52, Training loss: 1.352495, Validation loss: 1.3784, lr: 0.0010\n",
      "Epoch: 53, Training loss: 1.336591, Validation loss: 1.3726, lr: 0.0010\n",
      "Epoch: 54, Training loss: 1.366333, Validation loss: 1.3653, lr: 0.0010\n",
      "Epoch: 55, Training loss: 1.333456, Validation loss: 1.3843, lr: 0.0010\n",
      "Epoch: 56, Training loss: 1.364533, Validation loss: 1.3840, lr: 0.0010\n",
      "Epoch: 57, Training loss: 1.373047, Validation loss: 1.4110, lr: 0.0010\n",
      "Epoch: 58, Training loss: 1.380101, Validation loss: 1.3826, lr: 0.0010\n",
      "Epoch: 59, Training loss: 1.342312, Validation loss: 1.3626, lr: 0.0010\n",
      "Epoch: 60, Training loss: 1.364772, Validation loss: 1.3805, lr: 0.0010\n",
      "Epoch: 61, Training loss: 1.364070, Validation loss: 1.3671, lr: 0.0010\n",
      " *och: 62, Training loss: 1.341931, Validation loss: 1.3423, lr: 0.0010\n",
      "Epoch: 63, Training loss: 1.403422, Validation loss: 1.3756, lr: 0.0010\n",
      "Epoch: 64, Training loss: 1.357117, Validation loss: 1.3806, lr: 0.0010\n",
      "Epoch: 65, Training loss: 1.340661, Validation loss: 1.3765, lr: 0.0010\n",
      "Epoch: 66, Training loss: 1.378592, Validation loss: 1.4875, lr: 0.0001\n",
      "Epoch: 67, Training loss: 1.392724, Validation loss: 1.3782, lr: 0.0001\n",
      "Epoch: 68, Training loss: 1.317995, Validation loss: 1.3608, lr: 0.0001\n",
      "Epoch: 69, Training loss: 1.360499, Validation loss: 1.3856, lr: 0.0001\n",
      "Epoch: 70, Training loss: 1.369109, Validation loss: 1.3761, lr: 0.0001\n",
      "Epoch: 71, Training loss: 1.367201, Validation loss: 1.3773, lr: 0.0001\n",
      "Epoch: 72, Training loss: 1.376260, Validation loss: 1.3796, lr: 0.0001\n",
      "Epoch: 73, Training loss: 1.375251, Validation loss: 1.3638, lr: 0.0001\n",
      "Epoch: 74, Training loss: 1.353642, Validation loss: 1.3774, lr: 0.0001\n",
      "Epoch: 75, Training loss: 1.344133, Validation loss: 1.3600, lr: 0.0001\n",
      "Epoch: 76, Training loss: 1.354414, Validation loss: 1.3770, lr: 0.0001\n",
      "Epoch: 77, Training loss: 1.350903, Validation loss: 1.3765, lr: 0.0001\n",
      "Epoch: 78, Training loss: 1.385395, Validation loss: 1.3834, lr: 0.0001\n",
      "Epoch: 79, Training loss: 1.329541, Validation loss: 1.3672, lr: 0.0000\n",
      "Epoch: 80, Training loss: 1.380791, Validation loss: 1.8847, lr: 0.0000\n",
      "Epoch: 81, Training loss: 1.359107, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 82, Training loss: 1.370748, Validation loss: 1.4060, lr: 0.0000\n",
      "Epoch: 83, Training loss: 1.340188, Validation loss: 1.3685, lr: 0.0000\n",
      "Epoch: 84, Training loss: 1.352153, Validation loss: 1.3752, lr: 0.0000\n",
      "Epoch: 85, Training loss: 1.353264, Validation loss: 1.3716, lr: 0.0000\n",
      "Epoch: 86, Training loss: 1.363038, Validation loss: 1.5233, lr: 0.0000\n",
      "Epoch: 87, Training loss: 1.355317, Validation loss: 1.3720, lr: 0.0000\n",
      "Epoch: 88, Training loss: 1.375030, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 89, Training loss: 1.342829, Validation loss: 1.3518, lr: 0.0000\n",
      "Epoch: 90, Training loss: 1.378381, Validation loss: 1.3733, lr: 0.0000\n",
      "Epoch: 91, Training loss: 1.354665, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 92, Training loss: 1.349927, Validation loss: 1.3724, lr: 0.0000\n",
      "Epoch: 93, Training loss: 1.348587, Validation loss: 1.3728, lr: 0.0000\n",
      "Epoch: 94, Training loss: 1.359576, Validation loss: 1.3692, lr: 0.0000\n",
      "Epoch: 95, Training loss: 1.342808, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 96, Training loss: 1.358365, Validation loss: 1.3658, lr: 0.0000\n",
      "Epoch: 97, Training loss: 1.371362, Validation loss: 1.3704, lr: 0.0000\n",
      "Epoch: 98, Training loss: 1.341644, Validation loss: 1.3762, lr: 0.0000\n",
      "Epoch: 99, Training loss: 1.340259, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 100, Training loss: 1.373086, Validation loss: 1.3607, lr: 0.0000\n",
      "Epoch: 101, Training loss: 1.361093, Validation loss: 1.3663, lr: 0.0000\n",
      "Epoch: 102, Training loss: 1.385518, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 103, Training loss: 1.352938, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 104, Training loss: 1.403602, Validation loss: 1.3743, lr: 0.0000\n",
      "Epoch: 105, Training loss: 1.360631, Validation loss: 1.3450, lr: 0.0000\n",
      "Epoch: 106, Training loss: 1.362998, Validation loss: 1.3533, lr: 0.0000\n",
      "Epoch: 107, Training loss: 1.356647, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 108, Training loss: 1.373060, Validation loss: 1.3650, lr: 0.0000\n",
      "Epoch: 109, Training loss: 1.403819, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 110, Training loss: 1.358215, Validation loss: 1.3750, lr: 0.0000\n",
      "Epoch: 111, Training loss: 1.373306, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 112, Training loss: 1.388529, Validation loss: 1.3705, lr: 0.0000\n",
      "Epoch: 113, Training loss: 1.364207, Validation loss: 1.3913, lr: 0.0000\n",
      "Epoch: 114, Training loss: 1.411544, Validation loss: 1.3608, lr: 0.0000\n",
      "Epoch: 115, Training loss: 1.362148, Validation loss: 1.3794, lr: 0.0000\n",
      "Epoch: 116, Training loss: 1.349255, Validation loss: 1.3762, lr: 0.0000\n",
      "Epoch: 117, Training loss: 1.375304, Validation loss: 1.3729, lr: 0.0000\n",
      "Epoch: 118, Training loss: 1.383925, Validation loss: 1.3746, lr: 0.0000\n",
      "Epoch: 119, Training loss: 1.355267, Validation loss: 1.3770, lr: 0.0000\n",
      "Epoch: 120, Training loss: 1.371644, Validation loss: 1.3940, lr: 0.0000\n",
      "Epoch: 121, Training loss: 1.348256, Validation loss: 1.3792, lr: 0.0000\n",
      "Epoch: 122, Training loss: 1.346320, Validation loss: 1.3487, lr: 0.0000\n",
      "Epoch: 123, Training loss: 1.372662, Validation loss: 1.3770, lr: 0.0000\n",
      "Epoch: 124, Training loss: 1.369813, Validation loss: 1.3645, lr: 0.0000\n",
      "Epoch: 125, Training loss: 1.350177, Validation loss: 1.3714, lr: 0.0000\n",
      "Epoch: 126, Training loss: 1.373969, Validation loss: 1.3723, lr: 0.0000\n",
      "Epoch: 127, Training loss: 1.354005, Validation loss: 1.3916, lr: 0.0000\n",
      "Epoch: 128, Training loss: 1.371452, Validation loss: 1.3593, lr: 0.0000\n",
      "Epoch: 129, Training loss: 1.359147, Validation loss: 1.3672, lr: 0.0000\n",
      "Epoch: 130, Training loss: 1.340489, Validation loss: 1.3718, lr: 0.0000\n",
      "Epoch: 131, Training loss: 1.379292, Validation loss: 1.3529, lr: 0.0000\n",
      "Epoch: 132, Training loss: 1.361226, Validation loss: 1.3748, lr: 0.0000\n",
      "Epoch: 133, Training loss: 1.335751, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 134, Training loss: 1.351118, Validation loss: 1.3776, lr: 0.0000\n",
      "Epoch: 135, Training loss: 1.349189, Validation loss: 1.3724, lr: 0.0000\n",
      "Epoch: 136, Training loss: 1.365086, Validation loss: 1.4048, lr: 0.0000\n",
      "Epoch: 137, Training loss: 1.376789, Validation loss: 1.3517, lr: 0.0000\n",
      "Epoch: 138, Training loss: 1.354162, Validation loss: 1.3599, lr: 0.0000\n",
      "Epoch: 139, Training loss: 1.377368, Validation loss: 1.4403, lr: 0.0000\n",
      "Epoch: 140, Training loss: 1.378792, Validation loss: 1.3796, lr: 0.0000\n",
      "Epoch: 141, Training loss: 1.382956, Validation loss: 1.3445, lr: 0.0000\n",
      "Epoch: 142, Training loss: 1.349188, Validation loss: 1.3670, lr: 0.0000\n",
      "Epoch: 143, Training loss: 1.374704, Validation loss: 1.3762, lr: 0.0000\n",
      "Epoch: 144, Training loss: 1.355979, Validation loss: 1.3761, lr: 0.0000\n",
      "Epoch: 145, Training loss: 1.362347, Validation loss: 1.3872, lr: 0.0000\n",
      "Epoch: 146, Training loss: 1.345664, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 147, Training loss: 1.378197, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 148, Training loss: 1.366128, Validation loss: 1.3731, lr: 0.0000\n",
      "Epoch: 149, Training loss: 1.349732, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 150, Training loss: 1.382667, Validation loss: 1.3566, lr: 0.0000\n",
      "Epoch: 151, Training loss: 1.375407, Validation loss: 1.3684, lr: 0.0000\n",
      "Epoch: 152, Training loss: 1.356622, Validation loss: 1.3675, lr: 0.0000\n",
      "Epoch: 153, Training loss: 1.362473, Validation loss: 1.3796, lr: 0.0000\n",
      "Epoch: 154, Training loss: 1.355314, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 155, Training loss: 1.375475, Validation loss: 1.3692, lr: 0.0000\n",
      " *och: 156, Training loss: 1.349623, Validation loss: 1.3173, lr: 0.0000\n",
      "Epoch: 157, Training loss: 1.379552, Validation loss: 1.3652, lr: 0.0000\n",
      "Epoch: 158, Training loss: 1.366014, Validation loss: 1.3678, lr: 0.0000\n",
      "Epoch: 159, Training loss: 1.385778, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 160, Training loss: 1.370729, Validation loss: 1.3609, lr: 0.0000\n",
      "Epoch: 161, Training loss: 1.335937, Validation loss: 1.3798, lr: 0.0000\n",
      "Epoch: 162, Training loss: 1.369608, Validation loss: 1.3778, lr: 0.0000\n",
      "Epoch: 163, Training loss: 1.349669, Validation loss: 1.3761, lr: 0.0000\n",
      "Epoch: 164, Training loss: 1.401489, Validation loss: 1.3754, lr: 0.0000\n",
      "Epoch: 165, Training loss: 1.355722, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 166, Training loss: 1.405291, Validation loss: 1.3886, lr: 0.0000\n",
      "Epoch: 167, Training loss: 1.361741, Validation loss: 1.3643, lr: 0.0000\n",
      "Epoch: 168, Training loss: 1.343591, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 169, Training loss: 1.381496, Validation loss: 1.3756, lr: 0.0000\n",
      "Epoch: 170, Training loss: 1.389827, Validation loss: 1.3981, lr: 0.0000\n",
      "Epoch: 171, Training loss: 1.352654, Validation loss: 1.3749, lr: 0.0000\n",
      "Epoch: 172, Training loss: 1.361900, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 173, Training loss: 1.399092, Validation loss: 1.3778, lr: 0.0000\n",
      "Epoch: 174, Training loss: 1.390679, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 175, Training loss: 1.372996, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 176, Training loss: 1.399514, Validation loss: 1.3614, lr: 0.0000\n",
      "Epoch: 177, Training loss: 1.358728, Validation loss: 1.3735, lr: 0.0000\n",
      "Epoch: 178, Training loss: 1.347606, Validation loss: 1.3742, lr: 0.0000\n",
      "Epoch: 179, Training loss: 1.368300, Validation loss: 1.3756, lr: 0.0000\n",
      "Epoch: 180, Training loss: 1.351418, Validation loss: 1.3703, lr: 0.0000\n",
      "Epoch: 181, Training loss: 1.366433, Validation loss: 1.3796, lr: 0.0000\n",
      "Epoch: 182, Training loss: 1.366628, Validation loss: 1.3525, lr: 0.0000\n",
      "Epoch: 183, Training loss: 1.343411, Validation loss: 1.3704, lr: 0.0000\n",
      "Epoch: 184, Training loss: 1.374198, Validation loss: 1.3755, lr: 0.0000\n",
      "Epoch: 185, Training loss: 1.444838, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 186, Training loss: 1.355275, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 187, Training loss: 1.351655, Validation loss: 1.3524, lr: 0.0000\n",
      "Epoch: 188, Training loss: 1.414768, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 189, Training loss: 1.358592, Validation loss: 1.3756, lr: 0.0000\n",
      "Epoch: 190, Training loss: 1.370159, Validation loss: 1.3751, lr: 0.0000\n",
      "Epoch: 191, Training loss: 1.360673, Validation loss: 1.3582, lr: 0.0000\n",
      "Epoch: 192, Training loss: 1.355700, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 193, Training loss: 1.379177, Validation loss: 1.3795, lr: 0.0000\n",
      "Epoch: 194, Training loss: 1.356463, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 195, Training loss: 1.371912, Validation loss: 1.4235, lr: 0.0000\n",
      "Epoch: 196, Training loss: 1.342621, Validation loss: 1.3713, lr: 0.0000\n",
      "Epoch: 197, Training loss: 1.488278, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 198, Training loss: 1.360797, Validation loss: 1.3795, lr: 0.0000\n",
      "Epoch: 199, Training loss: 1.340350, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 200, Training loss: 1.338273, Validation loss: 1.3788, lr: 0.0000\n",
      "Epoch: 201, Training loss: 1.355360, Validation loss: 1.3809, lr: 0.0000\n",
      "Epoch: 202, Training loss: 1.356527, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 203, Training loss: 1.345466, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 204, Training loss: 1.341349, Validation loss: 1.3796, lr: 0.0000\n",
      "Epoch: 205, Training loss: 1.367375, Validation loss: 1.3768, lr: 0.0000\n",
      "Epoch: 206, Training loss: 1.360847, Validation loss: 1.3654, lr: 0.0000\n",
      "Epoch: 207, Training loss: 1.395296, Validation loss: 1.3667, lr: 0.0000\n",
      "Epoch: 208, Training loss: 1.357122, Validation loss: 1.3792, lr: 0.0000\n",
      "Epoch: 209, Training loss: 1.398591, Validation loss: 1.3784, lr: 0.0000\n",
      "Epoch: 210, Training loss: 1.409021, Validation loss: 1.3875, lr: 0.0000\n",
      "Epoch: 211, Training loss: 1.355040, Validation loss: 1.4400, lr: 0.0000\n",
      "Epoch: 212, Training loss: 1.347110, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 213, Training loss: 1.339859, Validation loss: 1.3625, lr: 0.0000\n",
      "Epoch: 214, Training loss: 1.355067, Validation loss: 1.3798, lr: 0.0000\n",
      "Epoch: 215, Training loss: 1.353551, Validation loss: 1.3803, lr: 0.0000\n",
      "Epoch: 216, Training loss: 1.356183, Validation loss: 1.3383, lr: 0.0000\n",
      "Epoch: 217, Training loss: 1.358973, Validation loss: 1.3613, lr: 0.0000\n",
      "Epoch: 218, Training loss: 1.351865, Validation loss: 1.3606, lr: 0.0000\n",
      "Epoch: 219, Training loss: 1.405584, Validation loss: 1.3727, lr: 0.0000\n",
      "Epoch: 220, Training loss: 1.370188, Validation loss: 1.4009, lr: 0.0000\n",
      "Epoch: 221, Training loss: 1.376214, Validation loss: 1.3762, lr: 0.0000\n",
      "Epoch: 222, Training loss: 1.354561, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 223, Training loss: 1.360104, Validation loss: 1.3667, lr: 0.0000\n",
      "Epoch: 224, Training loss: 1.369091, Validation loss: 1.3731, lr: 0.0000\n",
      "Epoch: 225, Training loss: 1.352603, Validation loss: 1.3466, lr: 0.0000\n",
      "Epoch: 226, Training loss: 1.403994, Validation loss: 1.3685, lr: 0.0000\n",
      "Epoch: 227, Training loss: 1.352488, Validation loss: 1.3746, lr: 0.0000\n",
      "Epoch: 228, Training loss: 1.353725, Validation loss: 1.3758, lr: 0.0000\n",
      "Epoch: 229, Training loss: 1.343446, Validation loss: 1.3945, lr: 0.0000\n",
      "Epoch: 230, Training loss: 1.359301, Validation loss: 1.3779, lr: 0.0000\n",
      "Epoch: 231, Training loss: 1.347867, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 232, Training loss: 1.359849, Validation loss: 1.3592, lr: 0.0000\n",
      "Epoch: 233, Training loss: 1.367370, Validation loss: 1.3548, lr: 0.0000\n",
      "Epoch: 234, Training loss: 1.381366, Validation loss: 1.3623, lr: 0.0000\n",
      "Epoch: 235, Training loss: 1.352980, Validation loss: 1.3777, lr: 0.0000\n",
      "Epoch: 236, Training loss: 1.376374, Validation loss: 1.3758, lr: 0.0000\n",
      "Epoch: 237, Training loss: 1.369051, Validation loss: 1.3741, lr: 0.0000\n",
      "Epoch: 238, Training loss: 1.358812, Validation loss: 1.3657, lr: 0.0000\n",
      "Epoch: 239, Training loss: 1.355154, Validation loss: 1.4515, lr: 0.0000\n",
      "Epoch: 240, Training loss: 1.366402, Validation loss: 1.3702, lr: 0.0000\n",
      "Epoch: 241, Training loss: 1.405643, Validation loss: 1.3803, lr: 0.0000\n",
      "Epoch: 242, Training loss: 1.432912, Validation loss: 1.3748, lr: 0.0000\n",
      "Epoch: 243, Training loss: 1.366400, Validation loss: 1.3689, lr: 0.0000\n",
      "Epoch: 244, Training loss: 1.354887, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 245, Training loss: 1.374990, Validation loss: 1.3890, lr: 0.0000\n",
      "Epoch: 246, Training loss: 1.361089, Validation loss: 1.3713, lr: 0.0000\n",
      "Epoch: 247, Training loss: 1.372702, Validation loss: 1.3793, lr: 0.0000\n",
      "Epoch: 248, Training loss: 1.343235, Validation loss: 1.4381, lr: 0.0000\n",
      "Epoch: 249, Training loss: 1.340225, Validation loss: 1.3703, lr: 0.0000\n",
      "Epoch: 250, Training loss: 1.355985, Validation loss: 1.3743, lr: 0.0000\n",
      "Epoch: 251, Training loss: 1.344035, Validation loss: 1.3788, lr: 0.0000\n",
      "Epoch: 252, Training loss: 1.392477, Validation loss: 1.3432, lr: 0.0000\n",
      "Epoch: 253, Training loss: 1.353742, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 254, Training loss: 1.346103, Validation loss: 1.3770, lr: 0.0000\n",
      "Epoch: 255, Training loss: 1.343994, Validation loss: 1.3772, lr: 0.0000\n",
      "Epoch: 256, Training loss: 1.354236, Validation loss: 1.3771, lr: 0.0000\n",
      "Epoch: 257, Training loss: 1.345910, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 258, Training loss: 1.374832, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 259, Training loss: 1.347359, Validation loss: 1.3800, lr: 0.0000\n",
      "Epoch: 260, Training loss: 1.367114, Validation loss: 1.4334, lr: 0.0000\n",
      "Epoch: 261, Training loss: 1.354667, Validation loss: 1.3659, lr: 0.0000\n",
      "Epoch: 262, Training loss: 1.346598, Validation loss: 1.3591, lr: 0.0000\n",
      "Epoch: 263, Training loss: 1.415485, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 264, Training loss: 1.360640, Validation loss: 1.3650, lr: 0.0000\n",
      "Epoch: 265, Training loss: 1.398533, Validation loss: 1.3744, lr: 0.0000\n",
      "Epoch: 266, Training loss: 1.369197, Validation loss: 1.3973, lr: 0.0000\n",
      "Epoch: 267, Training loss: 1.361338, Validation loss: 1.3663, lr: 0.0000\n",
      "Epoch: 268, Training loss: 1.341217, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 269, Training loss: 1.334764, Validation loss: 1.3723, lr: 0.0000\n",
      "Epoch: 270, Training loss: 1.379049, Validation loss: 1.3678, lr: 0.0000\n",
      "Epoch: 271, Training loss: 1.387314, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 272, Training loss: 1.391746, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 273, Training loss: 1.392612, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 274, Training loss: 1.344475, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 275, Training loss: 1.355824, Validation loss: 1.3982, lr: 0.0000\n",
      "Epoch: 276, Training loss: 1.353520, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 277, Training loss: 1.359942, Validation loss: 1.3879, lr: 0.0000\n",
      "Epoch: 278, Training loss: 1.371919, Validation loss: 1.3762, lr: 0.0000\n",
      "Epoch: 279, Training loss: 1.370108, Validation loss: 1.3600, lr: 0.0000\n",
      "Epoch: 280, Training loss: 1.351026, Validation loss: 1.3632, lr: 0.0000\n",
      "Epoch: 281, Training loss: 1.382229, Validation loss: 1.4053, lr: 0.0000\n",
      "Epoch: 282, Training loss: 1.351441, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 283, Training loss: 1.339354, Validation loss: 1.3654, lr: 0.0000\n",
      "Epoch: 284, Training loss: 1.358251, Validation loss: 1.3756, lr: 0.0000\n",
      "Epoch: 285, Training loss: 1.361694, Validation loss: 1.3802, lr: 0.0000\n",
      "Epoch: 286, Training loss: 1.360775, Validation loss: 1.3874, lr: 0.0000\n",
      "Epoch: 287, Training loss: 1.383896, Validation loss: 1.3783, lr: 0.0000\n",
      "Epoch: 288, Training loss: 1.340542, Validation loss: 1.3549, lr: 0.0000\n",
      "Epoch: 289, Training loss: 1.359021, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 290, Training loss: 1.378399, Validation loss: 1.3765, lr: 0.0000\n",
      "Epoch: 291, Training loss: 1.353927, Validation loss: 1.3969, lr: 0.0000\n",
      "Epoch: 292, Training loss: 1.366589, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 293, Training loss: 1.377239, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 294, Training loss: 1.366942, Validation loss: 1.3763, lr: 0.0000\n",
      "Epoch: 295, Training loss: 1.407740, Validation loss: 1.3911, lr: 0.0000\n",
      "Epoch: 296, Training loss: 1.354467, Validation loss: 1.3776, lr: 0.0000\n",
      "Epoch: 297, Training loss: 1.350522, Validation loss: 1.4167, lr: 0.0000\n",
      "Epoch: 298, Training loss: 1.347564, Validation loss: 1.3908, lr: 0.0000\n",
      "Epoch: 299, Training loss: 1.314250, Validation loss: 1.3713, lr: 0.0000\n",
      "Epoch: 300, Training loss: 1.350200, Validation loss: 1.3941, lr: 0.0000\n",
      "Epoch: 301, Training loss: 1.373585, Validation loss: 1.3443, lr: 0.0000\n",
      "Epoch: 302, Training loss: 1.341139, Validation loss: 1.3527, lr: 0.0000\n",
      "Epoch: 303, Training loss: 1.372139, Validation loss: 1.3434, lr: 0.0000\n",
      "Epoch: 304, Training loss: 1.342880, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 305, Training loss: 1.375141, Validation loss: 1.3755, lr: 0.0000\n",
      "Epoch: 306, Training loss: 1.337562, Validation loss: 1.3715, lr: 0.0000\n",
      "Epoch: 307, Training loss: 1.363697, Validation loss: 1.3792, lr: 0.0000\n",
      "Epoch: 308, Training loss: 1.343166, Validation loss: 1.3796, lr: 0.0000\n",
      "Epoch: 309, Training loss: 1.324357, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 310, Training loss: 1.380698, Validation loss: 1.3879, lr: 0.0000\n",
      "Epoch: 311, Training loss: 1.399083, Validation loss: 1.3730, lr: 0.0000\n",
      "Epoch: 312, Training loss: 1.337510, Validation loss: 1.4037, lr: 0.0000\n",
      "Epoch: 313, Training loss: 1.350116, Validation loss: 1.3735, lr: 0.0000\n",
      "Epoch: 314, Training loss: 1.447819, Validation loss: 1.3743, lr: 0.0000\n",
      "Epoch: 315, Training loss: 1.341635, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 316, Training loss: 1.356609, Validation loss: 1.3555, lr: 0.0000\n",
      "Epoch: 317, Training loss: 1.351067, Validation loss: 1.3771, lr: 0.0000\n",
      "Epoch: 318, Training loss: 1.359036, Validation loss: 1.3756, lr: 0.0000\n",
      "Epoch: 319, Training loss: 1.422191, Validation loss: 1.3602, lr: 0.0000\n",
      "Epoch: 320, Training loss: 1.386547, Validation loss: 1.3709, lr: 0.0000\n",
      "Epoch: 321, Training loss: 1.370247, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 322, Training loss: 1.375851, Validation loss: 1.3687, lr: 0.0000\n",
      "Epoch: 323, Training loss: 1.360884, Validation loss: 1.3770, lr: 0.0000\n",
      "Epoch: 324, Training loss: 1.369029, Validation loss: 1.3619, lr: 0.0000\n",
      "Epoch: 325, Training loss: 1.365380, Validation loss: 1.3745, lr: 0.0000\n",
      "Epoch: 326, Training loss: 1.351721, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 327, Training loss: 1.382775, Validation loss: 1.3956, lr: 0.0000\n",
      "Epoch: 328, Training loss: 1.366777, Validation loss: 1.3634, lr: 0.0000\n",
      "Epoch: 329, Training loss: 1.352847, Validation loss: 1.3729, lr: 0.0000\n",
      "Epoch: 330, Training loss: 1.358212, Validation loss: 1.3591, lr: 0.0000\n",
      "Epoch: 331, Training loss: 1.351959, Validation loss: 1.3731, lr: 0.0000\n",
      "Epoch: 332, Training loss: 1.360480, Validation loss: 1.3613, lr: 0.0000\n",
      "Epoch: 333, Training loss: 1.383348, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 334, Training loss: 1.360214, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 335, Training loss: 1.362403, Validation loss: 1.3707, lr: 0.0000\n",
      "Epoch: 336, Training loss: 1.360150, Validation loss: 1.3692, lr: 0.0000\n",
      "Epoch: 337, Training loss: 1.378225, Validation loss: 1.3579, lr: 0.0000\n",
      "Epoch: 338, Training loss: 1.376914, Validation loss: 1.3726, lr: 0.0000\n",
      "Epoch: 339, Training loss: 1.310197, Validation loss: 1.3936, lr: 0.0000\n",
      "Epoch: 340, Training loss: 1.359346, Validation loss: 1.3723, lr: 0.0000\n",
      "Epoch: 341, Training loss: 1.341155, Validation loss: 1.3697, lr: 0.0000\n",
      "Epoch: 342, Training loss: 1.366810, Validation loss: 1.3697, lr: 0.0000\n",
      "Epoch: 343, Training loss: 1.355304, Validation loss: 1.3576, lr: 0.0000\n",
      "Epoch: 344, Training loss: 1.356408, Validation loss: 1.4053, lr: 0.0000\n",
      "Epoch: 345, Training loss: 1.345155, Validation loss: 1.3902, lr: 0.0000\n",
      "Epoch: 346, Training loss: 1.331494, Validation loss: 1.3513, lr: 0.0000\n",
      "Epoch: 347, Training loss: 1.349878, Validation loss: 1.3753, lr: 0.0000\n",
      "Epoch: 348, Training loss: 1.348554, Validation loss: 1.3737, lr: 0.0000\n",
      "Epoch: 349, Training loss: 1.360886, Validation loss: 1.3716, lr: 0.0000\n",
      "Epoch: 350, Training loss: 1.342961, Validation loss: 1.3692, lr: 0.0000\n",
      "Epoch: 351, Training loss: 1.356659, Validation loss: 1.3678, lr: 0.0000\n",
      "Epoch: 352, Training loss: 1.362637, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 353, Training loss: 1.429350, Validation loss: 1.3760, lr: 0.0000\n",
      "Epoch: 354, Training loss: 1.353730, Validation loss: 1.3891, lr: 0.0000\n",
      "Epoch: 355, Training loss: 1.449698, Validation loss: 1.3795, lr: 0.0000\n",
      "Epoch: 356, Training loss: 1.436959, Validation loss: 1.3667, lr: 0.0000\n",
      "Epoch: 357, Training loss: 1.359841, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 358, Training loss: 1.362020, Validation loss: 1.3767, lr: 0.0000\n",
      "Epoch: 359, Training loss: 1.375465, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 360, Training loss: 1.346580, Validation loss: 1.3736, lr: 0.0000\n",
      "Epoch: 361, Training loss: 1.398889, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 362, Training loss: 1.373632, Validation loss: 1.3773, lr: 0.0000\n",
      "Epoch: 363, Training loss: 1.363086, Validation loss: 1.3777, lr: 0.0000\n",
      "Epoch: 364, Training loss: 1.383181, Validation loss: 1.3809, lr: 0.0000\n",
      "Epoch: 365, Training loss: 1.362768, Validation loss: 1.3775, lr: 0.0000\n",
      "Epoch: 366, Training loss: 1.363354, Validation loss: 1.3732, lr: 0.0000\n",
      "Epoch: 367, Training loss: 1.369619, Validation loss: 1.3618, lr: 0.0000\n",
      " *och: 368, Training loss: 1.354286, Validation loss: 1.2977, lr: 0.0000\n",
      "Epoch: 369, Training loss: 1.351577, Validation loss: 1.3726, lr: 0.0000\n",
      "Epoch: 370, Training loss: 1.338614, Validation loss: 1.3995, lr: 0.0000\n",
      "Epoch: 371, Training loss: 1.367053, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 372, Training loss: 1.360857, Validation loss: 1.3758, lr: 0.0000\n",
      "Epoch: 373, Training loss: 1.347796, Validation loss: 1.3778, lr: 0.0000\n",
      "Epoch: 374, Training loss: 1.356688, Validation loss: 1.3803, lr: 0.0000\n",
      "Epoch: 375, Training loss: 1.375240, Validation loss: 1.3788, lr: 0.0000\n",
      "Epoch: 376, Training loss: 1.364233, Validation loss: 1.3748, lr: 0.0000\n",
      "Epoch: 377, Training loss: 1.407126, Validation loss: 1.4042, lr: 0.0000\n",
      "Epoch: 378, Training loss: 1.351871, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 379, Training loss: 1.345486, Validation loss: 1.3656, lr: 0.0000\n",
      "Epoch: 380, Training loss: 1.343916, Validation loss: 1.4083, lr: 0.0000\n",
      "Epoch: 381, Training loss: 1.380910, Validation loss: 1.3641, lr: 0.0000\n",
      "Epoch: 382, Training loss: 1.380855, Validation loss: 1.3576, lr: 0.0000\n",
      "Epoch: 383, Training loss: 1.354495, Validation loss: 1.3787, lr: 0.0000\n",
      "Epoch: 384, Training loss: 1.365541, Validation loss: 1.3542, lr: 0.0000\n",
      "Epoch: 385, Training loss: 1.366382, Validation loss: 1.3994, lr: 0.0000\n",
      "Epoch: 386, Training loss: 1.382787, Validation loss: 1.3682, lr: 0.0000\n",
      "Epoch: 387, Training loss: 1.374000, Validation loss: 1.3778, lr: 0.0000\n",
      "Epoch: 388, Training loss: 1.358784, Validation loss: 1.3665, lr: 0.0000\n",
      "Epoch: 389, Training loss: 1.377808, Validation loss: 1.3508, lr: 0.0000\n",
      "Epoch: 390, Training loss: 1.358825, Validation loss: 1.3748, lr: 0.0000\n",
      "Epoch: 391, Training loss: 1.376182, Validation loss: 1.3636, lr: 0.0000\n",
      "Epoch: 392, Training loss: 1.353154, Validation loss: 1.3736, lr: 0.0000\n",
      "Epoch: 393, Training loss: 1.345929, Validation loss: 1.3669, lr: 0.0000\n",
      "Epoch: 394, Training loss: 1.368828, Validation loss: 1.3737, lr: 0.0000\n",
      "Epoch: 395, Training loss: 1.355094, Validation loss: 1.3759, lr: 0.0000\n",
      "Epoch: 396, Training loss: 1.363908, Validation loss: 1.3587, lr: 0.0000\n",
      "Epoch: 397, Training loss: 1.365279, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 398, Training loss: 1.376516, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 399, Training loss: 1.351303, Validation loss: 1.3769, lr: 0.0000\n",
      "Epoch: 400, Training loss: 1.370015, Validation loss: 1.3645, lr: 0.0000\n",
      "Epoch: 401, Training loss: 1.370876, Validation loss: 1.3710, lr: 0.0000\n",
      "Epoch: 402, Training loss: 1.352528, Validation loss: 1.3654, lr: 0.0000\n",
      "Epoch: 403, Training loss: 1.359839, Validation loss: 1.3698, lr: 0.0000\n",
      "Epoch: 404, Training loss: 1.355401, Validation loss: 1.3782, lr: 0.0000\n",
      "Epoch: 405, Training loss: 1.350794, Validation loss: 1.3785, lr: 0.0000\n",
      "Epoch: 406, Training loss: 1.355452, Validation loss: 1.3683, lr: 0.0000\n",
      "Epoch: 407, Training loss: 1.386150, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 408, Training loss: 1.368229, Validation loss: 1.3683, lr: 0.0000\n",
      "Epoch: 409, Training loss: 1.374149, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 410, Training loss: 1.375741, Validation loss: 1.3730, lr: 0.0000\n",
      "Epoch: 411, Training loss: 1.383641, Validation loss: 1.3597, lr: 0.0000\n",
      "Epoch: 412, Training loss: 1.398325, Validation loss: 1.3752, lr: 0.0000\n",
      "Epoch: 413, Training loss: 1.355818, Validation loss: 1.3608, lr: 0.0000\n",
      "Epoch: 414, Training loss: 1.434173, Validation loss: 1.3785, lr: 0.0000\n",
      "Epoch: 415, Training loss: 1.389935, Validation loss: 1.3771, lr: 0.0000\n",
      "Epoch: 416, Training loss: 1.366316, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 417, Training loss: 1.375942, Validation loss: 1.3695, lr: 0.0000\n",
      "Epoch: 418, Training loss: 1.365421, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 419, Training loss: 1.356439, Validation loss: 1.3079, lr: 0.0000\n",
      "Epoch: 420, Training loss: 1.340943, Validation loss: 1.3905, lr: 0.0000\n",
      "Epoch: 421, Training loss: 1.369720, Validation loss: 1.3735, lr: 0.0000\n",
      "Epoch: 422, Training loss: 1.378838, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 423, Training loss: 1.345894, Validation loss: 1.3744, lr: 0.0000\n",
      "Epoch: 424, Training loss: 1.338541, Validation loss: 1.3792, lr: 0.0000\n",
      "Epoch: 425, Training loss: 1.364260, Validation loss: 1.3537, lr: 0.0000\n",
      "Epoch: 426, Training loss: 1.346585, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 427, Training loss: 1.388444, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 428, Training loss: 1.365188, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 429, Training loss: 1.331614, Validation loss: 1.3699, lr: 0.0000\n",
      "Epoch: 430, Training loss: 1.430879, Validation loss: 1.3781, lr: 0.0000\n",
      "Epoch: 431, Training loss: 1.377446, Validation loss: 1.3765, lr: 0.0000\n",
      "Epoch: 432, Training loss: 1.341003, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 433, Training loss: 1.357450, Validation loss: 1.3789, lr: 0.0000\n",
      "Epoch: 434, Training loss: 1.340616, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 435, Training loss: 1.396610, Validation loss: 1.3975, lr: 0.0000\n",
      "Epoch: 436, Training loss: 1.347647, Validation loss: 1.3754, lr: 0.0000\n",
      "Epoch: 437, Training loss: 1.386676, Validation loss: 1.3616, lr: 0.0000\n",
      "Epoch: 438, Training loss: 1.399631, Validation loss: 1.3910, lr: 0.0000\n",
      "Epoch: 439, Training loss: 1.356954, Validation loss: 1.3534, lr: 0.0000\n",
      "Epoch: 440, Training loss: 1.352608, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 441, Training loss: 1.358833, Validation loss: 1.3672, lr: 0.0000\n",
      "Epoch: 442, Training loss: 1.351595, Validation loss: 1.3749, lr: 0.0000\n",
      "Epoch: 443, Training loss: 1.366214, Validation loss: 1.3560, lr: 0.0000\n",
      "Epoch: 444, Training loss: 1.339694, Validation loss: 1.3980, lr: 0.0000\n",
      "Epoch: 445, Training loss: 1.336729, Validation loss: 1.3792, lr: 0.0000\n",
      "Epoch: 446, Training loss: 1.345057, Validation loss: 1.3887, lr: 0.0000\n",
      "Epoch: 447, Training loss: 1.335943, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 448, Training loss: 1.365943, Validation loss: 1.3695, lr: 0.0000\n",
      "Epoch: 449, Training loss: 1.354503, Validation loss: 1.3603, lr: 0.0000\n",
      "Epoch: 450, Training loss: 1.395257, Validation loss: 1.3751, lr: 0.0000\n",
      "Epoch: 451, Training loss: 1.345507, Validation loss: 1.3710, lr: 0.0000\n",
      "Epoch: 452, Training loss: 1.459817, Validation loss: 1.3800, lr: 0.0000\n",
      "Epoch: 453, Training loss: 1.371391, Validation loss: 1.3723, lr: 0.0000\n",
      "Epoch: 454, Training loss: 1.381082, Validation loss: 1.3650, lr: 0.0000\n",
      "Epoch: 455, Training loss: 1.367436, Validation loss: 1.3744, lr: 0.0000\n",
      "Epoch: 456, Training loss: 1.388061, Validation loss: 1.3669, lr: 0.0000\n",
      "Epoch: 457, Training loss: 1.356580, Validation loss: 1.4080, lr: 0.0000\n",
      "Epoch: 458, Training loss: 1.372612, Validation loss: 1.3756, lr: 0.0000\n",
      "Epoch: 459, Training loss: 1.347903, Validation loss: 1.3595, lr: 0.0000\n",
      "Epoch: 460, Training loss: 1.371613, Validation loss: 1.3797, lr: 0.0000\n",
      "Epoch: 461, Training loss: 1.375142, Validation loss: 1.3753, lr: 0.0000\n",
      "Epoch: 462, Training loss: 1.318623, Validation loss: 1.3759, lr: 0.0000\n",
      "Epoch: 463, Training loss: 1.356580, Validation loss: 1.3546, lr: 0.0000\n",
      "Epoch: 464, Training loss: 1.349159, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 465, Training loss: 1.375554, Validation loss: 1.3911, lr: 0.0000\n",
      "Epoch: 466, Training loss: 1.380063, Validation loss: 1.3799, lr: 0.0000\n",
      "Epoch: 467, Training loss: 1.390818, Validation loss: 1.3715, lr: 0.0000\n",
      "Epoch: 468, Training loss: 1.367624, Validation loss: 1.4452, lr: 0.0000\n",
      "Epoch: 469, Training loss: 1.361582, Validation loss: 1.3794, lr: 0.0000\n",
      "Epoch: 470, Training loss: 1.370042, Validation loss: 1.3721, lr: 0.0000\n",
      "Epoch: 471, Training loss: 1.367292, Validation loss: 1.3783, lr: 0.0000\n",
      "Epoch: 472, Training loss: 1.407207, Validation loss: 1.3701, lr: 0.0000\n",
      "Epoch: 473, Training loss: 1.368514, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 474, Training loss: 1.349916, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 475, Training loss: 1.349438, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 476, Training loss: 1.366040, Validation loss: 1.3803, lr: 0.0000\n",
      "Epoch: 477, Training loss: 1.351353, Validation loss: 1.3687, lr: 0.0000\n",
      "Epoch: 478, Training loss: 1.364670, Validation loss: 1.3793, lr: 0.0000\n",
      "Epoch: 479, Training loss: 1.359537, Validation loss: 1.3700, lr: 0.0000\n",
      "Epoch: 480, Training loss: 1.343856, Validation loss: 1.3569, lr: 0.0000\n",
      "Epoch: 481, Training loss: 1.358270, Validation loss: 1.3780, lr: 0.0000\n",
      "Epoch: 482, Training loss: 1.360050, Validation loss: 1.3639, lr: 0.0000\n",
      "Epoch: 483, Training loss: 1.358027, Validation loss: 1.3655, lr: 0.0000\n",
      "Epoch: 484, Training loss: 1.388515, Validation loss: 1.3691, lr: 0.0000\n",
      "Epoch: 485, Training loss: 1.361308, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 486, Training loss: 1.382922, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 487, Training loss: 1.363613, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 488, Training loss: 1.348853, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 489, Training loss: 1.382889, Validation loss: 1.3787, lr: 0.0000\n",
      "Epoch: 490, Training loss: 1.356119, Validation loss: 1.3773, lr: 0.0000\n",
      "Epoch: 491, Training loss: 1.345218, Validation loss: 1.3747, lr: 0.0000\n",
      "Epoch: 492, Training loss: 1.334020, Validation loss: 1.3723, lr: 0.0000\n",
      "Epoch: 493, Training loss: 1.349192, Validation loss: 1.6392, lr: 0.0000\n",
      "Epoch: 494, Training loss: 1.364015, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 495, Training loss: 1.369350, Validation loss: 1.3944, lr: 0.0000\n",
      "Epoch: 496, Training loss: 1.355159, Validation loss: 1.3721, lr: 0.0000\n",
      "Epoch: 497, Training loss: 1.386068, Validation loss: 1.3786, lr: 0.0000\n",
      "Epoch: 498, Training loss: 1.359041, Validation loss: 1.3618, lr: 0.0000\n",
      "Epoch: 499, Training loss: 1.366201, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 500, Training loss: 1.370445, Validation loss: 1.3792, lr: 0.0000\n",
      "Epoch: 501, Training loss: 1.380656, Validation loss: 1.3753, lr: 0.0000\n",
      "Epoch: 502, Training loss: 1.395618, Validation loss: 1.3664, lr: 0.0000\n",
      "Epoch: 503, Training loss: 1.395759, Validation loss: 1.3724, lr: 0.0000\n",
      "Epoch: 504, Training loss: 1.360461, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 505, Training loss: 1.353786, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 506, Training loss: 1.365888, Validation loss: 1.3785, lr: 0.0000\n",
      "Epoch: 507, Training loss: 1.423456, Validation loss: 1.3636, lr: 0.0000\n",
      "Epoch: 508, Training loss: 1.400548, Validation loss: 1.3614, lr: 0.0000\n",
      "Epoch: 509, Training loss: 1.371278, Validation loss: 1.3893, lr: 0.0000\n",
      "Epoch: 510, Training loss: 1.345557, Validation loss: 1.3672, lr: 0.0000\n",
      "Epoch: 511, Training loss: 1.332540, Validation loss: 1.3644, lr: 0.0000\n",
      "Epoch: 512, Training loss: 1.391809, Validation loss: 1.3669, lr: 0.0000\n",
      "Epoch: 513, Training loss: 1.352805, Validation loss: 1.3731, lr: 0.0000\n",
      "Epoch: 514, Training loss: 1.362194, Validation loss: 1.3572, lr: 0.0000\n",
      "Epoch: 515, Training loss: 1.365133, Validation loss: 1.3894, lr: 0.0000\n",
      "Epoch: 516, Training loss: 1.448033, Validation loss: 1.7314, lr: 0.0000\n",
      "Epoch: 517, Training loss: 1.370554, Validation loss: 1.3590, lr: 0.0000\n",
      "Epoch: 518, Training loss: 1.339341, Validation loss: 1.4036, lr: 0.0000\n",
      "Epoch: 519, Training loss: 1.374747, Validation loss: 1.3311, lr: 0.0000\n",
      "Epoch: 520, Training loss: 1.361023, Validation loss: 1.3877, lr: 0.0000\n",
      "Epoch: 521, Training loss: 1.369461, Validation loss: 1.3899, lr: 0.0000\n",
      "Epoch: 522, Training loss: 1.396918, Validation loss: 1.3700, lr: 0.0000\n",
      "Epoch: 523, Training loss: 1.385385, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 524, Training loss: 1.390120, Validation loss: 1.3707, lr: 0.0000\n",
      "Epoch: 525, Training loss: 1.364750, Validation loss: 1.3559, lr: 0.0000\n",
      "Epoch: 526, Training loss: 1.363338, Validation loss: 1.3755, lr: 0.0000\n",
      "Epoch: 527, Training loss: 1.354438, Validation loss: 1.3676, lr: 0.0000\n",
      "Epoch: 528, Training loss: 1.372398, Validation loss: 1.3660, lr: 0.0000\n",
      "Epoch: 529, Training loss: 1.348809, Validation loss: 1.3655, lr: 0.0000\n",
      "Epoch: 530, Training loss: 1.344026, Validation loss: 1.3635, lr: 0.0000\n",
      "Epoch: 531, Training loss: 1.465849, Validation loss: 1.3354, lr: 0.0000\n",
      "Epoch: 532, Training loss: 1.354626, Validation loss: 1.3621, lr: 0.0000\n",
      "Epoch: 533, Training loss: 1.429028, Validation loss: 1.3739, lr: 0.0000\n",
      "Epoch: 534, Training loss: 1.368836, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 535, Training loss: 1.346144, Validation loss: 1.3958, lr: 0.0000\n",
      "Epoch: 536, Training loss: 1.342241, Validation loss: 1.3624, lr: 0.0000\n",
      "Epoch: 537, Training loss: 1.364723, Validation loss: 1.3653, lr: 0.0000\n",
      "Epoch: 538, Training loss: 1.349263, Validation loss: 1.3540, lr: 0.0000\n",
      "Epoch: 539, Training loss: 1.375201, Validation loss: 1.3986, lr: 0.0000\n",
      "Epoch: 540, Training loss: 1.380585, Validation loss: 1.3738, lr: 0.0000\n",
      "Epoch: 541, Training loss: 1.357342, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 542, Training loss: 1.372094, Validation loss: 1.3657, lr: 0.0000\n",
      "Epoch: 543, Training loss: 1.336566, Validation loss: 1.3802, lr: 0.0000\n",
      "Epoch: 544, Training loss: 1.394725, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 545, Training loss: 1.383464, Validation loss: 1.3766, lr: 0.0000\n",
      "Epoch: 546, Training loss: 1.368677, Validation loss: 1.3770, lr: 0.0000\n",
      "Epoch: 547, Training loss: 1.361917, Validation loss: 1.3744, lr: 0.0000\n",
      "Epoch: 548, Training loss: 1.398927, Validation loss: 1.3897, lr: 0.0000\n",
      "Epoch: 549, Training loss: 1.357451, Validation loss: 1.3614, lr: 0.0000\n",
      "Epoch: 550, Training loss: 1.373141, Validation loss: 1.3745, lr: 0.0000\n",
      "Epoch: 551, Training loss: 1.365603, Validation loss: 1.3769, lr: 0.0000\n",
      "Epoch: 552, Training loss: 1.351725, Validation loss: 1.3780, lr: 0.0000\n",
      "Epoch: 553, Training loss: 1.367987, Validation loss: 1.4319, lr: 0.0000\n",
      "Epoch: 554, Training loss: 1.364911, Validation loss: 1.3900, lr: 0.0000\n",
      "Epoch: 555, Training loss: 1.397796, Validation loss: 1.3597, lr: 0.0000\n",
      "Epoch: 556, Training loss: 1.344988, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 557, Training loss: 1.363606, Validation loss: 1.3346, lr: 0.0000\n",
      "Epoch: 558, Training loss: 1.350473, Validation loss: 1.3699, lr: 0.0000\n",
      "Epoch: 559, Training loss: 1.372311, Validation loss: 1.3796, lr: 0.0000\n",
      "Epoch: 560, Training loss: 1.371893, Validation loss: 1.3565, lr: 0.0000\n",
      "Epoch: 561, Training loss: 1.330482, Validation loss: 1.3655, lr: 0.0000\n",
      "Epoch: 562, Training loss: 1.336845, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 563, Training loss: 1.365834, Validation loss: 1.3784, lr: 0.0000\n",
      "Epoch: 564, Training loss: 1.396307, Validation loss: 1.3546, lr: 0.0000\n",
      "Epoch: 565, Training loss: 1.361507, Validation loss: 1.3759, lr: 0.0000\n",
      "Epoch: 566, Training loss: 1.387559, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 567, Training loss: 1.377352, Validation loss: 1.3739, lr: 0.0000\n",
      "Epoch: 568, Training loss: 1.379338, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 569, Training loss: 1.342333, Validation loss: 1.3773, lr: 0.0000\n",
      "Epoch: 570, Training loss: 1.348757, Validation loss: 1.4175, lr: 0.0000\n",
      "Epoch: 571, Training loss: 1.365016, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 572, Training loss: 1.327787, Validation loss: 1.3752, lr: 0.0000\n",
      "Epoch: 573, Training loss: 1.348078, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 574, Training loss: 1.348333, Validation loss: 1.3799, lr: 0.0000\n",
      "Epoch: 575, Training loss: 1.354853, Validation loss: 1.3599, lr: 0.0000\n",
      "Epoch: 576, Training loss: 1.397730, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 577, Training loss: 1.367722, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 578, Training loss: 1.353928, Validation loss: 1.3780, lr: 0.0000\n",
      "Epoch: 579, Training loss: 1.345212, Validation loss: 1.3741, lr: 0.0000\n",
      "Epoch: 580, Training loss: 1.361660, Validation loss: 1.3788, lr: 0.0000\n",
      "Epoch: 581, Training loss: 1.378540, Validation loss: 1.3903, lr: 0.0000\n",
      "Epoch: 582, Training loss: 1.369299, Validation loss: 1.3921, lr: 0.0000\n",
      "Epoch: 583, Training loss: 1.361245, Validation loss: 1.3712, lr: 0.0000\n",
      "Epoch: 584, Training loss: 1.379868, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 585, Training loss: 1.340440, Validation loss: 1.3631, lr: 0.0000\n",
      "Epoch: 586, Training loss: 1.365099, Validation loss: 1.3777, lr: 0.0000\n",
      "Epoch: 587, Training loss: 1.371240, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 588, Training loss: 1.351733, Validation loss: 1.3789, lr: 0.0000\n",
      "Epoch: 589, Training loss: 1.342957, Validation loss: 1.3673, lr: 0.0000\n",
      "Epoch: 590, Training loss: 1.374797, Validation loss: 1.3889, lr: 0.0000\n",
      "Epoch: 591, Training loss: 1.392757, Validation loss: 1.3766, lr: 0.0000\n",
      "Epoch: 592, Training loss: 1.362597, Validation loss: 1.3556, lr: 0.0000\n",
      "Epoch: 593, Training loss: 1.349824, Validation loss: 1.3559, lr: 0.0000\n",
      "Epoch: 594, Training loss: 1.385361, Validation loss: 1.3707, lr: 0.0000\n",
      "Epoch: 595, Training loss: 1.353288, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 596, Training loss: 1.362552, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 597, Training loss: 1.365824, Validation loss: 1.4149, lr: 0.0000\n",
      "Epoch: 598, Training loss: 1.338607, Validation loss: 1.3704, lr: 0.0000\n",
      "Epoch: 599, Training loss: 1.383112, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 600, Training loss: 1.402604, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 601, Training loss: 1.336318, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 602, Training loss: 1.355332, Validation loss: 1.3880, lr: 0.0000\n",
      "Epoch: 603, Training loss: 1.374334, Validation loss: 1.3571, lr: 0.0000\n",
      "Epoch: 604, Training loss: 1.361031, Validation loss: 1.3771, lr: 0.0000\n",
      "Epoch: 605, Training loss: 1.383014, Validation loss: 1.4182, lr: 0.0000\n",
      "Epoch: 606, Training loss: 1.359484, Validation loss: 1.3891, lr: 0.0000\n",
      "Epoch: 607, Training loss: 1.359789, Validation loss: 1.3779, lr: 0.0000\n",
      "Epoch: 608, Training loss: 1.326275, Validation loss: 1.3762, lr: 0.0000\n",
      "Epoch: 609, Training loss: 1.341473, Validation loss: 1.3743, lr: 0.0000\n",
      "Epoch: 610, Training loss: 1.374423, Validation loss: 1.3563, lr: 0.0000\n",
      "Epoch: 611, Training loss: 1.377165, Validation loss: 1.3760, lr: 0.0000\n",
      "Epoch: 612, Training loss: 1.393596, Validation loss: 1.3729, lr: 0.0000\n",
      "Epoch: 613, Training loss: 1.402840, Validation loss: 1.3802, lr: 0.0000\n",
      "Epoch: 614, Training loss: 1.358274, Validation loss: 1.3762, lr: 0.0000\n",
      "Epoch: 615, Training loss: 1.386716, Validation loss: 1.3786, lr: 0.0000\n",
      "Epoch: 616, Training loss: 1.396050, Validation loss: 1.3765, lr: 0.0000\n",
      "Epoch: 617, Training loss: 1.367903, Validation loss: 1.3771, lr: 0.0000\n",
      "Epoch: 618, Training loss: 1.336650, Validation loss: 1.3690, lr: 0.0000\n",
      "Epoch: 619, Training loss: 1.349295, Validation loss: 1.3684, lr: 0.0000\n",
      "Epoch: 620, Training loss: 1.372771, Validation loss: 1.3761, lr: 0.0000\n",
      "Epoch: 621, Training loss: 1.345752, Validation loss: 1.3660, lr: 0.0000\n",
      "Epoch: 622, Training loss: 1.376462, Validation loss: 1.3735, lr: 0.0000\n",
      "Epoch: 623, Training loss: 1.378037, Validation loss: 1.3735, lr: 0.0000\n",
      "Epoch: 624, Training loss: 1.385453, Validation loss: 1.3746, lr: 0.0000\n",
      "Epoch: 625, Training loss: 1.365118, Validation loss: 1.3784, lr: 0.0000\n",
      "Epoch: 626, Training loss: 1.381067, Validation loss: 1.3751, lr: 0.0000\n",
      "Epoch: 627, Training loss: 1.360860, Validation loss: 1.3785, lr: 0.0000\n",
      "Epoch: 628, Training loss: 1.373950, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 629, Training loss: 1.356681, Validation loss: 1.4013, lr: 0.0000\n",
      "Epoch: 630, Training loss: 1.376707, Validation loss: 1.3757, lr: 0.0000\n",
      "Epoch: 631, Training loss: 1.405235, Validation loss: 1.3750, lr: 0.0000\n",
      "Epoch: 632, Training loss: 1.367578, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 633, Training loss: 1.353168, Validation loss: 1.3930, lr: 0.0000\n",
      "Epoch: 634, Training loss: 1.390387, Validation loss: 1.3618, lr: 0.0000\n",
      "Epoch: 635, Training loss: 1.346056, Validation loss: 1.3429, lr: 0.0000\n",
      "Epoch: 636, Training loss: 1.371527, Validation loss: 1.3588, lr: 0.0000\n",
      "Epoch: 637, Training loss: 1.364091, Validation loss: 1.3729, lr: 0.0000\n",
      "Epoch: 638, Training loss: 1.332087, Validation loss: 1.3704, lr: 0.0000\n",
      "Epoch: 639, Training loss: 1.343866, Validation loss: 1.3800, lr: 0.0000\n",
      "Epoch: 640, Training loss: 1.347802, Validation loss: 1.3517, lr: 0.0000\n",
      "Epoch: 641, Training loss: 1.416695, Validation loss: 1.3803, lr: 0.0000\n",
      "Epoch: 642, Training loss: 1.320964, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 643, Training loss: 1.353159, Validation loss: 1.3730, lr: 0.0000\n",
      "Epoch: 644, Training loss: 1.380160, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 645, Training loss: 1.358828, Validation loss: 1.3691, lr: 0.0000\n",
      "Epoch: 646, Training loss: 1.379209, Validation loss: 1.3798, lr: 0.0000\n",
      "Epoch: 647, Training loss: 1.432277, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 648, Training loss: 1.365096, Validation loss: 1.3763, lr: 0.0000\n",
      "Epoch: 649, Training loss: 1.367804, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 650, Training loss: 1.376568, Validation loss: 1.3729, lr: 0.0000\n",
      "Epoch: 651, Training loss: 1.356960, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 652, Training loss: 1.334826, Validation loss: 1.3649, lr: 0.0000\n",
      "Epoch: 653, Training loss: 1.332472, Validation loss: 1.3305, lr: 0.0000\n",
      "Epoch: 654, Training loss: 1.476029, Validation loss: 1.3635, lr: 0.0000\n",
      "Epoch: 655, Training loss: 1.353684, Validation loss: 1.3735, lr: 0.0000\n",
      "Epoch: 656, Training loss: 1.395044, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 657, Training loss: 1.373000, Validation loss: 1.3767, lr: 0.0000\n",
      "Epoch: 658, Training loss: 1.327034, Validation loss: 1.4306, lr: 0.0000\n",
      "Epoch: 659, Training loss: 1.383855, Validation loss: 1.3546, lr: 0.0000\n",
      "Epoch: 660, Training loss: 1.356500, Validation loss: 1.3515, lr: 0.0000\n",
      "Epoch: 661, Training loss: 1.362678, Validation loss: 1.3731, lr: 0.0000\n",
      "Epoch: 662, Training loss: 1.376524, Validation loss: 1.3693, lr: 0.0000\n",
      "Epoch: 663, Training loss: 1.407950, Validation loss: 1.3782, lr: 0.0000\n",
      "Epoch: 664, Training loss: 1.344852, Validation loss: 1.3700, lr: 0.0000\n",
      "Epoch: 665, Training loss: 1.371657, Validation loss: 1.3792, lr: 0.0000\n",
      "Epoch: 666, Training loss: 1.364315, Validation loss: 1.3631, lr: 0.0000\n",
      "Epoch: 667, Training loss: 1.368998, Validation loss: 1.3688, lr: 0.0000\n",
      "Epoch: 668, Training loss: 1.364547, Validation loss: 1.3448, lr: 0.0000\n",
      "Epoch: 669, Training loss: 1.371170, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 670, Training loss: 1.340298, Validation loss: 1.3795, lr: 0.0000\n",
      "Epoch: 671, Training loss: 1.348255, Validation loss: 1.3754, lr: 0.0000\n",
      "Epoch: 672, Training loss: 1.341745, Validation loss: 1.3394, lr: 0.0000\n",
      "Epoch: 673, Training loss: 1.351803, Validation loss: 1.4040, lr: 0.0000\n",
      "Epoch: 674, Training loss: 1.372595, Validation loss: 1.3719, lr: 0.0000\n",
      "Epoch: 675, Training loss: 1.372110, Validation loss: 1.3720, lr: 0.0000\n",
      "Epoch: 676, Training loss: 1.382933, Validation loss: 1.3781, lr: 0.0000\n",
      "Epoch: 677, Training loss: 1.361922, Validation loss: 1.3707, lr: 0.0000\n",
      "Epoch: 678, Training loss: 1.371538, Validation loss: 1.3717, lr: 0.0000\n",
      "Epoch: 679, Training loss: 1.380729, Validation loss: 1.3800, lr: 0.0000\n",
      "Epoch: 680, Training loss: 1.346875, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 681, Training loss: 1.375867, Validation loss: 1.3717, lr: 0.0000\n",
      "Epoch: 682, Training loss: 1.370846, Validation loss: 1.3736, lr: 0.0000\n",
      "Epoch: 683, Training loss: 1.384918, Validation loss: 1.3664, lr: 0.0000\n",
      "Epoch: 684, Training loss: 1.356003, Validation loss: 1.3538, lr: 0.0000\n",
      "Epoch: 685, Training loss: 1.373427, Validation loss: 1.3746, lr: 0.0000\n",
      "Epoch: 686, Training loss: 1.370223, Validation loss: 1.3736, lr: 0.0000\n",
      "Epoch: 687, Training loss: 1.369544, Validation loss: 1.3762, lr: 0.0000\n",
      "Epoch: 688, Training loss: 1.317702, Validation loss: 1.3380, lr: 0.0000\n",
      "Epoch: 689, Training loss: 1.324975, Validation loss: 1.3749, lr: 0.0000\n",
      "Epoch: 690, Training loss: 1.405228, Validation loss: 1.3640, lr: 0.0000\n",
      "Epoch: 691, Training loss: 1.363878, Validation loss: 1.3800, lr: 0.0000\n",
      "Epoch: 692, Training loss: 1.365640, Validation loss: 1.3465, lr: 0.0000\n",
      "Epoch: 693, Training loss: 1.416719, Validation loss: 1.3543, lr: 0.0000\n",
      "Epoch: 694, Training loss: 1.353645, Validation loss: 1.3631, lr: 0.0000\n",
      "Epoch: 695, Training loss: 1.329253, Validation loss: 1.3742, lr: 0.0000\n",
      "Epoch: 696, Training loss: 1.351252, Validation loss: 1.3645, lr: 0.0000\n",
      "Epoch: 697, Training loss: 1.368565, Validation loss: 1.3752, lr: 0.0000\n",
      "Epoch: 698, Training loss: 1.371517, Validation loss: 1.3705, lr: 0.0000\n",
      "Epoch: 699, Training loss: 1.370917, Validation loss: 1.3885, lr: 0.0000\n",
      "Epoch: 700, Training loss: 1.339201, Validation loss: 1.3732, lr: 0.0000\n",
      "Epoch: 701, Training loss: 1.370030, Validation loss: 1.3781, lr: 0.0000\n",
      "Epoch: 702, Training loss: 1.348002, Validation loss: 1.3527, lr: 0.0000\n",
      "Epoch: 703, Training loss: 1.364416, Validation loss: 1.3786, lr: 0.0000\n",
      "Epoch: 704, Training loss: 1.407559, Validation loss: 1.3750, lr: 0.0000\n",
      "Epoch: 705, Training loss: 1.351672, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 706, Training loss: 1.371438, Validation loss: 1.3731, lr: 0.0000\n",
      "Epoch: 707, Training loss: 1.359353, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 708, Training loss: 1.355369, Validation loss: 1.3656, lr: 0.0000\n",
      "Epoch: 709, Training loss: 1.408623, Validation loss: 1.3678, lr: 0.0000\n",
      "Epoch: 710, Training loss: 1.353543, Validation loss: 1.3568, lr: 0.0000\n",
      "Epoch: 711, Training loss: 1.378035, Validation loss: 1.3787, lr: 0.0000\n",
      "Epoch: 712, Training loss: 1.379382, Validation loss: 1.3762, lr: 0.0000\n",
      "Epoch: 713, Training loss: 1.347081, Validation loss: 1.3704, lr: 0.0000\n",
      "Epoch: 714, Training loss: 1.354188, Validation loss: 1.3781, lr: 0.0000\n",
      "Epoch: 715, Training loss: 1.342269, Validation loss: 1.3637, lr: 0.0000\n",
      "Epoch: 716, Training loss: 1.366379, Validation loss: 1.3677, lr: 0.0000\n",
      "Epoch: 717, Training loss: 1.357148, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 718, Training loss: 1.379902, Validation loss: 1.3771, lr: 0.0000\n",
      "Epoch: 719, Training loss: 1.355990, Validation loss: 1.3745, lr: 0.0000\n",
      "Epoch: 720, Training loss: 1.330630, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 721, Training loss: 1.427318, Validation loss: 1.3674, lr: 0.0000\n",
      "Epoch: 722, Training loss: 1.342151, Validation loss: 1.3732, lr: 0.0000\n",
      "Epoch: 723, Training loss: 1.358096, Validation loss: 1.3510, lr: 0.0000\n",
      "Epoch: 724, Training loss: 1.348319, Validation loss: 1.3748, lr: 0.0000\n",
      "Epoch: 725, Training loss: 1.363726, Validation loss: 1.3599, lr: 0.0000\n",
      "Epoch: 726, Training loss: 1.347808, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 727, Training loss: 1.388348, Validation loss: 1.3771, lr: 0.0000\n",
      "Epoch: 728, Training loss: 1.352303, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 729, Training loss: 1.357772, Validation loss: 1.4418, lr: 0.0000\n",
      "Epoch: 730, Training loss: 1.342902, Validation loss: 1.3757, lr: 0.0000\n",
      "Epoch: 731, Training loss: 1.386074, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 732, Training loss: 1.357325, Validation loss: 1.3897, lr: 0.0000\n",
      "Epoch: 733, Training loss: 1.336942, Validation loss: 1.3539, lr: 0.0000\n",
      "Epoch: 734, Training loss: 1.404144, Validation loss: 1.3551, lr: 0.0000\n",
      "Epoch: 735, Training loss: 1.364501, Validation loss: 1.3747, lr: 0.0000\n",
      "Epoch: 736, Training loss: 1.362480, Validation loss: 1.3891, lr: 0.0000\n",
      "Epoch: 737, Training loss: 1.373090, Validation loss: 1.3716, lr: 0.0000\n",
      "Epoch: 738, Training loss: 1.334409, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 739, Training loss: 1.383996, Validation loss: 1.4106, lr: 0.0000\n",
      "Epoch: 740, Training loss: 1.333571, Validation loss: 1.3775, lr: 0.0000\n",
      "Epoch: 741, Training loss: 1.365833, Validation loss: 1.4067, lr: 0.0000\n",
      "Epoch: 742, Training loss: 1.339749, Validation loss: 1.3702, lr: 0.0000\n",
      "Epoch: 743, Training loss: 1.363251, Validation loss: 1.3769, lr: 0.0000\n",
      "Epoch: 744, Training loss: 1.373587, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 745, Training loss: 1.343456, Validation loss: 1.3930, lr: 0.0000\n",
      "Epoch: 746, Training loss: 1.399009, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 747, Training loss: 1.380203, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 748, Training loss: 1.357456, Validation loss: 1.3646, lr: 0.0000\n",
      "Epoch: 749, Training loss: 1.353149, Validation loss: 1.3767, lr: 0.0000\n",
      "Epoch: 750, Training loss: 1.380306, Validation loss: 1.3741, lr: 0.0000\n",
      "Epoch: 751, Training loss: 1.348875, Validation loss: 1.3959, lr: 0.0000\n",
      "Epoch: 752, Training loss: 1.347311, Validation loss: 1.3689, lr: 0.0000\n",
      "Epoch: 753, Training loss: 1.398023, Validation loss: 1.3598, lr: 0.0000\n",
      "Epoch: 754, Training loss: 1.367943, Validation loss: 1.3487, lr: 0.0000\n",
      "Epoch: 755, Training loss: 1.327967, Validation loss: 1.4982, lr: 0.0000\n",
      "Epoch: 756, Training loss: 1.352856, Validation loss: 1.3388, lr: 0.0000\n",
      "Epoch: 757, Training loss: 1.407944, Validation loss: 1.3941, lr: 0.0000\n",
      "Epoch: 758, Training loss: 1.336622, Validation loss: 1.3800, lr: 0.0000\n",
      "Epoch: 759, Training loss: 1.366226, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 760, Training loss: 1.335073, Validation loss: 1.3373, lr: 0.0000\n",
      "Epoch: 761, Training loss: 1.344742, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 762, Training loss: 1.396079, Validation loss: 1.3762, lr: 0.0000\n",
      "Epoch: 763, Training loss: 1.363788, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 764, Training loss: 1.363525, Validation loss: 1.3898, lr: 0.0000\n",
      "Epoch: 765, Training loss: 1.360992, Validation loss: 1.3962, lr: 0.0000\n",
      "Epoch: 766, Training loss: 1.366396, Validation loss: 1.3724, lr: 0.0000\n",
      "Epoch: 767, Training loss: 1.372392, Validation loss: 1.4014, lr: 0.0000\n",
      "Epoch: 768, Training loss: 1.363539, Validation loss: 1.3908, lr: 0.0000\n",
      "Epoch: 769, Training loss: 1.357679, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 770, Training loss: 1.345169, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 771, Training loss: 1.369456, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 772, Training loss: 1.366326, Validation loss: 1.3803, lr: 0.0000\n",
      "Epoch: 773, Training loss: 1.361978, Validation loss: 1.3627, lr: 0.0000\n",
      "Epoch: 774, Training loss: 1.373459, Validation loss: 1.3709, lr: 0.0000\n",
      "Epoch: 775, Training loss: 1.329049, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 776, Training loss: 1.370362, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 777, Training loss: 1.334048, Validation loss: 1.3697, lr: 0.0000\n",
      "Epoch: 778, Training loss: 1.409888, Validation loss: 1.3567, lr: 0.0000\n",
      "Epoch: 779, Training loss: 1.360023, Validation loss: 1.3685, lr: 0.0000\n",
      "Epoch: 780, Training loss: 1.344406, Validation loss: 1.3768, lr: 0.0000\n",
      "Epoch: 781, Training loss: 1.373846, Validation loss: 1.3788, lr: 0.0000\n",
      "Epoch: 782, Training loss: 1.349909, Validation loss: 1.3729, lr: 0.0000\n",
      "Epoch: 783, Training loss: 1.351896, Validation loss: 1.3506, lr: 0.0000\n",
      "Epoch: 784, Training loss: 1.345706, Validation loss: 1.3592, lr: 0.0000\n",
      "Epoch: 785, Training loss: 1.341601, Validation loss: 1.3712, lr: 0.0000\n",
      "Epoch: 786, Training loss: 1.378752, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 787, Training loss: 1.353185, Validation loss: 1.3764, lr: 0.0000\n",
      "Epoch: 788, Training loss: 1.395710, Validation loss: 1.3794, lr: 0.0000\n",
      "Epoch: 789, Training loss: 1.366756, Validation loss: 1.4011, lr: 0.0000\n",
      "Epoch: 790, Training loss: 1.376534, Validation loss: 1.3757, lr: 0.0000\n",
      "Epoch: 791, Training loss: 1.343505, Validation loss: 1.3563, lr: 0.0000\n",
      "Epoch: 792, Training loss: 1.372413, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 793, Training loss: 1.376014, Validation loss: 1.3757, lr: 0.0000\n",
      "Epoch: 794, Training loss: 1.350923, Validation loss: 1.3751, lr: 0.0000\n",
      "Epoch: 795, Training loss: 1.351957, Validation loss: 1.3786, lr: 0.0000\n",
      "Epoch: 796, Training loss: 1.406560, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 797, Training loss: 1.353727, Validation loss: 1.3705, lr: 0.0000\n",
      "Epoch: 798, Training loss: 1.360417, Validation loss: 1.3798, lr: 0.0000\n",
      "Epoch: 799, Training loss: 1.354014, Validation loss: 1.4058, lr: 0.0000\n",
      "Epoch: 800, Training loss: 1.364673, Validation loss: 1.3696, lr: 0.0000\n",
      "Epoch: 801, Training loss: 1.368072, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 802, Training loss: 1.355159, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 803, Training loss: 1.383368, Validation loss: 1.3772, lr: 0.0000\n",
      "Epoch: 804, Training loss: 1.357458, Validation loss: 1.3578, lr: 0.0000\n",
      "Epoch: 805, Training loss: 1.385601, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 806, Training loss: 1.352544, Validation loss: 1.3758, lr: 0.0000\n",
      "Epoch: 807, Training loss: 1.368207, Validation loss: 1.3654, lr: 0.0000\n",
      "Epoch: 808, Training loss: 1.332875, Validation loss: 1.3766, lr: 0.0000\n",
      "Epoch: 809, Training loss: 1.346646, Validation loss: 1.3793, lr: 0.0000\n",
      "Epoch: 810, Training loss: 1.346578, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 811, Training loss: 1.390284, Validation loss: 1.3767, lr: 0.0000\n",
      "Epoch: 812, Training loss: 1.373489, Validation loss: 1.3778, lr: 0.0000\n",
      "Epoch: 813, Training loss: 1.365386, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 814, Training loss: 1.391458, Validation loss: 1.3794, lr: 0.0000\n",
      "Epoch: 815, Training loss: 1.350122, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 816, Training loss: 1.361855, Validation loss: 1.3607, lr: 0.0000\n",
      "Epoch: 817, Training loss: 1.363648, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 818, Training loss: 1.334101, Validation loss: 1.3700, lr: 0.0000\n",
      "Epoch: 819, Training loss: 1.364568, Validation loss: 1.3640, lr: 0.0000\n",
      "Epoch: 820, Training loss: 1.374047, Validation loss: 1.3763, lr: 0.0000\n",
      "Epoch: 821, Training loss: 1.371061, Validation loss: 1.3873, lr: 0.0000\n",
      "Epoch: 822, Training loss: 1.355001, Validation loss: 1.3757, lr: 0.0000\n",
      "Epoch: 823, Training loss: 1.345331, Validation loss: 1.3543, lr: 0.0000\n",
      "Epoch: 824, Training loss: 1.361511, Validation loss: 1.3982, lr: 0.0000\n",
      "Epoch: 825, Training loss: 1.340422, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 826, Training loss: 1.427625, Validation loss: 1.3641, lr: 0.0000\n",
      "Epoch: 827, Training loss: 1.360731, Validation loss: 1.3712, lr: 0.0000\n",
      "Epoch: 828, Training loss: 1.343990, Validation loss: 1.3381, lr: 0.0000\n",
      "Epoch: 829, Training loss: 1.342417, Validation loss: 1.3427, lr: 0.0000\n",
      "Epoch: 830, Training loss: 1.355462, Validation loss: 1.3712, lr: 0.0000\n",
      "Epoch: 831, Training loss: 1.350331, Validation loss: 1.3588, lr: 0.0000\n",
      "Epoch: 832, Training loss: 1.354867, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 833, Training loss: 1.351910, Validation loss: 1.3536, lr: 0.0000\n",
      "Epoch: 834, Training loss: 1.345975, Validation loss: 1.3690, lr: 0.0000\n",
      "Epoch: 835, Training loss: 1.400991, Validation loss: 1.3913, lr: 0.0000\n",
      "Epoch: 836, Training loss: 1.350682, Validation loss: 1.3906, lr: 0.0000\n",
      "Epoch: 837, Training loss: 1.358584, Validation loss: 1.4367, lr: 0.0000\n",
      "Epoch: 838, Training loss: 1.363545, Validation loss: 1.3701, lr: 0.0000\n",
      "Epoch: 839, Training loss: 1.376283, Validation loss: 1.3476, lr: 0.0000\n",
      "Epoch: 840, Training loss: 1.370434, Validation loss: 1.3558, lr: 0.0000\n",
      "Epoch: 841, Training loss: 1.319129, Validation loss: 1.3691, lr: 0.0000\n",
      "Epoch: 842, Training loss: 1.350051, Validation loss: 1.4264, lr: 0.0000\n",
      "Epoch: 843, Training loss: 1.359547, Validation loss: 1.3540, lr: 0.0000\n",
      "Epoch: 844, Training loss: 1.373661, Validation loss: 1.3792, lr: 0.0000\n",
      "Epoch: 845, Training loss: 1.351925, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 846, Training loss: 1.373721, Validation loss: 1.3684, lr: 0.0000\n",
      "Epoch: 847, Training loss: 1.389262, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 848, Training loss: 1.390311, Validation loss: 1.3705, lr: 0.0000\n",
      "Epoch: 849, Training loss: 1.343505, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 850, Training loss: 1.402981, Validation loss: 1.3674, lr: 0.0000\n",
      "Epoch: 851, Training loss: 1.355930, Validation loss: 1.3580, lr: 0.0000\n",
      "Epoch: 852, Training loss: 1.375729, Validation loss: 1.3722, lr: 0.0000\n",
      "Epoch: 853, Training loss: 1.346704, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 854, Training loss: 1.367186, Validation loss: 1.3712, lr: 0.0000\n",
      "Epoch: 855, Training loss: 1.360586, Validation loss: 1.3712, lr: 0.0000\n",
      "Epoch: 856, Training loss: 1.340458, Validation loss: 1.3765, lr: 0.0000\n",
      "Epoch: 857, Training loss: 1.387082, Validation loss: 1.3561, lr: 0.0000\n",
      "Epoch: 858, Training loss: 1.369142, Validation loss: 1.3796, lr: 0.0000\n",
      "Epoch: 859, Training loss: 1.386585, Validation loss: 1.3710, lr: 0.0000\n",
      "Epoch: 860, Training loss: 1.377245, Validation loss: 1.3639, lr: 0.0000\n",
      "Epoch: 861, Training loss: 1.358211, Validation loss: 1.3795, lr: 0.0000\n",
      "Epoch: 862, Training loss: 1.363117, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 863, Training loss: 1.382316, Validation loss: 1.3740, lr: 0.0000\n",
      "Epoch: 864, Training loss: 1.378678, Validation loss: 1.3749, lr: 0.0000\n",
      "Epoch: 865, Training loss: 1.367858, Validation loss: 1.3636, lr: 0.0000\n",
      "Epoch: 866, Training loss: 1.371110, Validation loss: 1.3799, lr: 0.0000\n",
      "Epoch: 867, Training loss: 1.372467, Validation loss: 1.3649, lr: 0.0000\n",
      "Epoch: 868, Training loss: 1.357972, Validation loss: 1.3744, lr: 0.0000\n",
      "Epoch: 869, Training loss: 1.392098, Validation loss: 1.3779, lr: 0.0000\n",
      "Epoch: 870, Training loss: 1.377411, Validation loss: 1.3723, lr: 0.0000\n",
      "Epoch: 871, Training loss: 1.365567, Validation loss: 1.3765, lr: 0.0000\n",
      "Epoch: 872, Training loss: 1.381465, Validation loss: 1.3714, lr: 0.0000\n",
      "Epoch: 873, Training loss: 1.359569, Validation loss: 1.3783, lr: 0.0000\n",
      "Epoch: 874, Training loss: 1.350251, Validation loss: 1.3809, lr: 0.0000\n",
      "Epoch: 875, Training loss: 1.377600, Validation loss: 1.3790, lr: 0.0000\n",
      "Epoch: 876, Training loss: 1.366113, Validation loss: 1.3708, lr: 0.0000\n",
      "Epoch: 877, Training loss: 1.371414, Validation loss: 1.3700, lr: 0.0000\n",
      "Epoch: 878, Training loss: 1.330019, Validation loss: 1.3721, lr: 0.0000\n",
      "Epoch: 879, Training loss: 1.356007, Validation loss: 1.3572, lr: 0.0000\n",
      "Epoch: 880, Training loss: 1.356606, Validation loss: 1.3900, lr: 0.0000\n",
      "Epoch: 881, Training loss: 1.356758, Validation loss: 1.3680, lr: 0.0000\n",
      "Epoch: 882, Training loss: 1.368012, Validation loss: 1.3796, lr: 0.0000\n",
      "Epoch: 883, Training loss: 1.358222, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 884, Training loss: 1.354170, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 885, Training loss: 1.364649, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 886, Training loss: 1.386286, Validation loss: 1.3685, lr: 0.0000\n",
      "Epoch: 887, Training loss: 1.370456, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 888, Training loss: 1.351877, Validation loss: 1.3716, lr: 0.0000\n",
      "Epoch: 889, Training loss: 1.378897, Validation loss: 1.3790, lr: 0.0000\n",
      "Epoch: 890, Training loss: 1.375817, Validation loss: 1.3696, lr: 0.0000\n",
      "Epoch: 891, Training loss: 1.337458, Validation loss: 1.3798, lr: 0.0000\n",
      "Epoch: 892, Training loss: 1.406118, Validation loss: 1.3612, lr: 0.0000\n",
      "Epoch: 893, Training loss: 1.365255, Validation loss: 1.3684, lr: 0.0000\n",
      "Epoch: 894, Training loss: 1.351845, Validation loss: 1.3770, lr: 0.0000\n",
      "Epoch: 895, Training loss: 1.350245, Validation loss: 1.3758, lr: 0.0000\n",
      "Epoch: 896, Training loss: 1.354235, Validation loss: 1.3794, lr: 0.0000\n",
      "Epoch: 897, Training loss: 1.378909, Validation loss: 1.3759, lr: 0.0000\n",
      "Epoch: 898, Training loss: 1.374750, Validation loss: 1.3668, lr: 0.0000\n",
      "Epoch: 899, Training loss: 1.375834, Validation loss: 1.3747, lr: 0.0000\n",
      "Epoch: 900, Training loss: 1.364814, Validation loss: 1.3649, lr: 0.0000\n",
      "Epoch: 901, Training loss: 1.337589, Validation loss: 1.3705, lr: 0.0000\n",
      "Epoch: 902, Training loss: 1.365475, Validation loss: 1.3652, lr: 0.0000\n",
      "Epoch: 903, Training loss: 1.375883, Validation loss: 1.3656, lr: 0.0000\n",
      "Epoch: 904, Training loss: 1.365778, Validation loss: 1.3756, lr: 0.0000\n",
      "Epoch: 905, Training loss: 1.366777, Validation loss: 1.3702, lr: 0.0000\n",
      "Epoch: 906, Training loss: 1.345530, Validation loss: 1.3883, lr: 0.0000\n",
      "Epoch: 907, Training loss: 1.390284, Validation loss: 1.3554, lr: 0.0000\n",
      "Epoch: 908, Training loss: 1.363325, Validation loss: 1.3788, lr: 0.0000\n",
      "Epoch: 909, Training loss: 1.379949, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 910, Training loss: 1.344029, Validation loss: 1.3554, lr: 0.0000\n",
      "Epoch: 911, Training loss: 1.361623, Validation loss: 1.3533, lr: 0.0000\n",
      "Epoch: 912, Training loss: 1.376267, Validation loss: 1.3712, lr: 0.0000\n",
      "Epoch: 913, Training loss: 1.364935, Validation loss: 1.3744, lr: 0.0000\n",
      "Epoch: 914, Training loss: 1.360523, Validation loss: 1.3798, lr: 0.0000\n",
      "Epoch: 915, Training loss: 1.350281, Validation loss: 1.3767, lr: 0.0000\n",
      "Epoch: 916, Training loss: 1.357291, Validation loss: 1.3637, lr: 0.0000\n",
      "Epoch: 917, Training loss: 1.362136, Validation loss: 1.4425, lr: 0.0000\n",
      "Epoch: 918, Training loss: 1.339543, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 919, Training loss: 1.358398, Validation loss: 1.3745, lr: 0.0000\n",
      "Epoch: 920, Training loss: 1.356713, Validation loss: 1.3878, lr: 0.0000\n",
      "Epoch: 921, Training loss: 1.370275, Validation loss: 1.3715, lr: 0.0000\n",
      "Epoch: 922, Training loss: 1.348128, Validation loss: 1.3786, lr: 0.0000\n",
      "Epoch: 923, Training loss: 1.381248, Validation loss: 1.3755, lr: 0.0000\n",
      "Epoch: 924, Training loss: 1.362901, Validation loss: 1.3736, lr: 0.0000\n",
      "Epoch: 925, Training loss: 1.373230, Validation loss: 1.3706, lr: 0.0000\n",
      "Epoch: 926, Training loss: 1.395650, Validation loss: 1.3792, lr: 0.0000\n",
      "Epoch: 927, Training loss: 1.384025, Validation loss: 1.3705, lr: 0.0000\n",
      "Epoch: 928, Training loss: 1.391895, Validation loss: 1.3778, lr: 0.0000\n",
      "Epoch: 929, Training loss: 1.402625, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 930, Training loss: 1.374427, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 931, Training loss: 1.344113, Validation loss: 1.3746, lr: 0.0000\n",
      "Epoch: 932, Training loss: 1.363636, Validation loss: 1.3782, lr: 0.0000\n",
      "Epoch: 933, Training loss: 1.358524, Validation loss: 1.3746, lr: 0.0000\n",
      "Epoch: 934, Training loss: 1.343583, Validation loss: 1.3904, lr: 0.0000\n",
      "Epoch: 935, Training loss: 1.389981, Validation loss: 1.4052, lr: 0.0000\n",
      "Epoch: 936, Training loss: 1.332860, Validation loss: 1.3695, lr: 0.0000\n",
      "Epoch: 937, Training loss: 1.336689, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 938, Training loss: 1.345583, Validation loss: 1.3693, lr: 0.0000\n",
      "Epoch: 939, Training loss: 1.349148, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 940, Training loss: 1.354572, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 941, Training loss: 1.367698, Validation loss: 1.3781, lr: 0.0000\n",
      "Epoch: 942, Training loss: 1.385864, Validation loss: 1.4445, lr: 0.0000\n",
      "Epoch: 943, Training loss: 1.363497, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 944, Training loss: 1.378517, Validation loss: 1.3757, lr: 0.0000\n",
      "Epoch: 945, Training loss: 1.361229, Validation loss: 1.3702, lr: 0.0000\n",
      "Epoch: 946, Training loss: 1.328405, Validation loss: 1.3750, lr: 0.0000\n",
      "Epoch: 947, Training loss: 1.325506, Validation loss: 1.3404, lr: 0.0000\n",
      "Epoch: 948, Training loss: 1.353415, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 949, Training loss: 1.350597, Validation loss: 1.3672, lr: 0.0000\n",
      "Epoch: 950, Training loss: 1.356468, Validation loss: 1.3732, lr: 0.0000\n",
      "Epoch: 951, Training loss: 1.363632, Validation loss: 1.3783, lr: 0.0000\n",
      "Epoch: 952, Training loss: 1.391723, Validation loss: 1.3800, lr: 0.0000\n",
      "Epoch: 953, Training loss: 1.372503, Validation loss: 1.3679, lr: 0.0000\n",
      "Epoch: 954, Training loss: 1.351710, Validation loss: 1.3488, lr: 0.0000\n",
      "Epoch: 955, Training loss: 1.372472, Validation loss: 1.3722, lr: 0.0000\n",
      "Epoch: 956, Training loss: 1.388869, Validation loss: 1.3678, lr: 0.0000\n",
      "Epoch: 957, Training loss: 1.376561, Validation loss: 1.3753, lr: 0.0000\n",
      "Epoch: 958, Training loss: 1.360453, Validation loss: 1.3780, lr: 0.0000\n",
      "Epoch: 959, Training loss: 1.368126, Validation loss: 1.3792, lr: 0.0000\n",
      "Epoch: 960, Training loss: 1.356005, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 961, Training loss: 1.368468, Validation loss: 1.3778, lr: 0.0000\n",
      "Epoch: 962, Training loss: 1.358928, Validation loss: 1.3686, lr: 0.0000\n",
      "Epoch: 963, Training loss: 1.426704, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 964, Training loss: 1.355293, Validation loss: 1.3559, lr: 0.0000\n",
      "Epoch: 965, Training loss: 1.346994, Validation loss: 1.3787, lr: 0.0000\n",
      "Epoch: 966, Training loss: 1.392721, Validation loss: 1.3514, lr: 0.0000\n",
      "Epoch: 967, Training loss: 1.352137, Validation loss: 1.3803, lr: 0.0000\n",
      "Epoch: 968, Training loss: 1.394189, Validation loss: 1.3759, lr: 0.0000\n",
      "Epoch: 969, Training loss: 1.373602, Validation loss: 1.3559, lr: 0.0000\n",
      "Epoch: 970, Training loss: 1.355686, Validation loss: 1.3660, lr: 0.0000\n",
      "Epoch: 971, Training loss: 1.354918, Validation loss: 1.3720, lr: 0.0000\n",
      "Epoch: 972, Training loss: 1.377879, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 973, Training loss: 1.360736, Validation loss: 1.3771, lr: 0.0000\n",
      "Epoch: 974, Training loss: 1.367513, Validation loss: 1.3773, lr: 0.0000\n",
      "Epoch: 975, Training loss: 1.372785, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 976, Training loss: 1.371467, Validation loss: 1.3763, lr: 0.0000\n",
      "Epoch: 977, Training loss: 1.343826, Validation loss: 1.4145, lr: 0.0000\n",
      "Epoch: 978, Training loss: 1.405981, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 979, Training loss: 1.395660, Validation loss: 1.3803, lr: 0.0000\n",
      "Epoch: 980, Training loss: 1.418992, Validation loss: 1.3721, lr: 0.0000\n",
      "Epoch: 981, Training loss: 1.367171, Validation loss: 1.3789, lr: 0.0000\n",
      "Epoch: 982, Training loss: 1.349907, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 983, Training loss: 1.342556, Validation loss: 1.3754, lr: 0.0000\n",
      "Epoch: 984, Training loss: 1.374954, Validation loss: 1.3770, lr: 0.0000\n",
      "Epoch: 985, Training loss: 1.359527, Validation loss: 1.3684, lr: 0.0000\n",
      "Epoch: 986, Training loss: 1.353232, Validation loss: 1.3784, lr: 0.0000\n",
      "Epoch: 987, Training loss: 1.334065, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 988, Training loss: 1.380785, Validation loss: 1.3693, lr: 0.0000\n",
      "Epoch: 989, Training loss: 1.376565, Validation loss: 1.3788, lr: 0.0000\n",
      "Epoch: 990, Training loss: 1.395265, Validation loss: 1.3771, lr: 0.0000\n",
      "Epoch: 991, Training loss: 1.370897, Validation loss: 1.3796, lr: 0.0000\n",
      "Epoch: 992, Training loss: 1.383214, Validation loss: 1.3796, lr: 0.0000\n",
      "Epoch: 993, Training loss: 1.366720, Validation loss: 1.3728, lr: 0.0000\n",
      "Epoch: 994, Training loss: 1.343815, Validation loss: 1.3797, lr: 0.0000\n",
      "Epoch: 995, Training loss: 1.359879, Validation loss: 1.3546, lr: 0.0000\n",
      "Epoch: 996, Training loss: 1.362903, Validation loss: 1.3735, lr: 0.0000\n",
      "Epoch: 997, Training loss: 1.356418, Validation loss: 1.3634, lr: 0.0000\n",
      "Epoch: 998, Training loss: 1.330922, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 999, Training loss: 1.364561, Validation loss: 1.3726, lr: 0.0000\n",
      "Final test loss: 1.3811\n",
      "=== Run 02/10 ===\n",
      "\n",
      "---- Settings: \n",
      "\n",
      "epochs : 1000\n",
      "hidden_channels : [32]\n",
      "out_channels : 10\n",
      "inner_product_features : False\n",
      "batch_size : 64\n",
      "lr : 0.01\n",
      "momentum : 0.9\n",
      "dropout : 0.0\n",
      "batch_norm : batch_norm\n",
      "bias : True\n",
      "order : 2\n",
      "diffusion : True\n",
      "frac_sampled_nb : -1\n",
      "include_positions : False\n",
      "include_self : True\n",
      "vec_norm : False\n",
      "emb_norm : False\n",
      "seed : 0\n",
      "dim_signal : 100\n",
      "dim_emb : 100\n",
      "n_sampled_nb : -1\n",
      "\n",
      "---- Number of features to pass to the MLP:  1010100\n",
      "---- Total number of parameters:  32323627\n",
      "\n",
      "Using device cuda:0\n",
      "\n",
      "---- Training network ...\n",
      "\n",
      "---- Timestamp: 20250614-204818\n",
      "\n",
      " *och: 0, Training loss: 1.546211, Validation loss: 1.7072, lr: 0.0100\n",
      " *och: 1, Training loss: 1.399369, Validation loss: 1.3753, lr: 0.0100\n",
      "Epoch: 2, Training loss: 1.395314, Validation loss: 1.3828, lr: 0.0100\n",
      "Epoch: 3, Training loss: 1.368087, Validation loss: 1.4061, lr: 0.0100\n",
      "Epoch: 4, Training loss: 1.422338, Validation loss: 1.3841, lr: 0.0100\n",
      " *och: 5, Training loss: 1.445602, Validation loss: 1.3625, lr: 0.0100\n",
      "Epoch: 6, Training loss: 1.363626, Validation loss: 1.3843, lr: 0.0100\n",
      "Epoch: 7, Training loss: 1.394798, Validation loss: 1.3710, lr: 0.0100\n",
      "Epoch: 8, Training loss: 1.379582, Validation loss: 1.3919, lr: 0.0100\n",
      "Epoch: 9, Training loss: 1.458995, Validation loss: 1.3862, lr: 0.0100\n",
      "Epoch: 10, Training loss: 1.384894, Validation loss: 1.3880, lr: 0.0100\n",
      "Epoch: 11, Training loss: 1.379959, Validation loss: 1.3825, lr: 0.0100\n",
      "Epoch: 12, Training loss: 1.383973, Validation loss: 1.3754, lr: 0.0100\n",
      "Epoch: 13, Training loss: 1.395373, Validation loss: 1.3751, lr: 0.0100\n",
      "Epoch: 14, Training loss: 1.391955, Validation loss: 1.3872, lr: 0.0100\n",
      "Epoch: 15, Training loss: 1.385000, Validation loss: 1.3819, lr: 0.0100\n",
      "Epoch: 16, Training loss: 1.378619, Validation loss: 1.3859, lr: 0.0100\n",
      "Epoch: 17, Training loss: 1.374181, Validation loss: 1.3785, lr: 0.0010\n",
      "Epoch: 18, Training loss: 1.372972, Validation loss: 1.4481, lr: 0.0010\n",
      "Epoch: 19, Training loss: 1.374007, Validation loss: 1.3847, lr: 0.0010\n",
      " *och: 20, Training loss: 1.397360, Validation loss: 1.3565, lr: 0.0010\n",
      "Epoch: 21, Training loss: 1.385354, Validation loss: 1.3829, lr: 0.0010\n",
      "Epoch: 22, Training loss: 1.377465, Validation loss: 1.3771, lr: 0.0010\n",
      "Epoch: 23, Training loss: 1.396051, Validation loss: 1.3770, lr: 0.0010\n",
      "Epoch: 24, Training loss: 1.387586, Validation loss: 1.3690, lr: 0.0010\n",
      " *och: 25, Training loss: 1.395287, Validation loss: 1.3403, lr: 0.0010\n",
      "Epoch: 26, Training loss: 1.348729, Validation loss: 1.3908, lr: 0.0010\n",
      "Epoch: 27, Training loss: 1.399705, Validation loss: 1.3767, lr: 0.0010\n",
      "Epoch: 28, Training loss: 1.374855, Validation loss: 1.3550, lr: 0.0010\n",
      "Epoch: 29, Training loss: 1.383653, Validation loss: 1.3901, lr: 0.0010\n",
      "Epoch: 30, Training loss: 1.396167, Validation loss: 1.3695, lr: 0.0010\n",
      "Epoch: 31, Training loss: 1.417535, Validation loss: 1.3854, lr: 0.0010\n",
      "Epoch: 32, Training loss: 1.496394, Validation loss: 1.3769, lr: 0.0010\n",
      "Epoch: 33, Training loss: 1.386930, Validation loss: 1.3922, lr: 0.0010\n",
      "Epoch: 34, Training loss: 1.364179, Validation loss: 1.3867, lr: 0.0010\n",
      "Epoch: 35, Training loss: 1.357983, Validation loss: 1.3816, lr: 0.0010\n",
      "Epoch: 36, Training loss: 1.367476, Validation loss: 1.3798, lr: 0.0010\n",
      "Epoch: 37, Training loss: 1.399141, Validation loss: 1.3816, lr: 0.0001\n",
      "Epoch: 38, Training loss: 1.360562, Validation loss: 1.3774, lr: 0.0001\n",
      "Epoch: 39, Training loss: 1.428187, Validation loss: 1.3837, lr: 0.0001\n",
      "Epoch: 40, Training loss: 1.362039, Validation loss: 1.3808, lr: 0.0001\n",
      "Epoch: 41, Training loss: 1.380746, Validation loss: 1.3843, lr: 0.0001\n",
      "Epoch: 42, Training loss: 1.378333, Validation loss: 1.3914, lr: 0.0001\n",
      "Epoch: 43, Training loss: 1.376344, Validation loss: 1.3841, lr: 0.0001\n",
      "Epoch: 44, Training loss: 1.369145, Validation loss: 1.3817, lr: 0.0001\n",
      "Epoch: 45, Training loss: 1.417398, Validation loss: 1.3866, lr: 0.0001\n",
      "Epoch: 46, Training loss: 1.377716, Validation loss: 1.3848, lr: 0.0001\n",
      "Epoch: 47, Training loss: 1.369695, Validation loss: 1.3825, lr: 0.0001\n",
      "Epoch: 48, Training loss: 1.385384, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 49, Training loss: 1.397194, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 50, Training loss: 1.367370, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 51, Training loss: 1.381124, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 52, Training loss: 1.359644, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 53, Training loss: 1.377078, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 54, Training loss: 1.362483, Validation loss: 1.3649, lr: 0.0000\n",
      "Epoch: 55, Training loss: 1.385343, Validation loss: 1.3901, lr: 0.0000\n",
      "Epoch: 56, Training loss: 1.377001, Validation loss: 1.3972, lr: 0.0000\n",
      "Epoch: 57, Training loss: 1.384796, Validation loss: 1.3809, lr: 0.0000\n",
      "Epoch: 58, Training loss: 1.377919, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 59, Training loss: 1.375962, Validation loss: 1.4420, lr: 0.0000\n",
      "Epoch: 60, Training loss: 1.397852, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 61, Training loss: 1.389335, Validation loss: 1.3742, lr: 0.0000\n",
      "Epoch: 62, Training loss: 1.422745, Validation loss: 1.3690, lr: 0.0000\n",
      "Epoch: 63, Training loss: 1.393864, Validation loss: 1.3791, lr: 0.0000\n",
      "Epoch: 64, Training loss: 1.398330, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 65, Training loss: 1.381116, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 66, Training loss: 1.381413, Validation loss: 1.3809, lr: 0.0000\n",
      "Epoch: 67, Training loss: 1.375552, Validation loss: 1.3883, lr: 0.0000\n",
      "Epoch: 68, Training loss: 1.369944, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 69, Training loss: 1.385750, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 70, Training loss: 1.371574, Validation loss: 1.3664, lr: 0.0000\n",
      "Epoch: 71, Training loss: 1.398799, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 72, Training loss: 1.371103, Validation loss: 1.3795, lr: 0.0000\n",
      "Epoch: 73, Training loss: 1.393521, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 74, Training loss: 1.383228, Validation loss: 1.3879, lr: 0.0000\n",
      "Epoch: 75, Training loss: 1.398600, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 76, Training loss: 1.390911, Validation loss: 1.3709, lr: 0.0000\n",
      "Epoch: 77, Training loss: 1.382911, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 78, Training loss: 1.378078, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 79, Training loss: 1.375302, Validation loss: 1.3884, lr: 0.0000\n",
      "Epoch: 80, Training loss: 1.381553, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 81, Training loss: 1.379113, Validation loss: 1.3713, lr: 0.0000\n",
      "Epoch: 82, Training loss: 1.378195, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 83, Training loss: 1.370935, Validation loss: 1.3787, lr: 0.0000\n",
      "Epoch: 84, Training loss: 1.430471, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 85, Training loss: 1.390574, Validation loss: 1.4049, lr: 0.0000\n",
      "Epoch: 86, Training loss: 1.383240, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 87, Training loss: 1.385601, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 88, Training loss: 1.358951, Validation loss: 1.3968, lr: 0.0000\n",
      "Epoch: 89, Training loss: 1.393923, Validation loss: 1.3809, lr: 0.0000\n",
      "Epoch: 90, Training loss: 1.378892, Validation loss: 1.3667, lr: 0.0000\n",
      "Epoch: 91, Training loss: 1.372964, Validation loss: 1.3979, lr: 0.0000\n",
      "Epoch: 92, Training loss: 1.401142, Validation loss: 1.3684, lr: 0.0000\n",
      "Epoch: 93, Training loss: 1.367857, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 94, Training loss: 1.380741, Validation loss: 1.3788, lr: 0.0000\n",
      "Epoch: 95, Training loss: 1.396942, Validation loss: 1.3724, lr: 0.0000\n",
      "Epoch: 96, Training loss: 1.375937, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 97, Training loss: 1.386754, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 98, Training loss: 1.382613, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 99, Training loss: 1.401508, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 100, Training loss: 1.372323, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 101, Training loss: 1.379918, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 102, Training loss: 1.421252, Validation loss: 1.3898, lr: 0.0000\n",
      "Epoch: 103, Training loss: 1.375899, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 104, Training loss: 1.381952, Validation loss: 1.3766, lr: 0.0000\n",
      "Epoch: 105, Training loss: 1.373286, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 106, Training loss: 1.390195, Validation loss: 1.3911, lr: 0.0000\n",
      "Epoch: 107, Training loss: 1.359201, Validation loss: 1.4499, lr: 0.0000\n",
      "Epoch: 108, Training loss: 1.370757, Validation loss: 1.3775, lr: 0.0000\n",
      "Epoch: 109, Training loss: 1.363093, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 110, Training loss: 1.366041, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 111, Training loss: 1.378912, Validation loss: 1.3735, lr: 0.0000\n",
      "Epoch: 112, Training loss: 1.400359, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 113, Training loss: 1.398746, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 114, Training loss: 1.376852, Validation loss: 1.3928, lr: 0.0000\n",
      "Epoch: 115, Training loss: 1.397217, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 116, Training loss: 1.431602, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 117, Training loss: 1.370781, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 118, Training loss: 1.378412, Validation loss: 1.7369, lr: 0.0000\n",
      "Epoch: 119, Training loss: 1.391438, Validation loss: 1.3787, lr: 0.0000\n",
      "Epoch: 120, Training loss: 1.409970, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 121, Training loss: 1.385946, Validation loss: 1.3765, lr: 0.0000\n",
      "Epoch: 122, Training loss: 1.384133, Validation loss: 1.3899, lr: 0.0000\n",
      "Epoch: 123, Training loss: 1.363725, Validation loss: 1.3793, lr: 0.0000\n",
      "Epoch: 124, Training loss: 1.379896, Validation loss: 1.3936, lr: 0.0000\n",
      "Epoch: 125, Training loss: 1.421318, Validation loss: 1.3698, lr: 0.0000\n",
      "Epoch: 126, Training loss: 1.380769, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 127, Training loss: 1.382113, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 128, Training loss: 1.398726, Validation loss: 1.3882, lr: 0.0000\n",
      "Epoch: 129, Training loss: 1.386746, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 130, Training loss: 1.377207, Validation loss: 1.3703, lr: 0.0000\n",
      "Epoch: 131, Training loss: 1.387584, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 132, Training loss: 1.377813, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 133, Training loss: 1.369151, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 134, Training loss: 1.397801, Validation loss: 1.3894, lr: 0.0000\n",
      "Epoch: 135, Training loss: 1.391184, Validation loss: 1.3738, lr: 0.0000\n",
      "Epoch: 136, Training loss: 1.379393, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 137, Training loss: 1.366652, Validation loss: 1.3873, lr: 0.0000\n",
      "Epoch: 138, Training loss: 1.369435, Validation loss: 1.3765, lr: 0.0000\n",
      "Epoch: 139, Training loss: 1.377517, Validation loss: 1.3782, lr: 0.0000\n",
      "Epoch: 140, Training loss: 1.366496, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 141, Training loss: 1.385851, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 142, Training loss: 1.377509, Validation loss: 1.3942, lr: 0.0000\n",
      "Epoch: 143, Training loss: 1.374706, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 144, Training loss: 1.374708, Validation loss: 1.3916, lr: 0.0000\n",
      "Epoch: 145, Training loss: 1.384692, Validation loss: 1.3803, lr: 0.0000\n",
      "Epoch: 146, Training loss: 1.381568, Validation loss: 1.3781, lr: 0.0000\n",
      "Epoch: 147, Training loss: 1.384043, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 148, Training loss: 1.376383, Validation loss: 1.3898, lr: 0.0000\n",
      "Epoch: 149, Training loss: 1.376806, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 150, Training loss: 1.384195, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 151, Training loss: 1.387364, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 152, Training loss: 1.370499, Validation loss: 1.4413, lr: 0.0000\n",
      "Epoch: 153, Training loss: 1.382508, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 154, Training loss: 1.377745, Validation loss: 1.3788, lr: 0.0000\n",
      "Epoch: 155, Training loss: 1.381276, Validation loss: 1.3745, lr: 0.0000\n",
      "Epoch: 156, Training loss: 1.381323, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 157, Training loss: 1.384293, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 158, Training loss: 1.397297, Validation loss: 1.3789, lr: 0.0000\n",
      "Epoch: 159, Training loss: 1.381714, Validation loss: 1.3962, lr: 0.0000\n",
      "Epoch: 160, Training loss: 1.390724, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 161, Training loss: 1.373567, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 162, Training loss: 1.383659, Validation loss: 1.3666, lr: 0.0000\n",
      "Epoch: 163, Training loss: 1.387961, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 164, Training loss: 1.390638, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 165, Training loss: 1.388036, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 166, Training loss: 1.372221, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 167, Training loss: 1.380772, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 168, Training loss: 1.380356, Validation loss: 1.3925, lr: 0.0000\n",
      "Epoch: 169, Training loss: 1.413046, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 170, Training loss: 1.377044, Validation loss: 1.3895, lr: 0.0000\n",
      "Epoch: 171, Training loss: 1.372084, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 172, Training loss: 1.375246, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 173, Training loss: 1.415310, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 174, Training loss: 1.368997, Validation loss: 1.3723, lr: 0.0000\n",
      "Epoch: 175, Training loss: 1.383709, Validation loss: 1.3541, lr: 0.0000\n",
      "Epoch: 176, Training loss: 1.381302, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 177, Training loss: 1.400343, Validation loss: 1.3771, lr: 0.0000\n",
      "Epoch: 178, Training loss: 1.371781, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 179, Training loss: 1.387160, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 180, Training loss: 1.369842, Validation loss: 1.3969, lr: 0.0000\n",
      "Epoch: 181, Training loss: 1.384204, Validation loss: 1.3705, lr: 0.0000\n",
      "Epoch: 182, Training loss: 1.408890, Validation loss: 1.3890, lr: 0.0000\n",
      "Epoch: 183, Training loss: 1.376915, Validation loss: 1.3766, lr: 0.0000\n",
      "Epoch: 184, Training loss: 1.374776, Validation loss: 1.3697, lr: 0.0000\n",
      "Epoch: 185, Training loss: 1.388169, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 186, Training loss: 1.377392, Validation loss: 1.3896, lr: 0.0000\n",
      "Epoch: 187, Training loss: 1.366627, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 188, Training loss: 1.365540, Validation loss: 1.3897, lr: 0.0000\n",
      "Epoch: 189, Training loss: 1.363357, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 190, Training loss: 1.378284, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 191, Training loss: 1.379586, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 192, Training loss: 1.374461, Validation loss: 1.3796, lr: 0.0000\n",
      "Epoch: 193, Training loss: 1.369550, Validation loss: 1.3790, lr: 0.0000\n",
      "Epoch: 194, Training loss: 1.369940, Validation loss: 1.3742, lr: 0.0000\n",
      "Epoch: 195, Training loss: 1.369915, Validation loss: 1.3739, lr: 0.0000\n",
      "Epoch: 196, Training loss: 1.373374, Validation loss: 1.3692, lr: 0.0000\n",
      "Epoch: 197, Training loss: 1.374758, Validation loss: 1.3916, lr: 0.0000\n",
      "Epoch: 198, Training loss: 1.387276, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 199, Training loss: 1.376426, Validation loss: 1.3905, lr: 0.0000\n",
      "Epoch: 200, Training loss: 1.367264, Validation loss: 1.3698, lr: 0.0000\n",
      "Epoch: 201, Training loss: 1.388516, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 202, Training loss: 1.380454, Validation loss: 1.3912, lr: 0.0000\n",
      "Epoch: 203, Training loss: 1.370579, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 204, Training loss: 1.406753, Validation loss: 1.3661, lr: 0.0000\n",
      "Epoch: 205, Training loss: 1.368124, Validation loss: 1.3729, lr: 0.0000\n",
      "Epoch: 206, Training loss: 1.387837, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 207, Training loss: 1.391642, Validation loss: 1.3769, lr: 0.0000\n",
      "Epoch: 208, Training loss: 1.384548, Validation loss: 1.3944, lr: 0.0000\n",
      "Epoch: 209, Training loss: 1.380054, Validation loss: 1.3791, lr: 0.0000\n",
      "Epoch: 210, Training loss: 1.374124, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 211, Training loss: 1.405181, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 212, Training loss: 1.369325, Validation loss: 1.3872, lr: 0.0000\n",
      "Epoch: 213, Training loss: 1.371687, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 214, Training loss: 1.376869, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 215, Training loss: 1.386043, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 216, Training loss: 1.427655, Validation loss: 1.3877, lr: 0.0000\n",
      "Epoch: 217, Training loss: 1.379802, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 218, Training loss: 1.374515, Validation loss: 1.3972, lr: 0.0000\n",
      "Epoch: 219, Training loss: 1.393247, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 220, Training loss: 1.379973, Validation loss: 1.3905, lr: 0.0000\n",
      "Epoch: 221, Training loss: 1.399881, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 222, Training loss: 1.386720, Validation loss: 1.3875, lr: 0.0000\n",
      "Epoch: 223, Training loss: 1.372071, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 224, Training loss: 1.374890, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 225, Training loss: 1.369405, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 226, Training loss: 1.382725, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 227, Training loss: 1.372885, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 228, Training loss: 1.384116, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 229, Training loss: 1.379558, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 230, Training loss: 1.370929, Validation loss: 1.3760, lr: 0.0000\n",
      "Epoch: 231, Training loss: 1.392785, Validation loss: 1.3786, lr: 0.0000\n",
      "Epoch: 232, Training loss: 1.367149, Validation loss: 1.3881, lr: 0.0000\n",
      "Epoch: 233, Training loss: 1.364683, Validation loss: 1.3872, lr: 0.0000\n",
      "Epoch: 234, Training loss: 1.372871, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 235, Training loss: 1.382798, Validation loss: 1.4129, lr: 0.0000\n",
      "Epoch: 236, Training loss: 1.370194, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 237, Training loss: 1.381564, Validation loss: 1.3641, lr: 0.0000\n",
      "Epoch: 238, Training loss: 1.370689, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 239, Training loss: 1.433185, Validation loss: 1.3682, lr: 0.0000\n",
      "Epoch: 240, Training loss: 1.377208, Validation loss: 1.3933, lr: 0.0000\n",
      "Epoch: 241, Training loss: 1.369627, Validation loss: 1.3798, lr: 0.0000\n",
      "Epoch: 242, Training loss: 1.365201, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 243, Training loss: 1.378977, Validation loss: 1.3740, lr: 0.0000\n",
      "Epoch: 244, Training loss: 1.381026, Validation loss: 1.3898, lr: 0.0000\n",
      "Epoch: 245, Training loss: 1.383208, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 246, Training loss: 1.361620, Validation loss: 1.3727, lr: 0.0000\n",
      "Epoch: 247, Training loss: 1.469036, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 248, Training loss: 1.376319, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 249, Training loss: 1.377763, Validation loss: 1.3948, lr: 0.0000\n",
      "Epoch: 250, Training loss: 1.365023, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 251, Training loss: 1.378289, Validation loss: 1.3873, lr: 0.0000\n",
      "Epoch: 252, Training loss: 1.385900, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 253, Training loss: 1.380464, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 254, Training loss: 1.375521, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 255, Training loss: 1.393104, Validation loss: 1.3882, lr: 0.0000\n",
      "Epoch: 256, Training loss: 1.373774, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 257, Training loss: 1.381671, Validation loss: 1.3803, lr: 0.0000\n",
      "Epoch: 258, Training loss: 1.376987, Validation loss: 1.3788, lr: 0.0000\n",
      "Epoch: 259, Training loss: 1.383956, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 260, Training loss: 1.383151, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 261, Training loss: 1.380473, Validation loss: 1.3879, lr: 0.0000\n",
      "Epoch: 262, Training loss: 1.396747, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 263, Training loss: 1.362406, Validation loss: 1.3783, lr: 0.0000\n",
      "Epoch: 264, Training loss: 1.393648, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 265, Training loss: 1.378593, Validation loss: 1.3809, lr: 0.0000\n",
      "Epoch: 266, Training loss: 1.370772, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 267, Training loss: 1.371272, Validation loss: 1.3626, lr: 0.0000\n",
      "Epoch: 268, Training loss: 1.385742, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 269, Training loss: 1.383436, Validation loss: 1.4181, lr: 0.0000\n",
      "Epoch: 270, Training loss: 1.378789, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 271, Training loss: 1.363647, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 272, Training loss: 1.394971, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 273, Training loss: 1.386545, Validation loss: 1.3886, lr: 0.0000\n",
      "Epoch: 274, Training loss: 1.406164, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 275, Training loss: 1.370078, Validation loss: 1.3713, lr: 0.0000\n",
      "Epoch: 276, Training loss: 1.380033, Validation loss: 1.3912, lr: 0.0000\n",
      "Epoch: 277, Training loss: 1.383651, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 278, Training loss: 1.367081, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 279, Training loss: 1.369304, Validation loss: 1.3892, lr: 0.0000\n",
      "Epoch: 280, Training loss: 1.409932, Validation loss: 1.3793, lr: 0.0000\n",
      "Epoch: 281, Training loss: 1.385677, Validation loss: 1.3781, lr: 0.0000\n",
      "Epoch: 282, Training loss: 1.405608, Validation loss: 1.3903, lr: 0.0000\n",
      "Epoch: 283, Training loss: 1.384181, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 284, Training loss: 1.381129, Validation loss: 1.3890, lr: 0.0000\n",
      "Epoch: 285, Training loss: 1.356686, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 286, Training loss: 1.368416, Validation loss: 1.3973, lr: 0.0000\n",
      "Epoch: 287, Training loss: 1.377071, Validation loss: 1.3753, lr: 0.0000\n",
      "Epoch: 288, Training loss: 1.386194, Validation loss: 1.3620, lr: 0.0000\n",
      "Epoch: 289, Training loss: 1.382199, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 290, Training loss: 1.362337, Validation loss: 1.3711, lr: 0.0000\n",
      "Epoch: 291, Training loss: 1.372673, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 292, Training loss: 1.362001, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 293, Training loss: 1.367711, Validation loss: 1.3701, lr: 0.0000\n",
      "Epoch: 294, Training loss: 1.371639, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 295, Training loss: 1.393580, Validation loss: 1.3876, lr: 0.0000\n",
      "Epoch: 296, Training loss: 1.382976, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 297, Training loss: 1.392958, Validation loss: 1.4065, lr: 0.0000\n",
      "Epoch: 298, Training loss: 1.375778, Validation loss: 1.3854, lr: 0.0000\n",
      " *och: 299, Training loss: 1.368339, Validation loss: 1.3396, lr: 0.0000\n",
      "Epoch: 300, Training loss: 1.384424, Validation loss: 1.3920, lr: 0.0000\n",
      "Epoch: 301, Training loss: 1.388343, Validation loss: 1.3677, lr: 0.0000\n",
      "Epoch: 302, Training loss: 1.418533, Validation loss: 1.3979, lr: 0.0000\n",
      "Epoch: 303, Training loss: 1.398178, Validation loss: 1.3737, lr: 0.0000\n",
      "Epoch: 304, Training loss: 1.365175, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 305, Training loss: 1.381524, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 306, Training loss: 1.388684, Validation loss: 1.3746, lr: 0.0000\n",
      "Epoch: 307, Training loss: 1.392408, Validation loss: 1.3979, lr: 0.0000\n",
      "Epoch: 308, Training loss: 1.372750, Validation loss: 1.3510, lr: 0.0000\n",
      "Epoch: 309, Training loss: 1.375054, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 310, Training loss: 1.386066, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 311, Training loss: 1.376152, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 312, Training loss: 1.357758, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 313, Training loss: 1.401992, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 314, Training loss: 1.387732, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 315, Training loss: 1.376593, Validation loss: 1.3760, lr: 0.0000\n",
      "Epoch: 316, Training loss: 1.361797, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 317, Training loss: 1.389692, Validation loss: 1.3884, lr: 0.0000\n",
      "Epoch: 318, Training loss: 1.394926, Validation loss: 1.3744, lr: 0.0000\n",
      "Epoch: 319, Training loss: 1.390279, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 320, Training loss: 1.385257, Validation loss: 1.3965, lr: 0.0000\n",
      "Epoch: 321, Training loss: 1.395084, Validation loss: 1.3901, lr: 0.0000\n",
      "Epoch: 322, Training loss: 1.388143, Validation loss: 1.3793, lr: 0.0000\n",
      "Epoch: 323, Training loss: 1.380793, Validation loss: 1.3703, lr: 0.0000\n",
      "Epoch: 324, Training loss: 1.371274, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 325, Training loss: 1.380467, Validation loss: 1.3588, lr: 0.0000\n",
      "Epoch: 326, Training loss: 1.380138, Validation loss: 1.3989, lr: 0.0000\n",
      "Epoch: 327, Training loss: 1.372939, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 328, Training loss: 1.369606, Validation loss: 1.3919, lr: 0.0000\n",
      "Epoch: 329, Training loss: 1.361063, Validation loss: 1.3628, lr: 0.0000\n",
      "Epoch: 330, Training loss: 1.364966, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 331, Training loss: 1.369381, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 332, Training loss: 1.385210, Validation loss: 1.3738, lr: 0.0000\n",
      "Epoch: 333, Training loss: 1.369622, Validation loss: 1.3796, lr: 0.0000\n",
      "Epoch: 334, Training loss: 1.384924, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 335, Training loss: 1.359499, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 336, Training loss: 1.380265, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 337, Training loss: 1.389315, Validation loss: 1.3985, lr: 0.0000\n",
      "Epoch: 338, Training loss: 1.392308, Validation loss: 1.3887, lr: 0.0000\n",
      "Epoch: 339, Training loss: 1.392385, Validation loss: 1.3874, lr: 0.0000\n",
      "Epoch: 340, Training loss: 1.377547, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 341, Training loss: 1.387891, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 342, Training loss: 1.385771, Validation loss: 1.3663, lr: 0.0000\n",
      "Epoch: 343, Training loss: 1.403616, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 344, Training loss: 1.382698, Validation loss: 1.3800, lr: 0.0000\n",
      "Epoch: 345, Training loss: 1.368798, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 346, Training loss: 1.379364, Validation loss: 1.3740, lr: 0.0000\n",
      "Epoch: 347, Training loss: 1.375591, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 348, Training loss: 1.400972, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 349, Training loss: 1.379696, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 350, Training loss: 1.372947, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 351, Training loss: 1.392842, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 352, Training loss: 1.380464, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 353, Training loss: 1.365643, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 354, Training loss: 1.371684, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 355, Training loss: 1.388651, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 356, Training loss: 1.384087, Validation loss: 1.3765, lr: 0.0000\n",
      "Epoch: 357, Training loss: 1.407656, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 358, Training loss: 1.374289, Validation loss: 1.3789, lr: 0.0000\n",
      "Epoch: 359, Training loss: 1.385382, Validation loss: 1.3666, lr: 0.0000\n",
      "Epoch: 360, Training loss: 1.384680, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 361, Training loss: 1.371923, Validation loss: 1.3706, lr: 0.0000\n",
      "Epoch: 362, Training loss: 1.356163, Validation loss: 1.3768, lr: 0.0000\n",
      "Epoch: 363, Training loss: 1.384221, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 364, Training loss: 1.391413, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 365, Training loss: 1.384696, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 366, Training loss: 1.381232, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 367, Training loss: 1.389598, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 368, Training loss: 1.386463, Validation loss: 1.5331, lr: 0.0000\n",
      "Epoch: 369, Training loss: 1.367373, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 370, Training loss: 1.379675, Validation loss: 1.3720, lr: 0.0000\n",
      "Epoch: 371, Training loss: 1.398246, Validation loss: 1.3928, lr: 0.0000\n",
      "Epoch: 372, Training loss: 1.363929, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 373, Training loss: 1.378799, Validation loss: 1.3878, lr: 0.0000\n",
      "Epoch: 374, Training loss: 1.387472, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 375, Training loss: 1.401837, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 376, Training loss: 1.420522, Validation loss: 1.3974, lr: 0.0000\n",
      "Epoch: 377, Training loss: 1.409477, Validation loss: 1.3796, lr: 0.0000\n",
      "Epoch: 378, Training loss: 1.371613, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 379, Training loss: 1.396269, Validation loss: 1.3803, lr: 0.0000\n",
      "Epoch: 380, Training loss: 1.444644, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 381, Training loss: 1.385314, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 382, Training loss: 1.372253, Validation loss: 1.3975, lr: 0.0000\n",
      "Epoch: 383, Training loss: 1.383203, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 384, Training loss: 1.384897, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 385, Training loss: 1.387343, Validation loss: 1.3769, lr: 0.0000\n",
      "Epoch: 386, Training loss: 1.448164, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 387, Training loss: 1.403179, Validation loss: 1.4052, lr: 0.0000\n",
      "Epoch: 388, Training loss: 1.376082, Validation loss: 1.3673, lr: 0.0000\n",
      "Epoch: 389, Training loss: 1.385277, Validation loss: 1.3883, lr: 0.0000\n",
      "Epoch: 390, Training loss: 1.370802, Validation loss: 1.3679, lr: 0.0000\n",
      "Epoch: 391, Training loss: 1.371174, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 392, Training loss: 1.390102, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 393, Training loss: 1.379158, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 394, Training loss: 1.387172, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 395, Training loss: 1.375686, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 396, Training loss: 1.404922, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 397, Training loss: 1.359774, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 398, Training loss: 1.367627, Validation loss: 1.3802, lr: 0.0000\n",
      "Epoch: 399, Training loss: 1.398373, Validation loss: 1.3874, lr: 0.0000\n",
      "Epoch: 400, Training loss: 1.377810, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 401, Training loss: 1.377893, Validation loss: 1.3784, lr: 0.0000\n",
      "Epoch: 402, Training loss: 1.370792, Validation loss: 1.3915, lr: 0.0000\n",
      "Epoch: 403, Training loss: 1.363118, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 404, Training loss: 1.377767, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 405, Training loss: 1.377913, Validation loss: 1.3693, lr: 0.0000\n",
      "Epoch: 406, Training loss: 1.407614, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 407, Training loss: 1.369281, Validation loss: 1.3876, lr: 0.0000\n",
      "Epoch: 408, Training loss: 1.384311, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 409, Training loss: 1.377705, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 410, Training loss: 1.378498, Validation loss: 1.3964, lr: 0.0000\n",
      "Epoch: 411, Training loss: 1.374186, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 412, Training loss: 1.384525, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 413, Training loss: 1.363176, Validation loss: 1.3758, lr: 0.0000\n",
      "Epoch: 414, Training loss: 1.380142, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 415, Training loss: 1.378315, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 416, Training loss: 1.365549, Validation loss: 1.3874, lr: 0.0000\n",
      "Epoch: 417, Training loss: 1.376855, Validation loss: 1.4122, lr: 0.0000\n",
      "Epoch: 418, Training loss: 1.368881, Validation loss: 1.3889, lr: 0.0000\n",
      "Epoch: 419, Training loss: 1.373447, Validation loss: 1.3796, lr: 0.0000\n",
      "Epoch: 420, Training loss: 1.376288, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 421, Training loss: 1.420596, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 422, Training loss: 1.368513, Validation loss: 1.3880, lr: 0.0000\n",
      "Epoch: 423, Training loss: 1.383165, Validation loss: 1.3798, lr: 0.0000\n",
      "Epoch: 424, Training loss: 1.375313, Validation loss: 1.3888, lr: 0.0000\n",
      "Epoch: 425, Training loss: 1.383406, Validation loss: 1.3889, lr: 0.0000\n",
      "Epoch: 426, Training loss: 1.365634, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 427, Training loss: 1.381996, Validation loss: 1.3771, lr: 0.0000\n",
      "Epoch: 428, Training loss: 1.381476, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 429, Training loss: 1.384308, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 430, Training loss: 1.374904, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 431, Training loss: 1.398340, Validation loss: 1.3784, lr: 0.0000\n",
      "Epoch: 432, Training loss: 1.370147, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 433, Training loss: 1.375793, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 434, Training loss: 1.372587, Validation loss: 1.3749, lr: 0.0000\n",
      "Epoch: 435, Training loss: 1.395878, Validation loss: 1.3637, lr: 0.0000\n",
      "Epoch: 436, Training loss: 1.391416, Validation loss: 1.4012, lr: 0.0000\n",
      "Epoch: 437, Training loss: 1.366924, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 438, Training loss: 1.367338, Validation loss: 1.3750, lr: 0.0000\n",
      "Epoch: 439, Training loss: 1.366222, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 440, Training loss: 1.373178, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 441, Training loss: 1.371209, Validation loss: 1.3677, lr: 0.0000\n",
      "Epoch: 442, Training loss: 1.360763, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 443, Training loss: 1.407377, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 444, Training loss: 1.366630, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 445, Training loss: 1.387113, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 446, Training loss: 1.385732, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 447, Training loss: 1.382844, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 448, Training loss: 1.374953, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 449, Training loss: 1.374090, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 450, Training loss: 1.376993, Validation loss: 1.3668, lr: 0.0000\n",
      "Epoch: 451, Training loss: 1.384107, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 452, Training loss: 1.384726, Validation loss: 1.3562, lr: 0.0000\n",
      "Epoch: 453, Training loss: 1.365620, Validation loss: 1.3788, lr: 0.0000\n",
      "Epoch: 454, Training loss: 1.384855, Validation loss: 1.3787, lr: 0.0000\n",
      "Epoch: 455, Training loss: 1.377767, Validation loss: 1.3882, lr: 0.0000\n",
      "Epoch: 456, Training loss: 1.436992, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 457, Training loss: 1.392110, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 458, Training loss: 1.388278, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 459, Training loss: 1.373616, Validation loss: 1.3885, lr: 0.0000\n",
      "Epoch: 460, Training loss: 1.382768, Validation loss: 1.3685, lr: 0.0000\n",
      "Epoch: 461, Training loss: 1.387077, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 462, Training loss: 1.376471, Validation loss: 1.3649, lr: 0.0000\n",
      "Epoch: 463, Training loss: 1.428223, Validation loss: 1.3625, lr: 0.0000\n",
      "Epoch: 464, Training loss: 1.381831, Validation loss: 1.3654, lr: 0.0000\n",
      "Epoch: 465, Training loss: 1.354014, Validation loss: 1.3800, lr: 0.0000\n",
      "Epoch: 466, Training loss: 1.362526, Validation loss: 1.3769, lr: 0.0000\n",
      "Epoch: 467, Training loss: 1.381964, Validation loss: 1.3760, lr: 0.0000\n",
      "Epoch: 468, Training loss: 1.383569, Validation loss: 1.4427, lr: 0.0000\n",
      "Epoch: 469, Training loss: 1.394273, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 470, Training loss: 1.364418, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 471, Training loss: 1.384093, Validation loss: 1.3759, lr: 0.0000\n",
      "Epoch: 472, Training loss: 1.390788, Validation loss: 1.4770, lr: 0.0000\n",
      "Epoch: 473, Training loss: 1.382274, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 474, Training loss: 1.402226, Validation loss: 1.3740, lr: 0.0000\n",
      "Epoch: 475, Training loss: 1.377602, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 476, Training loss: 1.436014, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 477, Training loss: 1.454511, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 478, Training loss: 1.368489, Validation loss: 1.3878, lr: 0.0000\n",
      "Epoch: 479, Training loss: 1.397435, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 480, Training loss: 1.357978, Validation loss: 1.3892, lr: 0.0000\n",
      "Epoch: 481, Training loss: 1.385834, Validation loss: 1.4118, lr: 0.0000\n",
      "Epoch: 482, Training loss: 1.388837, Validation loss: 1.3884, lr: 0.0000\n",
      "Epoch: 483, Training loss: 1.376339, Validation loss: 1.3697, lr: 0.0000\n",
      "Epoch: 484, Training loss: 1.395538, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 485, Training loss: 1.395689, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 486, Training loss: 1.372097, Validation loss: 1.3789, lr: 0.0000\n",
      "Epoch: 487, Training loss: 1.389814, Validation loss: 1.3802, lr: 0.0000\n",
      "Epoch: 488, Training loss: 1.373772, Validation loss: 1.3759, lr: 0.0000\n",
      "Epoch: 489, Training loss: 1.385925, Validation loss: 1.3777, lr: 0.0000\n",
      "Epoch: 490, Training loss: 1.390752, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 491, Training loss: 1.373807, Validation loss: 1.3725, lr: 0.0000\n",
      "Epoch: 492, Training loss: 1.365492, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 493, Training loss: 1.379809, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 494, Training loss: 1.369217, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 495, Training loss: 1.373659, Validation loss: 1.4027, lr: 0.0000\n",
      "Epoch: 496, Training loss: 1.378281, Validation loss: 1.3732, lr: 0.0000\n",
      "Epoch: 497, Training loss: 1.419736, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 498, Training loss: 1.384357, Validation loss: 1.3924, lr: 0.0000\n",
      "Epoch: 499, Training loss: 1.392719, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 500, Training loss: 1.364319, Validation loss: 1.3888, lr: 0.0000\n",
      "Epoch: 501, Training loss: 1.387154, Validation loss: 1.3730, lr: 0.0000\n",
      "Epoch: 502, Training loss: 1.371270, Validation loss: 1.3924, lr: 0.0000\n",
      "Epoch: 503, Training loss: 1.400530, Validation loss: 1.3797, lr: 0.0000\n",
      "Epoch: 504, Training loss: 1.401002, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 505, Training loss: 1.447756, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 506, Training loss: 1.384714, Validation loss: 1.3882, lr: 0.0000\n",
      "Epoch: 507, Training loss: 1.368440, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 508, Training loss: 1.404394, Validation loss: 1.3873, lr: 0.0000\n",
      "Epoch: 509, Training loss: 1.386180, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 510, Training loss: 1.379142, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 511, Training loss: 1.380038, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 512, Training loss: 1.377170, Validation loss: 1.3884, lr: 0.0000\n",
      "Epoch: 513, Training loss: 1.371060, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 514, Training loss: 1.407485, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 515, Training loss: 1.376304, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 516, Training loss: 1.375225, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 517, Training loss: 1.390788, Validation loss: 1.3773, lr: 0.0000\n",
      "Epoch: 518, Training loss: 1.371044, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 519, Training loss: 1.352050, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 520, Training loss: 1.419159, Validation loss: 1.3672, lr: 0.0000\n",
      "Epoch: 521, Training loss: 1.394779, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 522, Training loss: 1.388265, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 523, Training loss: 1.399146, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 524, Training loss: 1.363630, Validation loss: 1.3799, lr: 0.0000\n",
      "Epoch: 525, Training loss: 1.402781, Validation loss: 1.3875, lr: 0.0000\n",
      "Epoch: 526, Training loss: 1.369601, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 527, Training loss: 1.374352, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 528, Training loss: 1.372836, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 529, Training loss: 1.374049, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 530, Training loss: 1.370529, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 531, Training loss: 1.369906, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 532, Training loss: 1.424656, Validation loss: 1.3882, lr: 0.0000\n",
      "Epoch: 533, Training loss: 1.365377, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 534, Training loss: 1.381526, Validation loss: 1.3878, lr: 0.0000\n",
      "Epoch: 535, Training loss: 1.396688, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 536, Training loss: 1.377761, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 537, Training loss: 1.379643, Validation loss: 1.3789, lr: 0.0000\n",
      "Epoch: 538, Training loss: 1.368177, Validation loss: 1.3873, lr: 0.0000\n",
      "Epoch: 539, Training loss: 1.372394, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 540, Training loss: 1.412954, Validation loss: 1.3892, lr: 0.0000\n",
      "Epoch: 541, Training loss: 1.383298, Validation loss: 1.3877, lr: 0.0000\n",
      "Epoch: 542, Training loss: 1.371910, Validation loss: 1.3886, lr: 0.0000\n",
      "Epoch: 543, Training loss: 1.369647, Validation loss: 1.3688, lr: 0.0000\n",
      "Epoch: 544, Training loss: 1.378574, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 545, Training loss: 1.369596, Validation loss: 1.4164, lr: 0.0000\n",
      "Epoch: 546, Training loss: 1.380113, Validation loss: 1.3946, lr: 0.0000\n",
      "Epoch: 547, Training loss: 1.383517, Validation loss: 1.3793, lr: 0.0000\n",
      "Epoch: 548, Training loss: 1.374619, Validation loss: 1.3932, lr: 0.0000\n",
      "Epoch: 549, Training loss: 1.380625, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 550, Training loss: 1.355111, Validation loss: 1.3722, lr: 0.0000\n",
      "Epoch: 551, Training loss: 1.387356, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 552, Training loss: 1.368301, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 553, Training loss: 1.383165, Validation loss: 1.3738, lr: 0.0000\n",
      "Epoch: 554, Training loss: 1.379984, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 555, Training loss: 1.361643, Validation loss: 1.3775, lr: 0.0000\n",
      "Epoch: 556, Training loss: 1.394032, Validation loss: 1.3730, lr: 0.0000\n",
      "Epoch: 557, Training loss: 1.379688, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 558, Training loss: 1.380447, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 559, Training loss: 1.379296, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 560, Training loss: 1.381090, Validation loss: 1.3775, lr: 0.0000\n",
      "Epoch: 561, Training loss: 1.385660, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 562, Training loss: 1.368405, Validation loss: 1.3898, lr: 0.0000\n",
      "Epoch: 563, Training loss: 1.384793, Validation loss: 1.4221, lr: 0.0000\n",
      "Epoch: 564, Training loss: 1.386860, Validation loss: 1.3740, lr: 0.0000\n",
      "Epoch: 565, Training loss: 1.375175, Validation loss: 1.3784, lr: 0.0000\n",
      "Epoch: 566, Training loss: 1.380433, Validation loss: 1.3800, lr: 0.0000\n",
      "Epoch: 567, Training loss: 1.367253, Validation loss: 1.3797, lr: 0.0000\n",
      "Epoch: 568, Training loss: 1.388615, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 569, Training loss: 1.380991, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 570, Training loss: 1.371878, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 571, Training loss: 1.373099, Validation loss: 1.3735, lr: 0.0000\n",
      "Epoch: 572, Training loss: 1.392172, Validation loss: 1.3882, lr: 0.0000\n",
      "Epoch: 573, Training loss: 1.381258, Validation loss: 1.3746, lr: 0.0000\n",
      "Epoch: 574, Training loss: 1.365562, Validation loss: 1.3510, lr: 0.0000\n",
      "Epoch: 575, Training loss: 1.393480, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 576, Training loss: 1.411205, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 577, Training loss: 1.376085, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 578, Training loss: 1.403039, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 579, Training loss: 1.380586, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 580, Training loss: 1.390853, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 581, Training loss: 1.374948, Validation loss: 1.3472, lr: 0.0000\n",
      "Epoch: 582, Training loss: 1.376674, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 583, Training loss: 1.372918, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 584, Training loss: 1.385591, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 585, Training loss: 1.384557, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 586, Training loss: 1.363112, Validation loss: 1.4055, lr: 0.0000\n",
      "Epoch: 587, Training loss: 1.373736, Validation loss: 1.4016, lr: 0.0000\n",
      "Epoch: 588, Training loss: 1.358987, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 589, Training loss: 1.375114, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 590, Training loss: 1.379266, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 591, Training loss: 1.387746, Validation loss: 1.3799, lr: 0.0000\n",
      "Epoch: 592, Training loss: 1.383817, Validation loss: 1.3944, lr: 0.0000\n",
      "Epoch: 593, Training loss: 1.383094, Validation loss: 1.3773, lr: 0.0000\n",
      "Epoch: 594, Training loss: 1.365342, Validation loss: 1.3440, lr: 0.0000\n",
      "Epoch: 595, Training loss: 1.374995, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 596, Training loss: 1.406558, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 597, Training loss: 1.376652, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 598, Training loss: 1.387324, Validation loss: 1.3875, lr: 0.0000\n",
      "Epoch: 599, Training loss: 1.411595, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 600, Training loss: 1.373315, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 601, Training loss: 1.383003, Validation loss: 1.3623, lr: 0.0000\n",
      "Epoch: 602, Training loss: 1.384747, Validation loss: 1.4134, lr: 0.0000\n",
      "Epoch: 603, Training loss: 1.385552, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 604, Training loss: 1.380387, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 605, Training loss: 1.397615, Validation loss: 1.3876, lr: 0.0000\n",
      "Epoch: 606, Training loss: 1.390102, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 607, Training loss: 1.380319, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 608, Training loss: 1.371590, Validation loss: 1.3916, lr: 0.0000\n",
      "Epoch: 609, Training loss: 1.378749, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 610, Training loss: 1.404749, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 611, Training loss: 1.373359, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 612, Training loss: 1.360168, Validation loss: 1.3739, lr: 0.0000\n",
      "Epoch: 613, Training loss: 1.389251, Validation loss: 1.3908, lr: 0.0000\n",
      "Epoch: 614, Training loss: 1.371038, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 615, Training loss: 1.377244, Validation loss: 1.3797, lr: 0.0000\n",
      "Epoch: 616, Training loss: 1.375839, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 617, Training loss: 1.377670, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 618, Training loss: 1.409600, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 619, Training loss: 1.379090, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 620, Training loss: 1.364578, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 621, Training loss: 1.395972, Validation loss: 1.3773, lr: 0.0000\n",
      "Epoch: 622, Training loss: 1.405167, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 623, Training loss: 1.378005, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 624, Training loss: 1.360317, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 625, Training loss: 1.387318, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 626, Training loss: 1.403097, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 627, Training loss: 1.375433, Validation loss: 1.3704, lr: 0.0000\n",
      "Epoch: 628, Training loss: 1.376372, Validation loss: 1.3948, lr: 0.0000\n",
      "Epoch: 629, Training loss: 1.399494, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 630, Training loss: 1.387333, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 631, Training loss: 1.383750, Validation loss: 1.3885, lr: 0.0000\n",
      "Epoch: 632, Training loss: 1.384730, Validation loss: 1.3772, lr: 0.0000\n",
      "Epoch: 633, Training loss: 1.366864, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 634, Training loss: 1.380956, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 635, Training loss: 1.378074, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 636, Training loss: 1.372343, Validation loss: 1.3896, lr: 0.0000\n",
      "Epoch: 637, Training loss: 1.374354, Validation loss: 1.3724, lr: 0.0000\n",
      "Epoch: 638, Training loss: 1.370059, Validation loss: 1.3583, lr: 0.0000\n",
      "Epoch: 639, Training loss: 1.436263, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 640, Training loss: 1.405639, Validation loss: 1.3875, lr: 0.0000\n",
      "Epoch: 641, Training loss: 1.411841, Validation loss: 1.3749, lr: 0.0000\n",
      "Epoch: 642, Training loss: 1.384443, Validation loss: 1.3987, lr: 0.0000\n",
      "Epoch: 643, Training loss: 1.374713, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 644, Training loss: 1.371341, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 645, Training loss: 1.375795, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 646, Training loss: 1.381108, Validation loss: 1.3670, lr: 0.0000\n",
      "Epoch: 647, Training loss: 1.394847, Validation loss: 1.3792, lr: 0.0000\n",
      "Epoch: 648, Training loss: 1.374622, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 649, Training loss: 1.383909, Validation loss: 1.3747, lr: 0.0000\n",
      "Epoch: 650, Training loss: 1.371772, Validation loss: 1.3564, lr: 0.0000\n",
      "Epoch: 651, Training loss: 1.410938, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 652, Training loss: 1.362156, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 653, Training loss: 1.380266, Validation loss: 1.3879, lr: 0.0000\n",
      "Epoch: 654, Training loss: 1.454783, Validation loss: 1.3744, lr: 0.0000\n",
      "Epoch: 655, Training loss: 1.389234, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 656, Training loss: 1.377675, Validation loss: 1.3757, lr: 0.0000\n",
      "Epoch: 657, Training loss: 1.391999, Validation loss: 1.3598, lr: 0.0000\n",
      "Epoch: 658, Training loss: 1.397541, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 659, Training loss: 1.404927, Validation loss: 1.3941, lr: 0.0000\n",
      "Epoch: 660, Training loss: 1.379720, Validation loss: 1.3593, lr: 0.0000\n",
      "Epoch: 661, Training loss: 1.392956, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 662, Training loss: 1.402543, Validation loss: 1.3880, lr: 0.0000\n",
      "Epoch: 663, Training loss: 1.386259, Validation loss: 1.3878, lr: 0.0000\n",
      "Epoch: 664, Training loss: 1.382935, Validation loss: 1.3788, lr: 0.0000\n",
      "Epoch: 665, Training loss: 1.369392, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 666, Training loss: 1.398502, Validation loss: 1.3871, lr: 0.0000\n",
      "Epoch: 667, Training loss: 1.429152, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 668, Training loss: 1.412395, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 669, Training loss: 1.365226, Validation loss: 1.3717, lr: 0.0000\n",
      "Epoch: 670, Training loss: 1.383215, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 671, Training loss: 1.379704, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 672, Training loss: 1.372802, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 673, Training loss: 1.356518, Validation loss: 1.3901, lr: 0.0000\n",
      "Epoch: 674, Training loss: 1.415456, Validation loss: 1.3779, lr: 0.0000\n",
      "Epoch: 675, Training loss: 1.365464, Validation loss: 1.3786, lr: 0.0000\n",
      "Epoch: 676, Training loss: 1.372225, Validation loss: 1.3878, lr: 0.0000\n",
      "Epoch: 677, Training loss: 1.383921, Validation loss: 1.3900, lr: 0.0000\n",
      "Epoch: 678, Training loss: 1.392950, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 679, Training loss: 1.382069, Validation loss: 1.3951, lr: 0.0000\n",
      "Epoch: 680, Training loss: 1.372261, Validation loss: 1.3882, lr: 0.0000\n",
      "Epoch: 681, Training loss: 1.375336, Validation loss: 1.3915, lr: 0.0000\n",
      "Epoch: 682, Training loss: 1.382290, Validation loss: 1.3768, lr: 0.0000\n",
      "Epoch: 683, Training loss: 1.363819, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 684, Training loss: 1.388670, Validation loss: 1.3876, lr: 0.0000\n",
      "Epoch: 685, Training loss: 1.383317, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 686, Training loss: 1.387014, Validation loss: 1.3696, lr: 0.0000\n",
      "Epoch: 687, Training loss: 1.385502, Validation loss: 1.3772, lr: 0.0000\n",
      "Epoch: 688, Training loss: 1.379659, Validation loss: 1.3743, lr: 0.0000\n",
      "Epoch: 689, Training loss: 1.416418, Validation loss: 1.3691, lr: 0.0000\n",
      "Epoch: 690, Training loss: 1.388740, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 691, Training loss: 1.366945, Validation loss: 1.3876, lr: 0.0000\n",
      "Epoch: 692, Training loss: 1.376769, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 693, Training loss: 1.388364, Validation loss: 1.3871, lr: 0.0000\n",
      "Epoch: 694, Training loss: 1.389291, Validation loss: 1.3872, lr: 0.0000\n",
      "Epoch: 695, Training loss: 1.389144, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 696, Training loss: 1.376874, Validation loss: 1.3591, lr: 0.0000\n",
      "Epoch: 697, Training loss: 1.374043, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 698, Training loss: 1.388082, Validation loss: 1.3704, lr: 0.0000\n",
      "Epoch: 699, Training loss: 1.373767, Validation loss: 1.3764, lr: 0.0000\n",
      "Epoch: 700, Training loss: 1.388814, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 701, Training loss: 1.381745, Validation loss: 1.3482, lr: 0.0000\n",
      "Epoch: 702, Training loss: 1.390770, Validation loss: 1.3657, lr: 0.0000\n",
      "Epoch: 703, Training loss: 1.385536, Validation loss: 1.3795, lr: 0.0000\n",
      "Epoch: 704, Training loss: 1.371925, Validation loss: 1.3917, lr: 0.0000\n",
      "Epoch: 705, Training loss: 1.454386, Validation loss: 1.3759, lr: 0.0000\n",
      "Epoch: 706, Training loss: 1.387290, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 707, Training loss: 1.389858, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 708, Training loss: 1.394249, Validation loss: 1.3906, lr: 0.0000\n",
      "Epoch: 709, Training loss: 1.383929, Validation loss: 1.3797, lr: 0.0000\n",
      "Epoch: 710, Training loss: 1.386764, Validation loss: 1.3882, lr: 0.0000\n",
      "Epoch: 711, Training loss: 1.377869, Validation loss: 1.4271, lr: 0.0000\n",
      "Epoch: 712, Training loss: 1.392881, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 713, Training loss: 1.374256, Validation loss: 1.3655, lr: 0.0000\n",
      "Epoch: 714, Training loss: 1.379621, Validation loss: 1.4068, lr: 0.0000\n",
      "Epoch: 715, Training loss: 1.374241, Validation loss: 1.3948, lr: 0.0000\n",
      "Epoch: 716, Training loss: 1.366329, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 717, Training loss: 1.377055, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 718, Training loss: 1.437633, Validation loss: 1.3798, lr: 0.0000\n",
      "Epoch: 719, Training loss: 1.378722, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 720, Training loss: 1.372028, Validation loss: 1.3728, lr: 0.0000\n",
      "Epoch: 721, Training loss: 1.380979, Validation loss: 1.5854, lr: 0.0000\n",
      "Epoch: 722, Training loss: 1.388839, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 723, Training loss: 1.393458, Validation loss: 1.3889, lr: 0.0000\n",
      "Epoch: 724, Training loss: 1.375624, Validation loss: 1.3924, lr: 0.0000\n",
      "Epoch: 725, Training loss: 1.384603, Validation loss: 1.3747, lr: 0.0000\n",
      "Epoch: 726, Training loss: 1.393522, Validation loss: 1.3752, lr: 0.0000\n",
      "Epoch: 727, Training loss: 1.368790, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 728, Training loss: 1.362035, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 729, Training loss: 1.369041, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 730, Training loss: 1.379338, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 731, Training loss: 1.371044, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 732, Training loss: 1.387160, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 733, Training loss: 1.397951, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 734, Training loss: 1.378165, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 735, Training loss: 1.395413, Validation loss: 1.3752, lr: 0.0000\n",
      "Epoch: 736, Training loss: 1.385791, Validation loss: 1.3906, lr: 0.0000\n",
      "Epoch: 737, Training loss: 1.368526, Validation loss: 1.3872, lr: 0.0000\n",
      "Epoch: 738, Training loss: 1.377505, Validation loss: 1.3918, lr: 0.0000\n",
      "Epoch: 739, Training loss: 1.386597, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 740, Training loss: 1.408748, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 741, Training loss: 1.393138, Validation loss: 1.3773, lr: 0.0000\n",
      "Epoch: 742, Training loss: 1.406979, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 743, Training loss: 1.373700, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 744, Training loss: 1.382870, Validation loss: 1.3872, lr: 0.0000\n",
      "Epoch: 745, Training loss: 1.374201, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 746, Training loss: 1.370655, Validation loss: 1.3873, lr: 0.0000\n",
      "Epoch: 747, Training loss: 1.371135, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 748, Training loss: 1.400034, Validation loss: 1.3887, lr: 0.0000\n",
      "Epoch: 749, Training loss: 1.374050, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 750, Training loss: 1.404055, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 751, Training loss: 1.354613, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 752, Training loss: 1.376960, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 753, Training loss: 1.414216, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 754, Training loss: 1.363923, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 755, Training loss: 1.366902, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 756, Training loss: 1.367735, Validation loss: 1.3803, lr: 0.0000\n",
      "Epoch: 757, Training loss: 1.407961, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 758, Training loss: 1.403246, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 759, Training loss: 1.396925, Validation loss: 1.3793, lr: 0.0000\n",
      "Epoch: 760, Training loss: 1.390164, Validation loss: 1.3895, lr: 0.0000\n",
      " *och: 761, Training loss: 1.384132, Validation loss: 1.3362, lr: 0.0000\n",
      "Epoch: 762, Training loss: 1.381307, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 763, Training loss: 1.369075, Validation loss: 1.4298, lr: 0.0000\n",
      "Epoch: 764, Training loss: 1.397371, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 765, Training loss: 1.364744, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 766, Training loss: 1.369714, Validation loss: 1.3621, lr: 0.0000\n",
      "Epoch: 767, Training loss: 1.391206, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 768, Training loss: 1.386211, Validation loss: 1.3712, lr: 0.0000\n",
      "Epoch: 769, Training loss: 1.362238, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 770, Training loss: 1.375348, Validation loss: 1.3660, lr: 0.0000\n",
      "Epoch: 771, Training loss: 1.381606, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 772, Training loss: 1.373658, Validation loss: 1.3978, lr: 0.0000\n",
      "Epoch: 773, Training loss: 1.359369, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 774, Training loss: 1.368322, Validation loss: 1.3730, lr: 0.0000\n",
      "Epoch: 775, Training loss: 1.364620, Validation loss: 1.3879, lr: 0.0000\n",
      "Epoch: 776, Training loss: 1.384203, Validation loss: 1.3773, lr: 0.0000\n",
      "Epoch: 777, Training loss: 1.364549, Validation loss: 1.3889, lr: 0.0000\n",
      "Epoch: 778, Training loss: 1.378007, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 779, Training loss: 1.378876, Validation loss: 1.3796, lr: 0.0000\n",
      "Epoch: 780, Training loss: 1.378287, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 781, Training loss: 1.385967, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 782, Training loss: 1.362576, Validation loss: 1.3921, lr: 0.0000\n",
      "Epoch: 783, Training loss: 1.378211, Validation loss: 1.3800, lr: 0.0000\n",
      "Epoch: 784, Training loss: 1.402705, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 785, Training loss: 1.397970, Validation loss: 1.3874, lr: 0.0000\n",
      "Epoch: 786, Training loss: 1.387321, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 787, Training loss: 1.382583, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 788, Training loss: 1.393148, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 789, Training loss: 1.390908, Validation loss: 1.3726, lr: 0.0000\n",
      "Epoch: 790, Training loss: 1.391400, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 791, Training loss: 1.365902, Validation loss: 1.3781, lr: 0.0000\n",
      "Epoch: 792, Training loss: 1.367679, Validation loss: 1.3962, lr: 0.0000\n",
      "Epoch: 793, Training loss: 1.371847, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 794, Training loss: 1.384582, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 795, Training loss: 1.409045, Validation loss: 1.3763, lr: 0.0000\n",
      "Epoch: 796, Training loss: 1.377978, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 797, Training loss: 1.373803, Validation loss: 1.4386, lr: 0.0000\n",
      "Epoch: 798, Training loss: 1.403646, Validation loss: 1.4092, lr: 0.0000\n",
      "Epoch: 799, Training loss: 1.410389, Validation loss: 1.3780, lr: 0.0000\n",
      "Epoch: 800, Training loss: 1.379917, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 801, Training loss: 1.367888, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 802, Training loss: 1.388359, Validation loss: 1.3793, lr: 0.0000\n",
      "Epoch: 803, Training loss: 1.358196, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 804, Training loss: 1.373528, Validation loss: 1.4115, lr: 0.0000\n",
      "Epoch: 805, Training loss: 1.379153, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 806, Training loss: 1.369770, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 807, Training loss: 1.385001, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 808, Training loss: 1.398864, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 809, Training loss: 1.371004, Validation loss: 1.3691, lr: 0.0000\n",
      "Epoch: 810, Training loss: 1.372888, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 811, Training loss: 1.446146, Validation loss: 1.3911, lr: 0.0000\n",
      "Epoch: 812, Training loss: 1.392081, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 813, Training loss: 1.373130, Validation loss: 1.3901, lr: 0.0000\n",
      "Epoch: 814, Training loss: 1.382627, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 815, Training loss: 1.376013, Validation loss: 1.3903, lr: 0.0000\n",
      "Epoch: 816, Training loss: 1.379387, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 817, Training loss: 1.381622, Validation loss: 1.3894, lr: 0.0000\n",
      "Epoch: 818, Training loss: 1.376861, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 819, Training loss: 1.368681, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 820, Training loss: 1.385544, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 821, Training loss: 1.367710, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 822, Training loss: 1.377871, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 823, Training loss: 1.345466, Validation loss: 1.3782, lr: 0.0000\n",
      "Epoch: 824, Training loss: 1.365688, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 825, Training loss: 1.384203, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 826, Training loss: 1.388514, Validation loss: 1.3761, lr: 0.0000\n",
      "Epoch: 827, Training loss: 1.378790, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 828, Training loss: 1.387818, Validation loss: 1.3903, lr: 0.0000\n",
      "Epoch: 829, Training loss: 1.382401, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 830, Training loss: 1.364868, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 831, Training loss: 1.372793, Validation loss: 1.3908, lr: 0.0000\n",
      "Epoch: 832, Training loss: 1.373275, Validation loss: 1.3927, lr: 0.0000\n",
      "Epoch: 833, Training loss: 1.382720, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 834, Training loss: 1.393924, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 835, Training loss: 1.377780, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 836, Training loss: 1.370316, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 837, Training loss: 1.373335, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 838, Training loss: 1.371182, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 839, Training loss: 1.405366, Validation loss: 1.4840, lr: 0.0000\n",
      "Epoch: 840, Training loss: 1.379510, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 841, Training loss: 1.386005, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 842, Training loss: 1.391464, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 843, Training loss: 1.398936, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 844, Training loss: 1.362365, Validation loss: 1.3784, lr: 0.0000\n",
      "Epoch: 845, Training loss: 1.396760, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 846, Training loss: 1.384132, Validation loss: 1.3789, lr: 0.0000\n",
      "Epoch: 847, Training loss: 1.370562, Validation loss: 1.3878, lr: 0.0000\n",
      "Epoch: 848, Training loss: 1.373571, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 849, Training loss: 1.377796, Validation loss: 1.3883, lr: 0.0000\n",
      "Epoch: 850, Training loss: 1.386902, Validation loss: 1.3705, lr: 0.0000\n",
      "Epoch: 851, Training loss: 1.364898, Validation loss: 1.3742, lr: 0.0000\n",
      "Epoch: 852, Training loss: 1.359816, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 853, Training loss: 1.385522, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 854, Training loss: 1.379671, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 855, Training loss: 1.382393, Validation loss: 1.3797, lr: 0.0000\n",
      "Epoch: 856, Training loss: 1.403930, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 857, Training loss: 1.385147, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 858, Training loss: 1.366494, Validation loss: 1.3929, lr: 0.0000\n",
      "Epoch: 859, Training loss: 1.394682, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 860, Training loss: 1.376676, Validation loss: 1.3684, lr: 0.0000\n",
      "Epoch: 861, Training loss: 1.373791, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 862, Training loss: 1.380478, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 863, Training loss: 1.400812, Validation loss: 1.3708, lr: 0.0000\n",
      "Epoch: 864, Training loss: 1.389025, Validation loss: 1.3717, lr: 0.0000\n",
      "Epoch: 865, Training loss: 1.421121, Validation loss: 1.3721, lr: 0.0000\n",
      "Epoch: 866, Training loss: 1.382145, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 867, Training loss: 1.372950, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 868, Training loss: 1.393397, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 869, Training loss: 1.368313, Validation loss: 1.3729, lr: 0.0000\n",
      "Epoch: 870, Training loss: 1.378924, Validation loss: 1.3872, lr: 0.0000\n",
      "Epoch: 871, Training loss: 1.364387, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 872, Training loss: 1.387066, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 873, Training loss: 1.376526, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 874, Training loss: 1.378574, Validation loss: 1.3944, lr: 0.0000\n",
      "Epoch: 875, Training loss: 1.379491, Validation loss: 1.3633, lr: 0.0000\n",
      "Epoch: 876, Training loss: 1.375692, Validation loss: 1.3888, lr: 0.0000\n",
      "Epoch: 877, Training loss: 1.415743, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 878, Training loss: 1.384694, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 879, Training loss: 1.373096, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 880, Training loss: 1.374625, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 881, Training loss: 1.369313, Validation loss: 1.3782, lr: 0.0000\n",
      "Epoch: 882, Training loss: 1.408815, Validation loss: 1.3750, lr: 0.0000\n",
      "Epoch: 883, Training loss: 1.369410, Validation loss: 1.3791, lr: 0.0000\n",
      "Epoch: 884, Training loss: 1.401701, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 885, Training loss: 1.379492, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 886, Training loss: 1.384208, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 887, Training loss: 1.380881, Validation loss: 1.3783, lr: 0.0000\n",
      "Epoch: 888, Training loss: 1.375892, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 889, Training loss: 1.394287, Validation loss: 1.3800, lr: 0.0000\n",
      "Epoch: 890, Training loss: 1.399337, Validation loss: 1.3651, lr: 0.0000\n",
      "Epoch: 891, Training loss: 1.385955, Validation loss: 1.3906, lr: 0.0000\n",
      "Epoch: 892, Training loss: 1.399409, Validation loss: 1.3878, lr: 0.0000\n",
      "Epoch: 893, Training loss: 1.384586, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 894, Training loss: 1.371608, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 895, Training loss: 1.374052, Validation loss: 1.4199, lr: 0.0000\n",
      "Epoch: 896, Training loss: 1.397540, Validation loss: 1.3673, lr: 0.0000\n",
      "Epoch: 897, Training loss: 1.377575, Validation loss: 1.3646, lr: 0.0000\n",
      "Epoch: 898, Training loss: 1.381868, Validation loss: 1.3892, lr: 0.0000\n",
      "Epoch: 899, Training loss: 1.377097, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 900, Training loss: 1.400388, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 901, Training loss: 1.379778, Validation loss: 1.3881, lr: 0.0000\n",
      "Epoch: 902, Training loss: 1.380585, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 903, Training loss: 1.368811, Validation loss: 1.3777, lr: 0.0000\n",
      "Epoch: 904, Training loss: 1.400422, Validation loss: 1.3876, lr: 0.0000\n",
      "Epoch: 905, Training loss: 1.366028, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 906, Training loss: 1.387124, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 907, Training loss: 1.389756, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 908, Training loss: 1.380531, Validation loss: 1.3803, lr: 0.0000\n",
      "Epoch: 909, Training loss: 1.383948, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 910, Training loss: 1.385089, Validation loss: 1.3757, lr: 0.0000\n",
      "Epoch: 911, Training loss: 1.384538, Validation loss: 1.3876, lr: 0.0000\n",
      "Epoch: 912, Training loss: 1.399152, Validation loss: 1.3635, lr: 0.0000\n",
      "Epoch: 913, Training loss: 1.382993, Validation loss: 1.3912, lr: 0.0000\n",
      "Epoch: 914, Training loss: 1.369693, Validation loss: 1.3529, lr: 0.0000\n",
      "Epoch: 915, Training loss: 1.425484, Validation loss: 1.3903, lr: 0.0000\n",
      "Epoch: 916, Training loss: 1.377765, Validation loss: 1.3894, lr: 0.0000\n",
      "Epoch: 917, Training loss: 1.367816, Validation loss: 1.3871, lr: 0.0000\n",
      "Epoch: 918, Training loss: 1.392860, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 919, Training loss: 1.424087, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 920, Training loss: 1.394160, Validation loss: 1.3886, lr: 0.0000\n",
      "Epoch: 921, Training loss: 1.372113, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 922, Training loss: 1.379855, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 923, Training loss: 1.381908, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 924, Training loss: 1.385518, Validation loss: 1.3910, lr: 0.0000\n",
      "Epoch: 925, Training loss: 1.384569, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 926, Training loss: 1.364374, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 927, Training loss: 1.370807, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 928, Training loss: 1.361070, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 929, Training loss: 1.381474, Validation loss: 1.3924, lr: 0.0000\n",
      "Epoch: 930, Training loss: 1.373466, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 931, Training loss: 1.387308, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 932, Training loss: 1.364899, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 933, Training loss: 1.372123, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 934, Training loss: 1.371192, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 935, Training loss: 1.368437, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 936, Training loss: 1.383478, Validation loss: 1.3778, lr: 0.0000\n",
      "Epoch: 937, Training loss: 1.389335, Validation loss: 1.4602, lr: 0.0000\n",
      "Epoch: 938, Training loss: 1.367274, Validation loss: 1.3786, lr: 0.0000\n",
      "Epoch: 939, Training loss: 1.374276, Validation loss: 1.3414, lr: 0.0000\n",
      "Epoch: 940, Training loss: 1.420829, Validation loss: 1.3774, lr: 0.0000\n",
      "Epoch: 941, Training loss: 1.461546, Validation loss: 1.3890, lr: 0.0000\n",
      "Epoch: 942, Training loss: 1.372056, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 943, Training loss: 1.392573, Validation loss: 1.3751, lr: 0.0000\n",
      "Epoch: 944, Training loss: 1.429312, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 945, Training loss: 1.381194, Validation loss: 1.3802, lr: 0.0000\n",
      "Epoch: 946, Training loss: 1.387264, Validation loss: 1.3796, lr: 0.0000\n",
      "Epoch: 947, Training loss: 1.402752, Validation loss: 1.3782, lr: 0.0000\n",
      "Epoch: 948, Training loss: 1.379252, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 949, Training loss: 1.382303, Validation loss: 1.3719, lr: 0.0000\n",
      "Epoch: 950, Training loss: 1.380723, Validation loss: 1.3571, lr: 0.0000\n",
      "Epoch: 951, Training loss: 1.394993, Validation loss: 1.3874, lr: 0.0000\n",
      "Epoch: 952, Training loss: 1.388363, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 953, Training loss: 1.368686, Validation loss: 1.3779, lr: 0.0000\n",
      "Epoch: 954, Training loss: 1.402108, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 955, Training loss: 1.389367, Validation loss: 1.3633, lr: 0.0000\n",
      "Epoch: 956, Training loss: 1.375266, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 957, Training loss: 1.383172, Validation loss: 1.3652, lr: 0.0000\n",
      "Epoch: 958, Training loss: 1.377549, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 959, Training loss: 1.378206, Validation loss: 1.3696, lr: 0.0000\n",
      "Epoch: 960, Training loss: 1.387228, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 961, Training loss: 1.365695, Validation loss: 1.3809, lr: 0.0000\n",
      "Epoch: 962, Training loss: 1.365895, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 963, Training loss: 1.391161, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 964, Training loss: 1.479406, Validation loss: 1.3903, lr: 0.0000\n",
      "Epoch: 965, Training loss: 1.359886, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 966, Training loss: 1.394105, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 967, Training loss: 1.394701, Validation loss: 1.3773, lr: 0.0000\n",
      "Epoch: 968, Training loss: 1.388162, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 969, Training loss: 1.370726, Validation loss: 1.3918, lr: 0.0000\n",
      "Epoch: 970, Training loss: 1.382576, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 971, Training loss: 1.366067, Validation loss: 1.3756, lr: 0.0000\n",
      "Epoch: 972, Training loss: 1.365675, Validation loss: 1.3762, lr: 0.0000\n",
      "Epoch: 973, Training loss: 1.381546, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 974, Training loss: 1.375189, Validation loss: 1.3774, lr: 0.0000\n",
      "Epoch: 975, Training loss: 1.384730, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 976, Training loss: 1.389046, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 977, Training loss: 1.397525, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 978, Training loss: 1.387060, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 979, Training loss: 1.373926, Validation loss: 1.3727, lr: 0.0000\n",
      "Epoch: 980, Training loss: 1.378982, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 981, Training loss: 1.382573, Validation loss: 1.3871, lr: 0.0000\n",
      "Epoch: 982, Training loss: 1.414218, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 983, Training loss: 1.383882, Validation loss: 1.5630, lr: 0.0000\n",
      "Epoch: 984, Training loss: 1.373187, Validation loss: 1.3875, lr: 0.0000\n",
      "Epoch: 985, Training loss: 1.393628, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 986, Training loss: 1.369182, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 987, Training loss: 1.366455, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 988, Training loss: 1.390295, Validation loss: 1.3774, lr: 0.0000\n",
      "Epoch: 989, Training loss: 1.388523, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 990, Training loss: 1.377122, Validation loss: 1.3789, lr: 0.0000\n",
      "Epoch: 991, Training loss: 1.384468, Validation loss: 1.3741, lr: 0.0000\n",
      "Epoch: 992, Training loss: 1.392700, Validation loss: 1.3761, lr: 0.0000\n",
      "Epoch: 993, Training loss: 1.376408, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 994, Training loss: 1.404635, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 995, Training loss: 1.381642, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 996, Training loss: 1.372847, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 997, Training loss: 1.400006, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 998, Training loss: 1.385327, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 999, Training loss: 1.372936, Validation loss: 1.3763, lr: 0.0000\n",
      "Final test loss: 1.3862\n",
      "=== Run 03/10 ===\n",
      "\n",
      "---- Settings: \n",
      "\n",
      "epochs : 1000\n",
      "hidden_channels : [32]\n",
      "out_channels : 10\n",
      "inner_product_features : False\n",
      "batch_size : 64\n",
      "lr : 0.01\n",
      "momentum : 0.9\n",
      "dropout : 0.0\n",
      "batch_norm : batch_norm\n",
      "bias : True\n",
      "order : 2\n",
      "diffusion : True\n",
      "frac_sampled_nb : -1\n",
      "include_positions : False\n",
      "include_self : True\n",
      "vec_norm : False\n",
      "emb_norm : False\n",
      "seed : 0\n",
      "dim_signal : 100\n",
      "dim_emb : 100\n",
      "n_sampled_nb : -1\n",
      "\n",
      "---- Number of features to pass to the MLP:  1010100\n",
      "---- Total number of parameters:  32323627\n",
      "\n",
      "Using device cuda:0\n",
      "\n",
      "---- Training network ...\n",
      "\n",
      "---- Timestamp: 20250614-220004\n",
      "\n",
      " *och: 0, Training loss: 1.413020, Validation loss: 1.8128, lr: 0.0100\n",
      " *och: 1, Training loss: 1.607118, Validation loss: 1.3758, lr: 0.0100\n",
      "Epoch: 2, Training loss: 1.386040, Validation loss: 1.4386, lr: 0.0100\n",
      " *och: 3, Training loss: 1.367245, Validation loss: 1.3731, lr: 0.0100\n",
      "Epoch: 4, Training loss: 1.398659, Validation loss: 1.3817, lr: 0.0100\n",
      "Epoch: 5, Training loss: 1.391012, Validation loss: 1.3831, lr: 0.0100\n",
      "Epoch: 6, Training loss: 1.389671, Validation loss: 1.4078, lr: 0.0100\n",
      "Epoch: 7, Training loss: 1.395999, Validation loss: 1.4058, lr: 0.0100\n",
      "Epoch: 8, Training loss: 1.387773, Validation loss: 1.3784, lr: 0.0100\n",
      " *och: 9, Training loss: 1.388391, Validation loss: 1.3689, lr: 0.0100\n",
      "Epoch: 10, Training loss: 1.383286, Validation loss: 1.3801, lr: 0.0100\n",
      "Epoch: 11, Training loss: 1.392350, Validation loss: 1.3939, lr: 0.0100\n",
      "Epoch: 12, Training loss: 1.378938, Validation loss: 1.3998, lr: 0.0100\n",
      "Epoch: 13, Training loss: 1.412971, Validation loss: 1.4869, lr: 0.0100\n",
      "Epoch: 14, Training loss: 1.357142, Validation loss: 1.3816, lr: 0.0100\n",
      " *och: 15, Training loss: 1.421512, Validation loss: 1.3496, lr: 0.0100\n",
      "Epoch: 16, Training loss: 1.397285, Validation loss: 1.5986, lr: 0.0100\n",
      "Epoch: 17, Training loss: 1.406398, Validation loss: 1.3830, lr: 0.0100\n",
      " *och: 18, Training loss: 1.402587, Validation loss: 1.3173, lr: 0.0100\n",
      "Epoch: 19, Training loss: 1.370534, Validation loss: 1.3910, lr: 0.0100\n",
      "Epoch: 20, Training loss: 1.405914, Validation loss: 1.3823, lr: 0.0100\n",
      "Epoch: 21, Training loss: 1.370867, Validation loss: 1.3787, lr: 0.0100\n",
      "Epoch: 22, Training loss: 1.438977, Validation loss: 1.3801, lr: 0.0100\n",
      "Epoch: 23, Training loss: 1.373100, Validation loss: 1.3807, lr: 0.0100\n",
      "Epoch: 24, Training loss: 1.380016, Validation loss: 1.3825, lr: 0.0100\n",
      "Epoch: 25, Training loss: 1.392009, Validation loss: 1.3734, lr: 0.0010\n",
      "Epoch: 26, Training loss: 1.456904, Validation loss: 1.3833, lr: 0.0010\n",
      "Epoch: 27, Training loss: 1.382671, Validation loss: 1.3824, lr: 0.0010\n",
      "Epoch: 28, Training loss: 1.412497, Validation loss: 1.3717, lr: 0.0010\n",
      "Epoch: 29, Training loss: 1.432270, Validation loss: 1.3800, lr: 0.0010\n",
      "Epoch: 30, Training loss: 1.379451, Validation loss: 1.3830, lr: 0.0010\n",
      "Epoch: 31, Training loss: 1.357187, Validation loss: 1.3830, lr: 0.0010\n",
      "Epoch: 32, Training loss: 1.354600, Validation loss: 1.3760, lr: 0.0010\n",
      "Epoch: 33, Training loss: 1.365360, Validation loss: 1.3815, lr: 0.0010\n",
      "Epoch: 34, Training loss: 1.360937, Validation loss: 1.3839, lr: 0.0010\n",
      "Epoch: 35, Training loss: 1.385318, Validation loss: 1.3880, lr: 0.0010\n",
      "Epoch: 36, Training loss: 1.363575, Validation loss: 1.3841, lr: 0.0010\n",
      "Epoch: 37, Training loss: 1.384829, Validation loss: 1.3720, lr: 0.0010\n",
      "Epoch: 38, Training loss: 1.368789, Validation loss: 1.3626, lr: 0.0010\n",
      "Epoch: 39, Training loss: 1.397750, Validation loss: 1.3839, lr: 0.0010\n",
      "Epoch: 40, Training loss: 1.384229, Validation loss: 1.3906, lr: 0.0010\n",
      "Epoch: 41, Training loss: 1.378097, Validation loss: 1.3463, lr: 0.0010\n",
      "Epoch: 42, Training loss: 1.410087, Validation loss: 1.3954, lr: 0.0010\n",
      "Epoch: 43, Training loss: 1.363750, Validation loss: 1.3789, lr: 0.0001\n",
      "Epoch: 44, Training loss: 1.396195, Validation loss: 1.3774, lr: 0.0001\n",
      "Epoch: 45, Training loss: 1.365940, Validation loss: 1.3702, lr: 0.0001\n",
      "Epoch: 46, Training loss: 1.362601, Validation loss: 1.3826, lr: 0.0001\n",
      "Epoch: 47, Training loss: 1.367951, Validation loss: 1.3763, lr: 0.0001\n",
      "Epoch: 48, Training loss: 1.372254, Validation loss: 1.3827, lr: 0.0001\n",
      "Epoch: 49, Training loss: 1.370835, Validation loss: 1.3789, lr: 0.0001\n",
      "Epoch: 50, Training loss: 1.379476, Validation loss: 1.3829, lr: 0.0001\n",
      "Epoch: 51, Training loss: 1.371241, Validation loss: 1.3748, lr: 0.0001\n",
      "Epoch: 52, Training loss: 1.380469, Validation loss: 1.3912, lr: 0.0001\n",
      "Epoch: 53, Training loss: 1.360870, Validation loss: 1.3664, lr: 0.0001\n",
      "Epoch: 54, Training loss: 1.396802, Validation loss: 1.3735, lr: 0.0000\n",
      "Epoch: 55, Training loss: 1.375936, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 56, Training loss: 1.376489, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 57, Training loss: 1.376176, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 58, Training loss: 1.355266, Validation loss: 1.3797, lr: 0.0000\n",
      "Epoch: 59, Training loss: 1.369375, Validation loss: 1.3888, lr: 0.0000\n",
      "Epoch: 60, Training loss: 1.387479, Validation loss: 1.3786, lr: 0.0000\n",
      "Epoch: 61, Training loss: 1.375503, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 62, Training loss: 1.401118, Validation loss: 1.3755, lr: 0.0000\n",
      "Epoch: 63, Training loss: 1.404791, Validation loss: 1.3778, lr: 0.0000\n",
      "Epoch: 64, Training loss: 1.368227, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 65, Training loss: 1.382670, Validation loss: 1.3923, lr: 0.0000\n",
      "Epoch: 66, Training loss: 1.390704, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 67, Training loss: 1.386069, Validation loss: 1.3882, lr: 0.0000\n",
      "Epoch: 68, Training loss: 1.377303, Validation loss: 1.3696, lr: 0.0000\n",
      "Epoch: 69, Training loss: 1.365878, Validation loss: 1.3761, lr: 0.0000\n",
      "Epoch: 70, Training loss: 1.415691, Validation loss: 1.3967, lr: 0.0000\n",
      "Epoch: 71, Training loss: 1.380105, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 72, Training loss: 1.393851, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 73, Training loss: 1.396175, Validation loss: 1.4051, lr: 0.0000\n",
      "Epoch: 74, Training loss: 1.396698, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 75, Training loss: 1.402334, Validation loss: 1.3769, lr: 0.0000\n",
      "Epoch: 76, Training loss: 1.393978, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 77, Training loss: 1.371609, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 78, Training loss: 1.355191, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 79, Training loss: 1.379167, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 80, Training loss: 1.395890, Validation loss: 1.4423, lr: 0.0000\n",
      "Epoch: 81, Training loss: 1.377298, Validation loss: 1.5278, lr: 0.0000\n",
      "Epoch: 82, Training loss: 1.377605, Validation loss: 1.3758, lr: 0.0000\n",
      "Epoch: 83, Training loss: 1.372235, Validation loss: 1.3784, lr: 0.0000\n",
      "Epoch: 84, Training loss: 1.379782, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 85, Training loss: 1.366504, Validation loss: 1.3713, lr: 0.0000\n",
      "Epoch: 86, Training loss: 1.376795, Validation loss: 1.3776, lr: 0.0000\n",
      "Epoch: 87, Training loss: 1.393740, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 88, Training loss: 1.378552, Validation loss: 1.3781, lr: 0.0000\n",
      "Epoch: 89, Training loss: 1.366166, Validation loss: 1.3783, lr: 0.0000\n",
      "Epoch: 90, Training loss: 1.416287, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 91, Training loss: 1.380567, Validation loss: 1.3799, lr: 0.0000\n",
      "Epoch: 92, Training loss: 1.393451, Validation loss: 1.3766, lr: 0.0000\n",
      "Epoch: 93, Training loss: 1.370171, Validation loss: 1.3756, lr: 0.0000\n",
      "Epoch: 94, Training loss: 1.377544, Validation loss: 1.3798, lr: 0.0000\n",
      "Epoch: 95, Training loss: 1.372819, Validation loss: 1.3878, lr: 0.0000\n",
      "Epoch: 96, Training loss: 1.374415, Validation loss: 1.3749, lr: 0.0000\n",
      "Epoch: 97, Training loss: 1.386694, Validation loss: 1.3738, lr: 0.0000\n",
      "Epoch: 98, Training loss: 1.379181, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 99, Training loss: 1.388840, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 100, Training loss: 1.369260, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 101, Training loss: 1.379939, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 102, Training loss: 1.372416, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 103, Training loss: 1.357323, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 104, Training loss: 1.380304, Validation loss: 1.3688, lr: 0.0000\n",
      "Epoch: 105, Training loss: 1.375870, Validation loss: 1.3777, lr: 0.0000\n",
      "Epoch: 106, Training loss: 1.367021, Validation loss: 1.3742, lr: 0.0000\n",
      "Epoch: 107, Training loss: 1.373683, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 108, Training loss: 1.365618, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 109, Training loss: 1.375301, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 110, Training loss: 1.395945, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 111, Training loss: 1.464118, Validation loss: 1.3669, lr: 0.0000\n",
      "Epoch: 112, Training loss: 1.373139, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 113, Training loss: 1.415256, Validation loss: 1.3702, lr: 0.0000\n",
      "Epoch: 114, Training loss: 1.405974, Validation loss: 1.3783, lr: 0.0000\n",
      "Epoch: 115, Training loss: 1.386962, Validation loss: 1.3780, lr: 0.0000\n",
      "Epoch: 116, Training loss: 1.399823, Validation loss: 1.3800, lr: 0.0000\n",
      "Epoch: 117, Training loss: 1.384558, Validation loss: 1.3692, lr: 0.0000\n",
      "Epoch: 118, Training loss: 1.364190, Validation loss: 1.3931, lr: 0.0000\n",
      "Epoch: 119, Training loss: 1.378587, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 120, Training loss: 1.403240, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 121, Training loss: 1.384610, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 122, Training loss: 1.384926, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 123, Training loss: 1.383557, Validation loss: 1.3661, lr: 0.0000\n",
      "Epoch: 124, Training loss: 1.397691, Validation loss: 1.3641, lr: 0.0000\n",
      "Epoch: 125, Training loss: 1.379857, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 126, Training loss: 1.396214, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 127, Training loss: 1.364970, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 128, Training loss: 1.369798, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 129, Training loss: 1.344677, Validation loss: 1.3954, lr: 0.0000\n",
      "Epoch: 130, Training loss: 1.401567, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 131, Training loss: 1.390235, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 132, Training loss: 1.427298, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 133, Training loss: 1.379313, Validation loss: 1.4021, lr: 0.0000\n",
      "Epoch: 134, Training loss: 1.413698, Validation loss: 1.4978, lr: 0.0000\n",
      "Epoch: 135, Training loss: 1.384455, Validation loss: 1.3704, lr: 0.0000\n",
      "Epoch: 136, Training loss: 1.373497, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 137, Training loss: 1.470600, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 138, Training loss: 1.366894, Validation loss: 1.3672, lr: 0.0000\n",
      "Epoch: 139, Training loss: 1.375482, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 140, Training loss: 1.365537, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 141, Training loss: 1.377467, Validation loss: 1.3782, lr: 0.0000\n",
      "Epoch: 142, Training loss: 1.356290, Validation loss: 1.3707, lr: 0.0000\n",
      "Epoch: 143, Training loss: 1.376496, Validation loss: 1.3732, lr: 0.0000\n",
      "Epoch: 144, Training loss: 1.370730, Validation loss: 1.3879, lr: 0.0000\n",
      "Epoch: 145, Training loss: 1.392250, Validation loss: 1.3777, lr: 0.0000\n",
      "Epoch: 146, Training loss: 1.391823, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 147, Training loss: 1.368329, Validation loss: 1.3877, lr: 0.0000\n",
      "Epoch: 148, Training loss: 1.373118, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 149, Training loss: 1.375087, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 150, Training loss: 1.393655, Validation loss: 1.3916, lr: 0.0000\n",
      "Epoch: 151, Training loss: 1.362776, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 152, Training loss: 1.382515, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 153, Training loss: 1.365744, Validation loss: 1.3783, lr: 0.0000\n",
      "Epoch: 154, Training loss: 1.373633, Validation loss: 1.3989, lr: 0.0000\n",
      "Epoch: 155, Training loss: 1.372307, Validation loss: 1.3791, lr: 0.0000\n",
      "Epoch: 156, Training loss: 1.386722, Validation loss: 1.3781, lr: 0.0000\n",
      "Epoch: 157, Training loss: 1.373136, Validation loss: 1.3771, lr: 0.0000\n",
      "Epoch: 158, Training loss: 1.417941, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 159, Training loss: 1.374354, Validation loss: 1.3429, lr: 0.0000\n",
      "Epoch: 160, Training loss: 1.357156, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 161, Training loss: 1.389594, Validation loss: 1.3784, lr: 0.0000\n",
      "Epoch: 162, Training loss: 1.377232, Validation loss: 1.3877, lr: 0.0000\n",
      "Epoch: 163, Training loss: 1.393625, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 164, Training loss: 1.364653, Validation loss: 1.3746, lr: 0.0000\n",
      "Epoch: 165, Training loss: 1.375163, Validation loss: 1.3700, lr: 0.0000\n",
      "Epoch: 166, Training loss: 1.379296, Validation loss: 1.3955, lr: 0.0000\n",
      "Epoch: 167, Training loss: 1.377430, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 168, Training loss: 1.386178, Validation loss: 1.3725, lr: 0.0000\n",
      "Epoch: 169, Training loss: 1.368922, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 170, Training loss: 1.378642, Validation loss: 1.3735, lr: 0.0000\n",
      "Epoch: 171, Training loss: 1.400040, Validation loss: 1.3899, lr: 0.0000\n",
      "Epoch: 172, Training loss: 1.374619, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 173, Training loss: 1.373499, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 174, Training loss: 1.398035, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 175, Training loss: 1.391551, Validation loss: 1.3645, lr: 0.0000\n",
      "Epoch: 176, Training loss: 1.439870, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 177, Training loss: 1.371241, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 178, Training loss: 1.424019, Validation loss: 1.3875, lr: 0.0000\n",
      "Epoch: 179, Training loss: 1.395782, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 180, Training loss: 1.367206, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 181, Training loss: 1.390078, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 182, Training loss: 1.369621, Validation loss: 1.3882, lr: 0.0000\n",
      "Epoch: 183, Training loss: 1.397738, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 184, Training loss: 1.353706, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 185, Training loss: 1.384342, Validation loss: 1.3587, lr: 0.0000\n",
      "Epoch: 186, Training loss: 1.366864, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 187, Training loss: 1.364070, Validation loss: 1.3610, lr: 0.0000\n",
      "Epoch: 188, Training loss: 1.389356, Validation loss: 1.3902, lr: 0.0000\n",
      "Epoch: 189, Training loss: 1.407352, Validation loss: 1.3713, lr: 0.0000\n",
      "Epoch: 190, Training loss: 1.345197, Validation loss: 1.3809, lr: 0.0000\n",
      "Epoch: 191, Training loss: 1.375469, Validation loss: 1.3781, lr: 0.0000\n",
      "Epoch: 192, Training loss: 1.371083, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 193, Training loss: 1.384488, Validation loss: 1.3884, lr: 0.0000\n",
      "Epoch: 194, Training loss: 1.358048, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 195, Training loss: 1.366189, Validation loss: 1.3890, lr: 0.0000\n",
      "Epoch: 196, Training loss: 1.358559, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 197, Training loss: 1.391417, Validation loss: 1.3781, lr: 0.0000\n",
      "Epoch: 198, Training loss: 1.395284, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 199, Training loss: 1.378933, Validation loss: 1.3883, lr: 0.0000\n",
      "Epoch: 200, Training loss: 1.408346, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 201, Training loss: 1.386407, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 202, Training loss: 1.370674, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 203, Training loss: 1.369050, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 204, Training loss: 1.369057, Validation loss: 1.3791, lr: 0.0000\n",
      "Epoch: 205, Training loss: 1.373863, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 206, Training loss: 1.386067, Validation loss: 1.3883, lr: 0.0000\n",
      "Epoch: 207, Training loss: 1.356386, Validation loss: 1.3874, lr: 0.0000\n",
      "Epoch: 208, Training loss: 1.377245, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 209, Training loss: 1.389962, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 210, Training loss: 1.392295, Validation loss: 1.3759, lr: 0.0000\n",
      "Epoch: 211, Training loss: 1.501005, Validation loss: 1.3712, lr: 0.0000\n",
      "Epoch: 212, Training loss: 1.381867, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 213, Training loss: 1.378635, Validation loss: 1.3508, lr: 0.0000\n",
      "Epoch: 214, Training loss: 1.374411, Validation loss: 1.3740, lr: 0.0000\n",
      "Epoch: 215, Training loss: 1.369900, Validation loss: 1.3759, lr: 0.0000\n",
      "Epoch: 216, Training loss: 1.389868, Validation loss: 1.3713, lr: 0.0000\n",
      "Epoch: 217, Training loss: 1.372231, Validation loss: 1.4413, lr: 0.0000\n",
      "Epoch: 218, Training loss: 1.383032, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 219, Training loss: 1.373534, Validation loss: 1.3760, lr: 0.0000\n",
      "Epoch: 220, Training loss: 1.374060, Validation loss: 1.3874, lr: 0.0000\n",
      "Epoch: 221, Training loss: 1.385448, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 222, Training loss: 1.386049, Validation loss: 1.3617, lr: 0.0000\n",
      "Epoch: 223, Training loss: 1.393020, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 224, Training loss: 1.351403, Validation loss: 1.4035, lr: 0.0000\n",
      "Epoch: 225, Training loss: 1.386099, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 226, Training loss: 1.412220, Validation loss: 1.4075, lr: 0.0000\n",
      "Epoch: 227, Training loss: 1.375177, Validation loss: 1.3679, lr: 0.0000\n",
      "Epoch: 228, Training loss: 1.355474, Validation loss: 1.3440, lr: 0.0000\n",
      "Epoch: 229, Training loss: 1.440954, Validation loss: 1.3727, lr: 0.0000\n",
      "Epoch: 230, Training loss: 1.411297, Validation loss: 1.3697, lr: 0.0000\n",
      "Epoch: 231, Training loss: 1.366617, Validation loss: 1.3784, lr: 0.0000\n",
      "Epoch: 232, Training loss: 1.387207, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 233, Training loss: 1.409261, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 234, Training loss: 1.375203, Validation loss: 1.3711, lr: 0.0000\n",
      "Epoch: 235, Training loss: 1.407170, Validation loss: 1.3875, lr: 0.0000\n",
      "Epoch: 236, Training loss: 1.367297, Validation loss: 1.3792, lr: 0.0000\n",
      "Epoch: 237, Training loss: 1.435841, Validation loss: 1.3724, lr: 0.0000\n",
      "Epoch: 238, Training loss: 1.428188, Validation loss: 1.3878, lr: 0.0000\n",
      "Epoch: 239, Training loss: 1.353091, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 240, Training loss: 1.360655, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 241, Training loss: 1.358166, Validation loss: 1.4004, lr: 0.0000\n",
      "Epoch: 242, Training loss: 1.353182, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 243, Training loss: 1.394603, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 244, Training loss: 1.457981, Validation loss: 1.3709, lr: 0.0000\n",
      "Epoch: 245, Training loss: 1.372256, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 246, Training loss: 1.357261, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 247, Training loss: 1.378155, Validation loss: 1.3734, lr: 0.0000\n",
      "Epoch: 248, Training loss: 1.372840, Validation loss: 1.4345, lr: 0.0000\n",
      "Epoch: 249, Training loss: 1.384992, Validation loss: 1.3796, lr: 0.0000\n",
      "Epoch: 250, Training loss: 1.363532, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 251, Training loss: 1.369556, Validation loss: 1.3700, lr: 0.0000\n",
      "Epoch: 252, Training loss: 1.374089, Validation loss: 1.3658, lr: 0.0000\n",
      "Epoch: 253, Training loss: 1.375365, Validation loss: 1.3479, lr: 0.0000\n",
      "Epoch: 254, Training loss: 1.392387, Validation loss: 1.3659, lr: 0.0000\n",
      "Epoch: 255, Training loss: 1.387346, Validation loss: 1.3675, lr: 0.0000\n",
      "Epoch: 256, Training loss: 1.385842, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 257, Training loss: 1.437422, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 258, Training loss: 1.367085, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 259, Training loss: 1.384152, Validation loss: 1.3788, lr: 0.0000\n",
      "Epoch: 260, Training loss: 1.368753, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 261, Training loss: 1.367050, Validation loss: 1.3673, lr: 0.0000\n",
      "Epoch: 262, Training loss: 1.374516, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 263, Training loss: 1.415502, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 264, Training loss: 1.382851, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 265, Training loss: 1.393620, Validation loss: 1.3800, lr: 0.0000\n",
      "Epoch: 266, Training loss: 1.378890, Validation loss: 1.3877, lr: 0.0000\n",
      "Epoch: 267, Training loss: 1.376545, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 268, Training loss: 1.373444, Validation loss: 1.3890, lr: 0.0000\n",
      "Epoch: 269, Training loss: 1.385793, Validation loss: 1.4067, lr: 0.0000\n",
      "Epoch: 270, Training loss: 1.363376, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 271, Training loss: 1.376330, Validation loss: 1.3905, lr: 0.0000\n",
      "Epoch: 272, Training loss: 1.371012, Validation loss: 1.3764, lr: 0.0000\n",
      "Epoch: 273, Training loss: 1.378614, Validation loss: 1.3649, lr: 0.0000\n",
      "Epoch: 274, Training loss: 1.366176, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 275, Training loss: 1.480878, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 276, Training loss: 1.382552, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 277, Training loss: 1.392312, Validation loss: 1.3935, lr: 0.0000\n",
      "Epoch: 278, Training loss: 1.357015, Validation loss: 1.3800, lr: 0.0000\n",
      "Epoch: 279, Training loss: 1.384956, Validation loss: 1.3974, lr: 0.0000\n",
      "Epoch: 280, Training loss: 1.381261, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 281, Training loss: 1.443632, Validation loss: 1.3398, lr: 0.0000\n",
      "Epoch: 282, Training loss: 1.376174, Validation loss: 1.3617, lr: 0.0000\n",
      "Epoch: 283, Training loss: 1.368873, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 284, Training loss: 1.375548, Validation loss: 1.3699, lr: 0.0000\n",
      "Epoch: 285, Training loss: 1.363335, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 286, Training loss: 1.378646, Validation loss: 1.3547, lr: 0.0000\n",
      "Epoch: 287, Training loss: 1.393780, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 288, Training loss: 1.363208, Validation loss: 1.3986, lr: 0.0000\n",
      "Epoch: 289, Training loss: 1.378033, Validation loss: 1.3574, lr: 0.0000\n",
      "Epoch: 290, Training loss: 1.386730, Validation loss: 1.3757, lr: 0.0000\n",
      "Epoch: 291, Training loss: 1.389156, Validation loss: 1.3765, lr: 0.0000\n",
      "Epoch: 292, Training loss: 1.363741, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 293, Training loss: 1.364270, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 294, Training loss: 1.371283, Validation loss: 1.3703, lr: 0.0000\n",
      "Epoch: 295, Training loss: 1.371117, Validation loss: 1.3779, lr: 0.0000\n",
      "Epoch: 296, Training loss: 1.388077, Validation loss: 1.3899, lr: 0.0000\n",
      "Epoch: 297, Training loss: 1.385602, Validation loss: 1.3633, lr: 0.0000\n",
      "Epoch: 298, Training loss: 1.416028, Validation loss: 1.3799, lr: 0.0000\n",
      "Epoch: 299, Training loss: 1.392213, Validation loss: 1.3734, lr: 0.0000\n",
      "Epoch: 300, Training loss: 1.374965, Validation loss: 1.3892, lr: 0.0000\n",
      "Epoch: 301, Training loss: 1.377266, Validation loss: 1.3536, lr: 0.0000\n",
      "Epoch: 302, Training loss: 1.373317, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 303, Training loss: 1.392531, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 304, Training loss: 1.364600, Validation loss: 1.3921, lr: 0.0000\n",
      "Epoch: 305, Training loss: 1.379787, Validation loss: 1.7926, lr: 0.0000\n",
      "Epoch: 306, Training loss: 1.388811, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 307, Training loss: 1.394050, Validation loss: 1.3883, lr: 0.0000\n",
      "Epoch: 308, Training loss: 1.400966, Validation loss: 1.3696, lr: 0.0000\n",
      "Epoch: 309, Training loss: 1.393233, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 310, Training loss: 1.393306, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 311, Training loss: 1.380593, Validation loss: 1.3793, lr: 0.0000\n",
      "Epoch: 312, Training loss: 1.404014, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 313, Training loss: 1.375932, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 314, Training loss: 1.366278, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 315, Training loss: 1.419256, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 316, Training loss: 1.384690, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 317, Training loss: 1.386180, Validation loss: 1.3908, lr: 0.0000\n",
      "Epoch: 318, Training loss: 1.374686, Validation loss: 1.3542, lr: 0.0000\n",
      "Epoch: 319, Training loss: 1.380481, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 320, Training loss: 1.354578, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 321, Training loss: 1.378925, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 322, Training loss: 1.373014, Validation loss: 1.4004, lr: 0.0000\n",
      "Epoch: 323, Training loss: 1.378072, Validation loss: 1.3778, lr: 0.0000\n",
      "Epoch: 324, Training loss: 1.378274, Validation loss: 1.3625, lr: 0.0000\n",
      "Epoch: 325, Training loss: 1.384209, Validation loss: 1.3799, lr: 0.0000\n",
      "Epoch: 326, Training loss: 1.400543, Validation loss: 1.3765, lr: 0.0000\n",
      "Epoch: 327, Training loss: 1.381949, Validation loss: 1.3711, lr: 0.0000\n",
      "Epoch: 328, Training loss: 1.380098, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 329, Training loss: 1.397278, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 330, Training loss: 1.392528, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 331, Training loss: 1.372525, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 332, Training loss: 1.383535, Validation loss: 1.3934, lr: 0.0000\n",
      "Epoch: 333, Training loss: 1.370212, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 334, Training loss: 1.384623, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 335, Training loss: 1.374235, Validation loss: 1.3793, lr: 0.0000\n",
      "Epoch: 336, Training loss: 1.392323, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 337, Training loss: 1.370637, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 338, Training loss: 1.401065, Validation loss: 1.3783, lr: 0.0000\n",
      "Epoch: 339, Training loss: 1.352859, Validation loss: 1.3791, lr: 0.0000\n",
      "Epoch: 340, Training loss: 1.362901, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 341, Training loss: 1.453535, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 342, Training loss: 1.375262, Validation loss: 1.3760, lr: 0.0000\n",
      "Epoch: 343, Training loss: 1.386223, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 344, Training loss: 1.370301, Validation loss: 1.3709, lr: 0.0000\n",
      "Epoch: 345, Training loss: 1.377526, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 346, Training loss: 1.383099, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 347, Training loss: 1.391128, Validation loss: 1.3757, lr: 0.0000\n",
      "Epoch: 348, Training loss: 1.382981, Validation loss: 1.3729, lr: 0.0000\n",
      "Epoch: 349, Training loss: 1.374092, Validation loss: 1.3498, lr: 0.0000\n",
      "Epoch: 350, Training loss: 1.359016, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 351, Training loss: 1.374041, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 352, Training loss: 1.380443, Validation loss: 1.3927, lr: 0.0000\n",
      "Epoch: 353, Training loss: 1.378171, Validation loss: 1.3642, lr: 0.0000\n",
      "Epoch: 354, Training loss: 1.374543, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 355, Training loss: 1.350971, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 356, Training loss: 1.374687, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 357, Training loss: 1.387513, Validation loss: 1.3667, lr: 0.0000\n",
      "Epoch: 358, Training loss: 1.387056, Validation loss: 1.3874, lr: 0.0000\n",
      "Epoch: 359, Training loss: 1.375436, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 360, Training loss: 1.382122, Validation loss: 1.3619, lr: 0.0000\n",
      "Epoch: 361, Training loss: 1.372264, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 362, Training loss: 1.380636, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 363, Training loss: 1.358565, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 364, Training loss: 1.380735, Validation loss: 1.3936, lr: 0.0000\n",
      "Epoch: 365, Training loss: 1.377427, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 366, Training loss: 1.398997, Validation loss: 1.4052, lr: 0.0000\n",
      "Epoch: 367, Training loss: 1.380706, Validation loss: 1.3681, lr: 0.0000\n",
      "Epoch: 368, Training loss: 1.397061, Validation loss: 1.3591, lr: 0.0000\n",
      "Epoch: 369, Training loss: 1.372473, Validation loss: 1.3736, lr: 0.0000\n",
      "Epoch: 370, Training loss: 1.371221, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 371, Training loss: 1.385110, Validation loss: 1.3707, lr: 0.0000\n",
      "Epoch: 372, Training loss: 1.408938, Validation loss: 1.3428, lr: 0.0000\n",
      "Epoch: 373, Training loss: 1.414682, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 374, Training loss: 1.369490, Validation loss: 1.3881, lr: 0.0000\n",
      "Epoch: 375, Training loss: 1.363109, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 376, Training loss: 1.370861, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 377, Training loss: 1.376483, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 378, Training loss: 1.357614, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 379, Training loss: 1.385569, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 380, Training loss: 1.364014, Validation loss: 1.3871, lr: 0.0000\n",
      "Epoch: 381, Training loss: 1.354437, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 382, Training loss: 1.352411, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 383, Training loss: 1.390852, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 384, Training loss: 1.430643, Validation loss: 1.3790, lr: 0.0000\n",
      "Epoch: 385, Training loss: 1.359033, Validation loss: 1.3894, lr: 0.0000\n",
      "Epoch: 386, Training loss: 1.379035, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 387, Training loss: 1.352909, Validation loss: 1.3660, lr: 0.0000\n",
      "Epoch: 388, Training loss: 1.381728, Validation loss: 1.3751, lr: 0.0000\n",
      "Epoch: 389, Training loss: 1.395812, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 390, Training loss: 1.379931, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 391, Training loss: 1.370446, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 392, Training loss: 1.381089, Validation loss: 1.3769, lr: 0.0000\n",
      "Epoch: 393, Training loss: 1.383648, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 394, Training loss: 1.357722, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 395, Training loss: 1.361709, Validation loss: 1.3874, lr: 0.0000\n",
      "Epoch: 396, Training loss: 1.375476, Validation loss: 1.3792, lr: 0.0000\n",
      "Epoch: 397, Training loss: 1.382322, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 398, Training loss: 1.379822, Validation loss: 1.3558, lr: 0.0000\n",
      "Epoch: 399, Training loss: 1.373860, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 400, Training loss: 1.378921, Validation loss: 1.3790, lr: 0.0000\n",
      "Epoch: 401, Training loss: 1.368615, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 402, Training loss: 1.380735, Validation loss: 1.3547, lr: 0.0000\n",
      "Epoch: 403, Training loss: 1.373062, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 404, Training loss: 1.359993, Validation loss: 1.3788, lr: 0.0000\n",
      "Epoch: 405, Training loss: 1.390780, Validation loss: 1.3756, lr: 0.0000\n",
      "Epoch: 406, Training loss: 1.371779, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 407, Training loss: 1.364388, Validation loss: 1.3699, lr: 0.0000\n",
      "Epoch: 408, Training loss: 1.380328, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 409, Training loss: 1.381106, Validation loss: 1.3705, lr: 0.0000\n",
      "Epoch: 410, Training loss: 1.367580, Validation loss: 1.3769, lr: 0.0000\n",
      "Epoch: 411, Training loss: 1.389190, Validation loss: 1.3775, lr: 0.0000\n",
      "Epoch: 412, Training loss: 1.398684, Validation loss: 1.3733, lr: 0.0000\n",
      "Epoch: 413, Training loss: 1.410919, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 414, Training loss: 1.432176, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 415, Training loss: 1.380293, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 416, Training loss: 1.371915, Validation loss: 1.3781, lr: 0.0000\n",
      "Epoch: 417, Training loss: 1.355846, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 418, Training loss: 1.363514, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 419, Training loss: 1.450625, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 420, Training loss: 1.397936, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 421, Training loss: 1.404258, Validation loss: 1.3705, lr: 0.0000\n",
      "Epoch: 422, Training loss: 1.403722, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 423, Training loss: 1.363151, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 424, Training loss: 1.389049, Validation loss: 1.4047, lr: 0.0000\n",
      "Epoch: 425, Training loss: 1.386591, Validation loss: 1.4777, lr: 0.0000\n",
      "Epoch: 426, Training loss: 1.410710, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 427, Training loss: 1.366159, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 428, Training loss: 1.381217, Validation loss: 1.3797, lr: 0.0000\n",
      "Epoch: 429, Training loss: 1.367191, Validation loss: 1.3612, lr: 0.0000\n",
      "Epoch: 430, Training loss: 1.365394, Validation loss: 1.3704, lr: 0.0000\n",
      "Epoch: 431, Training loss: 1.363566, Validation loss: 1.3716, lr: 0.0000\n",
      "Epoch: 432, Training loss: 1.369608, Validation loss: 1.3772, lr: 0.0000\n",
      "Epoch: 433, Training loss: 1.382024, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 434, Training loss: 1.367606, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 435, Training loss: 1.384210, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 436, Training loss: 1.363964, Validation loss: 1.3721, lr: 0.0000\n",
      "Epoch: 437, Training loss: 1.367970, Validation loss: 1.3788, lr: 0.0000\n",
      "Epoch: 438, Training loss: 1.388073, Validation loss: 1.3910, lr: 0.0000\n",
      "Epoch: 439, Training loss: 1.388924, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 440, Training loss: 1.389363, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 441, Training loss: 1.389219, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 442, Training loss: 1.367273, Validation loss: 1.3789, lr: 0.0000\n",
      "Epoch: 443, Training loss: 1.375900, Validation loss: 1.3748, lr: 0.0000\n",
      "Epoch: 444, Training loss: 1.392187, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 445, Training loss: 1.384398, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 446, Training loss: 1.399388, Validation loss: 1.3903, lr: 0.0000\n",
      "Epoch: 447, Training loss: 1.379141, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 448, Training loss: 1.383455, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 449, Training loss: 1.352442, Validation loss: 1.3798, lr: 0.0000\n",
      "Epoch: 450, Training loss: 1.357444, Validation loss: 1.3892, lr: 0.0000\n",
      "Epoch: 451, Training loss: 1.383761, Validation loss: 1.3796, lr: 0.0000\n",
      "Epoch: 452, Training loss: 1.372723, Validation loss: 1.3769, lr: 0.0000\n",
      "Epoch: 453, Training loss: 1.362211, Validation loss: 1.3727, lr: 0.0000\n",
      "Epoch: 454, Training loss: 1.389194, Validation loss: 1.3921, lr: 0.0000\n",
      "Epoch: 455, Training loss: 1.364275, Validation loss: 1.3555, lr: 0.0000\n",
      "Epoch: 456, Training loss: 1.395345, Validation loss: 1.3797, lr: 0.0000\n",
      "Epoch: 457, Training loss: 1.392328, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 458, Training loss: 1.374470, Validation loss: 1.3798, lr: 0.0000\n",
      "Epoch: 459, Training loss: 1.373142, Validation loss: 1.3768, lr: 0.0000\n",
      "Epoch: 460, Training loss: 1.365414, Validation loss: 1.3735, lr: 0.0000\n",
      "Epoch: 461, Training loss: 1.367337, Validation loss: 1.3875, lr: 0.0000\n",
      "Epoch: 462, Training loss: 1.374399, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 463, Training loss: 1.372069, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 464, Training loss: 1.375856, Validation loss: 1.4148, lr: 0.0000\n",
      "Epoch: 465, Training loss: 1.376408, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 466, Training loss: 1.367275, Validation loss: 1.3645, lr: 0.0000\n",
      "Epoch: 467, Training loss: 1.379291, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 468, Training loss: 1.402218, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 469, Training loss: 1.382898, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 470, Training loss: 1.414180, Validation loss: 1.3767, lr: 0.0000\n",
      "Epoch: 471, Training loss: 1.356323, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 472, Training loss: 1.388583, Validation loss: 1.3581, lr: 0.0000\n",
      "Epoch: 473, Training loss: 1.387489, Validation loss: 1.3726, lr: 0.0000\n",
      "Epoch: 474, Training loss: 1.382448, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 475, Training loss: 1.369509, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 476, Training loss: 1.385488, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 477, Training loss: 1.404009, Validation loss: 1.3892, lr: 0.0000\n",
      "Epoch: 478, Training loss: 1.403497, Validation loss: 1.3763, lr: 0.0000\n",
      "Epoch: 479, Training loss: 1.366176, Validation loss: 1.3571, lr: 0.0000\n",
      "Epoch: 480, Training loss: 1.356228, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 481, Training loss: 1.389380, Validation loss: 1.3778, lr: 0.0000\n",
      "Epoch: 482, Training loss: 1.366386, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 483, Training loss: 1.390129, Validation loss: 1.3653, lr: 0.0000\n",
      "Epoch: 484, Training loss: 1.378413, Validation loss: 1.3941, lr: 0.0000\n",
      "Epoch: 485, Training loss: 1.382388, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 486, Training loss: 1.362756, Validation loss: 1.3842, lr: 0.0000\n",
      " *och: 487, Training loss: 1.369525, Validation loss: 1.2851, lr: 0.0000\n",
      "Epoch: 488, Training loss: 1.375063, Validation loss: 1.3710, lr: 0.0000\n",
      "Epoch: 489, Training loss: 1.371097, Validation loss: 1.3609, lr: 0.0000\n",
      "Epoch: 490, Training loss: 1.366310, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 491, Training loss: 1.388142, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 492, Training loss: 1.391358, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 493, Training loss: 1.390913, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 494, Training loss: 1.372635, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 495, Training loss: 1.370358, Validation loss: 1.3901, lr: 0.0000\n",
      "Epoch: 496, Training loss: 1.380430, Validation loss: 1.4047, lr: 0.0000\n",
      "Epoch: 497, Training loss: 1.397119, Validation loss: 1.3909, lr: 0.0000\n",
      "Epoch: 498, Training loss: 1.374595, Validation loss: 1.3947, lr: 0.0000\n",
      "Epoch: 499, Training loss: 1.400080, Validation loss: 1.4841, lr: 0.0000\n",
      "Epoch: 500, Training loss: 1.382370, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 501, Training loss: 1.364975, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 502, Training loss: 1.383629, Validation loss: 1.3724, lr: 0.0000\n",
      "Epoch: 503, Training loss: 1.345840, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 504, Training loss: 1.382267, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 505, Training loss: 1.363432, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 506, Training loss: 1.368216, Validation loss: 1.4023, lr: 0.0000\n",
      "Epoch: 507, Training loss: 1.364707, Validation loss: 1.3702, lr: 0.0000\n",
      "Epoch: 508, Training loss: 1.382574, Validation loss: 1.3650, lr: 0.0000\n",
      "Epoch: 509, Training loss: 1.364442, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 510, Training loss: 1.384541, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 511, Training loss: 1.420273, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 512, Training loss: 1.372895, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 513, Training loss: 1.382157, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 514, Training loss: 1.373188, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 515, Training loss: 1.385532, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 516, Training loss: 1.359935, Validation loss: 1.3783, lr: 0.0000\n",
      "Epoch: 517, Training loss: 1.427343, Validation loss: 1.3732, lr: 0.0000\n",
      "Epoch: 518, Training loss: 1.380938, Validation loss: 1.3790, lr: 0.0000\n",
      "Epoch: 519, Training loss: 1.379149, Validation loss: 1.3691, lr: 0.0000\n",
      "Epoch: 520, Training loss: 1.393569, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 521, Training loss: 1.364643, Validation loss: 1.3777, lr: 0.0000\n",
      "Epoch: 522, Training loss: 1.363973, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 523, Training loss: 1.383000, Validation loss: 1.3780, lr: 0.0000\n",
      "Epoch: 524, Training loss: 1.388117, Validation loss: 1.3788, lr: 0.0000\n",
      "Epoch: 525, Training loss: 1.387249, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 526, Training loss: 1.449208, Validation loss: 1.3599, lr: 0.0000\n",
      "Epoch: 527, Training loss: 1.381764, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 528, Training loss: 1.401535, Validation loss: 1.3902, lr: 0.0000\n",
      "Epoch: 529, Training loss: 1.365697, Validation loss: 1.3756, lr: 0.0000\n",
      "Epoch: 530, Training loss: 1.367586, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 531, Training loss: 1.398724, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 532, Training loss: 1.376030, Validation loss: 1.3875, lr: 0.0000\n",
      "Epoch: 533, Training loss: 1.379550, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 534, Training loss: 1.375640, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 535, Training loss: 1.382783, Validation loss: 1.3698, lr: 0.0000\n",
      "Epoch: 536, Training loss: 1.380517, Validation loss: 1.3603, lr: 0.0000\n",
      "Epoch: 537, Training loss: 1.380437, Validation loss: 1.3689, lr: 0.0000\n",
      "Epoch: 538, Training loss: 1.362804, Validation loss: 1.3765, lr: 0.0000\n",
      "Epoch: 539, Training loss: 1.358341, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 540, Training loss: 1.396962, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 541, Training loss: 1.388147, Validation loss: 1.3699, lr: 0.0000\n",
      "Epoch: 542, Training loss: 1.380400, Validation loss: 1.3681, lr: 0.0000\n",
      "Epoch: 543, Training loss: 1.371399, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 544, Training loss: 1.379691, Validation loss: 1.3903, lr: 0.0000\n",
      "Epoch: 545, Training loss: 1.393352, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 546, Training loss: 1.383090, Validation loss: 1.3726, lr: 0.0000\n",
      "Epoch: 547, Training loss: 1.471750, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 548, Training loss: 1.378689, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 549, Training loss: 1.367001, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 550, Training loss: 1.375032, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 551, Training loss: 1.389944, Validation loss: 1.3791, lr: 0.0000\n",
      "Epoch: 552, Training loss: 1.365977, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 553, Training loss: 1.381405, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 554, Training loss: 1.378723, Validation loss: 1.3723, lr: 0.0000\n",
      "Epoch: 555, Training loss: 1.379258, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 556, Training loss: 1.368837, Validation loss: 1.3380, lr: 0.0000\n",
      "Epoch: 557, Training loss: 1.380237, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 558, Training loss: 1.356749, Validation loss: 1.3747, lr: 0.0000\n",
      "Epoch: 559, Training loss: 1.376844, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 560, Training loss: 1.378859, Validation loss: 1.3883, lr: 0.0000\n",
      "Epoch: 561, Training loss: 1.384873, Validation loss: 1.3915, lr: 0.0000\n",
      "Epoch: 562, Training loss: 1.384362, Validation loss: 1.3603, lr: 0.0000\n",
      "Epoch: 563, Training loss: 1.392002, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 564, Training loss: 1.379791, Validation loss: 1.3911, lr: 0.0000\n",
      "Epoch: 565, Training loss: 1.394373, Validation loss: 1.3643, lr: 0.0000\n",
      "Epoch: 566, Training loss: 1.384827, Validation loss: 1.3965, lr: 0.0000\n",
      "Epoch: 567, Training loss: 1.367014, Validation loss: 1.4487, lr: 0.0000\n",
      "Epoch: 568, Training loss: 1.347975, Validation loss: 1.3792, lr: 0.0000\n",
      "Epoch: 569, Training loss: 1.384597, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 570, Training loss: 1.362753, Validation loss: 1.3875, lr: 0.0000\n",
      "Epoch: 571, Training loss: 1.378359, Validation loss: 1.3671, lr: 0.0000\n",
      "Epoch: 572, Training loss: 1.377797, Validation loss: 1.3698, lr: 0.0000\n",
      "Epoch: 573, Training loss: 1.392887, Validation loss: 1.3277, lr: 0.0000\n",
      "Epoch: 574, Training loss: 1.356628, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 575, Training loss: 1.365222, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 576, Training loss: 1.380101, Validation loss: 1.4156, lr: 0.0000\n",
      "Epoch: 577, Training loss: 1.399226, Validation loss: 1.3761, lr: 0.0000\n",
      "Epoch: 578, Training loss: 1.379831, Validation loss: 1.3666, lr: 0.0000\n",
      "Epoch: 579, Training loss: 1.372695, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 580, Training loss: 1.357917, Validation loss: 1.3871, lr: 0.0000\n",
      "Epoch: 581, Training loss: 1.382742, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 582, Training loss: 1.378212, Validation loss: 1.3809, lr: 0.0000\n",
      "Epoch: 583, Training loss: 1.369090, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 584, Training loss: 1.402732, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 585, Training loss: 1.377431, Validation loss: 1.3411, lr: 0.0000\n",
      "Epoch: 586, Training loss: 1.366704, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 587, Training loss: 1.378721, Validation loss: 1.3629, lr: 0.0000\n",
      "Epoch: 588, Training loss: 1.369825, Validation loss: 1.7587, lr: 0.0000\n",
      "Epoch: 589, Training loss: 1.376263, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 590, Training loss: 1.391557, Validation loss: 1.5041, lr: 0.0000\n",
      "Epoch: 591, Training loss: 1.374111, Validation loss: 1.3744, lr: 0.0000\n",
      "Epoch: 592, Training loss: 1.364244, Validation loss: 1.3777, lr: 0.0000\n",
      "Epoch: 593, Training loss: 1.385858, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 594, Training loss: 1.389814, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 595, Training loss: 1.396682, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 596, Training loss: 1.375247, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 597, Training loss: 1.386578, Validation loss: 1.3793, lr: 0.0000\n",
      "Epoch: 598, Training loss: 1.389722, Validation loss: 1.3712, lr: 0.0000\n",
      "Epoch: 599, Training loss: 1.380547, Validation loss: 1.3654, lr: 0.0000\n",
      "Epoch: 600, Training loss: 1.368617, Validation loss: 1.3882, lr: 0.0000\n",
      "Epoch: 601, Training loss: 1.366228, Validation loss: 1.3790, lr: 0.0000\n",
      "Epoch: 602, Training loss: 1.363278, Validation loss: 1.3777, lr: 0.0000\n",
      "Epoch: 603, Training loss: 1.390687, Validation loss: 1.3792, lr: 0.0000\n",
      "Epoch: 604, Training loss: 1.379193, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 605, Training loss: 1.372054, Validation loss: 1.3955, lr: 0.0000\n",
      "Epoch: 606, Training loss: 1.381598, Validation loss: 1.3653, lr: 0.0000\n",
      "Epoch: 607, Training loss: 1.360416, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 608, Training loss: 1.371119, Validation loss: 1.3712, lr: 0.0000\n",
      "Epoch: 609, Training loss: 1.391195, Validation loss: 1.3920, lr: 0.0000\n",
      "Epoch: 610, Training loss: 1.375062, Validation loss: 1.3694, lr: 0.0000\n",
      "Epoch: 611, Training loss: 1.365186, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 612, Training loss: 1.390109, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 613, Training loss: 1.367326, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 614, Training loss: 1.361427, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 615, Training loss: 1.357155, Validation loss: 1.3948, lr: 0.0000\n",
      "Epoch: 616, Training loss: 1.375373, Validation loss: 1.3809, lr: 0.0000\n",
      "Epoch: 617, Training loss: 1.381208, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 618, Training loss: 1.368173, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 619, Training loss: 1.376643, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 620, Training loss: 1.366950, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 621, Training loss: 1.369723, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 622, Training loss: 1.346120, Validation loss: 1.3734, lr: 0.0000\n",
      "Epoch: 623, Training loss: 1.389921, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 624, Training loss: 1.371693, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 625, Training loss: 1.361619, Validation loss: 1.3871, lr: 0.0000\n",
      "Epoch: 626, Training loss: 1.352598, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 627, Training loss: 1.379993, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 628, Training loss: 1.373314, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 629, Training loss: 1.393509, Validation loss: 1.3999, lr: 0.0000\n",
      "Epoch: 630, Training loss: 1.399301, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 631, Training loss: 1.379112, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 632, Training loss: 1.368743, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 633, Training loss: 1.390627, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 634, Training loss: 1.371042, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 635, Training loss: 1.374405, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 636, Training loss: 1.379368, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 637, Training loss: 1.404279, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 638, Training loss: 1.360261, Validation loss: 1.3768, lr: 0.0000\n",
      "Epoch: 639, Training loss: 1.418809, Validation loss: 1.3549, lr: 0.0000\n",
      "Epoch: 640, Training loss: 1.390384, Validation loss: 1.3780, lr: 0.0000\n",
      "Epoch: 641, Training loss: 1.442704, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 642, Training loss: 1.381908, Validation loss: 1.3483, lr: 0.0000\n",
      "Epoch: 643, Training loss: 1.388684, Validation loss: 1.3678, lr: 0.0000\n",
      "Epoch: 644, Training loss: 1.384636, Validation loss: 1.3776, lr: 0.0000\n",
      "Epoch: 645, Training loss: 1.371276, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 646, Training loss: 1.379463, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 647, Training loss: 1.407534, Validation loss: 1.3776, lr: 0.0000\n",
      "Epoch: 648, Training loss: 1.367148, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 649, Training loss: 1.524362, Validation loss: 1.3876, lr: 0.0000\n",
      "Epoch: 650, Training loss: 1.397873, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 651, Training loss: 1.374221, Validation loss: 1.3757, lr: 0.0000\n",
      "Epoch: 652, Training loss: 1.370344, Validation loss: 1.3878, lr: 0.0000\n",
      "Epoch: 653, Training loss: 1.437047, Validation loss: 1.3766, lr: 0.0000\n",
      "Epoch: 654, Training loss: 1.381182, Validation loss: 1.3718, lr: 0.0000\n",
      "Epoch: 655, Training loss: 1.366396, Validation loss: 1.3594, lr: 0.0000\n",
      "Epoch: 656, Training loss: 1.389487, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 657, Training loss: 1.405491, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 658, Training loss: 1.362571, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 659, Training loss: 1.373225, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 660, Training loss: 1.374632, Validation loss: 1.3659, lr: 0.0000\n",
      "Epoch: 661, Training loss: 1.366277, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 662, Training loss: 1.380775, Validation loss: 1.4141, lr: 0.0000\n",
      "Epoch: 663, Training loss: 1.378616, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 664, Training loss: 1.378974, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 665, Training loss: 1.380788, Validation loss: 1.3788, lr: 0.0000\n",
      "Epoch: 666, Training loss: 1.373542, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 667, Training loss: 1.361987, Validation loss: 1.3802, lr: 0.0000\n",
      "Epoch: 668, Training loss: 1.393673, Validation loss: 1.3790, lr: 0.0000\n",
      "Epoch: 669, Training loss: 1.381657, Validation loss: 1.3778, lr: 0.0000\n",
      "Epoch: 670, Training loss: 1.356349, Validation loss: 1.4186, lr: 0.0000\n",
      "Epoch: 671, Training loss: 1.376096, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 672, Training loss: 1.359249, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 673, Training loss: 1.384388, Validation loss: 1.3884, lr: 0.0000\n",
      "Epoch: 674, Training loss: 1.382349, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 675, Training loss: 1.382204, Validation loss: 1.3757, lr: 0.0000\n",
      "Epoch: 676, Training loss: 1.395412, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 677, Training loss: 1.372836, Validation loss: 1.3929, lr: 0.0000\n",
      "Epoch: 678, Training loss: 1.355498, Validation loss: 1.3771, lr: 0.0000\n",
      "Epoch: 679, Training loss: 1.349300, Validation loss: 1.3772, lr: 0.0000\n",
      "Epoch: 680, Training loss: 1.379407, Validation loss: 1.3800, lr: 0.0000\n",
      "Epoch: 681, Training loss: 1.383151, Validation loss: 1.3794, lr: 0.0000\n",
      "Epoch: 682, Training loss: 1.369291, Validation loss: 1.3738, lr: 0.0000\n",
      "Epoch: 683, Training loss: 1.385444, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 684, Training loss: 1.360401, Validation loss: 1.3775, lr: 0.0000\n",
      "Epoch: 685, Training loss: 1.430903, Validation loss: 1.3928, lr: 0.0000\n",
      "Epoch: 686, Training loss: 1.437928, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 687, Training loss: 1.396966, Validation loss: 1.3715, lr: 0.0000\n",
      "Epoch: 688, Training loss: 1.418294, Validation loss: 1.3634, lr: 0.0000\n",
      "Epoch: 689, Training loss: 1.405780, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 690, Training loss: 1.386456, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 691, Training loss: 1.385634, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 692, Training loss: 1.376851, Validation loss: 1.3889, lr: 0.0000\n",
      "Epoch: 693, Training loss: 1.398935, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 694, Training loss: 1.385239, Validation loss: 1.3733, lr: 0.0000\n",
      "Epoch: 695, Training loss: 1.378985, Validation loss: 1.3732, lr: 0.0000\n",
      "Epoch: 696, Training loss: 1.396287, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 697, Training loss: 1.417639, Validation loss: 1.3750, lr: 0.0000\n",
      "Epoch: 698, Training loss: 1.377290, Validation loss: 1.3724, lr: 0.0000\n",
      "Epoch: 699, Training loss: 1.384443, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 700, Training loss: 1.379809, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 701, Training loss: 1.364394, Validation loss: 1.3749, lr: 0.0000\n",
      "Epoch: 702, Training loss: 1.369665, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 703, Training loss: 1.375851, Validation loss: 1.3966, lr: 0.0000\n",
      "Epoch: 704, Training loss: 1.378250, Validation loss: 1.3753, lr: 0.0000\n",
      "Epoch: 705, Training loss: 1.370561, Validation loss: 1.3683, lr: 0.0000\n",
      "Epoch: 706, Training loss: 1.395113, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 707, Training loss: 1.387765, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 708, Training loss: 1.369093, Validation loss: 1.3707, lr: 0.0000\n",
      "Epoch: 709, Training loss: 1.379162, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 710, Training loss: 1.397477, Validation loss: 1.3755, lr: 0.0000\n",
      "Epoch: 711, Training loss: 1.376282, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 712, Training loss: 1.371834, Validation loss: 1.3992, lr: 0.0000\n",
      "Epoch: 713, Training loss: 1.384289, Validation loss: 1.3738, lr: 0.0000\n",
      "Epoch: 714, Training loss: 1.387330, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 715, Training loss: 1.355946, Validation loss: 1.3786, lr: 0.0000\n",
      "Epoch: 716, Training loss: 1.372052, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 717, Training loss: 1.370914, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 718, Training loss: 1.428922, Validation loss: 1.3914, lr: 0.0000\n",
      "Epoch: 719, Training loss: 1.383531, Validation loss: 1.3871, lr: 0.0000\n",
      "Epoch: 720, Training loss: 1.393369, Validation loss: 1.3660, lr: 0.0000\n",
      "Epoch: 721, Training loss: 1.386639, Validation loss: 1.3771, lr: 0.0000\n",
      "Epoch: 722, Training loss: 1.349723, Validation loss: 1.3871, lr: 0.0000\n",
      "Epoch: 723, Training loss: 1.397985, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 724, Training loss: 1.383222, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 725, Training loss: 1.377185, Validation loss: 1.3752, lr: 0.0000\n",
      "Epoch: 726, Training loss: 1.382121, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 727, Training loss: 1.380609, Validation loss: 1.3970, lr: 0.0000\n",
      "Epoch: 728, Training loss: 1.379991, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 729, Training loss: 1.415690, Validation loss: 1.3763, lr: 0.0000\n",
      "Epoch: 730, Training loss: 1.390543, Validation loss: 1.3458, lr: 0.0000\n",
      "Epoch: 731, Training loss: 1.374090, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 732, Training loss: 1.373620, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 733, Training loss: 1.376687, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 734, Training loss: 1.366173, Validation loss: 1.3936, lr: 0.0000\n",
      "Epoch: 735, Training loss: 1.370544, Validation loss: 1.3713, lr: 0.0000\n",
      "Epoch: 736, Training loss: 1.376127, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 737, Training loss: 1.387826, Validation loss: 1.3697, lr: 0.0000\n",
      "Epoch: 738, Training loss: 1.362782, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 739, Training loss: 1.390445, Validation loss: 1.3677, lr: 0.0000\n",
      "Epoch: 740, Training loss: 1.372319, Validation loss: 1.3696, lr: 0.0000\n",
      "Epoch: 741, Training loss: 1.371951, Validation loss: 1.4007, lr: 0.0000\n",
      "Epoch: 742, Training loss: 1.373751, Validation loss: 1.3794, lr: 0.0000\n",
      "Epoch: 743, Training loss: 1.411336, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 744, Training loss: 1.370584, Validation loss: 1.3778, lr: 0.0000\n",
      "Epoch: 745, Training loss: 1.373236, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 746, Training loss: 1.372810, Validation loss: 1.3727, lr: 0.0000\n",
      "Epoch: 747, Training loss: 1.384067, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 748, Training loss: 1.391921, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 749, Training loss: 1.364976, Validation loss: 1.3599, lr: 0.0000\n",
      "Epoch: 750, Training loss: 1.383405, Validation loss: 1.4142, lr: 0.0000\n",
      "Epoch: 751, Training loss: 1.412573, Validation loss: 1.3589, lr: 0.0000\n",
      "Epoch: 752, Training loss: 1.387709, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 753, Training loss: 1.388902, Validation loss: 1.3909, lr: 0.0000\n",
      "Epoch: 754, Training loss: 1.376692, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 755, Training loss: 1.367249, Validation loss: 1.3447, lr: 0.0000\n",
      "Epoch: 756, Training loss: 1.379123, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 757, Training loss: 1.370757, Validation loss: 1.3782, lr: 0.0000\n",
      "Epoch: 758, Training loss: 1.384602, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 759, Training loss: 1.376600, Validation loss: 1.3795, lr: 0.0000\n",
      "Epoch: 760, Training loss: 1.399863, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 761, Training loss: 1.383724, Validation loss: 1.3780, lr: 0.0000\n",
      "Epoch: 762, Training loss: 1.381455, Validation loss: 1.3780, lr: 0.0000\n",
      "Epoch: 763, Training loss: 1.384577, Validation loss: 1.4177, lr: 0.0000\n",
      "Epoch: 764, Training loss: 1.376393, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 765, Training loss: 1.378692, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 766, Training loss: 1.386400, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 767, Training loss: 1.372178, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 768, Training loss: 1.385841, Validation loss: 1.3875, lr: 0.0000\n",
      "Epoch: 769, Training loss: 1.373341, Validation loss: 1.3699, lr: 0.0000\n",
      "Epoch: 770, Training loss: 1.368338, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 771, Training loss: 1.397191, Validation loss: 1.3803, lr: 0.0000\n",
      "Epoch: 772, Training loss: 1.380577, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 773, Training loss: 1.399271, Validation loss: 1.3890, lr: 0.0000\n",
      "Epoch: 774, Training loss: 1.369057, Validation loss: 1.3784, lr: 0.0000\n",
      "Epoch: 775, Training loss: 1.378335, Validation loss: 1.3614, lr: 0.0000\n",
      "Epoch: 776, Training loss: 1.376160, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 777, Training loss: 1.423702, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 778, Training loss: 1.364102, Validation loss: 1.3802, lr: 0.0000\n",
      "Epoch: 779, Training loss: 1.385365, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 780, Training loss: 1.377539, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 781, Training loss: 1.405454, Validation loss: 1.3781, lr: 0.0000\n",
      "Epoch: 782, Training loss: 1.370009, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 783, Training loss: 1.376846, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 784, Training loss: 1.366613, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 785, Training loss: 1.381218, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 786, Training loss: 1.385041, Validation loss: 1.3911, lr: 0.0000\n",
      "Epoch: 787, Training loss: 1.471515, Validation loss: 1.3755, lr: 0.0000\n",
      "Epoch: 788, Training loss: 1.419438, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 789, Training loss: 1.379446, Validation loss: 1.3809, lr: 0.0000\n",
      "Epoch: 790, Training loss: 1.369953, Validation loss: 1.3960, lr: 0.0000\n",
      "Epoch: 791, Training loss: 1.374596, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 792, Training loss: 1.379087, Validation loss: 1.5401, lr: 0.0000\n",
      "Epoch: 793, Training loss: 1.386159, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 794, Training loss: 1.388973, Validation loss: 1.3882, lr: 0.0000\n",
      "Epoch: 795, Training loss: 1.364316, Validation loss: 1.3774, lr: 0.0000\n",
      "Epoch: 796, Training loss: 1.389213, Validation loss: 1.3771, lr: 0.0000\n",
      "Epoch: 797, Training loss: 1.369565, Validation loss: 1.3883, lr: 0.0000\n",
      "Epoch: 798, Training loss: 1.379569, Validation loss: 1.3627, lr: 0.0000\n",
      "Epoch: 799, Training loss: 1.361880, Validation loss: 1.3798, lr: 0.0000\n",
      "Epoch: 800, Training loss: 1.357717, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 801, Training loss: 1.379664, Validation loss: 1.3717, lr: 0.0000\n",
      "Epoch: 802, Training loss: 1.377774, Validation loss: 1.4734, lr: 0.0000\n",
      "Epoch: 803, Training loss: 1.417561, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 804, Training loss: 1.391927, Validation loss: 1.3788, lr: 0.0000\n",
      "Epoch: 805, Training loss: 1.388121, Validation loss: 1.3753, lr: 0.0000\n",
      "Epoch: 806, Training loss: 1.396899, Validation loss: 1.3773, lr: 0.0000\n",
      "Epoch: 807, Training loss: 1.367795, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 808, Training loss: 1.373047, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 809, Training loss: 1.391045, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 810, Training loss: 1.403445, Validation loss: 1.3789, lr: 0.0000\n",
      "Epoch: 811, Training loss: 1.354206, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 812, Training loss: 1.368627, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 813, Training loss: 1.375450, Validation loss: 1.3894, lr: 0.0000\n",
      "Epoch: 814, Training loss: 1.375994, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 815, Training loss: 1.391135, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 816, Training loss: 1.398172, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 817, Training loss: 1.367099, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 818, Training loss: 1.357514, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 819, Training loss: 1.415772, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 820, Training loss: 1.376039, Validation loss: 1.3780, lr: 0.0000\n",
      "Epoch: 821, Training loss: 1.385976, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 822, Training loss: 1.408628, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 823, Training loss: 1.378037, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 824, Training loss: 1.370534, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 825, Training loss: 1.363253, Validation loss: 1.3973, lr: 0.0000\n",
      "Epoch: 826, Training loss: 1.356705, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 827, Training loss: 1.375126, Validation loss: 1.3890, lr: 0.0000\n",
      "Epoch: 828, Training loss: 1.412230, Validation loss: 1.3756, lr: 0.0000\n",
      "Epoch: 829, Training loss: 1.360017, Validation loss: 1.3988, lr: 0.0000\n",
      "Epoch: 830, Training loss: 1.385981, Validation loss: 1.3716, lr: 0.0000\n",
      "Epoch: 831, Training loss: 1.362124, Validation loss: 1.3605, lr: 0.0000\n",
      "Epoch: 832, Training loss: 1.366023, Validation loss: 1.3758, lr: 0.0000\n",
      "Epoch: 833, Training loss: 1.378986, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 834, Training loss: 1.385241, Validation loss: 1.3802, lr: 0.0000\n",
      "Epoch: 835, Training loss: 1.375045, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 836, Training loss: 1.377142, Validation loss: 1.3926, lr: 0.0000\n",
      "Epoch: 837, Training loss: 1.453693, Validation loss: 1.3880, lr: 0.0000\n",
      "Epoch: 838, Training loss: 1.376214, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 839, Training loss: 1.398088, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 840, Training loss: 1.413346, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 841, Training loss: 1.398426, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 842, Training loss: 1.396384, Validation loss: 1.3721, lr: 0.0000\n",
      "Epoch: 843, Training loss: 1.384276, Validation loss: 1.3887, lr: 0.0000\n",
      "Epoch: 844, Training loss: 1.383733, Validation loss: 1.5053, lr: 0.0000\n",
      "Epoch: 845, Training loss: 1.380482, Validation loss: 1.3724, lr: 0.0000\n",
      "Epoch: 846, Training loss: 1.469648, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 847, Training loss: 1.390874, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 848, Training loss: 1.376758, Validation loss: 1.3919, lr: 0.0000\n",
      "Epoch: 849, Training loss: 1.376763, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 850, Training loss: 1.410296, Validation loss: 1.3880, lr: 0.0000\n",
      "Epoch: 851, Training loss: 1.394057, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 852, Training loss: 1.365089, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 853, Training loss: 1.378687, Validation loss: 1.4099, lr: 0.0000\n",
      "Epoch: 854, Training loss: 1.372533, Validation loss: 1.3764, lr: 0.0000\n",
      "Epoch: 855, Training loss: 1.341936, Validation loss: 1.4002, lr: 0.0000\n",
      "Epoch: 856, Training loss: 1.372598, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 857, Training loss: 1.381064, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 858, Training loss: 1.383980, Validation loss: 1.3766, lr: 0.0000\n",
      "Epoch: 859, Training loss: 1.378316, Validation loss: 1.3695, lr: 0.0000\n",
      "Epoch: 860, Training loss: 1.432620, Validation loss: 1.3803, lr: 0.0000\n",
      "Epoch: 861, Training loss: 1.416522, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 862, Training loss: 1.381391, Validation loss: 1.3725, lr: 0.0000\n",
      "Epoch: 863, Training loss: 1.370269, Validation loss: 1.3740, lr: 0.0000\n",
      "Epoch: 864, Training loss: 1.390674, Validation loss: 1.3791, lr: 0.0000\n",
      "Epoch: 865, Training loss: 1.396555, Validation loss: 1.3716, lr: 0.0000\n",
      "Epoch: 866, Training loss: 1.379891, Validation loss: 1.4371, lr: 0.0000\n",
      "Epoch: 867, Training loss: 1.383072, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 868, Training loss: 1.405961, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 869, Training loss: 1.381111, Validation loss: 1.3933, lr: 0.0000\n",
      "Epoch: 870, Training loss: 1.371802, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 871, Training loss: 1.368031, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 872, Training loss: 1.367772, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 873, Training loss: 1.388002, Validation loss: 1.3992, lr: 0.0000\n",
      "Epoch: 874, Training loss: 1.449542, Validation loss: 1.3605, lr: 0.0000\n",
      "Epoch: 875, Training loss: 1.382053, Validation loss: 1.3721, lr: 0.0000\n",
      "Epoch: 876, Training loss: 1.387430, Validation loss: 1.3777, lr: 0.0000\n",
      "Epoch: 877, Training loss: 1.390774, Validation loss: 1.3891, lr: 0.0000\n",
      "Epoch: 878, Training loss: 1.381786, Validation loss: 1.3683, lr: 0.0000\n",
      "Epoch: 879, Training loss: 1.377851, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 880, Training loss: 1.390463, Validation loss: 1.3904, lr: 0.0000\n",
      "Epoch: 881, Training loss: 1.370676, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 882, Training loss: 1.376852, Validation loss: 1.3785, lr: 0.0000\n",
      "Epoch: 883, Training loss: 1.365486, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 884, Training loss: 1.375354, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 885, Training loss: 1.362387, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 886, Training loss: 1.369994, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 887, Training loss: 1.392016, Validation loss: 1.3691, lr: 0.0000\n",
      "Epoch: 888, Training loss: 1.383701, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 889, Training loss: 1.441021, Validation loss: 1.3501, lr: 0.0000\n",
      "Epoch: 890, Training loss: 1.378828, Validation loss: 1.3803, lr: 0.0000\n",
      "Epoch: 891, Training loss: 1.367275, Validation loss: 1.3803, lr: 0.0000\n",
      "Epoch: 892, Training loss: 1.370953, Validation loss: 1.3718, lr: 0.0000\n",
      "Epoch: 893, Training loss: 1.381705, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 894, Training loss: 1.368075, Validation loss: 1.3576, lr: 0.0000\n",
      "Epoch: 895, Training loss: 1.386554, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 896, Training loss: 1.362216, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 897, Training loss: 1.383205, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 898, Training loss: 1.385739, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 899, Training loss: 1.374441, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 900, Training loss: 1.378695, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 901, Training loss: 1.378509, Validation loss: 1.3742, lr: 0.0000\n",
      "Epoch: 902, Training loss: 1.375713, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 903, Training loss: 1.377271, Validation loss: 1.3697, lr: 0.0000\n",
      "Epoch: 904, Training loss: 1.442192, Validation loss: 1.3871, lr: 0.0000\n",
      "Epoch: 905, Training loss: 1.374058, Validation loss: 1.3887, lr: 0.0000\n",
      "Epoch: 906, Training loss: 1.369188, Validation loss: 1.3696, lr: 0.0000\n",
      "Epoch: 907, Training loss: 1.357450, Validation loss: 1.3787, lr: 0.0000\n",
      "Epoch: 908, Training loss: 1.377938, Validation loss: 1.3735, lr: 0.0000\n",
      "Epoch: 909, Training loss: 1.394930, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 910, Training loss: 1.373778, Validation loss: 1.4097, lr: 0.0000\n",
      "Epoch: 911, Training loss: 1.369694, Validation loss: 1.3594, lr: 0.0000\n",
      "Epoch: 912, Training loss: 1.373134, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 913, Training loss: 1.379989, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 914, Training loss: 1.387117, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 915, Training loss: 1.370025, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 916, Training loss: 1.369472, Validation loss: 1.3770, lr: 0.0000\n",
      "Epoch: 917, Training loss: 1.414423, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 918, Training loss: 1.371373, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 919, Training loss: 1.372272, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 920, Training loss: 1.384316, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 921, Training loss: 1.347823, Validation loss: 1.3790, lr: 0.0000\n",
      "Epoch: 922, Training loss: 1.369614, Validation loss: 1.4019, lr: 0.0000\n",
      "Epoch: 923, Training loss: 1.374555, Validation loss: 1.3642, lr: 0.0000\n",
      "Epoch: 924, Training loss: 1.402839, Validation loss: 1.3792, lr: 0.0000\n",
      "Epoch: 925, Training loss: 1.376424, Validation loss: 1.3630, lr: 0.0000\n",
      "Epoch: 926, Training loss: 1.367425, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 927, Training loss: 1.388960, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 928, Training loss: 1.378059, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 929, Training loss: 1.376199, Validation loss: 1.3732, lr: 0.0000\n",
      "Epoch: 930, Training loss: 1.396689, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 931, Training loss: 1.407258, Validation loss: 1.3959, lr: 0.0000\n",
      "Epoch: 932, Training loss: 1.372408, Validation loss: 1.3787, lr: 0.0000\n",
      "Epoch: 933, Training loss: 1.365884, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 934, Training loss: 1.367616, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 935, Training loss: 1.356592, Validation loss: 1.3776, lr: 0.0000\n",
      "Epoch: 936, Training loss: 1.368717, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 937, Training loss: 1.368679, Validation loss: 1.3642, lr: 0.0000\n",
      "Epoch: 938, Training loss: 1.410960, Validation loss: 1.3642, lr: 0.0000\n",
      "Epoch: 939, Training loss: 1.377398, Validation loss: 1.4586, lr: 0.0000\n",
      "Epoch: 940, Training loss: 1.382981, Validation loss: 1.3803, lr: 0.0000\n",
      "Epoch: 941, Training loss: 1.384631, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 942, Training loss: 1.376646, Validation loss: 1.3887, lr: 0.0000\n",
      "Epoch: 943, Training loss: 1.381451, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 944, Training loss: 1.390142, Validation loss: 1.3911, lr: 0.0000\n",
      "Epoch: 945, Training loss: 1.386953, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 946, Training loss: 1.371173, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 947, Training loss: 1.368433, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 948, Training loss: 1.412980, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 949, Training loss: 1.352596, Validation loss: 1.3776, lr: 0.0000\n",
      "Epoch: 950, Training loss: 1.419260, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 951, Training loss: 1.368452, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 952, Training loss: 1.368626, Validation loss: 1.3722, lr: 0.0000\n",
      "Epoch: 953, Training loss: 1.386978, Validation loss: 1.3883, lr: 0.0000\n",
      "Epoch: 954, Training loss: 1.378419, Validation loss: 1.3616, lr: 0.0000\n",
      "Epoch: 955, Training loss: 1.372340, Validation loss: 1.3750, lr: 0.0000\n",
      "Epoch: 956, Training loss: 1.372042, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 957, Training loss: 1.358098, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 958, Training loss: 1.354493, Validation loss: 1.3663, lr: 0.0000\n",
      "Epoch: 959, Training loss: 1.376428, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 960, Training loss: 1.372906, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 961, Training loss: 1.372249, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 962, Training loss: 1.371239, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 963, Training loss: 1.378731, Validation loss: 1.3746, lr: 0.0000\n",
      "Epoch: 964, Training loss: 1.372598, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 965, Training loss: 1.461505, Validation loss: 1.3798, lr: 0.0000\n",
      "Epoch: 966, Training loss: 1.393250, Validation loss: 1.3772, lr: 0.0000\n",
      "Epoch: 967, Training loss: 1.373726, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 968, Training loss: 1.390665, Validation loss: 1.3687, lr: 0.0000\n",
      "Epoch: 969, Training loss: 1.379989, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 970, Training loss: 1.366007, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 971, Training loss: 1.366394, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 972, Training loss: 1.374413, Validation loss: 1.3882, lr: 0.0000\n",
      "Epoch: 973, Training loss: 1.357129, Validation loss: 1.3900, lr: 0.0000\n",
      "Epoch: 974, Training loss: 1.371443, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 975, Training loss: 1.358944, Validation loss: 1.3774, lr: 0.0000\n",
      "Epoch: 976, Training loss: 1.369211, Validation loss: 1.4900, lr: 0.0000\n",
      "Epoch: 977, Training loss: 1.403941, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 978, Training loss: 1.374506, Validation loss: 1.3797, lr: 0.0000\n",
      "Epoch: 979, Training loss: 1.423318, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 980, Training loss: 1.357331, Validation loss: 1.3446, lr: 0.0000\n",
      "Epoch: 981, Training loss: 1.398587, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 982, Training loss: 1.380310, Validation loss: 1.3511, lr: 0.0000\n",
      "Epoch: 983, Training loss: 1.367355, Validation loss: 1.3752, lr: 0.0000\n",
      "Epoch: 984, Training loss: 1.361774, Validation loss: 1.3585, lr: 0.0000\n",
      "Epoch: 985, Training loss: 1.383912, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 986, Training loss: 1.383199, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 987, Training loss: 1.421935, Validation loss: 1.3981, lr: 0.0000\n",
      "Epoch: 988, Training loss: 1.377639, Validation loss: 1.3727, lr: 0.0000\n",
      "Epoch: 989, Training loss: 1.401075, Validation loss: 1.3888, lr: 0.0000\n",
      "Epoch: 990, Training loss: 1.369452, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 991, Training loss: 1.387297, Validation loss: 1.3795, lr: 0.0000\n",
      "Epoch: 992, Training loss: 1.351854, Validation loss: 1.3765, lr: 0.0000\n",
      "Epoch: 993, Training loss: 1.362266, Validation loss: 1.3906, lr: 0.0000\n",
      "Epoch: 994, Training loss: 1.397272, Validation loss: 1.3918, lr: 0.0000\n",
      "Epoch: 995, Training loss: 1.405624, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 996, Training loss: 1.375929, Validation loss: 1.4001, lr: 0.0000\n",
      "Epoch: 997, Training loss: 1.361073, Validation loss: 1.3885, lr: 0.0000\n",
      "Epoch: 998, Training loss: 1.386042, Validation loss: 1.3872, lr: 0.0000\n",
      "Epoch: 999, Training loss: 1.391661, Validation loss: 1.3866, lr: 0.0000\n",
      "Final test loss: 1.3840\n",
      "=== Run 04/10 ===\n",
      "\n",
      "---- Settings: \n",
      "\n",
      "epochs : 1000\n",
      "hidden_channels : [32]\n",
      "out_channels : 10\n",
      "inner_product_features : False\n",
      "batch_size : 64\n",
      "lr : 0.01\n",
      "momentum : 0.9\n",
      "dropout : 0.0\n",
      "batch_norm : batch_norm\n",
      "bias : True\n",
      "order : 2\n",
      "diffusion : True\n",
      "frac_sampled_nb : -1\n",
      "include_positions : False\n",
      "include_self : True\n",
      "vec_norm : False\n",
      "emb_norm : False\n",
      "seed : 0\n",
      "dim_signal : 100\n",
      "dim_emb : 100\n",
      "n_sampled_nb : -1\n",
      "\n",
      "---- Number of features to pass to the MLP:  1010100\n",
      "---- Total number of parameters:  32323627\n",
      "\n",
      "Using device cuda:0\n",
      "\n",
      "---- Training network ...\n",
      "\n",
      "---- Timestamp: 20250614-231150\n",
      "\n",
      " *och: 0, Training loss: 1.394151, Validation loss: 1.4102, lr: 0.0100\n",
      "Epoch: 1, Training loss: 1.430909, Validation loss: 1.4744, lr: 0.0100\n",
      " *och: 2, Training loss: 1.384347, Validation loss: 1.4023, lr: 0.0100\n",
      " *och: 3, Training loss: 1.376314, Validation loss: 1.4001, lr: 0.0100\n",
      " *och: 4, Training loss: 1.438812, Validation loss: 1.3778, lr: 0.0100\n",
      " *och: 5, Training loss: 1.384900, Validation loss: 1.3706, lr: 0.0100\n",
      "Epoch: 6, Training loss: 1.413402, Validation loss: 1.3820, lr: 0.0100\n",
      "Epoch: 7, Training loss: 1.383512, Validation loss: 1.3878, lr: 0.0100\n",
      " *och: 8, Training loss: 1.402959, Validation loss: 1.3690, lr: 0.0100\n",
      "Epoch: 9, Training loss: 1.406801, Validation loss: 1.3733, lr: 0.0100\n",
      "Epoch: 10, Training loss: 1.365114, Validation loss: 1.3890, lr: 0.0100\n",
      "Epoch: 11, Training loss: 1.383004, Validation loss: 1.3839, lr: 0.0100\n",
      "Epoch: 12, Training loss: 1.387107, Validation loss: 1.3791, lr: 0.0100\n",
      "Epoch: 13, Training loss: 1.416195, Validation loss: 1.3931, lr: 0.0100\n",
      " *och: 14, Training loss: 1.394365, Validation loss: 1.3643, lr: 0.0100\n",
      " *och: 15, Training loss: 1.398070, Validation loss: 1.3618, lr: 0.0100\n",
      "Epoch: 16, Training loss: 1.393531, Validation loss: 1.3878, lr: 0.0100\n",
      " *och: 17, Training loss: 1.370542, Validation loss: 1.3579, lr: 0.0100\n",
      "Epoch: 18, Training loss: 1.372099, Validation loss: 1.3821, lr: 0.0100\n",
      "Epoch: 19, Training loss: 1.376283, Validation loss: 1.3749, lr: 0.0100\n",
      " *och: 20, Training loss: 1.370015, Validation loss: 1.3568, lr: 0.0100\n",
      "Epoch: 21, Training loss: 1.381447, Validation loss: 1.3834, lr: 0.0010\n",
      "Epoch: 22, Training loss: 1.377790, Validation loss: 1.3821, lr: 0.0010\n",
      "Epoch: 23, Training loss: 1.359497, Validation loss: 1.3869, lr: 0.0010\n",
      "Epoch: 24, Training loss: 1.391588, Validation loss: 1.3690, lr: 0.0010\n",
      "Epoch: 25, Training loss: 1.373355, Validation loss: 1.3813, lr: 0.0010\n",
      "Epoch: 26, Training loss: 1.384966, Validation loss: 1.3873, lr: 0.0010\n",
      "Epoch: 27, Training loss: 1.364517, Validation loss: 1.3742, lr: 0.0010\n",
      "Epoch: 28, Training loss: 1.385838, Validation loss: 1.4107, lr: 0.0010\n",
      "Epoch: 29, Training loss: 1.370125, Validation loss: 1.3761, lr: 0.0010\n",
      "Epoch: 30, Training loss: 1.358932, Validation loss: 1.3830, lr: 0.0010\n",
      "Epoch: 31, Training loss: 1.399149, Validation loss: 1.3655, lr: 0.0010\n",
      "Epoch: 32, Training loss: 1.405307, Validation loss: 1.3821, lr: 0.0010\n",
      "Epoch: 33, Training loss: 1.382359, Validation loss: 1.3853, lr: 0.0010\n",
      "Epoch: 34, Training loss: 1.371825, Validation loss: 1.3792, lr: 0.0010\n",
      "Epoch: 35, Training loss: 1.368477, Validation loss: 1.3890, lr: 0.0010\n",
      "Epoch: 36, Training loss: 1.363794, Validation loss: 1.3863, lr: 0.0010\n",
      "Epoch: 37, Training loss: 1.376832, Validation loss: 1.3708, lr: 0.0010\n",
      "Epoch: 38, Training loss: 1.386937, Validation loss: 1.3808, lr: 0.0010\n",
      "Epoch: 39, Training loss: 1.392284, Validation loss: 1.4486, lr: 0.0010\n",
      "Epoch: 40, Training loss: 1.369494, Validation loss: 1.3818, lr: 0.0010\n",
      "Epoch: 41, Training loss: 1.358482, Validation loss: 1.3810, lr: 0.0010\n",
      "Epoch: 42, Training loss: 1.366591, Validation loss: 1.3834, lr: 0.0010\n",
      "Epoch: 43, Training loss: 1.372939, Validation loss: 1.3847, lr: 0.0010\n",
      "Epoch: 44, Training loss: 1.392589, Validation loss: 1.3707, lr: 0.0010\n",
      "Epoch: 45, Training loss: 1.352805, Validation loss: 1.3832, lr: 0.0010\n",
      "Epoch: 46, Training loss: 1.363846, Validation loss: 1.3763, lr: 0.0010\n",
      "Epoch: 47, Training loss: 1.386095, Validation loss: 1.3719, lr: 0.0010\n",
      "Epoch: 48, Training loss: 1.373625, Validation loss: 1.3976, lr: 0.0010\n",
      "Epoch: 49, Training loss: 1.367773, Validation loss: 1.3698, lr: 0.0010\n",
      "Epoch: 50, Training loss: 1.360013, Validation loss: 1.3940, lr: 0.0010\n",
      "Epoch: 51, Training loss: 1.364994, Validation loss: 1.3847, lr: 0.0010\n",
      "Epoch: 52, Training loss: 1.380982, Validation loss: 1.3690, lr: 0.0010\n",
      "Epoch: 53, Training loss: 1.373895, Validation loss: 1.4076, lr: 0.0010\n",
      "Epoch: 54, Training loss: 1.363126, Validation loss: 1.3785, lr: 0.0010\n",
      "Epoch: 55, Training loss: 1.388055, Validation loss: 1.3774, lr: 0.0010\n",
      "Epoch: 56, Training loss: 1.369407, Validation loss: 1.3848, lr: 0.0001\n",
      "Epoch: 57, Training loss: 1.372871, Validation loss: 1.3831, lr: 0.0001\n",
      "Epoch: 58, Training loss: 1.378526, Validation loss: 1.3875, lr: 0.0001\n",
      "Epoch: 59, Training loss: 1.382000, Validation loss: 1.3787, lr: 0.0001\n",
      "Epoch: 60, Training loss: 1.371406, Validation loss: 1.3798, lr: 0.0001\n",
      " *och: 61, Training loss: 1.358212, Validation loss: 1.3465, lr: 0.0001\n",
      "Epoch: 62, Training loss: 1.364007, Validation loss: 1.3747, lr: 0.0001\n",
      "Epoch: 63, Training loss: 1.402036, Validation loss: 1.3710, lr: 0.0001\n",
      "Epoch: 64, Training loss: 1.384390, Validation loss: 1.3728, lr: 0.0001\n",
      "Epoch: 65, Training loss: 1.370707, Validation loss: 1.3629, lr: 0.0001\n",
      "Epoch: 66, Training loss: 1.365577, Validation loss: 1.3685, lr: 0.0001\n",
      "Epoch: 67, Training loss: 1.373500, Validation loss: 1.5507, lr: 0.0000\n",
      "Epoch: 68, Training loss: 1.370705, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 69, Training loss: 1.362002, Validation loss: 1.4157, lr: 0.0000\n",
      "Epoch: 70, Training loss: 1.376855, Validation loss: 1.3875, lr: 0.0000\n",
      "Epoch: 71, Training loss: 1.382896, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 72, Training loss: 1.372972, Validation loss: 1.4060, lr: 0.0000\n",
      "Epoch: 73, Training loss: 1.380852, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 74, Training loss: 1.377687, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 75, Training loss: 1.358393, Validation loss: 1.3662, lr: 0.0000\n",
      "Epoch: 76, Training loss: 1.363325, Validation loss: 1.3759, lr: 0.0000\n",
      "Epoch: 77, Training loss: 1.382666, Validation loss: 1.3703, lr: 0.0000\n",
      "Epoch: 78, Training loss: 1.376781, Validation loss: 1.3669, lr: 0.0000\n",
      "Epoch: 79, Training loss: 1.367179, Validation loss: 1.3909, lr: 0.0000\n",
      "Epoch: 80, Training loss: 1.373241, Validation loss: 1.3849, lr: 0.0000\n",
      " *och: 81, Training loss: 1.362012, Validation loss: 1.3418, lr: 0.0000\n",
      "Epoch: 82, Training loss: 1.368661, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 83, Training loss: 1.374190, Validation loss: 1.3496, lr: 0.0000\n",
      "Epoch: 84, Training loss: 1.374196, Validation loss: 1.3776, lr: 0.0000\n",
      "Epoch: 85, Training loss: 1.363589, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 86, Training loss: 1.368555, Validation loss: 1.3796, lr: 0.0000\n",
      "Epoch: 87, Training loss: 1.368741, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 88, Training loss: 1.393375, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 89, Training loss: 1.408549, Validation loss: 1.3897, lr: 0.0000\n",
      "Epoch: 90, Training loss: 1.364405, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 91, Training loss: 1.365423, Validation loss: 1.3946, lr: 0.0000\n",
      "Epoch: 92, Training loss: 1.365094, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 93, Training loss: 1.359119, Validation loss: 1.3797, lr: 0.0000\n",
      "Epoch: 94, Training loss: 1.385735, Validation loss: 1.3741, lr: 0.0000\n",
      "Epoch: 95, Training loss: 1.379610, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 96, Training loss: 1.360296, Validation loss: 1.3780, lr: 0.0000\n",
      "Epoch: 97, Training loss: 1.373742, Validation loss: 1.3785, lr: 0.0000\n",
      "Epoch: 98, Training loss: 1.391127, Validation loss: 1.3762, lr: 0.0000\n",
      "Epoch: 99, Training loss: 1.372830, Validation loss: 1.3706, lr: 0.0000\n",
      "Epoch: 100, Training loss: 1.359907, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 101, Training loss: 1.377411, Validation loss: 1.4769, lr: 0.0000\n",
      "Epoch: 102, Training loss: 1.380440, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 103, Training loss: 1.350739, Validation loss: 1.3790, lr: 0.0000\n",
      "Epoch: 104, Training loss: 1.379316, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 105, Training loss: 1.374881, Validation loss: 1.3791, lr: 0.0000\n",
      "Epoch: 106, Training loss: 1.368238, Validation loss: 1.3827, lr: 0.0000\n",
      " *och: 107, Training loss: 1.515171, Validation loss: 1.3377, lr: 0.0000\n",
      "Epoch: 108, Training loss: 1.417638, Validation loss: 1.3781, lr: 0.0000\n",
      "Epoch: 109, Training loss: 1.370231, Validation loss: 1.3970, lr: 0.0000\n",
      "Epoch: 110, Training loss: 1.381311, Validation loss: 1.3890, lr: 0.0000\n",
      "Epoch: 111, Training loss: 1.360876, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 112, Training loss: 1.386097, Validation loss: 1.3795, lr: 0.0000\n",
      "Epoch: 113, Training loss: 1.371534, Validation loss: 1.3736, lr: 0.0000\n",
      "Epoch: 114, Training loss: 1.360845, Validation loss: 1.3654, lr: 0.0000\n",
      "Epoch: 115, Training loss: 1.370611, Validation loss: 1.3682, lr: 0.0000\n",
      "Epoch: 116, Training loss: 1.363835, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 117, Training loss: 1.379767, Validation loss: 1.3766, lr: 0.0000\n",
      "Epoch: 118, Training loss: 1.383333, Validation loss: 1.3792, lr: 0.0000\n",
      "Epoch: 119, Training loss: 1.372300, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 120, Training loss: 1.418458, Validation loss: 1.3664, lr: 0.0000\n",
      "Epoch: 121, Training loss: 1.360602, Validation loss: 1.3773, lr: 0.0000\n",
      "Epoch: 122, Training loss: 1.369016, Validation loss: 1.3735, lr: 0.0000\n",
      "Epoch: 123, Training loss: 1.409215, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 124, Training loss: 1.366381, Validation loss: 1.3777, lr: 0.0000\n",
      "Epoch: 125, Training loss: 1.361493, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 126, Training loss: 1.371222, Validation loss: 1.3744, lr: 0.0000\n",
      "Epoch: 127, Training loss: 1.429751, Validation loss: 1.3728, lr: 0.0000\n",
      "Epoch: 128, Training loss: 1.378380, Validation loss: 1.3683, lr: 0.0000\n",
      "Epoch: 129, Training loss: 1.380322, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 130, Training loss: 1.372958, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 131, Training loss: 1.389279, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 132, Training loss: 1.371364, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 133, Training loss: 1.367472, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 134, Training loss: 1.383607, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 135, Training loss: 1.398749, Validation loss: 1.3738, lr: 0.0000\n",
      "Epoch: 136, Training loss: 1.382376, Validation loss: 1.3752, lr: 0.0000\n",
      "Epoch: 137, Training loss: 1.378544, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 138, Training loss: 1.360934, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 139, Training loss: 1.384995, Validation loss: 1.3809, lr: 0.0000\n",
      "Epoch: 140, Training loss: 1.370960, Validation loss: 1.3938, lr: 0.0000\n",
      "Epoch: 141, Training loss: 1.360846, Validation loss: 1.3504, lr: 0.0000\n",
      "Epoch: 142, Training loss: 1.421583, Validation loss: 1.3898, lr: 0.0000\n",
      "Epoch: 143, Training loss: 1.409481, Validation loss: 1.4240, lr: 0.0000\n",
      "Epoch: 144, Training loss: 1.365380, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 145, Training loss: 1.348680, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 146, Training loss: 1.389264, Validation loss: 1.3750, lr: 0.0000\n",
      "Epoch: 147, Training loss: 1.376580, Validation loss: 1.3717, lr: 0.0000\n",
      "Epoch: 148, Training loss: 1.385757, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 149, Training loss: 1.379339, Validation loss: 1.3809, lr: 0.0000\n",
      "Epoch: 150, Training loss: 1.351199, Validation loss: 1.3711, lr: 0.0000\n",
      "Epoch: 151, Training loss: 1.364400, Validation loss: 1.3752, lr: 0.0000\n",
      "Epoch: 152, Training loss: 1.361443, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 153, Training loss: 1.364807, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 154, Training loss: 1.373731, Validation loss: 1.3741, lr: 0.0000\n",
      "Epoch: 155, Training loss: 1.373361, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 156, Training loss: 1.356008, Validation loss: 1.3953, lr: 0.0000\n",
      "Epoch: 157, Training loss: 1.372725, Validation loss: 1.3659, lr: 0.0000\n",
      "Epoch: 158, Training loss: 1.423462, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 159, Training loss: 1.384753, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 160, Training loss: 1.371428, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 161, Training loss: 1.353216, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 162, Training loss: 1.396435, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 163, Training loss: 1.357149, Validation loss: 1.4072, lr: 0.0000\n",
      "Epoch: 164, Training loss: 1.370403, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 165, Training loss: 1.380939, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 166, Training loss: 1.391164, Validation loss: 1.3661, lr: 0.0000\n",
      "Epoch: 167, Training loss: 1.467758, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 168, Training loss: 1.390506, Validation loss: 1.4000, lr: 0.0000\n",
      "Epoch: 169, Training loss: 1.378965, Validation loss: 1.3446, lr: 0.0000\n",
      "Epoch: 170, Training loss: 1.364072, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 171, Training loss: 1.428782, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 172, Training loss: 1.379737, Validation loss: 1.3874, lr: 0.0000\n",
      "Epoch: 173, Training loss: 1.387503, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 174, Training loss: 1.382958, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 175, Training loss: 1.356561, Validation loss: 1.3789, lr: 0.0000\n",
      "Epoch: 176, Training loss: 1.395289, Validation loss: 1.3800, lr: 0.0000\n",
      "Epoch: 177, Training loss: 1.368953, Validation loss: 1.3966, lr: 0.0000\n",
      "Epoch: 178, Training loss: 1.379011, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 179, Training loss: 1.381122, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 180, Training loss: 1.396094, Validation loss: 1.3984, lr: 0.0000\n",
      "Epoch: 181, Training loss: 1.349878, Validation loss: 1.3920, lr: 0.0000\n",
      "Epoch: 182, Training loss: 1.363078, Validation loss: 1.3784, lr: 0.0000\n",
      "Epoch: 183, Training loss: 1.363652, Validation loss: 1.3674, lr: 0.0000\n",
      "Epoch: 184, Training loss: 1.378075, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 185, Training loss: 1.379720, Validation loss: 1.3793, lr: 0.0000\n",
      "Epoch: 186, Training loss: 1.377936, Validation loss: 1.3591, lr: 0.0000\n",
      "Epoch: 187, Training loss: 1.359344, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 188, Training loss: 1.373058, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 189, Training loss: 1.366969, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 190, Training loss: 1.417834, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 191, Training loss: 1.368731, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 192, Training loss: 1.385072, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 193, Training loss: 1.365851, Validation loss: 1.3745, lr: 0.0000\n",
      "Epoch: 194, Training loss: 1.467101, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 195, Training loss: 1.373539, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 196, Training loss: 1.367720, Validation loss: 1.3681, lr: 0.0000\n",
      "Epoch: 197, Training loss: 1.383351, Validation loss: 1.3882, lr: 0.0000\n",
      "Epoch: 198, Training loss: 1.389035, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 199, Training loss: 1.377961, Validation loss: 1.3736, lr: 0.0000\n",
      "Epoch: 200, Training loss: 1.392348, Validation loss: 1.3619, lr: 0.0000\n",
      "Epoch: 201, Training loss: 1.394018, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 202, Training loss: 1.382070, Validation loss: 1.3787, lr: 0.0000\n",
      "Epoch: 203, Training loss: 1.364160, Validation loss: 1.3598, lr: 0.0000\n",
      "Epoch: 204, Training loss: 1.350997, Validation loss: 1.3667, lr: 0.0000\n",
      "Epoch: 205, Training loss: 1.406438, Validation loss: 1.3688, lr: 0.0000\n",
      "Epoch: 206, Training loss: 1.436194, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 207, Training loss: 1.374170, Validation loss: 1.3762, lr: 0.0000\n",
      "Epoch: 208, Training loss: 1.396803, Validation loss: 1.3888, lr: 0.0000\n",
      "Epoch: 209, Training loss: 1.380318, Validation loss: 1.3775, lr: 0.0000\n",
      "Epoch: 210, Training loss: 1.390195, Validation loss: 1.3748, lr: 0.0000\n",
      "Epoch: 211, Training loss: 1.390025, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 212, Training loss: 1.378279, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 213, Training loss: 1.371456, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 214, Training loss: 1.373854, Validation loss: 1.3738, lr: 0.0000\n",
      "Epoch: 215, Training loss: 1.377573, Validation loss: 1.3747, lr: 0.0000\n",
      "Epoch: 216, Training loss: 1.359507, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 217, Training loss: 1.396503, Validation loss: 1.3622, lr: 0.0000\n",
      "Epoch: 218, Training loss: 1.351891, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 219, Training loss: 1.401282, Validation loss: 1.3993, lr: 0.0000\n",
      "Epoch: 220, Training loss: 1.360622, Validation loss: 1.3585, lr: 0.0000\n",
      "Epoch: 221, Training loss: 1.372615, Validation loss: 1.3644, lr: 0.0000\n",
      "Epoch: 222, Training loss: 1.367230, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 223, Training loss: 1.390547, Validation loss: 1.3878, lr: 0.0000\n",
      "Epoch: 224, Training loss: 1.406073, Validation loss: 1.3651, lr: 0.0000\n",
      "Epoch: 225, Training loss: 1.367848, Validation loss: 1.3539, lr: 0.0000\n",
      "Epoch: 226, Training loss: 1.371123, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 227, Training loss: 1.368556, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 228, Training loss: 1.350219, Validation loss: 1.3747, lr: 0.0000\n",
      "Epoch: 229, Training loss: 1.359161, Validation loss: 1.3798, lr: 0.0000\n",
      "Epoch: 230, Training loss: 1.374260, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 231, Training loss: 1.380229, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 232, Training loss: 1.388159, Validation loss: 1.3883, lr: 0.0000\n",
      "Epoch: 233, Training loss: 1.382878, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 234, Training loss: 1.399333, Validation loss: 1.3641, lr: 0.0000\n",
      "Epoch: 235, Training loss: 1.373764, Validation loss: 1.3685, lr: 0.0000\n",
      "Epoch: 236, Training loss: 1.357832, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 237, Training loss: 1.370293, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 238, Training loss: 1.361069, Validation loss: 1.3891, lr: 0.0000\n",
      "Epoch: 239, Training loss: 1.364354, Validation loss: 1.3781, lr: 0.0000\n",
      "Epoch: 240, Training loss: 1.361183, Validation loss: 1.3765, lr: 0.0000\n",
      "Epoch: 241, Training loss: 1.370342, Validation loss: 1.3908, lr: 0.0000\n",
      "Epoch: 242, Training loss: 1.369326, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 243, Training loss: 1.368500, Validation loss: 1.3699, lr: 0.0000\n",
      "Epoch: 244, Training loss: 1.351749, Validation loss: 1.3783, lr: 0.0000\n",
      "Epoch: 245, Training loss: 1.381445, Validation loss: 1.3765, lr: 0.0000\n",
      "Epoch: 246, Training loss: 1.373062, Validation loss: 1.3649, lr: 0.0000\n",
      "Epoch: 247, Training loss: 1.378246, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 248, Training loss: 1.363415, Validation loss: 1.3761, lr: 0.0000\n",
      "Epoch: 249, Training loss: 1.372022, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 250, Training loss: 1.389019, Validation loss: 1.3887, lr: 0.0000\n",
      "Epoch: 251, Training loss: 1.388733, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 252, Training loss: 1.365438, Validation loss: 1.3943, lr: 0.0000\n",
      "Epoch: 253, Training loss: 1.353389, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 254, Training loss: 1.363789, Validation loss: 1.3535, lr: 0.0000\n",
      "Epoch: 255, Training loss: 1.391232, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 256, Training loss: 1.404829, Validation loss: 1.3664, lr: 0.0000\n",
      "Epoch: 257, Training loss: 1.375530, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 258, Training loss: 1.372660, Validation loss: 1.3893, lr: 0.0000\n",
      "Epoch: 259, Training loss: 1.361363, Validation loss: 1.4262, lr: 0.0000\n",
      "Epoch: 260, Training loss: 1.364291, Validation loss: 1.3936, lr: 0.0000\n",
      "Epoch: 261, Training loss: 1.407839, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 262, Training loss: 1.386993, Validation loss: 1.3785, lr: 0.0000\n",
      "Epoch: 263, Training loss: 1.449542, Validation loss: 1.3665, lr: 0.0000\n",
      "Epoch: 264, Training loss: 1.379183, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 265, Training loss: 1.388028, Validation loss: 1.3775, lr: 0.0000\n",
      "Epoch: 266, Training loss: 1.382854, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 267, Training loss: 1.361980, Validation loss: 1.4303, lr: 0.0000\n",
      "Epoch: 268, Training loss: 1.371673, Validation loss: 1.3689, lr: 0.0000\n",
      "Epoch: 269, Training loss: 1.426732, Validation loss: 1.3689, lr: 0.0000\n",
      "Epoch: 270, Training loss: 1.384953, Validation loss: 1.3802, lr: 0.0000\n",
      "Epoch: 271, Training loss: 1.365987, Validation loss: 1.3999, lr: 0.0000\n",
      "Epoch: 272, Training loss: 1.368010, Validation loss: 1.3751, lr: 0.0000\n",
      "Epoch: 273, Training loss: 1.372959, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 274, Training loss: 1.400330, Validation loss: 1.3885, lr: 0.0000\n",
      "Epoch: 275, Training loss: 1.371467, Validation loss: 1.3720, lr: 0.0000\n",
      "Epoch: 276, Training loss: 1.373986, Validation loss: 1.4045, lr: 0.0000\n",
      "Epoch: 277, Training loss: 1.378920, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 278, Training loss: 1.366472, Validation loss: 1.3699, lr: 0.0000\n",
      "Epoch: 279, Training loss: 1.389050, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 280, Training loss: 1.383663, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 281, Training loss: 1.401242, Validation loss: 1.3793, lr: 0.0000\n",
      "Epoch: 282, Training loss: 1.360831, Validation loss: 1.3727, lr: 0.0000\n",
      "Epoch: 283, Training loss: 1.396613, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 284, Training loss: 1.404383, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 285, Training loss: 1.378320, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 286, Training loss: 1.392775, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 287, Training loss: 1.358114, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 288, Training loss: 1.384874, Validation loss: 1.4100, lr: 0.0000\n",
      "Epoch: 289, Training loss: 1.370282, Validation loss: 1.4076, lr: 0.0000\n",
      "Epoch: 290, Training loss: 1.375235, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 291, Training loss: 1.382537, Validation loss: 1.3678, lr: 0.0000\n",
      "Epoch: 292, Training loss: 1.393015, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 293, Training loss: 1.382211, Validation loss: 1.3796, lr: 0.0000\n",
      "Epoch: 294, Training loss: 1.368387, Validation loss: 1.3794, lr: 0.0000\n",
      "Epoch: 295, Training loss: 1.400811, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 296, Training loss: 1.343214, Validation loss: 1.3756, lr: 0.0000\n",
      "Epoch: 297, Training loss: 1.371484, Validation loss: 1.4255, lr: 0.0000\n",
      "Epoch: 298, Training loss: 1.373684, Validation loss: 1.3945, lr: 0.0000\n",
      "Epoch: 299, Training loss: 1.386162, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 300, Training loss: 1.372802, Validation loss: 1.3692, lr: 0.0000\n",
      "Epoch: 301, Training loss: 1.373544, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 302, Training loss: 1.370195, Validation loss: 1.3783, lr: 0.0000\n",
      "Epoch: 303, Training loss: 1.359149, Validation loss: 1.3749, lr: 0.0000\n",
      "Epoch: 304, Training loss: 1.361311, Validation loss: 1.3690, lr: 0.0000\n",
      "Epoch: 305, Training loss: 1.380963, Validation loss: 1.3793, lr: 0.0000\n",
      "Epoch: 306, Training loss: 1.377444, Validation loss: 1.3420, lr: 0.0000\n",
      "Epoch: 307, Training loss: 1.350464, Validation loss: 1.3809, lr: 0.0000\n",
      "Epoch: 308, Training loss: 1.366770, Validation loss: 1.3447, lr: 0.0000\n",
      "Epoch: 309, Training loss: 1.357616, Validation loss: 1.3656, lr: 0.0000\n",
      "Epoch: 310, Training loss: 1.374500, Validation loss: 1.3791, lr: 0.0000\n",
      "Epoch: 311, Training loss: 1.377257, Validation loss: 1.3756, lr: 0.0000\n",
      "Epoch: 312, Training loss: 1.388448, Validation loss: 1.3800, lr: 0.0000\n",
      "Epoch: 313, Training loss: 1.434527, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 314, Training loss: 1.364496, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 315, Training loss: 1.378148, Validation loss: 1.3781, lr: 0.0000\n",
      "Epoch: 316, Training loss: 1.373106, Validation loss: 1.3787, lr: 0.0000\n",
      "Epoch: 317, Training loss: 1.373663, Validation loss: 1.3574, lr: 0.0000\n",
      "Epoch: 318, Training loss: 1.351652, Validation loss: 1.3511, lr: 0.0000\n",
      "Epoch: 319, Training loss: 1.395533, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 320, Training loss: 1.391938, Validation loss: 1.3776, lr: 0.0000\n",
      "Epoch: 321, Training loss: 1.361121, Validation loss: 1.4107, lr: 0.0000\n",
      "Epoch: 322, Training loss: 1.380016, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 323, Training loss: 1.383698, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 324, Training loss: 1.408639, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 325, Training loss: 1.393911, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 326, Training loss: 1.387126, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 327, Training loss: 1.367451, Validation loss: 1.3881, lr: 0.0000\n",
      "Epoch: 328, Training loss: 1.362797, Validation loss: 1.3800, lr: 0.0000\n",
      "Epoch: 329, Training loss: 1.399080, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 330, Training loss: 1.350156, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 331, Training loss: 1.404735, Validation loss: 1.3749, lr: 0.0000\n",
      "Epoch: 332, Training loss: 1.362670, Validation loss: 1.3797, lr: 0.0000\n",
      "Epoch: 333, Training loss: 1.369162, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 334, Training loss: 1.372352, Validation loss: 1.3967, lr: 0.0000\n",
      "Epoch: 335, Training loss: 1.373819, Validation loss: 1.3504, lr: 0.0000\n",
      "Epoch: 336, Training loss: 1.364523, Validation loss: 1.3960, lr: 0.0000\n",
      "Epoch: 337, Training loss: 1.375949, Validation loss: 1.3619, lr: 0.0000\n",
      "Epoch: 338, Training loss: 1.361416, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 339, Training loss: 1.367994, Validation loss: 1.3760, lr: 0.0000\n",
      "Epoch: 340, Training loss: 1.381432, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 341, Training loss: 1.369610, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 342, Training loss: 1.373872, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 343, Training loss: 1.363881, Validation loss: 1.4528, lr: 0.0000\n",
      "Epoch: 344, Training loss: 1.372173, Validation loss: 1.3744, lr: 0.0000\n",
      "Epoch: 345, Training loss: 1.356200, Validation loss: 1.3738, lr: 0.0000\n",
      "Epoch: 346, Training loss: 1.359573, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 347, Training loss: 1.356077, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 348, Training loss: 1.391600, Validation loss: 1.3772, lr: 0.0000\n",
      "Epoch: 349, Training loss: 1.383723, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 350, Training loss: 1.353346, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 351, Training loss: 1.376535, Validation loss: 1.3881, lr: 0.0000\n",
      "Epoch: 352, Training loss: 1.373904, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 353, Training loss: 1.381060, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 354, Training loss: 1.366424, Validation loss: 1.3736, lr: 0.0000\n",
      "Epoch: 355, Training loss: 1.385795, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 356, Training loss: 1.371040, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 357, Training loss: 1.363206, Validation loss: 1.3933, lr: 0.0000\n",
      "Epoch: 358, Training loss: 1.369222, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 359, Training loss: 1.385192, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 360, Training loss: 1.375132, Validation loss: 1.3798, lr: 0.0000\n",
      "Epoch: 361, Training loss: 1.357971, Validation loss: 1.3984, lr: 0.0000\n",
      "Epoch: 362, Training loss: 1.374848, Validation loss: 1.4228, lr: 0.0000\n",
      "Epoch: 363, Training loss: 1.367302, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 364, Training loss: 1.380550, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 365, Training loss: 1.439798, Validation loss: 1.3646, lr: 0.0000\n",
      "Epoch: 366, Training loss: 1.374840, Validation loss: 1.3718, lr: 0.0000\n",
      "Epoch: 367, Training loss: 1.443404, Validation loss: 1.3792, lr: 0.0000\n",
      "Epoch: 368, Training loss: 1.396220, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 369, Training loss: 1.372291, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 370, Training loss: 1.373487, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 371, Training loss: 1.390172, Validation loss: 1.3588, lr: 0.0000\n",
      "Epoch: 372, Training loss: 1.370527, Validation loss: 1.3702, lr: 0.0000\n",
      "Epoch: 373, Training loss: 1.347254, Validation loss: 1.3756, lr: 0.0000\n",
      "Epoch: 374, Training loss: 1.380457, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 375, Training loss: 1.378059, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 376, Training loss: 1.384913, Validation loss: 1.3935, lr: 0.0000\n",
      "Epoch: 377, Training loss: 1.370149, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 378, Training loss: 1.369867, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 379, Training loss: 1.395260, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 380, Training loss: 1.380776, Validation loss: 1.3878, lr: 0.0000\n",
      "Epoch: 381, Training loss: 1.390752, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 382, Training loss: 1.377869, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 383, Training loss: 1.355929, Validation loss: 1.3755, lr: 0.0000\n",
      "Epoch: 384, Training loss: 1.377178, Validation loss: 1.3750, lr: 0.0000\n",
      "Epoch: 385, Training loss: 1.378602, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 386, Training loss: 1.377031, Validation loss: 1.6481, lr: 0.0000\n",
      "Epoch: 387, Training loss: 1.352138, Validation loss: 1.3677, lr: 0.0000\n",
      "Epoch: 388, Training loss: 1.368670, Validation loss: 1.3791, lr: 0.0000\n",
      "Epoch: 389, Training loss: 1.373262, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 390, Training loss: 1.371858, Validation loss: 1.3690, lr: 0.0000\n",
      "Epoch: 391, Training loss: 1.367911, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 392, Training loss: 1.370610, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 393, Training loss: 1.405724, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 394, Training loss: 1.374499, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 395, Training loss: 1.380821, Validation loss: 1.3798, lr: 0.0000\n",
      "Epoch: 396, Training loss: 1.410947, Validation loss: 1.3781, lr: 0.0000\n",
      "Epoch: 397, Training loss: 1.373528, Validation loss: 1.3792, lr: 0.0000\n",
      "Epoch: 398, Training loss: 1.399766, Validation loss: 2.1577, lr: 0.0000\n",
      "Epoch: 399, Training loss: 1.354633, Validation loss: 1.3753, lr: 0.0000\n",
      "Epoch: 400, Training loss: 1.393508, Validation loss: 1.3956, lr: 0.0000\n",
      "Epoch: 401, Training loss: 1.375607, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 402, Training loss: 1.394470, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 403, Training loss: 1.396696, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 404, Training loss: 1.366915, Validation loss: 1.3700, lr: 0.0000\n",
      "Epoch: 405, Training loss: 1.370107, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 406, Training loss: 1.356912, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 407, Training loss: 1.375905, Validation loss: 1.3798, lr: 0.0000\n",
      "Epoch: 408, Training loss: 1.375866, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 409, Training loss: 1.360519, Validation loss: 1.3730, lr: 0.0000\n",
      "Epoch: 410, Training loss: 1.416034, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 411, Training loss: 1.377652, Validation loss: 1.5289, lr: 0.0000\n",
      "Epoch: 412, Training loss: 1.351145, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 413, Training loss: 1.370046, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 414, Training loss: 1.529039, Validation loss: 1.3697, lr: 0.0000\n",
      "Epoch: 415, Training loss: 1.358907, Validation loss: 1.3751, lr: 0.0000\n",
      "Epoch: 416, Training loss: 1.371752, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 417, Training loss: 1.380911, Validation loss: 1.3874, lr: 0.0000\n",
      "Epoch: 418, Training loss: 1.361364, Validation loss: 1.3795, lr: 0.0000\n",
      " *och: 419, Training loss: 1.380251, Validation loss: 1.3314, lr: 0.0000\n",
      "Epoch: 420, Training loss: 1.416544, Validation loss: 1.3897, lr: 0.0000\n",
      "Epoch: 421, Training loss: 1.370362, Validation loss: 1.3773, lr: 0.0000\n",
      "Epoch: 422, Training loss: 1.360050, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 423, Training loss: 1.378094, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 424, Training loss: 1.383407, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 425, Training loss: 1.350088, Validation loss: 1.3582, lr: 0.0000\n",
      "Epoch: 426, Training loss: 1.373132, Validation loss: 1.3909, lr: 0.0000\n",
      "Epoch: 427, Training loss: 1.376790, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 428, Training loss: 1.377508, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 429, Training loss: 1.369071, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 430, Training loss: 1.361902, Validation loss: 1.3575, lr: 0.0000\n",
      "Epoch: 431, Training loss: 1.353562, Validation loss: 1.3757, lr: 0.0000\n",
      "Epoch: 432, Training loss: 1.367473, Validation loss: 1.3725, lr: 0.0000\n",
      "Epoch: 433, Training loss: 1.387749, Validation loss: 1.3764, lr: 0.0000\n",
      "Epoch: 434, Training loss: 1.368277, Validation loss: 1.4669, lr: 0.0000\n",
      "Epoch: 435, Training loss: 1.378762, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 436, Training loss: 1.383128, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 437, Training loss: 1.376691, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 438, Training loss: 1.397057, Validation loss: 1.3771, lr: 0.0000\n",
      "Epoch: 439, Training loss: 1.394158, Validation loss: 1.3797, lr: 0.0000\n",
      "Epoch: 440, Training loss: 1.358198, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 441, Training loss: 1.381300, Validation loss: 1.3584, lr: 0.0000\n",
      "Epoch: 442, Training loss: 1.363387, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 443, Training loss: 1.372273, Validation loss: 1.3881, lr: 0.0000\n",
      "Epoch: 444, Training loss: 1.361098, Validation loss: 1.3702, lr: 0.0000\n",
      "Epoch: 445, Training loss: 1.372800, Validation loss: 1.3745, lr: 0.0000\n",
      "Epoch: 446, Training loss: 1.406912, Validation loss: 1.3783, lr: 0.0000\n",
      "Epoch: 447, Training loss: 1.386881, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 448, Training loss: 1.413234, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 449, Training loss: 1.370001, Validation loss: 1.4181, lr: 0.0000\n",
      "Epoch: 450, Training loss: 1.367126, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 451, Training loss: 1.343182, Validation loss: 1.3663, lr: 0.0000\n",
      "Epoch: 452, Training loss: 1.396680, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 453, Training loss: 1.381577, Validation loss: 1.3674, lr: 0.0000\n",
      "Epoch: 454, Training loss: 1.372696, Validation loss: 1.3624, lr: 0.0000\n",
      "Epoch: 455, Training loss: 1.371101, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 456, Training loss: 1.375015, Validation loss: 1.3688, lr: 0.0000\n",
      "Epoch: 457, Training loss: 1.365385, Validation loss: 1.3883, lr: 0.0000\n",
      "Epoch: 458, Training loss: 1.367319, Validation loss: 1.3594, lr: 0.0000\n",
      "Epoch: 459, Training loss: 1.391522, Validation loss: 1.3873, lr: 0.0000\n",
      "Epoch: 460, Training loss: 1.367679, Validation loss: 1.3896, lr: 0.0000\n",
      "Epoch: 461, Training loss: 1.359178, Validation loss: 1.3756, lr: 0.0000\n",
      "Epoch: 462, Training loss: 1.375798, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 463, Training loss: 1.349308, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 464, Training loss: 1.373506, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 465, Training loss: 1.374749, Validation loss: 1.3774, lr: 0.0000\n",
      "Epoch: 466, Training loss: 1.364328, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 467, Training loss: 1.392752, Validation loss: 1.3773, lr: 0.0000\n",
      "Epoch: 468, Training loss: 1.382960, Validation loss: 1.3763, lr: 0.0000\n",
      "Epoch: 469, Training loss: 1.383657, Validation loss: 1.3700, lr: 0.0000\n",
      "Epoch: 470, Training loss: 1.388843, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 471, Training loss: 1.395527, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 472, Training loss: 1.407813, Validation loss: 1.3837, lr: 0.0000\n",
      " *och: 473, Training loss: 1.374077, Validation loss: 1.3039, lr: 0.0000\n",
      "Epoch: 474, Training loss: 1.365627, Validation loss: 1.3907, lr: 0.0000\n",
      "Epoch: 475, Training loss: 1.352921, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 476, Training loss: 1.380359, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 477, Training loss: 1.380126, Validation loss: 1.3762, lr: 0.0000\n",
      "Epoch: 478, Training loss: 1.361140, Validation loss: 1.3924, lr: 0.0000\n",
      "Epoch: 479, Training loss: 1.401877, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 480, Training loss: 1.392277, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 481, Training loss: 1.418127, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 482, Training loss: 1.360620, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 483, Training loss: 1.371855, Validation loss: 1.3672, lr: 0.0000\n",
      "Epoch: 484, Training loss: 1.354398, Validation loss: 1.3877, lr: 0.0000\n",
      "Epoch: 485, Training loss: 1.354535, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 486, Training loss: 1.364239, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 487, Training loss: 1.359763, Validation loss: 1.3784, lr: 0.0000\n",
      "Epoch: 488, Training loss: 1.385992, Validation loss: 1.3792, lr: 0.0000\n",
      "Epoch: 489, Training loss: 1.362272, Validation loss: 1.3908, lr: 0.0000\n",
      "Epoch: 490, Training loss: 1.393719, Validation loss: 1.6619, lr: 0.0000\n",
      "Epoch: 491, Training loss: 1.364730, Validation loss: 1.3768, lr: 0.0000\n",
      "Epoch: 492, Training loss: 1.350986, Validation loss: 1.3786, lr: 0.0000\n",
      "Epoch: 493, Training loss: 1.375655, Validation loss: 1.3778, lr: 0.0000\n",
      "Epoch: 494, Training loss: 1.371083, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 495, Training loss: 1.373240, Validation loss: 1.3796, lr: 0.0000\n",
      "Epoch: 496, Training loss: 1.378871, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 497, Training loss: 1.368515, Validation loss: 1.3708, lr: 0.0000\n",
      "Epoch: 498, Training loss: 1.375164, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 499, Training loss: 1.377383, Validation loss: 1.3901, lr: 0.0000\n",
      "Epoch: 500, Training loss: 1.367584, Validation loss: 1.3714, lr: 0.0000\n",
      "Epoch: 501, Training loss: 1.378981, Validation loss: 1.3685, lr: 0.0000\n",
      "Epoch: 502, Training loss: 1.383824, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 503, Training loss: 1.370843, Validation loss: 1.3718, lr: 0.0000\n",
      "Epoch: 504, Training loss: 1.385312, Validation loss: 1.3634, lr: 0.0000\n",
      "Epoch: 505, Training loss: 1.380145, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 506, Training loss: 1.380629, Validation loss: 1.3692, lr: 0.0000\n",
      "Epoch: 507, Training loss: 1.372796, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 508, Training loss: 1.379291, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 509, Training loss: 1.361511, Validation loss: 1.3893, lr: 0.0000\n",
      "Epoch: 510, Training loss: 1.362332, Validation loss: 1.3710, lr: 0.0000\n",
      "Epoch: 511, Training loss: 1.355682, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 512, Training loss: 1.371827, Validation loss: 1.3628, lr: 0.0000\n",
      "Epoch: 513, Training loss: 1.364053, Validation loss: 1.3878, lr: 0.0000\n",
      "Epoch: 514, Training loss: 1.380273, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 515, Training loss: 1.429435, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 516, Training loss: 1.377431, Validation loss: 1.3684, lr: 0.0000\n",
      "Epoch: 517, Training loss: 1.382599, Validation loss: 1.3803, lr: 0.0000\n",
      "Epoch: 518, Training loss: 1.375878, Validation loss: 1.3786, lr: 0.0000\n",
      "Epoch: 519, Training loss: 1.357520, Validation loss: 1.3777, lr: 0.0000\n",
      "Epoch: 520, Training loss: 1.361168, Validation loss: 1.3706, lr: 0.0000\n",
      "Epoch: 521, Training loss: 1.379542, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 522, Training loss: 1.398084, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 523, Training loss: 1.379685, Validation loss: 1.3634, lr: 0.0000\n",
      "Epoch: 524, Training loss: 1.350851, Validation loss: 1.3785, lr: 0.0000\n",
      "Epoch: 525, Training loss: 1.370767, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 526, Training loss: 1.356876, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 527, Training loss: 1.365521, Validation loss: 1.3749, lr: 0.0000\n",
      "Epoch: 528, Training loss: 1.355977, Validation loss: 1.3791, lr: 0.0000\n",
      "Epoch: 529, Training loss: 1.371820, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 530, Training loss: 1.377275, Validation loss: 1.3634, lr: 0.0000\n",
      "Epoch: 531, Training loss: 1.366242, Validation loss: 1.4303, lr: 0.0000\n",
      "Epoch: 532, Training loss: 1.376888, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 533, Training loss: 1.401707, Validation loss: 1.3911, lr: 0.0000\n",
      "Epoch: 534, Training loss: 1.374893, Validation loss: 1.3762, lr: 0.0000\n",
      "Epoch: 535, Training loss: 1.393018, Validation loss: 1.3809, lr: 0.0000\n",
      "Epoch: 536, Training loss: 1.363716, Validation loss: 1.3802, lr: 0.0000\n",
      "Epoch: 537, Training loss: 1.364554, Validation loss: 1.3701, lr: 0.0000\n",
      "Epoch: 538, Training loss: 1.380456, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 539, Training loss: 1.351458, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 540, Training loss: 1.413302, Validation loss: 1.3720, lr: 0.0000\n",
      "Epoch: 541, Training loss: 1.370563, Validation loss: 1.3539, lr: 0.0000\n",
      "Epoch: 542, Training loss: 1.366798, Validation loss: 1.3623, lr: 0.0000\n",
      "Epoch: 543, Training loss: 1.385590, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 544, Training loss: 1.384056, Validation loss: 1.3645, lr: 0.0000\n",
      "Epoch: 545, Training loss: 1.378083, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 546, Training loss: 1.362757, Validation loss: 1.3762, lr: 0.0000\n",
      "Epoch: 547, Training loss: 1.363960, Validation loss: 1.9080, lr: 0.0000\n",
      "Epoch: 548, Training loss: 1.391931, Validation loss: 1.3651, lr: 0.0000\n",
      "Epoch: 549, Training loss: 1.377038, Validation loss: 1.3602, lr: 0.0000\n",
      "Epoch: 550, Training loss: 1.374565, Validation loss: 1.3795, lr: 0.0000\n",
      "Epoch: 551, Training loss: 1.374891, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 552, Training loss: 1.358868, Validation loss: 1.3791, lr: 0.0000\n",
      "Epoch: 553, Training loss: 1.379246, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 554, Training loss: 1.377343, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 555, Training loss: 1.361053, Validation loss: 1.3790, lr: 0.0000\n",
      "Epoch: 556, Training loss: 1.377039, Validation loss: 1.3529, lr: 0.0000\n",
      "Epoch: 557, Training loss: 1.372341, Validation loss: 1.3959, lr: 0.0000\n",
      "Epoch: 558, Training loss: 1.378294, Validation loss: 1.3803, lr: 0.0000\n",
      "Epoch: 559, Training loss: 1.362233, Validation loss: 1.4598, lr: 0.0000\n",
      "Epoch: 560, Training loss: 1.365635, Validation loss: 1.3795, lr: 0.0000\n",
      "Epoch: 561, Training loss: 1.354235, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 562, Training loss: 1.381571, Validation loss: 1.3941, lr: 0.0000\n",
      "Epoch: 563, Training loss: 1.376034, Validation loss: 1.3495, lr: 0.0000\n",
      "Epoch: 564, Training loss: 1.382652, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 565, Training loss: 1.375768, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 566, Training loss: 1.369243, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 567, Training loss: 1.374503, Validation loss: 1.3782, lr: 0.0000\n",
      "Epoch: 568, Training loss: 1.365723, Validation loss: 1.3742, lr: 0.0000\n",
      "Epoch: 569, Training loss: 1.386878, Validation loss: 1.3684, lr: 0.0000\n",
      "Epoch: 570, Training loss: 1.360346, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 571, Training loss: 1.364204, Validation loss: 1.3621, lr: 0.0000\n",
      "Epoch: 572, Training loss: 1.358174, Validation loss: 1.3541, lr: 0.0000\n",
      "Epoch: 573, Training loss: 1.373899, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 574, Training loss: 1.383216, Validation loss: 1.3741, lr: 0.0000\n",
      "Epoch: 575, Training loss: 1.359513, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 576, Training loss: 1.350855, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 577, Training loss: 1.375583, Validation loss: 1.3949, lr: 0.0000\n",
      "Epoch: 578, Training loss: 1.362239, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 579, Training loss: 1.374739, Validation loss: 1.3771, lr: 0.0000\n",
      "Epoch: 580, Training loss: 1.400937, Validation loss: 1.3895, lr: 0.0000\n",
      "Epoch: 581, Training loss: 1.373392, Validation loss: 1.3691, lr: 0.0000\n",
      "Epoch: 582, Training loss: 1.395246, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 583, Training loss: 1.369813, Validation loss: 1.3746, lr: 0.0000\n",
      "Epoch: 584, Training loss: 1.358853, Validation loss: 1.3764, lr: 0.0000\n",
      "Epoch: 585, Training loss: 1.358931, Validation loss: 1.3784, lr: 0.0000\n",
      "Epoch: 586, Training loss: 1.372296, Validation loss: 1.3648, lr: 0.0000\n",
      "Epoch: 587, Training loss: 1.357728, Validation loss: 1.3943, lr: 0.0000\n",
      "Epoch: 588, Training loss: 1.375152, Validation loss: 1.3893, lr: 0.0000\n",
      "Epoch: 589, Training loss: 1.482549, Validation loss: 1.3682, lr: 0.0000\n",
      "Epoch: 590, Training loss: 1.379447, Validation loss: 1.3774, lr: 0.0000\n",
      "Epoch: 591, Training loss: 1.355442, Validation loss: 1.3752, lr: 0.0000\n",
      "Epoch: 592, Training loss: 1.386059, Validation loss: 1.3684, lr: 0.0000\n",
      "Epoch: 593, Training loss: 1.385415, Validation loss: 1.3888, lr: 0.0000\n",
      "Epoch: 594, Training loss: 1.396988, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 595, Training loss: 1.396507, Validation loss: 1.3525, lr: 0.0000\n",
      "Epoch: 596, Training loss: 1.386509, Validation loss: 1.3749, lr: 0.0000\n",
      "Epoch: 597, Training loss: 1.384209, Validation loss: 1.3770, lr: 0.0000\n",
      "Epoch: 598, Training loss: 1.366190, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 599, Training loss: 1.394659, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 600, Training loss: 1.408644, Validation loss: 1.3739, lr: 0.0000\n",
      "Epoch: 601, Training loss: 1.376558, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 602, Training loss: 1.374311, Validation loss: 1.3875, lr: 0.0000\n",
      "Epoch: 603, Training loss: 1.391360, Validation loss: 1.3883, lr: 0.0000\n",
      "Epoch: 604, Training loss: 1.392315, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 605, Training loss: 1.387056, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 606, Training loss: 1.427960, Validation loss: 1.3708, lr: 0.0000\n",
      "Epoch: 607, Training loss: 1.371808, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 608, Training loss: 1.366808, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 609, Training loss: 1.350859, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 610, Training loss: 1.379762, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 611, Training loss: 1.365763, Validation loss: 1.3739, lr: 0.0000\n",
      "Epoch: 612, Training loss: 1.364638, Validation loss: 1.3537, lr: 0.0000\n",
      "Epoch: 613, Training loss: 1.355288, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 614, Training loss: 1.372700, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 615, Training loss: 1.356743, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 616, Training loss: 1.402422, Validation loss: 1.3686, lr: 0.0000\n",
      "Epoch: 617, Training loss: 1.351517, Validation loss: 1.3749, lr: 0.0000\n",
      "Epoch: 618, Training loss: 1.370347, Validation loss: 1.3796, lr: 0.0000\n",
      "Epoch: 619, Training loss: 1.371190, Validation loss: 1.3740, lr: 0.0000\n",
      "Epoch: 620, Training loss: 1.381723, Validation loss: 1.3924, lr: 0.0000\n",
      "Epoch: 621, Training loss: 1.360399, Validation loss: 1.3741, lr: 0.0000\n",
      "Epoch: 622, Training loss: 1.363870, Validation loss: 1.3724, lr: 0.0000\n",
      "Epoch: 623, Training loss: 1.367519, Validation loss: 1.3747, lr: 0.0000\n",
      "Epoch: 624, Training loss: 1.370981, Validation loss: 1.3784, lr: 0.0000\n",
      "Epoch: 625, Training loss: 1.377435, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 626, Training loss: 1.374134, Validation loss: 1.3717, lr: 0.0000\n",
      "Epoch: 627, Training loss: 1.377823, Validation loss: 1.3721, lr: 0.0000\n",
      "Epoch: 628, Training loss: 1.371771, Validation loss: 1.3778, lr: 0.0000\n",
      "Epoch: 629, Training loss: 1.381074, Validation loss: 1.3798, lr: 0.0000\n",
      "Epoch: 630, Training loss: 1.360899, Validation loss: 1.3713, lr: 0.0000\n",
      "Epoch: 631, Training loss: 1.372654, Validation loss: 1.4044, lr: 0.0000\n",
      "Epoch: 632, Training loss: 1.353559, Validation loss: 1.3799, lr: 0.0000\n",
      "Epoch: 633, Training loss: 1.375824, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 634, Training loss: 1.405198, Validation loss: 1.3803, lr: 0.0000\n",
      "Epoch: 635, Training loss: 1.376132, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 636, Training loss: 1.389040, Validation loss: 1.3584, lr: 0.0000\n",
      "Epoch: 637, Training loss: 1.362341, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 638, Training loss: 1.401870, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 639, Training loss: 1.471082, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 640, Training loss: 1.381706, Validation loss: 1.3901, lr: 0.0000\n",
      "Epoch: 641, Training loss: 1.370499, Validation loss: 1.3699, lr: 0.0000\n",
      "Epoch: 642, Training loss: 1.372410, Validation loss: 1.3872, lr: 0.0000\n",
      "Epoch: 643, Training loss: 1.382035, Validation loss: 1.3778, lr: 0.0000\n",
      "Epoch: 644, Training loss: 1.473335, Validation loss: 1.3791, lr: 0.0000\n",
      "Epoch: 645, Training loss: 1.367107, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 646, Training loss: 1.366810, Validation loss: 1.3666, lr: 0.0000\n",
      "Epoch: 647, Training loss: 1.357643, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 648, Training loss: 1.388944, Validation loss: 1.3796, lr: 0.0000\n",
      "Epoch: 649, Training loss: 1.376463, Validation loss: 1.3881, lr: 0.0000\n",
      "Epoch: 650, Training loss: 1.413615, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 651, Training loss: 1.386256, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 652, Training loss: 1.392362, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 653, Training loss: 1.387099, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 654, Training loss: 1.378885, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 655, Training loss: 1.384497, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 656, Training loss: 1.426832, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 657, Training loss: 1.387537, Validation loss: 1.3763, lr: 0.0000\n",
      "Epoch: 658, Training loss: 1.365905, Validation loss: 1.3649, lr: 0.0000\n",
      "Epoch: 659, Training loss: 1.340084, Validation loss: 1.3614, lr: 0.0000\n",
      "Epoch: 660, Training loss: 1.404499, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 661, Training loss: 1.357483, Validation loss: 1.3765, lr: 0.0000\n",
      "Epoch: 662, Training loss: 1.368790, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 663, Training loss: 1.526625, Validation loss: 1.3783, lr: 0.0000\n",
      "Epoch: 664, Training loss: 1.423171, Validation loss: 1.3880, lr: 0.0000\n",
      "Epoch: 665, Training loss: 1.381978, Validation loss: 1.5603, lr: 0.0000\n",
      "Epoch: 666, Training loss: 1.355673, Validation loss: 6.8878, lr: 0.0000\n",
      "Epoch: 667, Training loss: 1.372994, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 668, Training loss: 1.359637, Validation loss: 1.3940, lr: 0.0000\n",
      "Epoch: 669, Training loss: 1.367281, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 670, Training loss: 1.347209, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 671, Training loss: 1.352806, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 672, Training loss: 1.384259, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 673, Training loss: 1.371902, Validation loss: 1.3661, lr: 0.0000\n",
      "Epoch: 674, Training loss: 1.387861, Validation loss: 1.3599, lr: 0.0000\n",
      "Epoch: 675, Training loss: 1.366890, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 676, Training loss: 1.446833, Validation loss: 1.4181, lr: 0.0000\n",
      "Epoch: 677, Training loss: 1.411666, Validation loss: 1.3648, lr: 0.0000\n",
      "Epoch: 678, Training loss: 1.398362, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 679, Training loss: 1.364960, Validation loss: 1.3738, lr: 0.0000\n",
      "Epoch: 680, Training loss: 1.370008, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 681, Training loss: 1.379392, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 682, Training loss: 1.373651, Validation loss: 1.3872, lr: 0.0000\n",
      "Epoch: 683, Training loss: 1.369952, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 684, Training loss: 1.373483, Validation loss: 1.4278, lr: 0.0000\n",
      "Epoch: 685, Training loss: 1.359356, Validation loss: 1.3877, lr: 0.0000\n",
      "Epoch: 686, Training loss: 1.376153, Validation loss: 1.3724, lr: 0.0000\n",
      "Epoch: 687, Training loss: 1.355211, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 688, Training loss: 1.363313, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 689, Training loss: 1.360436, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 690, Training loss: 1.398765, Validation loss: 1.3781, lr: 0.0000\n",
      "Epoch: 691, Training loss: 1.388899, Validation loss: 1.3729, lr: 0.0000\n",
      "Epoch: 692, Training loss: 1.432519, Validation loss: 1.3576, lr: 0.0000\n",
      "Epoch: 693, Training loss: 1.384946, Validation loss: 1.3940, lr: 0.0000\n",
      "Epoch: 694, Training loss: 1.380330, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 695, Training loss: 1.363621, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 696, Training loss: 1.367073, Validation loss: 1.3378, lr: 0.0000\n",
      "Epoch: 697, Training loss: 1.375290, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 698, Training loss: 1.377194, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 699, Training loss: 1.362962, Validation loss: 1.3874, lr: 0.0000\n",
      "Epoch: 700, Training loss: 1.389535, Validation loss: 1.3767, lr: 0.0000\n",
      "Epoch: 701, Training loss: 1.361954, Validation loss: 1.3777, lr: 0.0000\n",
      "Epoch: 702, Training loss: 1.360561, Validation loss: 1.3777, lr: 0.0000\n",
      "Epoch: 703, Training loss: 1.375614, Validation loss: 1.3970, lr: 0.0000\n",
      "Epoch: 704, Training loss: 1.369517, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 705, Training loss: 1.377433, Validation loss: 1.3778, lr: 0.0000\n",
      "Epoch: 706, Training loss: 1.386438, Validation loss: 1.3873, lr: 0.0000\n",
      "Epoch: 707, Training loss: 1.401372, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 708, Training loss: 1.369698, Validation loss: 1.4433, lr: 0.0000\n",
      "Epoch: 709, Training loss: 1.376549, Validation loss: 1.3706, lr: 0.0000\n",
      "Epoch: 710, Training loss: 1.370785, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 711, Training loss: 1.360010, Validation loss: 1.3760, lr: 0.0000\n",
      "Epoch: 712, Training loss: 1.368196, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 713, Training loss: 1.364224, Validation loss: 1.3768, lr: 0.0000\n",
      "Epoch: 714, Training loss: 1.405069, Validation loss: 1.3798, lr: 0.0000\n",
      "Epoch: 715, Training loss: 1.356568, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 716, Training loss: 1.375277, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 717, Training loss: 1.358815, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 718, Training loss: 1.383997, Validation loss: 1.3735, lr: 0.0000\n",
      "Epoch: 719, Training loss: 1.372453, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 720, Training loss: 1.382011, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 721, Training loss: 1.372085, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 722, Training loss: 1.375368, Validation loss: 1.3784, lr: 0.0000\n",
      "Epoch: 723, Training loss: 1.357994, Validation loss: 1.3728, lr: 0.0000\n",
      "Epoch: 724, Training loss: 1.397790, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 725, Training loss: 1.379826, Validation loss: 1.3743, lr: 0.0000\n",
      "Epoch: 726, Training loss: 1.426561, Validation loss: 1.3785, lr: 0.0000\n",
      "Epoch: 727, Training loss: 1.365964, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 728, Training loss: 1.361209, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 729, Training loss: 1.385810, Validation loss: 1.3738, lr: 0.0000\n",
      "Epoch: 730, Training loss: 1.363614, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 731, Training loss: 1.369804, Validation loss: 1.3884, lr: 0.0000\n",
      "Epoch: 732, Training loss: 1.367034, Validation loss: 1.3884, lr: 0.0000\n",
      "Epoch: 733, Training loss: 1.389104, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 734, Training loss: 1.381699, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 735, Training loss: 1.374685, Validation loss: 1.3742, lr: 0.0000\n",
      "Epoch: 736, Training loss: 1.362927, Validation loss: 1.3714, lr: 0.0000\n",
      "Epoch: 737, Training loss: 1.387567, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 738, Training loss: 1.400090, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 739, Training loss: 1.370753, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 740, Training loss: 1.378122, Validation loss: 1.3787, lr: 0.0000\n",
      "Epoch: 741, Training loss: 1.351571, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 742, Training loss: 1.375430, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 743, Training loss: 1.360984, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 744, Training loss: 1.370735, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 745, Training loss: 1.354998, Validation loss: 1.3875, lr: 0.0000\n",
      "Epoch: 746, Training loss: 1.359985, Validation loss: 1.3791, lr: 0.0000\n",
      "Epoch: 747, Training loss: 1.385512, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 748, Training loss: 1.371094, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 749, Training loss: 1.366770, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 750, Training loss: 1.375664, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 751, Training loss: 1.354314, Validation loss: 1.3756, lr: 0.0000\n",
      "Epoch: 752, Training loss: 1.384720, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 753, Training loss: 1.369536, Validation loss: 1.3702, lr: 0.0000\n",
      "Epoch: 754, Training loss: 1.376747, Validation loss: 1.3767, lr: 0.0000\n",
      "Epoch: 755, Training loss: 1.380517, Validation loss: 1.3886, lr: 0.0000\n",
      "Epoch: 756, Training loss: 1.389756, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 757, Training loss: 1.365980, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 758, Training loss: 1.383354, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 759, Training loss: 1.364992, Validation loss: 1.3724, lr: 0.0000\n",
      "Epoch: 760, Training loss: 1.373042, Validation loss: 1.3881, lr: 0.0000\n",
      "Epoch: 761, Training loss: 1.357251, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 762, Training loss: 1.359737, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 763, Training loss: 1.367601, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 764, Training loss: 1.362587, Validation loss: 1.3729, lr: 0.0000\n",
      "Epoch: 765, Training loss: 1.379550, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 766, Training loss: 1.369806, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 767, Training loss: 1.384880, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 768, Training loss: 1.365426, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 769, Training loss: 1.414661, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 770, Training loss: 1.369391, Validation loss: 1.3760, lr: 0.0000\n",
      "Epoch: 771, Training loss: 1.377362, Validation loss: 1.3878, lr: 0.0000\n",
      "Epoch: 772, Training loss: 1.378968, Validation loss: 1.3963, lr: 0.0000\n",
      "Epoch: 773, Training loss: 1.421859, Validation loss: 1.3800, lr: 0.0000\n",
      "Epoch: 774, Training loss: 1.364199, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 775, Training loss: 1.414073, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 776, Training loss: 1.373912, Validation loss: 1.3679, lr: 0.0000\n",
      "Epoch: 777, Training loss: 1.352180, Validation loss: 1.3793, lr: 0.0000\n",
      "Epoch: 778, Training loss: 1.365272, Validation loss: 1.3692, lr: 0.0000\n",
      "Epoch: 779, Training loss: 1.369287, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 780, Training loss: 1.413053, Validation loss: 1.3683, lr: 0.0000\n",
      "Epoch: 781, Training loss: 1.379931, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 782, Training loss: 1.370749, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 783, Training loss: 1.376525, Validation loss: 1.3785, lr: 0.0000\n",
      "Epoch: 784, Training loss: 1.432103, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 785, Training loss: 1.389437, Validation loss: 1.3631, lr: 0.0000\n",
      "Epoch: 786, Training loss: 1.382459, Validation loss: 1.3535, lr: 0.0000\n",
      "Epoch: 787, Training loss: 1.354916, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 788, Training loss: 1.377260, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 789, Training loss: 1.372197, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 790, Training loss: 1.368466, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 791, Training loss: 1.370617, Validation loss: 1.3773, lr: 0.0000\n",
      "Epoch: 792, Training loss: 1.375414, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 793, Training loss: 1.354333, Validation loss: 1.3763, lr: 0.0000\n",
      "Epoch: 794, Training loss: 1.347005, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 795, Training loss: 1.373350, Validation loss: 1.3788, lr: 0.0000\n",
      "Epoch: 796, Training loss: 1.355721, Validation loss: 1.3732, lr: 0.0000\n",
      "Epoch: 797, Training loss: 1.352008, Validation loss: 1.3312, lr: 0.0000\n",
      "Epoch: 798, Training loss: 1.373204, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 799, Training loss: 1.365357, Validation loss: 1.3707, lr: 0.0000\n",
      "Epoch: 800, Training loss: 1.368213, Validation loss: 1.3991, lr: 0.0000\n",
      "Epoch: 801, Training loss: 1.393827, Validation loss: 1.3780, lr: 0.0000\n",
      "Epoch: 802, Training loss: 1.382848, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 803, Training loss: 1.373790, Validation loss: 1.3638, lr: 0.0000\n",
      "Epoch: 804, Training loss: 1.352894, Validation loss: 1.3889, lr: 0.0000\n",
      "Epoch: 805, Training loss: 1.357308, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 806, Training loss: 1.380084, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 807, Training loss: 1.368562, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 808, Training loss: 1.366291, Validation loss: 1.3792, lr: 0.0000\n",
      "Epoch: 809, Training loss: 1.387185, Validation loss: 1.3707, lr: 0.0000\n",
      "Epoch: 810, Training loss: 1.365954, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 811, Training loss: 1.364473, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 812, Training loss: 1.358974, Validation loss: 1.3738, lr: 0.0000\n",
      "Epoch: 813, Training loss: 1.376414, Validation loss: 1.4014, lr: 0.0000\n",
      "Epoch: 814, Training loss: 1.382360, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 815, Training loss: 1.394438, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 816, Training loss: 1.372188, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 817, Training loss: 1.371828, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 818, Training loss: 1.377697, Validation loss: 1.3903, lr: 0.0000\n",
      "Epoch: 819, Training loss: 1.363301, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 820, Training loss: 1.366097, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 821, Training loss: 1.367755, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 822, Training loss: 1.429336, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 823, Training loss: 1.402085, Validation loss: 1.3787, lr: 0.0000\n",
      "Epoch: 824, Training loss: 1.385574, Validation loss: 1.3780, lr: 0.0000\n",
      "Epoch: 825, Training loss: 1.358217, Validation loss: 1.3909, lr: 0.0000\n",
      "Epoch: 826, Training loss: 1.374715, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 827, Training loss: 1.388964, Validation loss: 1.3877, lr: 0.0000\n",
      "Epoch: 828, Training loss: 1.386898, Validation loss: 1.3809, lr: 0.0000\n",
      "Epoch: 829, Training loss: 1.410480, Validation loss: 1.3802, lr: 0.0000\n",
      "Epoch: 830, Training loss: 1.369094, Validation loss: 1.3768, lr: 0.0000\n",
      "Epoch: 831, Training loss: 1.366723, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 832, Training loss: 1.396535, Validation loss: 1.3767, lr: 0.0000\n",
      "Epoch: 833, Training loss: 1.377563, Validation loss: 1.3619, lr: 0.0000\n",
      "Epoch: 834, Training loss: 1.365173, Validation loss: 1.8100, lr: 0.0000\n",
      "Epoch: 835, Training loss: 1.367296, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 836, Training loss: 1.376793, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 837, Training loss: 1.358895, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 838, Training loss: 1.368573, Validation loss: 1.3799, lr: 0.0000\n",
      "Epoch: 839, Training loss: 1.363130, Validation loss: 1.3893, lr: 0.0000\n",
      "Epoch: 840, Training loss: 1.361757, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 841, Training loss: 1.377421, Validation loss: 1.4143, lr: 0.0000\n",
      "Epoch: 842, Training loss: 1.377834, Validation loss: 1.3766, lr: 0.0000\n",
      "Epoch: 843, Training loss: 1.400534, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 844, Training loss: 1.375432, Validation loss: 1.3768, lr: 0.0000\n",
      "Epoch: 845, Training loss: 1.383420, Validation loss: 1.3776, lr: 0.0000\n",
      "Epoch: 846, Training loss: 1.362520, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 847, Training loss: 1.374959, Validation loss: 1.3677, lr: 0.0000\n",
      "Epoch: 848, Training loss: 1.370888, Validation loss: 1.3690, lr: 0.0000\n",
      "Epoch: 849, Training loss: 1.358252, Validation loss: 1.3916, lr: 0.0000\n",
      "Epoch: 850, Training loss: 1.386813, Validation loss: 1.3695, lr: 0.0000\n",
      "Epoch: 851, Training loss: 1.435755, Validation loss: 1.3794, lr: 0.0000\n",
      "Epoch: 852, Training loss: 1.364477, Validation loss: 1.3707, lr: 0.0000\n",
      "Epoch: 853, Training loss: 1.383756, Validation loss: 1.3748, lr: 0.0000\n",
      "Epoch: 854, Training loss: 1.372094, Validation loss: 1.3708, lr: 0.0000\n",
      "Epoch: 855, Training loss: 1.392091, Validation loss: 1.3796, lr: 0.0000\n",
      "Epoch: 856, Training loss: 1.360851, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 857, Training loss: 1.380247, Validation loss: 1.3527, lr: 0.0000\n",
      "Epoch: 858, Training loss: 1.362496, Validation loss: 1.3916, lr: 0.0000\n",
      "Epoch: 859, Training loss: 1.390079, Validation loss: 1.3710, lr: 0.0000\n",
      "Epoch: 860, Training loss: 1.387405, Validation loss: 1.3726, lr: 0.0000\n",
      "Epoch: 861, Training loss: 1.374860, Validation loss: 1.3669, lr: 0.0000\n",
      "Epoch: 862, Training loss: 1.386099, Validation loss: 1.3642, lr: 0.0000\n",
      "Epoch: 863, Training loss: 1.370599, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 864, Training loss: 1.363410, Validation loss: 1.3802, lr: 0.0000\n",
      "Epoch: 865, Training loss: 1.390494, Validation loss: 1.3766, lr: 0.0000\n",
      "Epoch: 866, Training loss: 1.413374, Validation loss: 1.3767, lr: 0.0000\n",
      "Epoch: 867, Training loss: 1.356086, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 868, Training loss: 1.370900, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 869, Training loss: 1.364333, Validation loss: 1.3909, lr: 0.0000\n",
      "Epoch: 870, Training loss: 1.374340, Validation loss: 1.3711, lr: 0.0000\n",
      "Epoch: 871, Training loss: 1.378874, Validation loss: 1.3567, lr: 0.0000\n",
      "Epoch: 872, Training loss: 1.384763, Validation loss: 1.3754, lr: 0.0000\n",
      "Epoch: 873, Training loss: 1.424562, Validation loss: 1.3707, lr: 0.0000\n",
      "Epoch: 874, Training loss: 1.372534, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 875, Training loss: 1.399331, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 876, Training loss: 1.348670, Validation loss: 1.3809, lr: 0.0000\n",
      "Epoch: 877, Training loss: 1.386371, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 878, Training loss: 1.362731, Validation loss: 1.3893, lr: 0.0000\n",
      "Epoch: 879, Training loss: 1.365346, Validation loss: 1.4063, lr: 0.0000\n",
      "Epoch: 880, Training loss: 1.384732, Validation loss: 1.3669, lr: 0.0000\n",
      "Epoch: 881, Training loss: 1.377019, Validation loss: 1.3777, lr: 0.0000\n",
      "Epoch: 882, Training loss: 1.358278, Validation loss: 1.3992, lr: 0.0000\n",
      "Epoch: 883, Training loss: 1.382168, Validation loss: 1.3741, lr: 0.0000\n",
      "Epoch: 884, Training loss: 1.388315, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 885, Training loss: 1.368463, Validation loss: 1.4874, lr: 0.0000\n",
      "Epoch: 886, Training loss: 1.369760, Validation loss: 1.3960, lr: 0.0000\n",
      "Epoch: 887, Training loss: 1.403775, Validation loss: 1.3766, lr: 0.0000\n",
      "Epoch: 888, Training loss: 1.390867, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 889, Training loss: 1.363457, Validation loss: 1.3920, lr: 0.0000\n",
      "Epoch: 890, Training loss: 1.368224, Validation loss: 1.3930, lr: 0.0000\n",
      "Epoch: 891, Training loss: 1.363962, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 892, Training loss: 1.361184, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 893, Training loss: 1.374334, Validation loss: 1.3758, lr: 0.0000\n",
      "Epoch: 894, Training loss: 1.443258, Validation loss: 1.3709, lr: 0.0000\n",
      "Epoch: 895, Training loss: 1.368540, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 896, Training loss: 1.378748, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 897, Training loss: 1.370409, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 898, Training loss: 1.384501, Validation loss: 1.3625, lr: 0.0000\n",
      "Epoch: 899, Training loss: 1.368402, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 900, Training loss: 1.381371, Validation loss: 1.3792, lr: 0.0000\n",
      "Epoch: 901, Training loss: 1.369012, Validation loss: 1.3688, lr: 0.0000\n",
      "Epoch: 902, Training loss: 1.368992, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 903, Training loss: 1.387697, Validation loss: 1.3546, lr: 0.0000\n",
      "Epoch: 904, Training loss: 1.385267, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 905, Training loss: 1.377921, Validation loss: 1.3766, lr: 0.0000\n",
      "Epoch: 906, Training loss: 1.504526, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 907, Training loss: 1.421493, Validation loss: 1.3957, lr: 0.0000\n",
      "Epoch: 908, Training loss: 1.374544, Validation loss: 1.3673, lr: 0.0000\n",
      "Epoch: 909, Training loss: 1.390577, Validation loss: 1.3774, lr: 0.0000\n",
      "Epoch: 910, Training loss: 1.389428, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 911, Training loss: 1.372316, Validation loss: 1.3883, lr: 0.0000\n",
      "Epoch: 912, Training loss: 1.385012, Validation loss: 1.3733, lr: 0.0000\n",
      "Epoch: 913, Training loss: 1.369002, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 914, Training loss: 1.368308, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 915, Training loss: 1.367784, Validation loss: 1.3871, lr: 0.0000\n",
      "Epoch: 916, Training loss: 1.396960, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 917, Training loss: 1.375409, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 918, Training loss: 1.367869, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 919, Training loss: 1.413607, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 920, Training loss: 1.366866, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 921, Training loss: 1.396043, Validation loss: 1.3769, lr: 0.0000\n",
      "Epoch: 922, Training loss: 1.382938, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 923, Training loss: 1.352720, Validation loss: 1.3519, lr: 0.0000\n",
      "Epoch: 924, Training loss: 1.378763, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 925, Training loss: 1.391597, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 926, Training loss: 1.503248, Validation loss: 1.3794, lr: 0.0000\n",
      "Epoch: 927, Training loss: 1.361404, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 928, Training loss: 1.381772, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 929, Training loss: 1.355756, Validation loss: 1.3644, lr: 0.0000\n",
      "Epoch: 930, Training loss: 1.362595, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 931, Training loss: 1.383834, Validation loss: 1.3702, lr: 0.0000\n",
      "Epoch: 932, Training loss: 1.395366, Validation loss: 1.3796, lr: 0.0000\n",
      "Epoch: 933, Training loss: 1.384155, Validation loss: 1.3787, lr: 0.0000\n",
      "Epoch: 934, Training loss: 1.380124, Validation loss: 1.3713, lr: 0.0000\n",
      "Epoch: 935, Training loss: 1.390162, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 936, Training loss: 1.370809, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 937, Training loss: 1.383155, Validation loss: 1.3873, lr: 0.0000\n",
      "Epoch: 938, Training loss: 1.427911, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 939, Training loss: 1.380831, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 940, Training loss: 1.380691, Validation loss: 1.3748, lr: 0.0000\n",
      "Epoch: 941, Training loss: 1.404033, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 942, Training loss: 1.367478, Validation loss: 1.4761, lr: 0.0000\n",
      "Epoch: 943, Training loss: 1.404167, Validation loss: 1.3914, lr: 0.0000\n",
      "Epoch: 944, Training loss: 1.375952, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 945, Training loss: 1.391465, Validation loss: 1.3785, lr: 0.0000\n",
      "Epoch: 946, Training loss: 1.411165, Validation loss: 1.3789, lr: 0.0000\n",
      "Epoch: 947, Training loss: 1.363687, Validation loss: 1.3701, lr: 0.0000\n",
      "Epoch: 948, Training loss: 1.367788, Validation loss: 1.3789, lr: 0.0000\n",
      "Epoch: 949, Training loss: 1.364069, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 950, Training loss: 1.367236, Validation loss: 1.3659, lr: 0.0000\n",
      "Epoch: 951, Training loss: 1.368991, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 952, Training loss: 1.381597, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 953, Training loss: 1.371355, Validation loss: 1.3895, lr: 0.0000\n",
      "Epoch: 954, Training loss: 1.357126, Validation loss: 1.3725, lr: 0.0000\n",
      "Epoch: 955, Training loss: 1.382643, Validation loss: 1.3725, lr: 0.0000\n",
      "Epoch: 956, Training loss: 1.368198, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 957, Training loss: 1.387030, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 958, Training loss: 1.386960, Validation loss: 1.3898, lr: 0.0000\n",
      "Epoch: 959, Training loss: 1.352480, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 960, Training loss: 1.381914, Validation loss: 1.3340, lr: 0.0000\n",
      "Epoch: 961, Training loss: 1.420572, Validation loss: 1.4777, lr: 0.0000\n",
      "Epoch: 962, Training loss: 1.363251, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 963, Training loss: 1.446646, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 964, Training loss: 1.369056, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 965, Training loss: 1.358519, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 966, Training loss: 1.376111, Validation loss: 1.3717, lr: 0.0000\n",
      "Epoch: 967, Training loss: 1.408976, Validation loss: 1.3693, lr: 0.0000\n",
      "Epoch: 968, Training loss: 1.388641, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 969, Training loss: 1.374207, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 970, Training loss: 1.363901, Validation loss: 1.3695, lr: 0.0000\n",
      "Epoch: 971, Training loss: 1.388303, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 972, Training loss: 1.384409, Validation loss: 1.3878, lr: 0.0000\n",
      "Epoch: 973, Training loss: 1.394712, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 974, Training loss: 1.369179, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 975, Training loss: 1.369878, Validation loss: 1.3754, lr: 0.0000\n",
      "Epoch: 976, Training loss: 1.370352, Validation loss: 1.3703, lr: 0.0000\n",
      "Epoch: 977, Training loss: 1.369817, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 978, Training loss: 1.361426, Validation loss: 1.3883, lr: 0.0000\n",
      "Epoch: 979, Training loss: 1.368795, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 980, Training loss: 1.374957, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 981, Training loss: 1.394752, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 982, Training loss: 1.394559, Validation loss: 1.3788, lr: 0.0000\n",
      "Epoch: 983, Training loss: 1.380713, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 984, Training loss: 1.379656, Validation loss: 1.3904, lr: 0.0000\n",
      "Epoch: 985, Training loss: 1.359420, Validation loss: 1.3809, lr: 0.0000\n",
      "Epoch: 986, Training loss: 1.373880, Validation loss: 1.3753, lr: 0.0000\n",
      "Epoch: 987, Training loss: 1.421734, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 988, Training loss: 1.374238, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 989, Training loss: 1.370648, Validation loss: 1.3720, lr: 0.0000\n",
      "Epoch: 990, Training loss: 1.385039, Validation loss: 1.3638, lr: 0.0000\n",
      "Epoch: 991, Training loss: 1.358455, Validation loss: 1.3907, lr: 0.0000\n",
      "Epoch: 992, Training loss: 1.387345, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 993, Training loss: 1.359160, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 994, Training loss: 1.343863, Validation loss: 1.3933, lr: 0.0000\n",
      "Epoch: 995, Training loss: 1.366256, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 996, Training loss: 1.378083, Validation loss: 1.3872, lr: 0.0000\n",
      "Epoch: 997, Training loss: 1.369365, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 998, Training loss: 1.384896, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 999, Training loss: 1.416501, Validation loss: 1.3839, lr: 0.0000\n",
      "Final test loss: 1.3708\n",
      "=== Run 05/10 ===\n",
      "\n",
      "---- Settings: \n",
      "\n",
      "epochs : 1000\n",
      "hidden_channels : [32]\n",
      "out_channels : 10\n",
      "inner_product_features : False\n",
      "batch_size : 64\n",
      "lr : 0.01\n",
      "momentum : 0.9\n",
      "dropout : 0.0\n",
      "batch_norm : batch_norm\n",
      "bias : True\n",
      "order : 2\n",
      "diffusion : True\n",
      "frac_sampled_nb : -1\n",
      "include_positions : False\n",
      "include_self : True\n",
      "vec_norm : False\n",
      "emb_norm : False\n",
      "seed : 0\n",
      "dim_signal : 100\n",
      "dim_emb : 100\n",
      "n_sampled_nb : -1\n",
      "\n",
      "---- Number of features to pass to the MLP:  1010100\n",
      "---- Total number of parameters:  32323627\n",
      "\n",
      "Using device cuda:0\n",
      "\n",
      "---- Training network ...\n",
      "\n",
      "---- Timestamp: 20250615-002359\n",
      "\n",
      " *och: 0, Training loss: 1.409201, Validation loss: 1.3581, lr: 0.0100\n",
      "Epoch: 1, Training loss: 1.438478, Validation loss: 1.3761, lr: 0.0100\n",
      "Epoch: 2, Training loss: 1.386005, Validation loss: 1.3740, lr: 0.0100\n",
      "Epoch: 3, Training loss: 1.591169, Validation loss: 1.3843, lr: 0.0100\n",
      "Epoch: 4, Training loss: 1.408014, Validation loss: 1.3952, lr: 0.0100\n",
      "Epoch: 5, Training loss: 1.429141, Validation loss: 1.4029, lr: 0.0100\n",
      "Epoch: 6, Training loss: 1.472807, Validation loss: 1.3840, lr: 0.0100\n",
      "Epoch: 7, Training loss: 1.363973, Validation loss: 1.3699, lr: 0.0100\n",
      "Epoch: 8, Training loss: 1.390084, Validation loss: 1.3828, lr: 0.0100\n",
      "Epoch: 9, Training loss: 1.440162, Validation loss: 1.3987, lr: 0.0100\n",
      "Epoch: 10, Training loss: 1.400958, Validation loss: 1.3854, lr: 0.0100\n",
      "Epoch: 11, Training loss: 1.381606, Validation loss: 1.3850, lr: 0.0100\n",
      "Epoch: 12, Training loss: 1.389485, Validation loss: 1.3748, lr: 0.0100\n",
      "Epoch: 13, Training loss: 1.366561, Validation loss: 1.3845, lr: 0.0100\n",
      "Epoch: 14, Training loss: 1.388695, Validation loss: 1.3820, lr: 0.0100\n",
      "Epoch: 15, Training loss: 1.399627, Validation loss: 1.3788, lr: 0.0100\n",
      "Epoch: 16, Training loss: 1.372583, Validation loss: 1.3833, lr: 0.0100\n",
      "Epoch: 17, Training loss: 1.373908, Validation loss: 1.3809, lr: 0.0100\n",
      "Epoch: 18, Training loss: 1.380358, Validation loss: 1.3879, lr: 0.0010\n",
      "Epoch: 19, Training loss: 1.389250, Validation loss: 1.3581, lr: 0.0010\n",
      "Epoch: 20, Training loss: 1.384316, Validation loss: 1.3804, lr: 0.0010\n",
      "Epoch: 21, Training loss: 1.373618, Validation loss: 1.3761, lr: 0.0010\n",
      "Epoch: 22, Training loss: 1.380724, Validation loss: 1.3774, lr: 0.0010\n",
      "Epoch: 23, Training loss: 1.387295, Validation loss: 1.3809, lr: 0.0010\n",
      "Epoch: 24, Training loss: 1.388785, Validation loss: 1.3799, lr: 0.0010\n",
      "Epoch: 25, Training loss: 1.364741, Validation loss: 1.3850, lr: 0.0010\n",
      "Epoch: 26, Training loss: 1.457464, Validation loss: 1.3858, lr: 0.0010\n",
      "Epoch: 27, Training loss: 1.401293, Validation loss: 1.3833, lr: 0.0010\n",
      "Epoch: 28, Training loss: 1.409893, Validation loss: 1.3815, lr: 0.0010\n",
      "Epoch: 29, Training loss: 1.396309, Validation loss: 1.3860, lr: 0.0001\n",
      "Epoch: 30, Training loss: 1.366407, Validation loss: 1.3851, lr: 0.0001\n",
      "Epoch: 31, Training loss: 1.394568, Validation loss: 1.3883, lr: 0.0001\n",
      "Epoch: 32, Training loss: 1.382939, Validation loss: 1.3915, lr: 0.0001\n",
      "Epoch: 33, Training loss: 1.383551, Validation loss: 1.3738, lr: 0.0001\n",
      "Epoch: 34, Training loss: 1.368257, Validation loss: 1.3719, lr: 0.0001\n",
      "Epoch: 35, Training loss: 1.374665, Validation loss: 1.3784, lr: 0.0001\n",
      "Epoch: 36, Training loss: 1.376735, Validation loss: 1.3785, lr: 0.0001\n",
      "Epoch: 37, Training loss: 1.361720, Validation loss: 1.3814, lr: 0.0001\n",
      "Epoch: 38, Training loss: 1.375167, Validation loss: 1.3831, lr: 0.0001\n",
      "Epoch: 39, Training loss: 1.368978, Validation loss: 1.3734, lr: 0.0001\n",
      "Epoch: 40, Training loss: 1.365115, Validation loss: 1.3846, lr: 0.0001\n",
      "Epoch: 41, Training loss: 1.389813, Validation loss: 1.3769, lr: 0.0001\n",
      "Epoch: 42, Training loss: 1.360013, Validation loss: 1.3766, lr: 0.0001\n",
      "Epoch: 43, Training loss: 1.382304, Validation loss: 1.3861, lr: 0.0001\n",
      "Epoch: 44, Training loss: 1.405456, Validation loss: 1.3921, lr: 0.0001\n",
      "Epoch: 45, Training loss: 1.388609, Validation loss: 1.3800, lr: 0.0001\n",
      "Epoch: 46, Training loss: 1.372799, Validation loss: 1.3756, lr: 0.0001\n",
      "Epoch: 47, Training loss: 1.380136, Validation loss: 1.3887, lr: 0.0001\n",
      "Epoch: 48, Training loss: 1.384315, Validation loss: 1.3779, lr: 0.0001\n",
      "Epoch: 49, Training loss: 1.402693, Validation loss: 1.3702, lr: 0.0001\n",
      "Epoch: 50, Training loss: 1.389408, Validation loss: 1.3855, lr: 0.0001\n",
      "Epoch: 51, Training loss: 1.366988, Validation loss: 1.3759, lr: 0.0001\n",
      "Epoch: 52, Training loss: 1.380870, Validation loss: 1.3870, lr: 0.0001\n",
      "Epoch: 53, Training loss: 1.372941, Validation loss: 1.3884, lr: 0.0000\n",
      "Epoch: 54, Training loss: 1.375009, Validation loss: 1.3926, lr: 0.0000\n",
      "Epoch: 55, Training loss: 1.378809, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 56, Training loss: 1.389456, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 57, Training loss: 1.390509, Validation loss: 1.3880, lr: 0.0000\n",
      "Epoch: 58, Training loss: 1.388414, Validation loss: 1.3642, lr: 0.0000\n",
      "Epoch: 59, Training loss: 1.382760, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 60, Training loss: 1.418370, Validation loss: 1.3655, lr: 0.0000\n",
      "Epoch: 61, Training loss: 1.419850, Validation loss: 1.3729, lr: 0.0000\n",
      "Epoch: 62, Training loss: 1.368374, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 63, Training loss: 1.374691, Validation loss: 1.4452, lr: 0.0000\n",
      "Epoch: 64, Training loss: 1.393169, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 65, Training loss: 1.383557, Validation loss: 1.3773, lr: 0.0000\n",
      "Epoch: 66, Training loss: 1.364025, Validation loss: 1.3697, lr: 0.0000\n",
      "Epoch: 67, Training loss: 1.387631, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 68, Training loss: 1.379837, Validation loss: 1.3694, lr: 0.0000\n",
      "Epoch: 69, Training loss: 1.362881, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 70, Training loss: 1.440730, Validation loss: 1.3755, lr: 0.0000\n",
      "Epoch: 71, Training loss: 1.398184, Validation loss: 1.3726, lr: 0.0000\n",
      "Epoch: 72, Training loss: 1.371503, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 73, Training loss: 1.394385, Validation loss: 1.3861, lr: 0.0000\n",
      " *och: 74, Training loss: 1.423232, Validation loss: 1.3556, lr: 0.0000\n",
      "Epoch: 75, Training loss: 1.388266, Validation loss: 1.3727, lr: 0.0000\n",
      "Epoch: 76, Training loss: 1.380952, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 77, Training loss: 1.383566, Validation loss: 1.3910, lr: 0.0000\n",
      "Epoch: 78, Training loss: 1.392824, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 79, Training loss: 1.380990, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 80, Training loss: 1.380568, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 81, Training loss: 1.412740, Validation loss: 1.4127, lr: 0.0000\n",
      "Epoch: 82, Training loss: 1.377802, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 83, Training loss: 1.364694, Validation loss: 1.3718, lr: 0.0000\n",
      "Epoch: 84, Training loss: 1.388951, Validation loss: 1.3889, lr: 0.0000\n",
      "Epoch: 85, Training loss: 1.375093, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 86, Training loss: 1.431988, Validation loss: 1.3773, lr: 0.0000\n",
      "Epoch: 87, Training loss: 1.382357, Validation loss: 1.3900, lr: 0.0000\n",
      "Epoch: 88, Training loss: 1.379378, Validation loss: 1.3797, lr: 0.0000\n",
      "Epoch: 89, Training loss: 1.392178, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 90, Training loss: 1.376990, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 91, Training loss: 1.376639, Validation loss: 1.3792, lr: 0.0000\n",
      "Epoch: 92, Training loss: 1.391422, Validation loss: 1.4003, lr: 0.0000\n",
      "Epoch: 93, Training loss: 1.381195, Validation loss: 1.3883, lr: 0.0000\n",
      "Epoch: 94, Training loss: 1.360394, Validation loss: 1.3968, lr: 0.0000\n",
      "Epoch: 95, Training loss: 1.365091, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 96, Training loss: 1.395780, Validation loss: 1.3923, lr: 0.0000\n",
      "Epoch: 97, Training loss: 1.375403, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 98, Training loss: 1.388572, Validation loss: 1.3803, lr: 0.0000\n",
      "Epoch: 99, Training loss: 1.375839, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 100, Training loss: 1.363968, Validation loss: 1.3873, lr: 0.0000\n",
      "Epoch: 101, Training loss: 1.386612, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 102, Training loss: 1.387330, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 103, Training loss: 1.371209, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 104, Training loss: 1.373917, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 105, Training loss: 1.382741, Validation loss: 1.3771, lr: 0.0000\n",
      "Epoch: 106, Training loss: 1.378831, Validation loss: 1.3787, lr: 0.0000\n",
      "Epoch: 107, Training loss: 1.379425, Validation loss: 1.3783, lr: 0.0000\n",
      "Epoch: 108, Training loss: 1.381179, Validation loss: 1.3807, lr: 0.0000\n",
      " *och: 109, Training loss: 1.355016, Validation loss: 1.3458, lr: 0.0000\n",
      "Epoch: 110, Training loss: 1.370042, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 111, Training loss: 1.370428, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 112, Training loss: 1.391203, Validation loss: 1.3760, lr: 0.0000\n",
      "Epoch: 113, Training loss: 1.383309, Validation loss: 1.3712, lr: 0.0000\n",
      "Epoch: 114, Training loss: 1.395242, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 115, Training loss: 1.374992, Validation loss: 1.3913, lr: 0.0000\n",
      "Epoch: 116, Training loss: 1.373443, Validation loss: 1.3787, lr: 0.0000\n",
      "Epoch: 117, Training loss: 1.393919, Validation loss: 1.3881, lr: 0.0000\n",
      "Epoch: 118, Training loss: 1.374607, Validation loss: 1.3700, lr: 0.0000\n",
      "Epoch: 119, Training loss: 1.471047, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 120, Training loss: 1.380849, Validation loss: 1.3871, lr: 0.0000\n",
      "Epoch: 121, Training loss: 1.381956, Validation loss: 1.3749, lr: 0.0000\n",
      "Epoch: 122, Training loss: 1.375559, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 123, Training loss: 1.371102, Validation loss: 1.3955, lr: 0.0000\n",
      "Epoch: 124, Training loss: 1.379599, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 125, Training loss: 1.396729, Validation loss: 1.3700, lr: 0.0000\n",
      "Epoch: 126, Training loss: 1.387662, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 127, Training loss: 1.375522, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 128, Training loss: 1.368548, Validation loss: 1.3778, lr: 0.0000\n",
      "Epoch: 129, Training loss: 1.372154, Validation loss: 1.3794, lr: 0.0000\n",
      "Epoch: 130, Training loss: 1.390782, Validation loss: 1.3881, lr: 0.0000\n",
      "Epoch: 131, Training loss: 1.394368, Validation loss: 1.3614, lr: 0.0000\n",
      "Epoch: 132, Training loss: 1.376334, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 133, Training loss: 1.371497, Validation loss: 1.3755, lr: 0.0000\n",
      "Epoch: 134, Training loss: 1.372678, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 135, Training loss: 1.379842, Validation loss: 1.3864, lr: 0.0000\n",
      " *och: 136, Training loss: 1.381844, Validation loss: 1.3394, lr: 0.0000\n",
      "Epoch: 137, Training loss: 1.381037, Validation loss: 1.3662, lr: 0.0000\n",
      "Epoch: 138, Training loss: 1.375882, Validation loss: 1.3802, lr: 0.0000\n",
      "Epoch: 139, Training loss: 1.376187, Validation loss: 1.3902, lr: 0.0000\n",
      "Epoch: 140, Training loss: 1.362251, Validation loss: 1.3552, lr: 0.0000\n",
      "Epoch: 141, Training loss: 1.387388, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 142, Training loss: 1.375493, Validation loss: 1.3907, lr: 0.0000\n",
      "Epoch: 143, Training loss: 1.380152, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 144, Training loss: 1.375653, Validation loss: 1.3877, lr: 0.0000\n",
      "Epoch: 145, Training loss: 1.415240, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 146, Training loss: 1.371244, Validation loss: 1.3795, lr: 0.0000\n",
      "Epoch: 147, Training loss: 1.375059, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 148, Training loss: 1.370440, Validation loss: 1.3707, lr: 0.0000\n",
      "Epoch: 149, Training loss: 1.367655, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 150, Training loss: 1.375207, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 151, Training loss: 1.370793, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 152, Training loss: 1.407624, Validation loss: 1.3625, lr: 0.0000\n",
      "Epoch: 153, Training loss: 1.362392, Validation loss: 1.3892, lr: 0.0000\n",
      "Epoch: 154, Training loss: 1.378137, Validation loss: 1.3772, lr: 0.0000\n",
      " *och: 155, Training loss: 1.385947, Validation loss: 1.3280, lr: 0.0000\n",
      "Epoch: 156, Training loss: 1.372716, Validation loss: 1.3763, lr: 0.0000\n",
      "Epoch: 157, Training loss: 1.376677, Validation loss: 1.3902, lr: 0.0000\n",
      "Epoch: 158, Training loss: 1.405758, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 159, Training loss: 1.420903, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 160, Training loss: 1.377652, Validation loss: 1.3883, lr: 0.0000\n",
      "Epoch: 161, Training loss: 1.400372, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 162, Training loss: 1.370461, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 163, Training loss: 1.398403, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 164, Training loss: 1.369071, Validation loss: 1.3795, lr: 0.0000\n",
      "Epoch: 165, Training loss: 1.379882, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 166, Training loss: 1.406259, Validation loss: 1.3760, lr: 0.0000\n",
      "Epoch: 167, Training loss: 1.370240, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 168, Training loss: 1.368399, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 169, Training loss: 1.369807, Validation loss: 1.3760, lr: 0.0000\n",
      "Epoch: 170, Training loss: 1.355872, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 171, Training loss: 1.382270, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 172, Training loss: 1.406133, Validation loss: 1.3879, lr: 0.0000\n",
      "Epoch: 173, Training loss: 1.380120, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 174, Training loss: 1.384402, Validation loss: 1.3979, lr: 0.0000\n",
      "Epoch: 175, Training loss: 1.369320, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 176, Training loss: 1.401908, Validation loss: 1.3705, lr: 0.0000\n",
      "Epoch: 177, Training loss: 1.380019, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 178, Training loss: 1.371506, Validation loss: 1.3962, lr: 0.0000\n",
      "Epoch: 179, Training loss: 1.359046, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 180, Training loss: 1.369773, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 181, Training loss: 1.366786, Validation loss: 1.3900, lr: 0.0000\n",
      "Epoch: 182, Training loss: 1.370201, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 183, Training loss: 1.371475, Validation loss: 1.3874, lr: 0.0000\n",
      "Epoch: 184, Training loss: 1.378792, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 185, Training loss: 1.380306, Validation loss: 1.3682, lr: 0.0000\n",
      "Epoch: 186, Training loss: 1.361882, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 187, Training loss: 1.375959, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 188, Training loss: 1.379296, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 189, Training loss: 1.385634, Validation loss: 1.3923, lr: 0.0000\n",
      "Epoch: 190, Training loss: 1.365324, Validation loss: 1.3750, lr: 0.0000\n",
      "Epoch: 191, Training loss: 1.392859, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 192, Training loss: 1.401751, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 193, Training loss: 1.389909, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 194, Training loss: 1.399973, Validation loss: 1.3890, lr: 0.0000\n",
      "Epoch: 195, Training loss: 1.387162, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 196, Training loss: 1.373123, Validation loss: 1.3873, lr: 0.0000\n",
      "Epoch: 197, Training loss: 1.389613, Validation loss: 1.3624, lr: 0.0000\n",
      "Epoch: 198, Training loss: 1.372557, Validation loss: 1.3774, lr: 0.0000\n",
      "Epoch: 199, Training loss: 1.373814, Validation loss: 1.3775, lr: 0.0000\n",
      "Epoch: 200, Training loss: 1.365426, Validation loss: 1.4430, lr: 0.0000\n",
      "Epoch: 201, Training loss: 1.380473, Validation loss: 1.3764, lr: 0.0000\n",
      "Epoch: 202, Training loss: 1.369861, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 203, Training loss: 1.380990, Validation loss: 1.3970, lr: 0.0000\n",
      "Epoch: 204, Training loss: 1.448239, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 205, Training loss: 1.383434, Validation loss: 1.3703, lr: 0.0000\n",
      "Epoch: 206, Training loss: 1.374677, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 207, Training loss: 1.392378, Validation loss: 1.4068, lr: 0.0000\n",
      "Epoch: 208, Training loss: 1.376903, Validation loss: 1.3799, lr: 0.0000\n",
      "Epoch: 209, Training loss: 1.364275, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 210, Training loss: 1.385909, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 211, Training loss: 1.376745, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 212, Training loss: 1.424475, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 213, Training loss: 1.419104, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 214, Training loss: 1.408041, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 215, Training loss: 1.399696, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 216, Training loss: 1.364256, Validation loss: 1.3809, lr: 0.0000\n",
      "Epoch: 217, Training loss: 1.374843, Validation loss: 1.3782, lr: 0.0000\n",
      "Epoch: 218, Training loss: 1.409831, Validation loss: 1.3798, lr: 0.0000\n",
      "Epoch: 219, Training loss: 1.386506, Validation loss: 1.3761, lr: 0.0000\n",
      "Epoch: 220, Training loss: 1.374753, Validation loss: 1.4688, lr: 0.0000\n",
      "Epoch: 221, Training loss: 1.381973, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 222, Training loss: 1.359057, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 223, Training loss: 1.387879, Validation loss: 1.3882, lr: 0.0000\n",
      "Epoch: 224, Training loss: 1.376732, Validation loss: 1.3971, lr: 0.0000\n",
      "Epoch: 225, Training loss: 1.383164, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 226, Training loss: 1.384248, Validation loss: 1.3701, lr: 0.0000\n",
      "Epoch: 227, Training loss: 1.382449, Validation loss: 1.3872, lr: 0.0000\n",
      "Epoch: 228, Training loss: 1.410381, Validation loss: 1.3444, lr: 0.0000\n",
      "Epoch: 229, Training loss: 1.366782, Validation loss: 1.3711, lr: 0.0000\n",
      "Epoch: 230, Training loss: 1.432497, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 231, Training loss: 1.366772, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 232, Training loss: 1.354766, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 233, Training loss: 1.407754, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 234, Training loss: 1.353471, Validation loss: 1.3795, lr: 0.0000\n",
      "Epoch: 235, Training loss: 1.384421, Validation loss: 1.3722, lr: 0.0000\n",
      "Epoch: 236, Training loss: 1.396205, Validation loss: 1.3670, lr: 0.0000\n",
      "Epoch: 237, Training loss: 1.396026, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 238, Training loss: 1.375886, Validation loss: 1.3739, lr: 0.0000\n",
      "Epoch: 239, Training loss: 1.372945, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 240, Training loss: 1.360559, Validation loss: 1.4031, lr: 0.0000\n",
      "Epoch: 241, Training loss: 1.377867, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 242, Training loss: 1.383790, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 243, Training loss: 1.382359, Validation loss: 1.3709, lr: 0.0000\n",
      "Epoch: 244, Training loss: 1.377454, Validation loss: 1.3791, lr: 0.0000\n",
      "Epoch: 245, Training loss: 1.373193, Validation loss: 1.3734, lr: 0.0000\n",
      "Epoch: 246, Training loss: 1.374780, Validation loss: 1.5791, lr: 0.0000\n",
      "Epoch: 247, Training loss: 1.372914, Validation loss: 1.3779, lr: 0.0000\n",
      "Epoch: 248, Training loss: 1.422403, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 249, Training loss: 1.386266, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 250, Training loss: 1.352522, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 251, Training loss: 1.389169, Validation loss: 1.3941, lr: 0.0000\n",
      "Epoch: 252, Training loss: 1.365976, Validation loss: 1.3743, lr: 0.0000\n",
      "Epoch: 253, Training loss: 1.376555, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 254, Training loss: 1.378522, Validation loss: 1.5067, lr: 0.0000\n",
      "Epoch: 255, Training loss: 1.404983, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 256, Training loss: 1.410757, Validation loss: 1.3787, lr: 0.0000\n",
      "Epoch: 257, Training loss: 1.363546, Validation loss: 1.3750, lr: 0.0000\n",
      "Epoch: 258, Training loss: 1.385504, Validation loss: 1.3891, lr: 0.0000\n",
      "Epoch: 259, Training loss: 1.384349, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 260, Training loss: 1.372356, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 261, Training loss: 1.425336, Validation loss: 1.3759, lr: 0.0000\n",
      "Epoch: 262, Training loss: 1.374701, Validation loss: 1.3689, lr: 0.0000\n",
      "Epoch: 263, Training loss: 1.376375, Validation loss: 1.3750, lr: 0.0000\n",
      "Epoch: 264, Training loss: 1.379035, Validation loss: 1.3778, lr: 0.0000\n",
      "Epoch: 265, Training loss: 1.373057, Validation loss: 1.3783, lr: 0.0000\n",
      "Epoch: 266, Training loss: 1.364882, Validation loss: 1.3652, lr: 0.0000\n",
      "Epoch: 267, Training loss: 1.369189, Validation loss: 1.3891, lr: 0.0000\n",
      "Epoch: 268, Training loss: 1.383130, Validation loss: 1.4042, lr: 0.0000\n",
      "Epoch: 269, Training loss: 1.363305, Validation loss: 1.3717, lr: 0.0000\n",
      "Epoch: 270, Training loss: 1.383895, Validation loss: 1.3725, lr: 0.0000\n",
      "Epoch: 271, Training loss: 1.372714, Validation loss: 1.3798, lr: 0.0000\n",
      "Epoch: 272, Training loss: 1.405545, Validation loss: 1.3878, lr: 0.0000\n",
      "Epoch: 273, Training loss: 1.399165, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 274, Training loss: 1.388557, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 275, Training loss: 1.388631, Validation loss: 1.3652, lr: 0.0000\n",
      "Epoch: 276, Training loss: 1.363403, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 277, Training loss: 1.355693, Validation loss: 1.3794, lr: 0.0000\n",
      "Epoch: 278, Training loss: 1.469777, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 279, Training loss: 1.369684, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 280, Training loss: 1.362492, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 281, Training loss: 1.376102, Validation loss: 1.3906, lr: 0.0000\n",
      "Epoch: 282, Training loss: 1.427924, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 283, Training loss: 1.431248, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 284, Training loss: 1.385071, Validation loss: 1.3778, lr: 0.0000\n",
      "Epoch: 285, Training loss: 1.397358, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 286, Training loss: 1.373028, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 287, Training loss: 1.385908, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 288, Training loss: 1.381368, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 289, Training loss: 1.381103, Validation loss: 1.3894, lr: 0.0000\n",
      "Epoch: 290, Training loss: 1.363722, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 291, Training loss: 1.411513, Validation loss: 1.3758, lr: 0.0000\n",
      "Epoch: 292, Training loss: 1.378318, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 293, Training loss: 1.386529, Validation loss: 1.3702, lr: 0.0000\n",
      "Epoch: 294, Training loss: 1.372610, Validation loss: 1.3791, lr: 0.0000\n",
      "Epoch: 295, Training loss: 1.381718, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 296, Training loss: 1.386474, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 297, Training loss: 1.391171, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 298, Training loss: 1.374289, Validation loss: 1.3784, lr: 0.0000\n",
      "Epoch: 299, Training loss: 1.372106, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 300, Training loss: 1.369262, Validation loss: 1.3883, lr: 0.0000\n",
      "Epoch: 301, Training loss: 1.385015, Validation loss: 1.3717, lr: 0.0000\n",
      "Epoch: 302, Training loss: 1.385073, Validation loss: 1.3657, lr: 0.0000\n",
      "Epoch: 303, Training loss: 1.367540, Validation loss: 1.3873, lr: 0.0000\n",
      "Epoch: 304, Training loss: 1.384119, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 305, Training loss: 1.390357, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 306, Training loss: 1.392750, Validation loss: 1.3989, lr: 0.0000\n",
      "Epoch: 307, Training loss: 1.369251, Validation loss: 1.3883, lr: 0.0000\n",
      "Epoch: 308, Training loss: 1.395924, Validation loss: 1.3809, lr: 0.0000\n",
      "Epoch: 309, Training loss: 1.396856, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 310, Training loss: 1.373989, Validation loss: 1.3872, lr: 0.0000\n",
      "Epoch: 311, Training loss: 1.507357, Validation loss: 1.3877, lr: 0.0000\n",
      "Epoch: 312, Training loss: 1.372196, Validation loss: 1.3803, lr: 0.0000\n",
      "Epoch: 313, Training loss: 1.369011, Validation loss: 1.3684, lr: 0.0000\n",
      "Epoch: 314, Training loss: 1.393238, Validation loss: 1.3777, lr: 0.0000\n",
      "Epoch: 315, Training loss: 1.371819, Validation loss: 1.3784, lr: 0.0000\n",
      "Epoch: 316, Training loss: 1.397759, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 317, Training loss: 1.375222, Validation loss: 1.3800, lr: 0.0000\n",
      "Epoch: 318, Training loss: 1.383848, Validation loss: 1.3720, lr: 0.0000\n",
      "Epoch: 319, Training loss: 1.388109, Validation loss: 1.3886, lr: 0.0000\n",
      "Epoch: 320, Training loss: 1.389368, Validation loss: 1.3760, lr: 0.0000\n",
      "Epoch: 321, Training loss: 1.419449, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 322, Training loss: 1.372060, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 323, Training loss: 1.389269, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 324, Training loss: 1.476321, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 325, Training loss: 1.450276, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 326, Training loss: 1.378295, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 327, Training loss: 1.375447, Validation loss: 1.3889, lr: 0.0000\n",
      "Epoch: 328, Training loss: 1.379754, Validation loss: 1.3899, lr: 0.0000\n",
      "Epoch: 329, Training loss: 1.365126, Validation loss: 1.4002, lr: 0.0000\n",
      "Epoch: 330, Training loss: 1.394461, Validation loss: 1.3782, lr: 0.0000\n",
      "Epoch: 331, Training loss: 1.370980, Validation loss: 1.3646, lr: 0.0000\n",
      "Epoch: 332, Training loss: 1.382542, Validation loss: 1.3755, lr: 0.0000\n",
      "Epoch: 333, Training loss: 1.374992, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 334, Training loss: 1.369831, Validation loss: 1.3943, lr: 0.0000\n",
      "Epoch: 335, Training loss: 1.391983, Validation loss: 1.3456, lr: 0.0000\n",
      "Epoch: 336, Training loss: 1.407516, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 337, Training loss: 1.370627, Validation loss: 1.3773, lr: 0.0000\n",
      "Epoch: 338, Training loss: 1.379013, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 339, Training loss: 1.390716, Validation loss: 1.3722, lr: 0.0000\n",
      "Epoch: 340, Training loss: 1.378139, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 341, Training loss: 1.375907, Validation loss: 1.5831, lr: 0.0000\n",
      "Epoch: 342, Training loss: 1.386405, Validation loss: 1.3717, lr: 0.0000\n",
      "Epoch: 343, Training loss: 1.364968, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 344, Training loss: 1.376678, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 345, Training loss: 1.386176, Validation loss: 1.3883, lr: 0.0000\n",
      "Epoch: 346, Training loss: 1.380315, Validation loss: 1.3671, lr: 0.0000\n",
      "Epoch: 347, Training loss: 1.382108, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 348, Training loss: 1.372565, Validation loss: 1.3646, lr: 0.0000\n",
      "Epoch: 349, Training loss: 1.373980, Validation loss: 1.3891, lr: 0.0000\n",
      "Epoch: 350, Training loss: 1.411515, Validation loss: 1.3776, lr: 0.0000\n",
      "Epoch: 351, Training loss: 1.389665, Validation loss: 1.3887, lr: 0.0000\n",
      "Epoch: 352, Training loss: 1.401363, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 353, Training loss: 1.385525, Validation loss: 1.3914, lr: 0.0000\n",
      "Epoch: 354, Training loss: 1.386048, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 355, Training loss: 1.364779, Validation loss: 1.4034, lr: 0.0000\n",
      "Epoch: 356, Training loss: 1.385064, Validation loss: 1.3951, lr: 0.0000\n",
      "Epoch: 357, Training loss: 1.399943, Validation loss: 1.3887, lr: 0.0000\n",
      "Epoch: 358, Training loss: 1.370676, Validation loss: 1.3884, lr: 0.0000\n",
      "Epoch: 359, Training loss: 1.383766, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 360, Training loss: 1.380472, Validation loss: 1.3884, lr: 0.0000\n",
      "Epoch: 361, Training loss: 1.382332, Validation loss: 1.3771, lr: 0.0000\n",
      "Epoch: 362, Training loss: 1.381885, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 363, Training loss: 1.371490, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 364, Training loss: 1.429438, Validation loss: 1.3899, lr: 0.0000\n",
      "Epoch: 365, Training loss: 1.395134, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 366, Training loss: 1.384531, Validation loss: 1.3754, lr: 0.0000\n",
      "Epoch: 367, Training loss: 1.398061, Validation loss: 1.3775, lr: 0.0000\n",
      "Epoch: 368, Training loss: 1.371123, Validation loss: 1.3733, lr: 0.0000\n",
      "Epoch: 369, Training loss: 1.385678, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 370, Training loss: 1.409638, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 371, Training loss: 1.385564, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 372, Training loss: 1.371694, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 373, Training loss: 1.404316, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 374, Training loss: 1.370033, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 375, Training loss: 1.373633, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 376, Training loss: 1.366859, Validation loss: 1.3787, lr: 0.0000\n",
      "Epoch: 377, Training loss: 1.376179, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 378, Training loss: 1.384079, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 379, Training loss: 1.381006, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 380, Training loss: 1.369702, Validation loss: 1.3913, lr: 0.0000\n",
      "Epoch: 381, Training loss: 1.379892, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 382, Training loss: 1.420021, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 383, Training loss: 1.377191, Validation loss: 1.3878, lr: 0.0000\n",
      "Epoch: 384, Training loss: 1.373801, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 385, Training loss: 1.384609, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 386, Training loss: 1.396888, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 387, Training loss: 1.377373, Validation loss: 1.3961, lr: 0.0000\n",
      "Epoch: 388, Training loss: 1.398737, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 389, Training loss: 1.399588, Validation loss: 1.6581, lr: 0.0000\n",
      "Epoch: 390, Training loss: 1.372658, Validation loss: 1.3640, lr: 0.0000\n",
      "Epoch: 391, Training loss: 1.368968, Validation loss: 1.3748, lr: 0.0000\n",
      "Epoch: 392, Training loss: 1.404809, Validation loss: 1.3938, lr: 0.0000\n",
      "Epoch: 393, Training loss: 1.370621, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 394, Training loss: 1.374154, Validation loss: 1.3490, lr: 0.0000\n",
      "Epoch: 395, Training loss: 1.367729, Validation loss: 1.3792, lr: 0.0000\n",
      "Epoch: 396, Training loss: 1.406476, Validation loss: 1.4095, lr: 0.0000\n",
      "Epoch: 397, Training loss: 1.375862, Validation loss: 1.3616, lr: 0.0000\n",
      "Epoch: 398, Training loss: 1.384734, Validation loss: 1.3775, lr: 0.0000\n",
      "Epoch: 399, Training loss: 1.385234, Validation loss: 1.3781, lr: 0.0000\n",
      "Epoch: 400, Training loss: 1.387077, Validation loss: 1.3759, lr: 0.0000\n",
      "Epoch: 401, Training loss: 1.375589, Validation loss: 1.3887, lr: 0.0000\n",
      "Epoch: 402, Training loss: 1.366619, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 403, Training loss: 1.390134, Validation loss: 1.3722, lr: 0.0000\n",
      "Epoch: 404, Training loss: 1.402230, Validation loss: 1.3775, lr: 0.0000\n",
      "Epoch: 405, Training loss: 1.397704, Validation loss: 1.3915, lr: 0.0000\n",
      "Epoch: 406, Training loss: 1.379055, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 407, Training loss: 1.379359, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 408, Training loss: 1.397928, Validation loss: 1.3881, lr: 0.0000\n",
      "Epoch: 409, Training loss: 1.371101, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 410, Training loss: 1.372546, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 411, Training loss: 1.403001, Validation loss: 1.3765, lr: 0.0000\n",
      "Epoch: 412, Training loss: 1.365322, Validation loss: 1.3771, lr: 0.0000\n",
      "Epoch: 413, Training loss: 1.388534, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 414, Training loss: 1.381718, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 415, Training loss: 1.371822, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 416, Training loss: 1.428934, Validation loss: 1.3669, lr: 0.0000\n",
      "Epoch: 417, Training loss: 1.383908, Validation loss: 1.4257, lr: 0.0000\n",
      "Epoch: 418, Training loss: 1.373440, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 419, Training loss: 1.398280, Validation loss: 1.3883, lr: 0.0000\n",
      "Epoch: 420, Training loss: 1.412141, Validation loss: 1.3906, lr: 0.0000\n",
      "Epoch: 421, Training loss: 1.371672, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 422, Training loss: 1.380713, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 423, Training loss: 1.370787, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 424, Training loss: 1.362000, Validation loss: 1.3877, lr: 0.0000\n",
      "Epoch: 425, Training loss: 1.388019, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 426, Training loss: 1.388150, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 427, Training loss: 1.373266, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 428, Training loss: 1.358586, Validation loss: 1.3777, lr: 0.0000\n",
      "Epoch: 429, Training loss: 1.383724, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 430, Training loss: 1.382362, Validation loss: 1.3690, lr: 0.0000\n",
      "Epoch: 431, Training loss: 1.410362, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 432, Training loss: 1.401898, Validation loss: 1.3933, lr: 0.0000\n",
      "Epoch: 433, Training loss: 1.367798, Validation loss: 1.3793, lr: 0.0000\n",
      "Epoch: 434, Training loss: 1.373212, Validation loss: 1.3714, lr: 0.0000\n",
      "Epoch: 435, Training loss: 1.367694, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 436, Training loss: 1.369629, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 437, Training loss: 1.400462, Validation loss: 1.3753, lr: 0.0000\n",
      "Epoch: 438, Training loss: 1.405890, Validation loss: 1.3983, lr: 0.0000\n",
      "Epoch: 439, Training loss: 1.358994, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 440, Training loss: 1.392306, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 441, Training loss: 1.388289, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 442, Training loss: 1.379712, Validation loss: 1.3921, lr: 0.0000\n",
      "Epoch: 443, Training loss: 1.381253, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 444, Training loss: 1.399264, Validation loss: 1.3689, lr: 0.0000\n",
      "Epoch: 445, Training loss: 1.378505, Validation loss: 1.3774, lr: 0.0000\n",
      "Epoch: 446, Training loss: 1.369368, Validation loss: 1.3757, lr: 0.0000\n",
      "Epoch: 447, Training loss: 1.371870, Validation loss: 1.3657, lr: 0.0000\n",
      "Epoch: 448, Training loss: 1.386658, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 449, Training loss: 1.373653, Validation loss: 1.4307, lr: 0.0000\n",
      "Epoch: 450, Training loss: 1.355412, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 451, Training loss: 1.374449, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 452, Training loss: 1.368971, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 453, Training loss: 1.381966, Validation loss: 1.3517, lr: 0.0000\n",
      "Epoch: 454, Training loss: 1.372865, Validation loss: 1.3690, lr: 0.0000\n",
      "Epoch: 455, Training loss: 1.379722, Validation loss: 1.3953, lr: 0.0000\n",
      "Epoch: 456, Training loss: 1.383446, Validation loss: 1.3709, lr: 0.0000\n",
      "Epoch: 457, Training loss: 1.412230, Validation loss: 1.3627, lr: 0.0000\n",
      "Epoch: 458, Training loss: 1.391312, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 459, Training loss: 1.369534, Validation loss: 1.3989, lr: 0.0000\n",
      "Epoch: 460, Training loss: 1.376346, Validation loss: 1.3748, lr: 0.0000\n",
      "Epoch: 461, Training loss: 1.424399, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 462, Training loss: 1.377498, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 463, Training loss: 1.369172, Validation loss: 1.3510, lr: 0.0000\n",
      "Epoch: 464, Training loss: 1.373084, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 465, Training loss: 1.374238, Validation loss: 1.3482, lr: 0.0000\n",
      "Epoch: 466, Training loss: 1.393119, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 467, Training loss: 1.372210, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 468, Training loss: 1.401799, Validation loss: 1.3741, lr: 0.0000\n",
      "Epoch: 469, Training loss: 1.441072, Validation loss: 1.4067, lr: 0.0000\n",
      "Epoch: 470, Training loss: 1.378264, Validation loss: 1.3886, lr: 0.0000\n",
      "Epoch: 471, Training loss: 1.388587, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 472, Training loss: 1.376422, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 473, Training loss: 1.364069, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 474, Training loss: 1.365647, Validation loss: 1.4220, lr: 0.0000\n",
      "Epoch: 475, Training loss: 1.373918, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 476, Training loss: 1.385499, Validation loss: 1.3759, lr: 0.0000\n",
      "Epoch: 477, Training loss: 1.368276, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 478, Training loss: 1.366680, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 479, Training loss: 1.370197, Validation loss: 1.3798, lr: 0.0000\n",
      "Epoch: 480, Training loss: 1.376467, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 481, Training loss: 1.396167, Validation loss: 1.3938, lr: 0.0000\n",
      "Epoch: 482, Training loss: 1.375709, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 483, Training loss: 1.381357, Validation loss: 1.3911, lr: 0.0000\n",
      "Epoch: 484, Training loss: 1.406830, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 485, Training loss: 1.357597, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 486, Training loss: 1.384672, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 487, Training loss: 1.381487, Validation loss: 1.3766, lr: 0.0000\n",
      "Epoch: 488, Training loss: 1.373660, Validation loss: 1.3798, lr: 0.0000\n",
      "Epoch: 489, Training loss: 1.388077, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 490, Training loss: 1.376722, Validation loss: 1.3918, lr: 0.0000\n",
      "Epoch: 491, Training loss: 1.391015, Validation loss: 1.3889, lr: 0.0000\n",
      "Epoch: 492, Training loss: 1.385158, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 493, Training loss: 1.372112, Validation loss: 1.3740, lr: 0.0000\n",
      "Epoch: 494, Training loss: 1.367094, Validation loss: 1.3886, lr: 0.0000\n",
      "Epoch: 495, Training loss: 1.386509, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 496, Training loss: 1.384904, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 497, Training loss: 1.372519, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 498, Training loss: 1.384817, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 499, Training loss: 1.388545, Validation loss: 1.3661, lr: 0.0000\n",
      "Epoch: 500, Training loss: 1.427712, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 501, Training loss: 1.415224, Validation loss: 1.3572, lr: 0.0000\n",
      "Epoch: 502, Training loss: 1.364891, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 503, Training loss: 1.358646, Validation loss: 1.3688, lr: 0.0000\n",
      "Epoch: 504, Training loss: 1.389805, Validation loss: 1.3779, lr: 0.0000\n",
      "Epoch: 505, Training loss: 1.391620, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 506, Training loss: 1.404721, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 507, Training loss: 1.418684, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 508, Training loss: 1.411350, Validation loss: 1.3770, lr: 0.0000\n",
      "Epoch: 509, Training loss: 1.400215, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 510, Training loss: 1.380967, Validation loss: 1.3669, lr: 0.0000\n",
      "Epoch: 511, Training loss: 1.383082, Validation loss: 1.3744, lr: 0.0000\n",
      "Epoch: 512, Training loss: 1.375457, Validation loss: 1.3744, lr: 0.0000\n",
      "Epoch: 513, Training loss: 1.387950, Validation loss: 1.3719, lr: 0.0000\n",
      "Epoch: 514, Training loss: 1.386528, Validation loss: 1.3919, lr: 0.0000\n",
      "Epoch: 515, Training loss: 1.378373, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 516, Training loss: 1.379406, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 517, Training loss: 1.370441, Validation loss: 1.3873, lr: 0.0000\n",
      "Epoch: 518, Training loss: 1.387493, Validation loss: 1.3888, lr: 0.0000\n",
      "Epoch: 519, Training loss: 1.411398, Validation loss: 1.3906, lr: 0.0000\n",
      "Epoch: 520, Training loss: 1.439560, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 521, Training loss: 1.380943, Validation loss: 1.3746, lr: 0.0000\n",
      "Epoch: 522, Training loss: 1.396670, Validation loss: 1.3776, lr: 0.0000\n",
      "Epoch: 523, Training loss: 1.368569, Validation loss: 1.3681, lr: 0.0000\n",
      "Epoch: 524, Training loss: 1.378036, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 525, Training loss: 1.393332, Validation loss: 1.3731, lr: 0.0000\n",
      "Epoch: 526, Training loss: 1.378316, Validation loss: 1.3693, lr: 0.0000\n",
      "Epoch: 527, Training loss: 1.380830, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 528, Training loss: 1.375686, Validation loss: 1.3622, lr: 0.0000\n",
      "Epoch: 529, Training loss: 1.396402, Validation loss: 1.3778, lr: 0.0000\n",
      "Epoch: 530, Training loss: 1.371644, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 531, Training loss: 1.376990, Validation loss: 1.3736, lr: 0.0000\n",
      "Epoch: 532, Training loss: 1.390737, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 533, Training loss: 1.389319, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 534, Training loss: 1.371706, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 535, Training loss: 1.381794, Validation loss: 1.3911, lr: 0.0000\n",
      "Epoch: 536, Training loss: 1.395661, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 537, Training loss: 1.366320, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 538, Training loss: 1.385660, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 539, Training loss: 1.524943, Validation loss: 1.3892, lr: 0.0000\n",
      "Epoch: 540, Training loss: 1.394336, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 541, Training loss: 1.381893, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 542, Training loss: 1.418373, Validation loss: 1.3793, lr: 0.0000\n",
      "Epoch: 543, Training loss: 1.392418, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 544, Training loss: 1.370507, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 545, Training loss: 1.389155, Validation loss: 1.3712, lr: 0.0000\n",
      "Epoch: 546, Training loss: 1.381418, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 547, Training loss: 1.470345, Validation loss: 1.3747, lr: 0.0000\n",
      "Epoch: 548, Training loss: 1.391202, Validation loss: 1.3793, lr: 0.0000\n",
      "Epoch: 549, Training loss: 1.379840, Validation loss: 1.3782, lr: 0.0000\n",
      "Epoch: 550, Training loss: 1.389766, Validation loss: 1.3761, lr: 0.0000\n",
      "Epoch: 551, Training loss: 1.377619, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 552, Training loss: 1.393040, Validation loss: 1.3750, lr: 0.0000\n",
      "Epoch: 553, Training loss: 1.364582, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 554, Training loss: 1.374911, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 555, Training loss: 1.369996, Validation loss: 1.3879, lr: 0.0000\n",
      "Epoch: 556, Training loss: 1.387999, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 557, Training loss: 1.375322, Validation loss: 1.3748, lr: 0.0000\n",
      "Epoch: 558, Training loss: 1.422260, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 559, Training loss: 1.376259, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 560, Training loss: 1.367678, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 561, Training loss: 1.360011, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 562, Training loss: 1.380697, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 563, Training loss: 1.382896, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 564, Training loss: 1.373344, Validation loss: 1.3743, lr: 0.0000\n",
      "Epoch: 565, Training loss: 1.380668, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 566, Training loss: 1.372888, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 567, Training loss: 1.387057, Validation loss: 1.3684, lr: 0.0000\n",
      "Epoch: 568, Training loss: 1.380499, Validation loss: 1.3915, lr: 0.0000\n",
      "Epoch: 569, Training loss: 1.382012, Validation loss: 1.3768, lr: 0.0000\n",
      "Epoch: 570, Training loss: 1.367282, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 571, Training loss: 1.420288, Validation loss: 1.3738, lr: 0.0000\n",
      "Epoch: 572, Training loss: 1.371350, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 573, Training loss: 1.388596, Validation loss: 1.3746, lr: 0.0000\n",
      "Epoch: 574, Training loss: 1.385800, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 575, Training loss: 1.378085, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 576, Training loss: 1.396189, Validation loss: 1.3876, lr: 0.0000\n",
      "Epoch: 577, Training loss: 1.400925, Validation loss: 1.3800, lr: 0.0000\n",
      "Epoch: 578, Training loss: 1.383874, Validation loss: 1.3895, lr: 0.0000\n",
      "Epoch: 579, Training loss: 1.436910, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 580, Training loss: 1.373300, Validation loss: 1.3911, lr: 0.0000\n",
      "Epoch: 581, Training loss: 1.389637, Validation loss: 1.3703, lr: 0.0000\n",
      "Epoch: 582, Training loss: 1.378517, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 583, Training loss: 1.376934, Validation loss: 1.3721, lr: 0.0000\n",
      "Epoch: 584, Training loss: 1.385912, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 585, Training loss: 1.382076, Validation loss: 1.3770, lr: 0.0000\n",
      "Epoch: 586, Training loss: 1.364446, Validation loss: 1.3747, lr: 0.0000\n",
      "Epoch: 587, Training loss: 1.456599, Validation loss: 1.3883, lr: 0.0000\n",
      "Epoch: 588, Training loss: 1.372686, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 589, Training loss: 1.393190, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 590, Training loss: 1.365820, Validation loss: 1.3921, lr: 0.0000\n",
      "Epoch: 591, Training loss: 1.366999, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 592, Training loss: 1.386151, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 593, Training loss: 1.372157, Validation loss: 1.3748, lr: 0.0000\n",
      "Epoch: 594, Training loss: 1.363981, Validation loss: 1.6601, lr: 0.0000\n",
      "Epoch: 595, Training loss: 1.379724, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 596, Training loss: 1.360072, Validation loss: 1.3788, lr: 0.0000\n",
      "Epoch: 597, Training loss: 1.379863, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 598, Training loss: 1.377610, Validation loss: 1.3922, lr: 0.0000\n",
      "Epoch: 599, Training loss: 1.370671, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 600, Training loss: 1.373229, Validation loss: 1.3564, lr: 0.0000\n",
      "Epoch: 601, Training loss: 1.366203, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 602, Training loss: 1.398535, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 603, Training loss: 1.372290, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 604, Training loss: 1.373173, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 605, Training loss: 1.410657, Validation loss: 1.3775, lr: 0.0000\n",
      "Epoch: 606, Training loss: 1.375382, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 607, Training loss: 1.374964, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 608, Training loss: 1.384247, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 609, Training loss: 1.369061, Validation loss: 1.3876, lr: 0.0000\n",
      "Epoch: 610, Training loss: 1.375409, Validation loss: 1.3764, lr: 0.0000\n",
      "Epoch: 611, Training loss: 1.408251, Validation loss: 1.3798, lr: 0.0000\n",
      "Epoch: 612, Training loss: 1.362522, Validation loss: 1.3949, lr: 0.0000\n",
      "Epoch: 613, Training loss: 1.380022, Validation loss: 1.3880, lr: 0.0000\n",
      "Epoch: 614, Training loss: 1.399516, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 615, Training loss: 1.390247, Validation loss: 1.3518, lr: 0.0000\n",
      "Epoch: 616, Training loss: 1.387141, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 617, Training loss: 1.385365, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 618, Training loss: 1.382070, Validation loss: 1.3762, lr: 0.0000\n",
      "Epoch: 619, Training loss: 1.380119, Validation loss: 1.3886, lr: 0.0000\n",
      "Epoch: 620, Training loss: 1.380518, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 621, Training loss: 1.358579, Validation loss: 1.3908, lr: 0.0000\n",
      "Epoch: 622, Training loss: 1.383672, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 623, Training loss: 1.485287, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 624, Training loss: 1.376682, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 625, Training loss: 1.365143, Validation loss: 1.3776, lr: 0.0000\n",
      "Epoch: 626, Training loss: 1.376898, Validation loss: 1.3921, lr: 0.0000\n",
      "Epoch: 627, Training loss: 1.382133, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 628, Training loss: 1.361780, Validation loss: 1.3729, lr: 0.0000\n",
      "Epoch: 629, Training loss: 1.374786, Validation loss: 1.3882, lr: 0.0000\n",
      "Epoch: 630, Training loss: 1.438849, Validation loss: 1.4000, lr: 0.0000\n",
      "Epoch: 631, Training loss: 1.360885, Validation loss: 1.3913, lr: 0.0000\n",
      "Epoch: 632, Training loss: 1.399094, Validation loss: 1.3774, lr: 0.0000\n",
      "Epoch: 633, Training loss: 1.393825, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 634, Training loss: 1.381790, Validation loss: 1.3676, lr: 0.0000\n",
      "Epoch: 635, Training loss: 1.387365, Validation loss: 1.3809, lr: 0.0000\n",
      "Epoch: 636, Training loss: 1.362100, Validation loss: 1.3967, lr: 0.0000\n",
      "Epoch: 637, Training loss: 1.475493, Validation loss: 1.3784, lr: 0.0000\n",
      "Epoch: 638, Training loss: 1.370240, Validation loss: 1.3572, lr: 0.0000\n",
      "Epoch: 639, Training loss: 1.393964, Validation loss: 1.3893, lr: 0.0000\n",
      "Epoch: 640, Training loss: 1.379601, Validation loss: 1.3754, lr: 0.0000\n",
      "Epoch: 641, Training loss: 1.361796, Validation loss: 1.3919, lr: 0.0000\n",
      "Epoch: 642, Training loss: 1.388178, Validation loss: 1.3731, lr: 0.0000\n",
      "Epoch: 643, Training loss: 1.376646, Validation loss: 1.3800, lr: 0.0000\n",
      "Epoch: 644, Training loss: 1.422657, Validation loss: 1.3738, lr: 0.0000\n",
      "Epoch: 645, Training loss: 1.363931, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 646, Training loss: 1.367405, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 647, Training loss: 1.397618, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 648, Training loss: 1.391146, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 649, Training loss: 1.373527, Validation loss: 1.3780, lr: 0.0000\n",
      "Epoch: 650, Training loss: 1.365323, Validation loss: 1.3749, lr: 0.0000\n",
      "Epoch: 651, Training loss: 1.368990, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 652, Training loss: 1.386334, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 653, Training loss: 1.390902, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 654, Training loss: 1.419238, Validation loss: 1.3878, lr: 0.0000\n",
      "Epoch: 655, Training loss: 1.427179, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 656, Training loss: 1.434929, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 657, Training loss: 1.368865, Validation loss: 1.3875, lr: 0.0000\n",
      "Epoch: 658, Training loss: 1.360632, Validation loss: 1.3886, lr: 0.0000\n",
      "Epoch: 659, Training loss: 1.372735, Validation loss: 1.3789, lr: 0.0000\n",
      "Epoch: 660, Training loss: 1.402026, Validation loss: 1.3797, lr: 0.0000\n",
      "Epoch: 661, Training loss: 1.387453, Validation loss: 1.4023, lr: 0.0000\n",
      "Epoch: 662, Training loss: 1.432239, Validation loss: 1.3883, lr: 0.0000\n",
      "Epoch: 663, Training loss: 1.392240, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 664, Training loss: 1.390254, Validation loss: 1.3776, lr: 0.0000\n",
      "Epoch: 665, Training loss: 1.392521, Validation loss: 1.3745, lr: 0.0000\n",
      "Epoch: 666, Training loss: 1.432162, Validation loss: 1.3747, lr: 0.0000\n",
      "Epoch: 667, Training loss: 1.371830, Validation loss: 1.3893, lr: 0.0000\n",
      "Epoch: 668, Training loss: 1.386959, Validation loss: 1.3726, lr: 0.0000\n",
      "Epoch: 669, Training loss: 1.384572, Validation loss: 1.3663, lr: 0.0000\n",
      "Epoch: 670, Training loss: 1.382287, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 671, Training loss: 1.391369, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 672, Training loss: 1.375404, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 673, Training loss: 1.375994, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 674, Training loss: 1.369018, Validation loss: 1.3741, lr: 0.0000\n",
      "Epoch: 675, Training loss: 1.370025, Validation loss: 1.3590, lr: 0.0000\n",
      "Epoch: 676, Training loss: 1.372367, Validation loss: 1.3785, lr: 0.0000\n",
      "Epoch: 677, Training loss: 1.372619, Validation loss: 1.3913, lr: 0.0000\n",
      "Epoch: 678, Training loss: 1.381554, Validation loss: 1.4007, lr: 0.0000\n",
      "Epoch: 679, Training loss: 1.422297, Validation loss: 1.3748, lr: 0.0000\n",
      "Epoch: 680, Training loss: 1.393794, Validation loss: 1.3685, lr: 0.0000\n",
      "Epoch: 681, Training loss: 1.370239, Validation loss: 1.3668, lr: 0.0000\n",
      "Epoch: 682, Training loss: 1.378257, Validation loss: 1.3755, lr: 0.0000\n",
      "Epoch: 683, Training loss: 1.407092, Validation loss: 1.3674, lr: 0.0000\n",
      "Epoch: 684, Training loss: 1.378802, Validation loss: 1.3809, lr: 0.0000\n",
      "Epoch: 685, Training loss: 1.363870, Validation loss: 1.3906, lr: 0.0000\n",
      "Epoch: 686, Training loss: 1.408088, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 687, Training loss: 1.396960, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 688, Training loss: 1.379479, Validation loss: 1.3915, lr: 0.0000\n",
      "Epoch: 689, Training loss: 1.408775, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 690, Training loss: 1.383872, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 691, Training loss: 1.415362, Validation loss: 1.3771, lr: 0.0000\n",
      "Epoch: 692, Training loss: 1.357797, Validation loss: 1.3767, lr: 0.0000\n",
      "Epoch: 693, Training loss: 1.373865, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 694, Training loss: 1.364504, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 695, Training loss: 1.384282, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 696, Training loss: 1.397037, Validation loss: 1.3661, lr: 0.0000\n",
      "Epoch: 697, Training loss: 1.370013, Validation loss: 1.3909, lr: 0.0000\n",
      "Epoch: 698, Training loss: 1.371093, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 699, Training loss: 1.388330, Validation loss: 1.3895, lr: 0.0000\n",
      "Epoch: 700, Training loss: 1.366893, Validation loss: 1.3683, lr: 0.0000\n",
      "Epoch: 701, Training loss: 1.383367, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 702, Training loss: 1.376605, Validation loss: 1.3902, lr: 0.0000\n",
      "Epoch: 703, Training loss: 1.380356, Validation loss: 1.3491, lr: 0.0000\n",
      "Epoch: 704, Training loss: 1.404142, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 705, Training loss: 1.374083, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 706, Training loss: 1.385028, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 707, Training loss: 1.391479, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 708, Training loss: 1.374445, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 709, Training loss: 1.375080, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 710, Training loss: 1.366489, Validation loss: 1.3899, lr: 0.0000\n",
      "Epoch: 711, Training loss: 1.377246, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 712, Training loss: 1.387110, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 713, Training loss: 1.371864, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 714, Training loss: 1.378284, Validation loss: 1.3780, lr: 0.0000\n",
      "Epoch: 715, Training loss: 1.371301, Validation loss: 1.3581, lr: 0.0000\n",
      "Epoch: 716, Training loss: 1.372152, Validation loss: 1.3730, lr: 0.0000\n",
      "Epoch: 717, Training loss: 1.404776, Validation loss: 1.3773, lr: 0.0000\n",
      "Epoch: 718, Training loss: 1.386417, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 719, Training loss: 1.388470, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 720, Training loss: 1.383147, Validation loss: 1.3878, lr: 0.0000\n",
      "Epoch: 721, Training loss: 1.374604, Validation loss: 1.3754, lr: 0.0000\n",
      "Epoch: 722, Training loss: 1.374037, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 723, Training loss: 1.409122, Validation loss: 1.3760, lr: 0.0000\n",
      "Epoch: 724, Training loss: 1.380354, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 725, Training loss: 1.377253, Validation loss: 1.3796, lr: 0.0000\n",
      "Epoch: 726, Training loss: 1.392729, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 727, Training loss: 1.371530, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 728, Training loss: 1.385283, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 729, Training loss: 1.384928, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 730, Training loss: 1.417331, Validation loss: 1.3932, lr: 0.0000\n",
      "Epoch: 731, Training loss: 1.383617, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 732, Training loss: 1.382232, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 733, Training loss: 1.384286, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 734, Training loss: 1.380434, Validation loss: 1.3875, lr: 0.0000\n",
      "Epoch: 735, Training loss: 1.373074, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 736, Training loss: 1.380121, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 737, Training loss: 1.386745, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 738, Training loss: 1.392162, Validation loss: 1.5798, lr: 0.0000\n",
      "Epoch: 739, Training loss: 1.412970, Validation loss: 1.3957, lr: 0.0000\n",
      "Epoch: 740, Training loss: 1.379604, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 741, Training loss: 1.372778, Validation loss: 1.3742, lr: 0.0000\n",
      "Epoch: 742, Training loss: 1.387974, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 743, Training loss: 1.376198, Validation loss: 1.3904, lr: 0.0000\n",
      "Epoch: 744, Training loss: 1.392419, Validation loss: 1.3891, lr: 0.0000\n",
      "Epoch: 745, Training loss: 1.378111, Validation loss: 1.3763, lr: 0.0000\n",
      "Epoch: 746, Training loss: 1.397721, Validation loss: 1.4573, lr: 0.0000\n",
      "Epoch: 747, Training loss: 1.376628, Validation loss: 1.3749, lr: 0.0000\n",
      "Epoch: 748, Training loss: 1.377559, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 749, Training loss: 1.398533, Validation loss: 1.3993, lr: 0.0000\n",
      "Epoch: 750, Training loss: 1.373219, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 751, Training loss: 1.371748, Validation loss: 1.3740, lr: 0.0000\n",
      "Epoch: 752, Training loss: 1.366630, Validation loss: 1.3529, lr: 0.0000\n",
      "Epoch: 753, Training loss: 1.367533, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 754, Training loss: 1.369194, Validation loss: 1.3769, lr: 0.0000\n",
      "Epoch: 755, Training loss: 1.385498, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 756, Training loss: 1.365118, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 757, Training loss: 1.448313, Validation loss: 1.3885, lr: 0.0000\n",
      "Epoch: 758, Training loss: 1.366149, Validation loss: 1.3965, lr: 0.0000\n",
      "Epoch: 759, Training loss: 1.409044, Validation loss: 1.3877, lr: 0.0000\n",
      "Epoch: 760, Training loss: 1.382671, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 761, Training loss: 1.383098, Validation loss: 1.3799, lr: 0.0000\n",
      "Epoch: 762, Training loss: 1.381666, Validation loss: 1.3560, lr: 0.0000\n",
      "Epoch: 763, Training loss: 1.421403, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 764, Training loss: 1.383390, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 765, Training loss: 1.389975, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 766, Training loss: 1.360972, Validation loss: 1.3724, lr: 0.0000\n",
      "Epoch: 767, Training loss: 1.415876, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 768, Training loss: 1.362197, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 769, Training loss: 1.386942, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 770, Training loss: 1.392770, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 771, Training loss: 1.364193, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 772, Training loss: 1.361887, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 773, Training loss: 1.370323, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 774, Training loss: 1.369666, Validation loss: 1.3703, lr: 0.0000\n",
      "Epoch: 775, Training loss: 1.376450, Validation loss: 1.3877, lr: 0.0000\n",
      "Epoch: 776, Training loss: 1.388591, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 777, Training loss: 1.377056, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 778, Training loss: 1.393414, Validation loss: 1.8827, lr: 0.0000\n",
      "Epoch: 779, Training loss: 1.375219, Validation loss: 1.3683, lr: 0.0000\n",
      "Epoch: 780, Training loss: 1.376515, Validation loss: 1.3880, lr: 0.0000\n",
      "Epoch: 781, Training loss: 1.379115, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 782, Training loss: 1.379255, Validation loss: 1.3877, lr: 0.0000\n",
      "Epoch: 783, Training loss: 1.377771, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 784, Training loss: 1.361971, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 785, Training loss: 1.401099, Validation loss: 1.3745, lr: 0.0000\n",
      "Epoch: 786, Training loss: 1.400162, Validation loss: 1.3762, lr: 0.0000\n",
      "Epoch: 787, Training loss: 1.392030, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 788, Training loss: 1.375999, Validation loss: 1.3791, lr: 0.0000\n",
      "Epoch: 789, Training loss: 1.361432, Validation loss: 1.3765, lr: 0.0000\n",
      "Epoch: 790, Training loss: 1.391587, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 791, Training loss: 1.405884, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 792, Training loss: 1.404661, Validation loss: 1.3904, lr: 0.0000\n",
      "Epoch: 793, Training loss: 1.426604, Validation loss: 1.4059, lr: 0.0000\n",
      "Epoch: 794, Training loss: 1.367651, Validation loss: 1.3798, lr: 0.0000\n",
      "Epoch: 795, Training loss: 1.395293, Validation loss: 1.3757, lr: 0.0000\n",
      "Epoch: 796, Training loss: 1.423427, Validation loss: 1.3767, lr: 0.0000\n",
      "Epoch: 797, Training loss: 1.398042, Validation loss: 1.3771, lr: 0.0000\n",
      "Epoch: 798, Training loss: 1.409737, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 799, Training loss: 1.368641, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 800, Training loss: 1.369958, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 801, Training loss: 1.386550, Validation loss: 1.3665, lr: 0.0000\n",
      "Epoch: 802, Training loss: 1.400955, Validation loss: 1.3803, lr: 0.0000\n",
      "Epoch: 803, Training loss: 1.393965, Validation loss: 1.4281, lr: 0.0000\n",
      "Epoch: 804, Training loss: 1.367203, Validation loss: 1.3874, lr: 0.0000\n",
      "Epoch: 805, Training loss: 1.381531, Validation loss: 1.3778, lr: 0.0000\n",
      "Epoch: 806, Training loss: 1.389999, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 807, Training loss: 1.419080, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 808, Training loss: 1.373291, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 809, Training loss: 1.372532, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 810, Training loss: 1.369571, Validation loss: 1.3722, lr: 0.0000\n",
      "Epoch: 811, Training loss: 1.462531, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 812, Training loss: 1.365938, Validation loss: 1.3626, lr: 0.0000\n",
      "Epoch: 813, Training loss: 1.365253, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 814, Training loss: 1.388387, Validation loss: 1.3940, lr: 0.0000\n",
      "Epoch: 815, Training loss: 1.425763, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 816, Training loss: 1.388430, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 817, Training loss: 1.395131, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 818, Training loss: 1.375779, Validation loss: 1.3795, lr: 0.0000\n",
      "Epoch: 819, Training loss: 1.372743, Validation loss: 1.3878, lr: 0.0000\n",
      "Epoch: 820, Training loss: 1.383362, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 821, Training loss: 1.380787, Validation loss: 1.4191, lr: 0.0000\n",
      "Epoch: 822, Training loss: 1.384411, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 823, Training loss: 1.362345, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 824, Training loss: 1.377340, Validation loss: 1.3886, lr: 0.0000\n",
      "Epoch: 825, Training loss: 1.374436, Validation loss: 1.3741, lr: 0.0000\n",
      "Epoch: 826, Training loss: 1.369318, Validation loss: 1.3740, lr: 0.0000\n",
      "Epoch: 827, Training loss: 1.377771, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 828, Training loss: 1.395702, Validation loss: 1.3774, lr: 0.0000\n",
      "Epoch: 829, Training loss: 1.377217, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 830, Training loss: 1.392725, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 831, Training loss: 1.381346, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 832, Training loss: 1.403995, Validation loss: 1.3943, lr: 0.0000\n",
      "Epoch: 833, Training loss: 1.363520, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 834, Training loss: 1.387777, Validation loss: 1.3989, lr: 0.0000\n",
      "Epoch: 835, Training loss: 1.387840, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 836, Training loss: 1.387893, Validation loss: 1.3882, lr: 0.0000\n",
      "Epoch: 837, Training loss: 1.387122, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 838, Training loss: 1.370774, Validation loss: 1.3896, lr: 0.0000\n",
      "Epoch: 839, Training loss: 1.385531, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 840, Training loss: 1.377778, Validation loss: 1.3675, lr: 0.0000\n",
      "Epoch: 841, Training loss: 1.386993, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 842, Training loss: 1.386984, Validation loss: 1.4123, lr: 0.0000\n",
      "Epoch: 843, Training loss: 1.367896, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 844, Training loss: 1.393497, Validation loss: 1.3772, lr: 0.0000\n",
      "Epoch: 845, Training loss: 1.370242, Validation loss: 1.3705, lr: 0.0000\n",
      "Epoch: 846, Training loss: 1.374416, Validation loss: 1.3635, lr: 0.0000\n",
      "Epoch: 847, Training loss: 1.401340, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 848, Training loss: 1.369532, Validation loss: 1.3937, lr: 0.0000\n",
      "Epoch: 849, Training loss: 1.394760, Validation loss: 1.3873, lr: 0.0000\n",
      "Epoch: 850, Training loss: 1.412374, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 851, Training loss: 1.366852, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 852, Training loss: 1.387281, Validation loss: 1.3902, lr: 0.0000\n",
      "Epoch: 853, Training loss: 1.395610, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 854, Training loss: 1.372349, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 855, Training loss: 1.386349, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 856, Training loss: 1.382608, Validation loss: 1.3796, lr: 0.0000\n",
      "Epoch: 857, Training loss: 1.384020, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 858, Training loss: 1.373182, Validation loss: 1.3897, lr: 0.0000\n",
      "Epoch: 859, Training loss: 1.376111, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 860, Training loss: 1.373253, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 861, Training loss: 1.378965, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 862, Training loss: 1.375183, Validation loss: 1.4044, lr: 0.0000\n",
      "Epoch: 863, Training loss: 1.368259, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 864, Training loss: 1.372522, Validation loss: 1.4283, lr: 0.0000\n",
      "Epoch: 865, Training loss: 1.381468, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 866, Training loss: 1.364326, Validation loss: 1.3759, lr: 0.0000\n",
      "Epoch: 867, Training loss: 1.387854, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 868, Training loss: 1.376951, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 869, Training loss: 1.377830, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 870, Training loss: 1.379085, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 871, Training loss: 1.382926, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 872, Training loss: 1.389017, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 873, Training loss: 1.403323, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 874, Training loss: 1.376528, Validation loss: 1.3763, lr: 0.0000\n",
      "Epoch: 875, Training loss: 1.386971, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 876, Training loss: 1.409567, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 877, Training loss: 1.384142, Validation loss: 1.3882, lr: 0.0000\n",
      "Epoch: 878, Training loss: 1.394788, Validation loss: 1.3940, lr: 0.0000\n",
      "Epoch: 879, Training loss: 1.394775, Validation loss: 1.3908, lr: 0.0000\n",
      "Epoch: 880, Training loss: 1.369326, Validation loss: 1.4609, lr: 0.0000\n",
      "Epoch: 881, Training loss: 1.388761, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 882, Training loss: 1.380850, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 883, Training loss: 1.406005, Validation loss: 1.3716, lr: 0.0000\n",
      "Epoch: 884, Training loss: 1.380874, Validation loss: 1.3639, lr: 0.0000\n",
      "Epoch: 885, Training loss: 1.365806, Validation loss: 1.3721, lr: 0.0000\n",
      "Epoch: 886, Training loss: 1.377474, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 887, Training loss: 1.381477, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 888, Training loss: 1.386174, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 889, Training loss: 1.376962, Validation loss: 1.3712, lr: 0.0000\n",
      "Epoch: 890, Training loss: 1.371630, Validation loss: 1.3700, lr: 0.0000\n",
      "Epoch: 891, Training loss: 1.386770, Validation loss: 1.3767, lr: 0.0000\n",
      "Epoch: 892, Training loss: 1.362112, Validation loss: 1.3802, lr: 0.0000\n",
      "Epoch: 893, Training loss: 1.426094, Validation loss: 1.3809, lr: 0.0000\n",
      "Epoch: 894, Training loss: 1.389071, Validation loss: 1.3749, lr: 0.0000\n",
      "Epoch: 895, Training loss: 1.361300, Validation loss: 1.3895, lr: 0.0000\n",
      "Epoch: 896, Training loss: 1.366822, Validation loss: 1.3518, lr: 0.0000\n",
      "Epoch: 897, Training loss: 1.391817, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 898, Training loss: 1.379920, Validation loss: 1.3921, lr: 0.0000\n",
      "Epoch: 899, Training loss: 1.392795, Validation loss: 1.3773, lr: 0.0000\n",
      "Epoch: 900, Training loss: 1.397814, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 901, Training loss: 1.420725, Validation loss: 1.3693, lr: 0.0000\n",
      "Epoch: 902, Training loss: 1.384045, Validation loss: 1.3744, lr: 0.0000\n",
      "Epoch: 903, Training loss: 1.430922, Validation loss: 1.3786, lr: 0.0000\n",
      "Epoch: 904, Training loss: 1.372824, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 905, Training loss: 1.396163, Validation loss: 1.3794, lr: 0.0000\n",
      "Epoch: 906, Training loss: 1.383482, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 907, Training loss: 1.373072, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 908, Training loss: 1.385366, Validation loss: 1.3468, lr: 0.0000\n",
      "Epoch: 909, Training loss: 1.424772, Validation loss: 1.4034, lr: 0.0000\n",
      "Epoch: 910, Training loss: 1.380723, Validation loss: 1.3719, lr: 0.0000\n",
      "Epoch: 911, Training loss: 1.366378, Validation loss: 1.3712, lr: 0.0000\n",
      "Epoch: 912, Training loss: 1.409183, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 913, Training loss: 1.363816, Validation loss: 1.3887, lr: 0.0000\n",
      "Epoch: 914, Training loss: 1.366392, Validation loss: 1.3872, lr: 0.0000\n",
      "Epoch: 915, Training loss: 1.366986, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 916, Training loss: 1.436271, Validation loss: 1.3797, lr: 0.0000\n",
      "Epoch: 917, Training loss: 1.365009, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 918, Training loss: 1.398170, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 919, Training loss: 1.385952, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 920, Training loss: 1.365231, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 921, Training loss: 1.376182, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 922, Training loss: 1.390378, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 923, Training loss: 1.369006, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 924, Training loss: 1.381919, Validation loss: 1.3761, lr: 0.0000\n",
      "Epoch: 925, Training loss: 1.384213, Validation loss: 1.3787, lr: 0.0000\n",
      "Epoch: 926, Training loss: 1.393496, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 927, Training loss: 1.383821, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 928, Training loss: 1.370715, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 929, Training loss: 1.384232, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 930, Training loss: 1.368344, Validation loss: 1.4771, lr: 0.0000\n",
      "Epoch: 931, Training loss: 1.370328, Validation loss: 1.3799, lr: 0.0000\n",
      "Epoch: 932, Training loss: 1.378969, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 933, Training loss: 1.392699, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 934, Training loss: 1.366588, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 935, Training loss: 1.381218, Validation loss: 1.3871, lr: 0.0000\n",
      "Epoch: 936, Training loss: 1.390141, Validation loss: 1.3772, lr: 0.0000\n",
      "Epoch: 937, Training loss: 1.376470, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 938, Training loss: 1.349634, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 939, Training loss: 1.377204, Validation loss: 1.3906, lr: 0.0000\n",
      "Epoch: 940, Training loss: 1.394257, Validation loss: 1.3756, lr: 0.0000\n",
      "Epoch: 941, Training loss: 1.376165, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 942, Training loss: 1.400041, Validation loss: 1.3695, lr: 0.0000\n",
      "Epoch: 943, Training loss: 1.382373, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 944, Training loss: 1.399089, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 945, Training loss: 1.376745, Validation loss: 1.5551, lr: 0.0000\n",
      "Epoch: 946, Training loss: 1.388706, Validation loss: 1.3914, lr: 0.0000\n",
      "Epoch: 947, Training loss: 1.365431, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 948, Training loss: 1.368305, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 949, Training loss: 1.384777, Validation loss: 1.3800, lr: 0.0000\n",
      "Epoch: 950, Training loss: 1.385392, Validation loss: 1.3785, lr: 0.0000\n",
      "Epoch: 951, Training loss: 1.393674, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 952, Training loss: 1.379070, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 953, Training loss: 1.386630, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 954, Training loss: 1.367163, Validation loss: 1.3796, lr: 0.0000\n",
      "Epoch: 955, Training loss: 1.369447, Validation loss: 1.3882, lr: 0.0000\n",
      "Epoch: 956, Training loss: 1.370166, Validation loss: 1.4083, lr: 0.0000\n",
      "Epoch: 957, Training loss: 1.413695, Validation loss: 1.4377, lr: 0.0000\n",
      "Epoch: 958, Training loss: 1.398609, Validation loss: 1.3652, lr: 0.0000\n",
      "Epoch: 959, Training loss: 1.371664, Validation loss: 1.3783, lr: 0.0000\n",
      "Epoch: 960, Training loss: 1.381841, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 961, Training loss: 1.394338, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 962, Training loss: 1.413466, Validation loss: 1.3762, lr: 0.0000\n",
      "Epoch: 963, Training loss: 1.378294, Validation loss: 1.3647, lr: 0.0000\n",
      "Epoch: 964, Training loss: 1.381395, Validation loss: 1.3915, lr: 0.0000\n",
      "Epoch: 965, Training loss: 1.411305, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 966, Training loss: 1.365258, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 967, Training loss: 1.371742, Validation loss: 1.3884, lr: 0.0000\n",
      "Epoch: 968, Training loss: 1.398026, Validation loss: 1.3693, lr: 0.0000\n",
      "Epoch: 969, Training loss: 1.395420, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 970, Training loss: 1.372918, Validation loss: 1.3739, lr: 0.0000\n",
      "Epoch: 971, Training loss: 1.383464, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 972, Training loss: 1.375127, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 973, Training loss: 1.403366, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 974, Training loss: 1.371486, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 975, Training loss: 1.363961, Validation loss: 1.3770, lr: 0.0000\n",
      "Epoch: 976, Training loss: 1.382663, Validation loss: 1.3708, lr: 0.0000\n",
      "Epoch: 977, Training loss: 1.390517, Validation loss: 1.3871, lr: 0.0000\n",
      "Epoch: 978, Training loss: 1.360570, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 979, Training loss: 1.390865, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 980, Training loss: 1.382899, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 981, Training loss: 1.400180, Validation loss: 1.3769, lr: 0.0000\n",
      "Epoch: 982, Training loss: 1.383599, Validation loss: 1.3917, lr: 0.0000\n",
      "Epoch: 983, Training loss: 1.386067, Validation loss: 1.3887, lr: 0.0000\n",
      "Epoch: 984, Training loss: 1.398593, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 985, Training loss: 1.374886, Validation loss: 1.3882, lr: 0.0000\n",
      "Epoch: 986, Training loss: 1.384230, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 987, Training loss: 1.364974, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 988, Training loss: 1.353789, Validation loss: 1.3683, lr: 0.0000\n",
      "Epoch: 989, Training loss: 1.426993, Validation loss: 1.3534, lr: 0.0000\n",
      "Epoch: 990, Training loss: 1.378007, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 991, Training loss: 1.416613, Validation loss: 1.3790, lr: 0.0000\n",
      "Epoch: 992, Training loss: 1.379955, Validation loss: 1.3748, lr: 0.0000\n",
      "Epoch: 993, Training loss: 1.375445, Validation loss: 1.3664, lr: 0.0000\n",
      "Epoch: 994, Training loss: 1.401723, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 995, Training loss: 1.398774, Validation loss: 1.3647, lr: 0.0000\n",
      "Epoch: 996, Training loss: 1.377539, Validation loss: 1.3721, lr: 0.0000\n",
      "Epoch: 997, Training loss: 1.389781, Validation loss: 1.3881, lr: 0.0000\n",
      "Epoch: 998, Training loss: 1.386910, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 999, Training loss: 1.497728, Validation loss: 1.3765, lr: 0.0000\n",
      "Final test loss: 1.3523\n",
      "=== Run 06/10 ===\n",
      "\n",
      "---- Settings: \n",
      "\n",
      "epochs : 1000\n",
      "hidden_channels : [32]\n",
      "out_channels : 10\n",
      "inner_product_features : False\n",
      "batch_size : 64\n",
      "lr : 0.01\n",
      "momentum : 0.9\n",
      "dropout : 0.0\n",
      "batch_norm : batch_norm\n",
      "bias : True\n",
      "order : 2\n",
      "diffusion : True\n",
      "frac_sampled_nb : -1\n",
      "include_positions : False\n",
      "include_self : True\n",
      "vec_norm : False\n",
      "emb_norm : False\n",
      "seed : 0\n",
      "dim_signal : 100\n",
      "dim_emb : 100\n",
      "n_sampled_nb : -1\n",
      "\n",
      "---- Number of features to pass to the MLP:  1010100\n",
      "---- Total number of parameters:  32323627\n",
      "\n",
      "Using device cuda:0\n",
      "\n",
      "---- Training network ...\n",
      "\n",
      "---- Timestamp: 20250615-013542\n",
      "\n",
      " *och: 0, Training loss: 1.540518, Validation loss: 2.7313, lr: 0.0100\n",
      " *och: 1, Training loss: 1.372285, Validation loss: 1.4032, lr: 0.0100\n",
      "Epoch: 2, Training loss: 1.465697, Validation loss: 1.4355, lr: 0.0100\n",
      " *och: 3, Training loss: 1.395370, Validation loss: 1.3877, lr: 0.0100\n",
      "Epoch: 4, Training loss: 1.423526, Validation loss: 1.3905, lr: 0.0100\n",
      " *och: 5, Training loss: 1.398551, Validation loss: 1.3811, lr: 0.0100\n",
      "Epoch: 6, Training loss: 1.359159, Validation loss: 1.3865, lr: 0.0100\n",
      " *och: 7, Training loss: 1.366218, Validation loss: 1.3764, lr: 0.0100\n",
      "Epoch: 8, Training loss: 1.403246, Validation loss: 1.3844, lr: 0.0100\n",
      " *och: 9, Training loss: 1.369024, Validation loss: 1.3703, lr: 0.0100\n",
      "Epoch: 10, Training loss: 1.457560, Validation loss: 1.3805, lr: 0.0100\n",
      "Epoch: 11, Training loss: 1.376385, Validation loss: 1.3883, lr: 0.0100\n",
      "Epoch: 12, Training loss: 1.356067, Validation loss: 1.3869, lr: 0.0100\n",
      "Epoch: 13, Training loss: 1.421708, Validation loss: 1.3767, lr: 0.0100\n",
      "Epoch: 14, Training loss: 1.414719, Validation loss: 1.3946, lr: 0.0100\n",
      " *och: 15, Training loss: 1.379673, Validation loss: 1.3657, lr: 0.0100\n",
      "Epoch: 16, Training loss: 1.367655, Validation loss: 1.3854, lr: 0.0100\n",
      "Epoch: 17, Training loss: 1.371252, Validation loss: 1.3811, lr: 0.0100\n",
      "Epoch: 18, Training loss: 1.378990, Validation loss: 1.3843, lr: 0.0100\n",
      "Epoch: 19, Training loss: 1.371670, Validation loss: 1.3859, lr: 0.0100\n",
      "Epoch: 20, Training loss: 1.388042, Validation loss: 1.3870, lr: 0.0100\n",
      "Epoch: 21, Training loss: 1.392686, Validation loss: 1.3753, lr: 0.0100\n",
      "Epoch: 22, Training loss: 1.383141, Validation loss: 1.3766, lr: 0.0100\n",
      "Epoch: 23, Training loss: 1.374344, Validation loss: 1.3957, lr: 0.0010\n",
      "Epoch: 24, Training loss: 1.381796, Validation loss: 1.4480, lr: 0.0010\n",
      "Epoch: 25, Training loss: 1.390305, Validation loss: 1.3875, lr: 0.0010\n",
      "Epoch: 26, Training loss: 1.385042, Validation loss: 1.4122, lr: 0.0010\n",
      "Epoch: 27, Training loss: 1.386600, Validation loss: 1.3912, lr: 0.0010\n",
      "Epoch: 28, Training loss: 1.390067, Validation loss: 1.3883, lr: 0.0010\n",
      "Epoch: 29, Training loss: 1.366534, Validation loss: 1.3760, lr: 0.0010\n",
      "Epoch: 30, Training loss: 1.371247, Validation loss: 1.3854, lr: 0.0010\n",
      "Epoch: 31, Training loss: 1.371830, Validation loss: 1.3835, lr: 0.0010\n",
      "Epoch: 32, Training loss: 1.389085, Validation loss: 1.3848, lr: 0.0010\n",
      "Epoch: 33, Training loss: 1.382948, Validation loss: 1.3857, lr: 0.0010\n",
      "Epoch: 34, Training loss: 1.375991, Validation loss: 1.3854, lr: 0.0001\n",
      "Epoch: 35, Training loss: 1.371876, Validation loss: 1.3814, lr: 0.0001\n",
      "Epoch: 36, Training loss: 1.372063, Validation loss: 1.3794, lr: 0.0001\n",
      "Epoch: 37, Training loss: 1.368386, Validation loss: 1.3881, lr: 0.0001\n",
      "Epoch: 38, Training loss: 1.383530, Validation loss: 1.3830, lr: 0.0001\n",
      "Epoch: 39, Training loss: 1.374903, Validation loss: 1.3826, lr: 0.0001\n",
      " *och: 40, Training loss: 1.386750, Validation loss: 1.3542, lr: 0.0001\n",
      "Epoch: 41, Training loss: 1.376511, Validation loss: 1.3813, lr: 0.0001\n",
      "Epoch: 42, Training loss: 1.406558, Validation loss: 1.3859, lr: 0.0001\n",
      "Epoch: 43, Training loss: 1.372890, Validation loss: 1.3776, lr: 0.0001\n",
      "Epoch: 44, Training loss: 1.380145, Validation loss: 1.3693, lr: 0.0001\n",
      "Epoch: 45, Training loss: 1.397206, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 46, Training loss: 1.397328, Validation loss: 1.3786, lr: 0.0000\n",
      "Epoch: 47, Training loss: 1.400040, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 48, Training loss: 1.383135, Validation loss: 1.3678, lr: 0.0000\n",
      "Epoch: 49, Training loss: 1.375880, Validation loss: 1.5327, lr: 0.0000\n",
      "Epoch: 50, Training loss: 1.385123, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 51, Training loss: 1.386530, Validation loss: 1.3644, lr: 0.0000\n",
      "Epoch: 52, Training loss: 1.385339, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 53, Training loss: 1.381785, Validation loss: 1.3771, lr: 0.0000\n",
      "Epoch: 54, Training loss: 1.391997, Validation loss: 1.3776, lr: 0.0000\n",
      "Epoch: 55, Training loss: 1.371379, Validation loss: 1.3752, lr: 0.0000\n",
      "Epoch: 56, Training loss: 1.364846, Validation loss: 1.3957, lr: 0.0000\n",
      "Epoch: 57, Training loss: 1.392430, Validation loss: 1.3706, lr: 0.0000\n",
      "Epoch: 58, Training loss: 1.382181, Validation loss: 1.3894, lr: 0.0000\n",
      "Epoch: 59, Training loss: 1.383093, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 60, Training loss: 1.404038, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 61, Training loss: 1.373049, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 62, Training loss: 1.401322, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 63, Training loss: 1.386282, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 64, Training loss: 1.373207, Validation loss: 1.3809, lr: 0.0000\n",
      "Epoch: 65, Training loss: 1.392687, Validation loss: 1.3737, lr: 0.0000\n",
      "Epoch: 66, Training loss: 1.365532, Validation loss: 1.3756, lr: 0.0000\n",
      "Epoch: 67, Training loss: 1.381009, Validation loss: 1.3777, lr: 0.0000\n",
      "Epoch: 68, Training loss: 1.374758, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 69, Training loss: 1.366662, Validation loss: 1.3865, lr: 0.0000\n",
      " *och: 70, Training loss: 1.357629, Validation loss: 1.3391, lr: 0.0000\n",
      "Epoch: 71, Training loss: 1.386076, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 72, Training loss: 1.370269, Validation loss: 1.3785, lr: 0.0000\n",
      "Epoch: 73, Training loss: 1.390129, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 74, Training loss: 1.373760, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 75, Training loss: 1.366412, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 76, Training loss: 1.429458, Validation loss: 1.3873, lr: 0.0000\n",
      "Epoch: 77, Training loss: 1.371728, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 78, Training loss: 1.462374, Validation loss: 1.3890, lr: 0.0000\n",
      "Epoch: 79, Training loss: 1.378317, Validation loss: 1.3879, lr: 0.0000\n",
      "Epoch: 80, Training loss: 1.377425, Validation loss: 1.3605, lr: 0.0000\n",
      "Epoch: 81, Training loss: 1.368299, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 82, Training loss: 1.422025, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 83, Training loss: 1.380048, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 84, Training loss: 1.385397, Validation loss: 1.3424, lr: 0.0000\n",
      "Epoch: 85, Training loss: 1.358206, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 86, Training loss: 1.390438, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 87, Training loss: 1.379797, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 88, Training loss: 1.373875, Validation loss: 1.3783, lr: 0.0000\n",
      "Epoch: 89, Training loss: 1.371000, Validation loss: 1.4075, lr: 0.0000\n",
      "Epoch: 90, Training loss: 1.379353, Validation loss: 1.3911, lr: 0.0000\n",
      "Epoch: 91, Training loss: 1.386314, Validation loss: 1.3770, lr: 0.0000\n",
      "Epoch: 92, Training loss: 1.370894, Validation loss: 2.0855, lr: 0.0000\n",
      "Epoch: 93, Training loss: 1.389288, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 94, Training loss: 1.377890, Validation loss: 1.3665, lr: 0.0000\n",
      "Epoch: 95, Training loss: 1.497725, Validation loss: 1.3752, lr: 0.0000\n",
      "Epoch: 96, Training loss: 1.388348, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 97, Training loss: 1.353328, Validation loss: 1.3782, lr: 0.0000\n",
      "Epoch: 98, Training loss: 1.376991, Validation loss: 1.3708, lr: 0.0000\n",
      "Epoch: 99, Training loss: 1.370570, Validation loss: 1.3904, lr: 0.0000\n",
      "Epoch: 100, Training loss: 1.378403, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 101, Training loss: 1.386496, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 102, Training loss: 1.376094, Validation loss: 1.3730, lr: 0.0000\n",
      "Epoch: 103, Training loss: 1.364813, Validation loss: 1.3774, lr: 0.0000\n",
      "Epoch: 104, Training loss: 1.395291, Validation loss: 1.3788, lr: 0.0000\n",
      "Epoch: 105, Training loss: 1.412617, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 106, Training loss: 1.365232, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 107, Training loss: 1.380443, Validation loss: 1.3762, lr: 0.0000\n",
      "Epoch: 108, Training loss: 1.377053, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 109, Training loss: 1.376711, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 110, Training loss: 1.372375, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 111, Training loss: 1.374966, Validation loss: 1.3744, lr: 0.0000\n",
      "Epoch: 112, Training loss: 1.391725, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 113, Training loss: 1.407405, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 114, Training loss: 1.375404, Validation loss: 1.3884, lr: 0.0000\n",
      "Epoch: 115, Training loss: 1.375039, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 116, Training loss: 1.392543, Validation loss: 1.3876, lr: 0.0000\n",
      "Epoch: 117, Training loss: 1.391721, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 118, Training loss: 1.381588, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 119, Training loss: 1.366723, Validation loss: 1.3809, lr: 0.0000\n",
      "Epoch: 120, Training loss: 1.383856, Validation loss: 1.3871, lr: 0.0000\n",
      "Epoch: 121, Training loss: 1.389531, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 122, Training loss: 1.377962, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 123, Training loss: 1.411203, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 124, Training loss: 1.364529, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 125, Training loss: 1.363696, Validation loss: 1.3655, lr: 0.0000\n",
      "Epoch: 126, Training loss: 1.367634, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 127, Training loss: 1.366209, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 128, Training loss: 1.372304, Validation loss: 1.3685, lr: 0.0000\n",
      "Epoch: 129, Training loss: 1.380371, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 130, Training loss: 1.391182, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 131, Training loss: 1.399758, Validation loss: 1.3900, lr: 0.0000\n",
      "Epoch: 132, Training loss: 1.383699, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 133, Training loss: 1.373618, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 134, Training loss: 1.390079, Validation loss: 1.3575, lr: 0.0000\n",
      "Epoch: 135, Training loss: 1.376868, Validation loss: 1.3707, lr: 0.0000\n",
      "Epoch: 136, Training loss: 1.372402, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 137, Training loss: 1.377461, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 138, Training loss: 1.398384, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 139, Training loss: 1.368076, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 140, Training loss: 1.385045, Validation loss: 1.3914, lr: 0.0000\n",
      "Epoch: 141, Training loss: 1.375847, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 142, Training loss: 1.383980, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 143, Training loss: 1.374870, Validation loss: 1.3974, lr: 0.0000\n",
      "Epoch: 144, Training loss: 1.388789, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 145, Training loss: 1.391552, Validation loss: 1.3791, lr: 0.0000\n",
      "Epoch: 146, Training loss: 1.449214, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 147, Training loss: 1.359576, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 148, Training loss: 1.380215, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 149, Training loss: 1.401391, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 150, Training loss: 1.373038, Validation loss: 1.3809, lr: 0.0000\n",
      "Epoch: 151, Training loss: 1.390668, Validation loss: 1.3760, lr: 0.0000\n",
      "Epoch: 152, Training loss: 1.386294, Validation loss: 1.3873, lr: 0.0000\n",
      "Epoch: 153, Training loss: 1.400015, Validation loss: 1.3782, lr: 0.0000\n",
      "Epoch: 154, Training loss: 1.371972, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 155, Training loss: 1.370954, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 156, Training loss: 1.358768, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 157, Training loss: 1.378477, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 158, Training loss: 1.392705, Validation loss: 1.3873, lr: 0.0000\n",
      "Epoch: 159, Training loss: 1.392033, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 160, Training loss: 1.375323, Validation loss: 1.3776, lr: 0.0000\n",
      "Epoch: 161, Training loss: 1.378213, Validation loss: 1.3708, lr: 0.0000\n",
      "Epoch: 162, Training loss: 1.375351, Validation loss: 1.4499, lr: 0.0000\n",
      "Epoch: 163, Training loss: 1.382579, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 164, Training loss: 1.393638, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 165, Training loss: 1.379624, Validation loss: 1.3781, lr: 0.0000\n",
      "Epoch: 166, Training loss: 1.397882, Validation loss: 1.3800, lr: 0.0000\n",
      "Epoch: 167, Training loss: 1.400077, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 168, Training loss: 1.448506, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 169, Training loss: 1.370899, Validation loss: 1.3698, lr: 0.0000\n",
      "Epoch: 170, Training loss: 1.372897, Validation loss: 1.3873, lr: 0.0000\n",
      "Epoch: 171, Training loss: 1.372573, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 172, Training loss: 1.355410, Validation loss: 1.3796, lr: 0.0000\n",
      "Epoch: 173, Training loss: 1.391284, Validation loss: 1.3794, lr: 0.0000\n",
      "Epoch: 174, Training loss: 1.367152, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 175, Training loss: 1.382367, Validation loss: 1.3734, lr: 0.0000\n",
      "Epoch: 176, Training loss: 1.368036, Validation loss: 1.3789, lr: 0.0000\n",
      "Epoch: 177, Training loss: 1.353204, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 178, Training loss: 1.374894, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 179, Training loss: 1.381611, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 180, Training loss: 1.386293, Validation loss: 1.3649, lr: 0.0000\n",
      "Epoch: 181, Training loss: 1.377276, Validation loss: 1.3687, lr: 0.0000\n",
      "Epoch: 182, Training loss: 1.401022, Validation loss: 1.3809, lr: 0.0000\n",
      "Epoch: 183, Training loss: 1.389095, Validation loss: 1.3790, lr: 0.0000\n",
      "Epoch: 184, Training loss: 1.392327, Validation loss: 1.3687, lr: 0.0000\n",
      "Epoch: 185, Training loss: 1.386730, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 186, Training loss: 1.374693, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 187, Training loss: 1.381284, Validation loss: 1.3702, lr: 0.0000\n",
      "Epoch: 188, Training loss: 1.365751, Validation loss: 1.3984, lr: 0.0000\n",
      "Epoch: 189, Training loss: 1.371315, Validation loss: 1.3645, lr: 0.0000\n",
      "Epoch: 190, Training loss: 1.367289, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 191, Training loss: 1.369053, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 192, Training loss: 1.369879, Validation loss: 1.3537, lr: 0.0000\n",
      "Epoch: 193, Training loss: 1.385504, Validation loss: 1.3882, lr: 0.0000\n",
      "Epoch: 194, Training loss: 1.374693, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 195, Training loss: 1.379325, Validation loss: 1.7545, lr: 0.0000\n",
      "Epoch: 196, Training loss: 1.385030, Validation loss: 1.3803, lr: 0.0000\n",
      "Epoch: 197, Training loss: 1.370610, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 198, Training loss: 1.371806, Validation loss: 1.3809, lr: 0.0000\n",
      "Epoch: 199, Training loss: 1.380197, Validation loss: 1.3777, lr: 0.0000\n",
      "Epoch: 200, Training loss: 1.380201, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 201, Training loss: 1.362302, Validation loss: 1.3787, lr: 0.0000\n",
      "Epoch: 202, Training loss: 1.369662, Validation loss: 1.3883, lr: 0.0000\n",
      "Epoch: 203, Training loss: 1.383457, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 204, Training loss: 1.378449, Validation loss: 1.3437, lr: 0.0000\n",
      "Epoch: 205, Training loss: 1.387458, Validation loss: 1.3799, lr: 0.0000\n",
      "Epoch: 206, Training loss: 1.428139, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 207, Training loss: 1.376746, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 208, Training loss: 1.429119, Validation loss: 1.3966, lr: 0.0000\n",
      "Epoch: 209, Training loss: 1.361406, Validation loss: 1.3655, lr: 0.0000\n",
      "Epoch: 210, Training loss: 1.397620, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 211, Training loss: 1.376069, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 212, Training loss: 1.399242, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 213, Training loss: 1.375309, Validation loss: 1.3553, lr: 0.0000\n",
      "Epoch: 214, Training loss: 1.386229, Validation loss: 1.3594, lr: 0.0000\n",
      "Epoch: 215, Training loss: 1.389726, Validation loss: 1.3733, lr: 0.0000\n",
      "Epoch: 216, Training loss: 1.366101, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 217, Training loss: 1.385208, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 218, Training loss: 1.374007, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 219, Training loss: 1.375350, Validation loss: 1.3640, lr: 0.0000\n",
      "Epoch: 220, Training loss: 1.380043, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 221, Training loss: 1.379675, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 222, Training loss: 1.404509, Validation loss: 1.3701, lr: 0.0000\n",
      "Epoch: 223, Training loss: 1.369869, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 224, Training loss: 1.362845, Validation loss: 1.3884, lr: 0.0000\n",
      "Epoch: 225, Training loss: 1.374260, Validation loss: 1.3809, lr: 0.0000\n",
      "Epoch: 226, Training loss: 1.365371, Validation loss: 1.3665, lr: 0.0000\n",
      "Epoch: 227, Training loss: 1.384726, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 228, Training loss: 1.368059, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 229, Training loss: 1.371072, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 230, Training loss: 1.365279, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 231, Training loss: 1.380916, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 232, Training loss: 1.407411, Validation loss: 1.3809, lr: 0.0000\n",
      "Epoch: 233, Training loss: 1.374248, Validation loss: 1.3695, lr: 0.0000\n",
      "Epoch: 234, Training loss: 1.398660, Validation loss: 1.3908, lr: 0.0000\n",
      "Epoch: 235, Training loss: 1.360449, Validation loss: 1.3699, lr: 0.0000\n",
      "Epoch: 236, Training loss: 1.384969, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 237, Training loss: 1.378076, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 238, Training loss: 1.365881, Validation loss: 1.3765, lr: 0.0000\n",
      "Epoch: 239, Training loss: 1.379670, Validation loss: 1.3725, lr: 0.0000\n",
      "Epoch: 240, Training loss: 1.378310, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 241, Training loss: 1.389278, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 242, Training loss: 1.378649, Validation loss: 1.3740, lr: 0.0000\n",
      "Epoch: 243, Training loss: 1.378368, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 244, Training loss: 1.368284, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 245, Training loss: 1.378319, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 246, Training loss: 1.387215, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 247, Training loss: 1.381711, Validation loss: 1.3946, lr: 0.0000\n",
      "Epoch: 248, Training loss: 1.376750, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 249, Training loss: 1.367544, Validation loss: 1.3875, lr: 0.0000\n",
      "Epoch: 250, Training loss: 1.374425, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 251, Training loss: 1.383323, Validation loss: 1.3750, lr: 0.0000\n",
      "Epoch: 252, Training loss: 1.367647, Validation loss: 1.3729, lr: 0.0000\n",
      "Epoch: 253, Training loss: 1.400353, Validation loss: 1.3755, lr: 0.0000\n",
      "Epoch: 254, Training loss: 1.411008, Validation loss: 1.3893, lr: 0.0000\n",
      "Epoch: 255, Training loss: 1.371814, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 256, Training loss: 1.365076, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 257, Training loss: 1.377507, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 258, Training loss: 1.404203, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 259, Training loss: 1.378367, Validation loss: 1.3876, lr: 0.0000\n",
      "Epoch: 260, Training loss: 1.378796, Validation loss: 1.3723, lr: 0.0000\n",
      "Epoch: 261, Training loss: 1.373187, Validation loss: 1.3763, lr: 0.0000\n",
      "Epoch: 262, Training loss: 1.406366, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 263, Training loss: 1.370291, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 264, Training loss: 1.378077, Validation loss: 1.3774, lr: 0.0000\n",
      "Epoch: 265, Training loss: 1.385779, Validation loss: 1.3881, lr: 0.0000\n",
      "Epoch: 266, Training loss: 1.372842, Validation loss: 1.3755, lr: 0.0000\n",
      "Epoch: 267, Training loss: 1.376919, Validation loss: 1.3739, lr: 0.0000\n",
      "Epoch: 268, Training loss: 1.386046, Validation loss: 1.3795, lr: 0.0000\n",
      "Epoch: 269, Training loss: 1.378403, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 270, Training loss: 1.381893, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 271, Training loss: 1.379444, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 272, Training loss: 1.385880, Validation loss: 1.3620, lr: 0.0000\n",
      "Epoch: 273, Training loss: 1.377349, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 274, Training loss: 1.379670, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 275, Training loss: 1.383161, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 276, Training loss: 1.386962, Validation loss: 1.3733, lr: 0.0000\n",
      "Epoch: 277, Training loss: 1.408693, Validation loss: 1.3986, lr: 0.0000\n",
      "Epoch: 278, Training loss: 1.391868, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 279, Training loss: 1.377018, Validation loss: 1.3794, lr: 0.0000\n",
      "Epoch: 280, Training loss: 1.378824, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 281, Training loss: 1.363960, Validation loss: 1.3742, lr: 0.0000\n",
      "Epoch: 282, Training loss: 1.395002, Validation loss: 1.3799, lr: 0.0000\n",
      "Epoch: 283, Training loss: 1.370786, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 284, Training loss: 1.378402, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 285, Training loss: 1.390983, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 286, Training loss: 1.377514, Validation loss: 1.3763, lr: 0.0000\n",
      "Epoch: 287, Training loss: 1.372975, Validation loss: 1.3796, lr: 0.0000\n",
      "Epoch: 288, Training loss: 1.366847, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 289, Training loss: 1.378974, Validation loss: 1.3603, lr: 0.0000\n",
      "Epoch: 290, Training loss: 1.383205, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 291, Training loss: 1.393595, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 292, Training loss: 1.386849, Validation loss: 1.3767, lr: 0.0000\n",
      "Epoch: 293, Training loss: 1.391157, Validation loss: 1.3884, lr: 0.0000\n",
      "Epoch: 294, Training loss: 1.391787, Validation loss: 1.3907, lr: 0.0000\n",
      "Epoch: 295, Training loss: 1.546371, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 296, Training loss: 1.377567, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 297, Training loss: 1.365038, Validation loss: 1.3755, lr: 0.0000\n",
      "Epoch: 298, Training loss: 1.395011, Validation loss: 1.3883, lr: 0.0000\n",
      "Epoch: 299, Training loss: 1.381981, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 300, Training loss: 1.369367, Validation loss: 1.3670, lr: 0.0000\n",
      "Epoch: 301, Training loss: 1.399949, Validation loss: 1.3896, lr: 0.0000\n",
      "Epoch: 302, Training loss: 1.372437, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 303, Training loss: 1.393055, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 304, Training loss: 1.376747, Validation loss: 1.3631, lr: 0.0000\n",
      "Epoch: 305, Training loss: 1.392015, Validation loss: 1.3962, lr: 0.0000\n",
      "Epoch: 306, Training loss: 1.371587, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 307, Training loss: 1.392590, Validation loss: 1.3770, lr: 0.0000\n",
      "Epoch: 308, Training loss: 1.364842, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 309, Training loss: 1.378399, Validation loss: 1.3871, lr: 0.0000\n",
      "Epoch: 310, Training loss: 1.395478, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 311, Training loss: 1.378854, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 312, Training loss: 1.381441, Validation loss: 1.3876, lr: 0.0000\n",
      "Epoch: 313, Training loss: 1.383107, Validation loss: 1.3764, lr: 0.0000\n",
      "Epoch: 314, Training loss: 1.407393, Validation loss: 1.3881, lr: 0.0000\n",
      "Epoch: 315, Training loss: 1.408515, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 316, Training loss: 1.383596, Validation loss: 1.3802, lr: 0.0000\n",
      "Epoch: 317, Training loss: 1.369579, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 318, Training loss: 1.386622, Validation loss: 1.3794, lr: 0.0000\n",
      "Epoch: 319, Training loss: 1.386889, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 320, Training loss: 1.357728, Validation loss: 1.3704, lr: 0.0000\n",
      "Epoch: 321, Training loss: 1.371189, Validation loss: 1.3785, lr: 0.0000\n",
      "Epoch: 322, Training loss: 1.366837, Validation loss: 1.3776, lr: 0.0000\n",
      "Epoch: 323, Training loss: 1.372405, Validation loss: 1.3802, lr: 0.0000\n",
      "Epoch: 324, Training loss: 1.376473, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 325, Training loss: 1.375413, Validation loss: 1.3746, lr: 0.0000\n",
      "Epoch: 326, Training loss: 1.354667, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 327, Training loss: 1.384055, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 328, Training loss: 1.363714, Validation loss: 1.4232, lr: 0.0000\n",
      "Epoch: 329, Training loss: 1.381603, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 330, Training loss: 1.378833, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 331, Training loss: 1.374822, Validation loss: 1.3874, lr: 0.0000\n",
      "Epoch: 332, Training loss: 1.395981, Validation loss: 1.3737, lr: 0.0000\n",
      "Epoch: 333, Training loss: 1.375265, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 334, Training loss: 1.359974, Validation loss: 1.3788, lr: 0.0000\n",
      "Epoch: 335, Training loss: 1.390863, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 336, Training loss: 1.430983, Validation loss: 1.3785, lr: 0.0000\n",
      "Epoch: 337, Training loss: 1.383233, Validation loss: 1.3802, lr: 0.0000\n",
      "Epoch: 338, Training loss: 1.383551, Validation loss: 1.3885, lr: 0.0000\n",
      "Epoch: 339, Training loss: 1.375948, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 340, Training loss: 1.408159, Validation loss: 1.4335, lr: 0.0000\n",
      "Epoch: 341, Training loss: 1.371989, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 342, Training loss: 1.383360, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 343, Training loss: 1.374936, Validation loss: 1.3794, lr: 0.0000\n",
      "Epoch: 344, Training loss: 1.376371, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 345, Training loss: 1.379544, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 346, Training loss: 1.371447, Validation loss: 1.3737, lr: 0.0000\n",
      "Epoch: 347, Training loss: 1.383551, Validation loss: 1.3886, lr: 0.0000\n",
      "Epoch: 348, Training loss: 1.382353, Validation loss: 1.3780, lr: 0.0000\n",
      "Epoch: 349, Training loss: 1.364385, Validation loss: 1.3886, lr: 0.0000\n",
      "Epoch: 350, Training loss: 1.374097, Validation loss: 1.4424, lr: 0.0000\n",
      "Epoch: 351, Training loss: 1.376326, Validation loss: 1.3729, lr: 0.0000\n",
      "Epoch: 352, Training loss: 1.359673, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 353, Training loss: 1.385236, Validation loss: 1.3879, lr: 0.0000\n",
      "Epoch: 354, Training loss: 1.393217, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 355, Training loss: 1.392171, Validation loss: 1.8217, lr: 0.0000\n",
      "Epoch: 356, Training loss: 1.401120, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 357, Training loss: 1.446337, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 358, Training loss: 1.391702, Validation loss: 1.3809, lr: 0.0000\n",
      "Epoch: 359, Training loss: 1.360032, Validation loss: 1.3797, lr: 0.0000\n",
      "Epoch: 360, Training loss: 1.370907, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 361, Training loss: 1.393684, Validation loss: 1.3648, lr: 0.0000\n",
      "Epoch: 362, Training loss: 1.371753, Validation loss: 1.3802, lr: 0.0000\n",
      "Epoch: 363, Training loss: 1.376689, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 364, Training loss: 1.370773, Validation loss: 1.3884, lr: 0.0000\n",
      "Epoch: 365, Training loss: 1.378140, Validation loss: 1.3889, lr: 0.0000\n",
      "Epoch: 366, Training loss: 1.415424, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 367, Training loss: 1.389564, Validation loss: 1.3877, lr: 0.0000\n",
      "Epoch: 368, Training loss: 1.404885, Validation loss: 1.3789, lr: 0.0000\n",
      "Epoch: 369, Training loss: 1.380886, Validation loss: 1.3769, lr: 0.0000\n",
      "Epoch: 370, Training loss: 1.381376, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 371, Training loss: 1.376473, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 372, Training loss: 1.371987, Validation loss: 1.3711, lr: 0.0000\n",
      "Epoch: 373, Training loss: 1.362448, Validation loss: 1.3774, lr: 0.0000\n",
      "Epoch: 374, Training loss: 1.368199, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 375, Training loss: 1.378388, Validation loss: 1.3796, lr: 0.0000\n",
      "Epoch: 376, Training loss: 1.380217, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 377, Training loss: 1.429587, Validation loss: 1.3777, lr: 0.0000\n",
      "Epoch: 378, Training loss: 1.375235, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 379, Training loss: 1.395678, Validation loss: 1.3911, lr: 0.0000\n",
      "Epoch: 380, Training loss: 1.400700, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 381, Training loss: 1.396370, Validation loss: 1.3710, lr: 0.0000\n",
      "Epoch: 382, Training loss: 1.376287, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 383, Training loss: 1.387129, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 384, Training loss: 1.393170, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 385, Training loss: 1.366367, Validation loss: 1.3717, lr: 0.0000\n",
      "Epoch: 386, Training loss: 1.374620, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 387, Training loss: 1.381287, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 388, Training loss: 1.436667, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 389, Training loss: 1.370900, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 390, Training loss: 1.378985, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 391, Training loss: 1.377518, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 392, Training loss: 1.396485, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 393, Training loss: 1.366787, Validation loss: 1.3881, lr: 0.0000\n",
      "Epoch: 394, Training loss: 1.405728, Validation loss: 1.3878, lr: 0.0000\n",
      "Epoch: 395, Training loss: 1.375783, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 396, Training loss: 1.382499, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 397, Training loss: 1.400854, Validation loss: 1.3902, lr: 0.0000\n",
      "Epoch: 398, Training loss: 1.377660, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 399, Training loss: 1.385746, Validation loss: 1.3746, lr: 0.0000\n",
      "Epoch: 400, Training loss: 1.391134, Validation loss: 1.3788, lr: 0.0000\n",
      "Epoch: 401, Training loss: 1.380073, Validation loss: 1.3803, lr: 0.0000\n",
      "Epoch: 402, Training loss: 1.379301, Validation loss: 1.3760, lr: 0.0000\n",
      "Epoch: 403, Training loss: 1.374541, Validation loss: 1.3752, lr: 0.0000\n",
      "Epoch: 404, Training loss: 1.373432, Validation loss: 1.3775, lr: 0.0000\n",
      "Epoch: 405, Training loss: 1.379084, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 406, Training loss: 1.407055, Validation loss: 1.3734, lr: 0.0000\n",
      "Epoch: 407, Training loss: 1.368950, Validation loss: 1.3475, lr: 0.0000\n",
      "Epoch: 408, Training loss: 1.380615, Validation loss: 1.3741, lr: 0.0000\n",
      "Epoch: 409, Training loss: 1.369750, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 410, Training loss: 1.383952, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 411, Training loss: 1.371776, Validation loss: 1.3729, lr: 0.0000\n",
      "Epoch: 412, Training loss: 1.369584, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 413, Training loss: 1.387374, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 414, Training loss: 1.393441, Validation loss: 1.3876, lr: 0.0000\n",
      "Epoch: 415, Training loss: 1.377989, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 416, Training loss: 1.383295, Validation loss: 1.3887, lr: 0.0000\n",
      "Epoch: 417, Training loss: 1.362498, Validation loss: 1.3767, lr: 0.0000\n",
      "Epoch: 418, Training loss: 1.385618, Validation loss: 1.3798, lr: 0.0000\n",
      "Epoch: 419, Training loss: 1.374723, Validation loss: 1.3790, lr: 0.0000\n",
      "Epoch: 420, Training loss: 1.369234, Validation loss: 1.3727, lr: 0.0000\n",
      "Epoch: 421, Training loss: 1.364644, Validation loss: 1.3665, lr: 0.0000\n",
      "Epoch: 422, Training loss: 1.400743, Validation loss: 1.4038, lr: 0.0000\n",
      "Epoch: 423, Training loss: 1.475650, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 424, Training loss: 1.365637, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 425, Training loss: 1.384926, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 426, Training loss: 1.369580, Validation loss: 1.3803, lr: 0.0000\n",
      "Epoch: 427, Training loss: 1.365134, Validation loss: 1.3898, lr: 0.0000\n",
      "Epoch: 428, Training loss: 1.375930, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 429, Training loss: 1.388141, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 430, Training loss: 1.432396, Validation loss: 1.3877, lr: 0.0000\n",
      "Epoch: 431, Training loss: 1.367419, Validation loss: 1.3799, lr: 0.0000\n",
      "Epoch: 432, Training loss: 1.384497, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 433, Training loss: 1.374893, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 434, Training loss: 1.386728, Validation loss: 1.3779, lr: 0.0000\n",
      "Epoch: 435, Training loss: 1.378546, Validation loss: 1.3735, lr: 0.0000\n",
      "Epoch: 436, Training loss: 1.372442, Validation loss: 1.3720, lr: 0.0000\n",
      "Epoch: 437, Training loss: 1.405444, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 438, Training loss: 1.368846, Validation loss: 1.3796, lr: 0.0000\n",
      "Epoch: 439, Training loss: 1.387668, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 440, Training loss: 1.387575, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 441, Training loss: 1.391972, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 442, Training loss: 1.397286, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 443, Training loss: 1.377186, Validation loss: 1.3621, lr: 0.0000\n",
      "Epoch: 444, Training loss: 1.372695, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 445, Training loss: 1.382501, Validation loss: 1.3873, lr: 0.0000\n",
      "Epoch: 446, Training loss: 1.381628, Validation loss: 1.3896, lr: 0.0000\n",
      "Epoch: 447, Training loss: 1.379663, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 448, Training loss: 1.388316, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 449, Training loss: 1.388447, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 450, Training loss: 1.369267, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 451, Training loss: 1.391796, Validation loss: 1.3666, lr: 0.0000\n",
      "Epoch: 452, Training loss: 1.364542, Validation loss: 1.3778, lr: 0.0000\n",
      "Epoch: 453, Training loss: 1.377213, Validation loss: 1.3696, lr: 0.0000\n",
      "Epoch: 454, Training loss: 1.372713, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 455, Training loss: 1.381536, Validation loss: 1.3924, lr: 0.0000\n",
      "Epoch: 456, Training loss: 1.374092, Validation loss: 1.3777, lr: 0.0000\n",
      "Epoch: 457, Training loss: 1.355435, Validation loss: 1.3640, lr: 0.0000\n",
      "Epoch: 458, Training loss: 1.369112, Validation loss: 1.3743, lr: 0.0000\n",
      "Epoch: 459, Training loss: 1.386894, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 460, Training loss: 1.368990, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 461, Training loss: 1.378586, Validation loss: 1.3749, lr: 0.0000\n",
      "Epoch: 462, Training loss: 1.386945, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 463, Training loss: 1.382228, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 464, Training loss: 1.381247, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 465, Training loss: 1.361936, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 466, Training loss: 1.381324, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 467, Training loss: 1.388759, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 468, Training loss: 1.378509, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 469, Training loss: 1.373628, Validation loss: 1.3931, lr: 0.0000\n",
      "Epoch: 470, Training loss: 1.379974, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 471, Training loss: 1.369040, Validation loss: 1.3765, lr: 0.0000\n",
      "Epoch: 472, Training loss: 1.367662, Validation loss: 1.3721, lr: 0.0000\n",
      "Epoch: 473, Training loss: 1.387477, Validation loss: 1.3781, lr: 0.0000\n",
      "Epoch: 474, Training loss: 1.374064, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 475, Training loss: 1.432424, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 476, Training loss: 1.375967, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 477, Training loss: 1.373516, Validation loss: 1.3790, lr: 0.0000\n",
      "Epoch: 478, Training loss: 1.380914, Validation loss: 1.3802, lr: 0.0000\n",
      "Epoch: 479, Training loss: 1.386202, Validation loss: 1.3786, lr: 0.0000\n",
      "Epoch: 480, Training loss: 1.375559, Validation loss: 1.3726, lr: 0.0000\n",
      "Epoch: 481, Training loss: 1.370151, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 482, Training loss: 1.402700, Validation loss: 1.3758, lr: 0.0000\n",
      "Epoch: 483, Training loss: 1.373645, Validation loss: 1.3791, lr: 0.0000\n",
      "Epoch: 484, Training loss: 1.372274, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 485, Training loss: 1.370620, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 486, Training loss: 1.375564, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 487, Training loss: 1.366367, Validation loss: 1.3880, lr: 0.0000\n",
      "Epoch: 488, Training loss: 1.388356, Validation loss: 1.3753, lr: 0.0000\n",
      "Epoch: 489, Training loss: 1.375036, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 490, Training loss: 1.358253, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 491, Training loss: 1.388856, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 492, Training loss: 1.403015, Validation loss: 1.3714, lr: 0.0000\n",
      "Epoch: 493, Training loss: 1.360865, Validation loss: 1.3687, lr: 0.0000\n",
      "Epoch: 494, Training loss: 1.374085, Validation loss: 1.3761, lr: 0.0000\n",
      "Epoch: 495, Training loss: 1.391509, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 496, Training loss: 1.374566, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 497, Training loss: 1.404003, Validation loss: 1.3782, lr: 0.0000\n",
      " *och: 498, Training loss: 1.376947, Validation loss: 1.3330, lr: 0.0000\n",
      "Epoch: 499, Training loss: 1.408916, Validation loss: 1.3614, lr: 0.0000\n",
      "Epoch: 500, Training loss: 1.382735, Validation loss: 1.3791, lr: 0.0000\n",
      "Epoch: 501, Training loss: 1.380184, Validation loss: 1.3609, lr: 0.0000\n",
      "Epoch: 502, Training loss: 1.378911, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 503, Training loss: 1.377208, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 504, Training loss: 1.385942, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 505, Training loss: 1.370665, Validation loss: 1.3878, lr: 0.0000\n",
      "Epoch: 506, Training loss: 1.371121, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 507, Training loss: 1.374456, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 508, Training loss: 1.363947, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 509, Training loss: 1.369490, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 510, Training loss: 1.382722, Validation loss: 1.3748, lr: 0.0000\n",
      "Epoch: 511, Training loss: 1.384204, Validation loss: 1.3672, lr: 0.0000\n",
      "Epoch: 512, Training loss: 1.394534, Validation loss: 1.3792, lr: 0.0000\n",
      "Epoch: 513, Training loss: 1.359848, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 514, Training loss: 1.377149, Validation loss: 1.3796, lr: 0.0000\n",
      "Epoch: 515, Training loss: 1.373671, Validation loss: 1.3769, lr: 0.0000\n",
      "Epoch: 516, Training loss: 1.394490, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 517, Training loss: 1.381321, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 518, Training loss: 1.363837, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 519, Training loss: 1.371904, Validation loss: 1.3924, lr: 0.0000\n",
      "Epoch: 520, Training loss: 1.382189, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 521, Training loss: 1.382548, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 522, Training loss: 1.377804, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 523, Training loss: 1.385676, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 524, Training loss: 1.377958, Validation loss: 1.3756, lr: 0.0000\n",
      "Epoch: 525, Training loss: 1.378738, Validation loss: 1.3783, lr: 0.0000\n",
      "Epoch: 526, Training loss: 1.371828, Validation loss: 1.3752, lr: 0.0000\n",
      "Epoch: 527, Training loss: 1.387091, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 528, Training loss: 1.380498, Validation loss: 1.3739, lr: 0.0000\n",
      "Epoch: 529, Training loss: 1.383185, Validation loss: 1.3349, lr: 0.0000\n",
      "Epoch: 530, Training loss: 1.371007, Validation loss: 1.3776, lr: 0.0000\n",
      "Epoch: 531, Training loss: 1.380015, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 532, Training loss: 1.390105, Validation loss: 1.3778, lr: 0.0000\n",
      "Epoch: 533, Training loss: 1.374990, Validation loss: 1.3711, lr: 0.0000\n",
      "Epoch: 534, Training loss: 1.378894, Validation loss: 1.3631, lr: 0.0000\n",
      "Epoch: 535, Training loss: 1.374745, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 536, Training loss: 1.371928, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 537, Training loss: 1.378658, Validation loss: 1.3784, lr: 0.0000\n",
      "Epoch: 538, Training loss: 1.372234, Validation loss: 1.3679, lr: 0.0000\n",
      "Epoch: 539, Training loss: 1.381367, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 540, Training loss: 1.375924, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 541, Training loss: 1.379793, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 542, Training loss: 1.378227, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 543, Training loss: 1.368824, Validation loss: 1.4128, lr: 0.0000\n",
      "Epoch: 544, Training loss: 1.366676, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 545, Training loss: 1.378657, Validation loss: 1.3969, lr: 0.0000\n",
      "Epoch: 546, Training loss: 1.380140, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 547, Training loss: 1.364741, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 548, Training loss: 1.379442, Validation loss: 1.3875, lr: 0.0000\n",
      "Epoch: 549, Training loss: 1.366868, Validation loss: 1.3746, lr: 0.0000\n",
      "Epoch: 550, Training loss: 1.373852, Validation loss: 1.3887, lr: 0.0000\n",
      "Epoch: 551, Training loss: 1.389510, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 552, Training loss: 1.366711, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 553, Training loss: 1.406554, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 554, Training loss: 1.372837, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 555, Training loss: 1.368938, Validation loss: 1.3800, lr: 0.0000\n",
      "Epoch: 556, Training loss: 1.376192, Validation loss: 1.3656, lr: 0.0000\n",
      "Epoch: 557, Training loss: 1.382072, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 558, Training loss: 1.356330, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 559, Training loss: 1.365311, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 560, Training loss: 1.412254, Validation loss: 1.3770, lr: 0.0000\n",
      "Epoch: 561, Training loss: 1.376888, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 562, Training loss: 1.385043, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 563, Training loss: 1.393375, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 564, Training loss: 1.378983, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 565, Training loss: 1.366676, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 566, Training loss: 1.385271, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 567, Training loss: 1.358322, Validation loss: 1.3782, lr: 0.0000\n",
      "Epoch: 568, Training loss: 1.400419, Validation loss: 1.3715, lr: 0.0000\n",
      "Epoch: 569, Training loss: 1.380177, Validation loss: 1.3744, lr: 0.0000\n",
      "Epoch: 570, Training loss: 1.378492, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 571, Training loss: 1.370447, Validation loss: 1.3758, lr: 0.0000\n",
      "Epoch: 572, Training loss: 1.375811, Validation loss: 1.3749, lr: 0.0000\n",
      "Epoch: 573, Training loss: 1.379581, Validation loss: 1.3773, lr: 0.0000\n",
      "Epoch: 574, Training loss: 1.388747, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 575, Training loss: 1.378622, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 576, Training loss: 1.382446, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 577, Training loss: 1.386573, Validation loss: 1.3688, lr: 0.0000\n",
      "Epoch: 578, Training loss: 1.412245, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 579, Training loss: 1.380305, Validation loss: 1.3934, lr: 0.0000\n",
      "Epoch: 580, Training loss: 1.373055, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 581, Training loss: 1.400763, Validation loss: 1.3744, lr: 0.0000\n",
      "Epoch: 582, Training loss: 1.371726, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 583, Training loss: 1.375630, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 584, Training loss: 1.395056, Validation loss: 1.3903, lr: 0.0000\n",
      "Epoch: 585, Training loss: 1.368201, Validation loss: 1.3708, lr: 0.0000\n",
      "Epoch: 586, Training loss: 1.383349, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 587, Training loss: 1.365098, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 588, Training loss: 1.401715, Validation loss: 1.3782, lr: 0.0000\n",
      "Epoch: 589, Training loss: 1.382179, Validation loss: 1.3916, lr: 0.0000\n",
      "Epoch: 590, Training loss: 1.354908, Validation loss: 1.3871, lr: 0.0000\n",
      "Epoch: 591, Training loss: 1.386157, Validation loss: 1.3715, lr: 0.0000\n",
      "Epoch: 592, Training loss: 1.384834, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 593, Training loss: 1.374154, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 594, Training loss: 1.391272, Validation loss: 1.3899, lr: 0.0000\n",
      "Epoch: 595, Training loss: 1.371575, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 596, Training loss: 1.378831, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 597, Training loss: 1.401386, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 598, Training loss: 1.390590, Validation loss: 1.3750, lr: 0.0000\n",
      "Epoch: 599, Training loss: 1.381308, Validation loss: 1.3781, lr: 0.0000\n",
      "Epoch: 600, Training loss: 1.381038, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 601, Training loss: 1.366024, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 602, Training loss: 1.370533, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 603, Training loss: 1.389493, Validation loss: 1.3803, lr: 0.0000\n",
      "Epoch: 604, Training loss: 1.375330, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 605, Training loss: 1.390690, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 606, Training loss: 1.358918, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 607, Training loss: 1.384708, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 608, Training loss: 1.393686, Validation loss: 1.3502, lr: 0.0000\n",
      "Epoch: 609, Training loss: 1.365436, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 610, Training loss: 1.377115, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 611, Training loss: 1.375841, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 612, Training loss: 1.365837, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 613, Training loss: 1.400297, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 614, Training loss: 1.412701, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 615, Training loss: 1.381130, Validation loss: 1.3902, lr: 0.0000\n",
      "Epoch: 616, Training loss: 1.369715, Validation loss: 1.3871, lr: 0.0000\n",
      "Epoch: 617, Training loss: 1.393399, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 618, Training loss: 1.369679, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 619, Training loss: 1.366863, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 620, Training loss: 1.375835, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 621, Training loss: 1.377559, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 622, Training loss: 1.378119, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 623, Training loss: 1.380864, Validation loss: 1.3678, lr: 0.0000\n",
      "Epoch: 624, Training loss: 1.379849, Validation loss: 1.3733, lr: 0.0000\n",
      "Epoch: 625, Training loss: 1.392728, Validation loss: 1.3785, lr: 0.0000\n",
      "Epoch: 626, Training loss: 1.373427, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 627, Training loss: 1.370321, Validation loss: 1.3652, lr: 0.0000\n",
      "Epoch: 628, Training loss: 1.429202, Validation loss: 1.3786, lr: 0.0000\n",
      "Epoch: 629, Training loss: 1.380377, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 630, Training loss: 1.362781, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 631, Training loss: 1.382397, Validation loss: 1.3910, lr: 0.0000\n",
      "Epoch: 632, Training loss: 1.388870, Validation loss: 1.3353, lr: 0.0000\n",
      "Epoch: 633, Training loss: 1.389799, Validation loss: 1.3774, lr: 0.0000\n",
      "Epoch: 634, Training loss: 1.381120, Validation loss: 1.3689, lr: 0.0000\n",
      "Epoch: 635, Training loss: 1.373858, Validation loss: 1.3687, lr: 0.0000\n",
      "Epoch: 636, Training loss: 1.380378, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 637, Training loss: 1.383297, Validation loss: 1.3798, lr: 0.0000\n",
      "Epoch: 638, Training loss: 1.382333, Validation loss: 1.3671, lr: 0.0000\n",
      "Epoch: 639, Training loss: 1.378599, Validation loss: 1.3793, lr: 0.0000\n",
      "Epoch: 640, Training loss: 1.365595, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 641, Training loss: 1.422292, Validation loss: 1.3687, lr: 0.0000\n",
      "Epoch: 642, Training loss: 1.391060, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 643, Training loss: 1.389927, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 644, Training loss: 1.404511, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 645, Training loss: 1.385667, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 646, Training loss: 1.380690, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 647, Training loss: 1.377780, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 648, Training loss: 1.364136, Validation loss: 1.3543, lr: 0.0000\n",
      "Epoch: 649, Training loss: 1.370131, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 650, Training loss: 1.368862, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 651, Training loss: 1.365194, Validation loss: 1.3900, lr: 0.0000\n",
      "Epoch: 652, Training loss: 1.392341, Validation loss: 1.3795, lr: 0.0000\n",
      "Epoch: 653, Training loss: 1.398516, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 654, Training loss: 1.414816, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 655, Training loss: 1.387710, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 656, Training loss: 1.391493, Validation loss: 1.3735, lr: 0.0000\n",
      "Epoch: 657, Training loss: 1.381843, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 658, Training loss: 1.367106, Validation loss: 1.3761, lr: 0.0000\n",
      "Epoch: 659, Training loss: 1.381198, Validation loss: 1.3771, lr: 0.0000\n",
      "Epoch: 660, Training loss: 1.384078, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 661, Training loss: 1.375567, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 662, Training loss: 1.368730, Validation loss: 1.3873, lr: 0.0000\n",
      "Epoch: 663, Training loss: 1.380866, Validation loss: 1.3750, lr: 0.0000\n",
      "Epoch: 664, Training loss: 1.376431, Validation loss: 1.3715, lr: 0.0000\n",
      "Epoch: 665, Training loss: 1.374445, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 666, Training loss: 1.364948, Validation loss: 1.3888, lr: 0.0000\n",
      "Epoch: 667, Training loss: 1.381228, Validation loss: 1.3741, lr: 0.0000\n",
      "Epoch: 668, Training loss: 1.394515, Validation loss: 1.3551, lr: 0.0000\n",
      "Epoch: 669, Training loss: 1.378652, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 670, Training loss: 1.383784, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 671, Training loss: 1.367952, Validation loss: 1.3599, lr: 0.0000\n",
      "Epoch: 672, Training loss: 1.391962, Validation loss: 1.3734, lr: 0.0000\n",
      "Epoch: 673, Training loss: 1.378127, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 674, Training loss: 1.385251, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 675, Training loss: 1.364113, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 676, Training loss: 1.370852, Validation loss: 1.3890, lr: 0.0000\n",
      "Epoch: 677, Training loss: 1.382725, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 678, Training loss: 1.372056, Validation loss: 1.3874, lr: 0.0000\n",
      "Epoch: 679, Training loss: 1.372310, Validation loss: 1.3707, lr: 0.0000\n",
      "Epoch: 680, Training loss: 1.386400, Validation loss: 1.3791, lr: 0.0000\n",
      "Epoch: 681, Training loss: 1.374646, Validation loss: 1.3915, lr: 0.0000\n",
      "Epoch: 682, Training loss: 1.416196, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 683, Training loss: 1.385237, Validation loss: 1.4754, lr: 0.0000\n",
      "Epoch: 684, Training loss: 1.368099, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 685, Training loss: 1.372676, Validation loss: 1.3772, lr: 0.0000\n",
      "Epoch: 686, Training loss: 1.381815, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 687, Training loss: 1.396762, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 688, Training loss: 1.377721, Validation loss: 1.3982, lr: 0.0000\n",
      "Epoch: 689, Training loss: 1.380559, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 690, Training loss: 1.384640, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 691, Training loss: 1.367798, Validation loss: 1.3761, lr: 0.0000\n",
      "Epoch: 692, Training loss: 1.371252, Validation loss: 1.4002, lr: 0.0000\n",
      "Epoch: 693, Training loss: 1.380703, Validation loss: 1.4311, lr: 0.0000\n",
      "Epoch: 694, Training loss: 1.378839, Validation loss: 1.3982, lr: 0.0000\n",
      "Epoch: 695, Training loss: 1.378125, Validation loss: 1.3720, lr: 0.0000\n",
      "Epoch: 696, Training loss: 1.371160, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 697, Training loss: 1.390784, Validation loss: 1.3670, lr: 0.0000\n",
      "Epoch: 698, Training loss: 1.376290, Validation loss: 1.4432, lr: 0.0000\n",
      "Epoch: 699, Training loss: 1.375433, Validation loss: 1.3794, lr: 0.0000\n",
      "Epoch: 700, Training loss: 1.375081, Validation loss: 1.3723, lr: 0.0000\n",
      "Epoch: 701, Training loss: 1.360575, Validation loss: 1.3721, lr: 0.0000\n",
      "Epoch: 702, Training loss: 1.385220, Validation loss: 1.3741, lr: 0.0000\n",
      "Epoch: 703, Training loss: 1.361674, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 704, Training loss: 1.401246, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 705, Training loss: 1.374034, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 706, Training loss: 1.373659, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 707, Training loss: 1.380484, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 708, Training loss: 1.404102, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 709, Training loss: 1.369912, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 710, Training loss: 1.373806, Validation loss: 1.3762, lr: 0.0000\n",
      "Epoch: 711, Training loss: 1.361586, Validation loss: 1.3651, lr: 0.0000\n",
      "Epoch: 712, Training loss: 1.395746, Validation loss: 1.3900, lr: 0.0000\n",
      "Epoch: 713, Training loss: 1.371495, Validation loss: 1.3889, lr: 0.0000\n",
      "Epoch: 714, Training loss: 1.381100, Validation loss: 1.3748, lr: 0.0000\n",
      "Epoch: 715, Training loss: 1.379150, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 716, Training loss: 1.367046, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 717, Training loss: 1.377101, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 718, Training loss: 1.382339, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 719, Training loss: 1.372260, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 720, Training loss: 1.383993, Validation loss: 1.4433, lr: 0.0000\n",
      "Epoch: 721, Training loss: 1.416355, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 722, Training loss: 1.375845, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 723, Training loss: 1.364416, Validation loss: 1.3798, lr: 0.0000\n",
      "Epoch: 724, Training loss: 1.420556, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 725, Training loss: 1.376565, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 726, Training loss: 1.398048, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 727, Training loss: 1.377881, Validation loss: 1.3754, lr: 0.0000\n",
      "Epoch: 728, Training loss: 1.373899, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 729, Training loss: 1.362343, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 730, Training loss: 1.369746, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 731, Training loss: 1.375601, Validation loss: 1.3888, lr: 0.0000\n",
      "Epoch: 732, Training loss: 1.386267, Validation loss: 1.3872, lr: 0.0000\n",
      "Epoch: 733, Training loss: 1.378720, Validation loss: 1.3705, lr: 0.0000\n",
      "Epoch: 734, Training loss: 1.380234, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 735, Training loss: 1.373196, Validation loss: 1.3792, lr: 0.0000\n",
      "Epoch: 736, Training loss: 1.375161, Validation loss: 1.3956, lr: 0.0000\n",
      "Epoch: 737, Training loss: 1.389906, Validation loss: 1.3376, lr: 0.0000\n",
      "Epoch: 738, Training loss: 1.384055, Validation loss: 1.3721, lr: 0.0000\n",
      "Epoch: 739, Training loss: 1.362075, Validation loss: 1.3755, lr: 0.0000\n",
      "Epoch: 740, Training loss: 1.385993, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 741, Training loss: 1.374679, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 742, Training loss: 1.369682, Validation loss: 1.3474, lr: 0.0000\n",
      "Epoch: 743, Training loss: 1.379155, Validation loss: 1.3789, lr: 0.0000\n",
      "Epoch: 744, Training loss: 1.381169, Validation loss: 1.3548, lr: 0.0000\n",
      "Epoch: 745, Training loss: 1.379501, Validation loss: 1.3742, lr: 0.0000\n",
      "Epoch: 746, Training loss: 1.392730, Validation loss: 1.3786, lr: 0.0000\n",
      "Epoch: 747, Training loss: 1.364171, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 748, Training loss: 1.396384, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 749, Training loss: 1.386957, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 750, Training loss: 1.369491, Validation loss: 1.3728, lr: 0.0000\n",
      "Epoch: 751, Training loss: 1.394062, Validation loss: 1.3893, lr: 0.0000\n",
      "Epoch: 752, Training loss: 1.371974, Validation loss: 1.3683, lr: 0.0000\n",
      "Epoch: 753, Training loss: 1.372680, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 754, Training loss: 1.380804, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 755, Training loss: 1.382815, Validation loss: 1.3656, lr: 0.0000\n",
      "Epoch: 756, Training loss: 1.377408, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 757, Training loss: 1.379420, Validation loss: 1.3676, lr: 0.0000\n",
      "Epoch: 758, Training loss: 1.367857, Validation loss: 1.3773, lr: 0.0000\n",
      "Epoch: 759, Training loss: 1.385386, Validation loss: 1.3713, lr: 0.0000\n",
      "Epoch: 760, Training loss: 1.368178, Validation loss: 1.3950, lr: 0.0000\n",
      "Epoch: 761, Training loss: 1.380339, Validation loss: 1.3783, lr: 0.0000\n",
      "Epoch: 762, Training loss: 1.413153, Validation loss: 1.3710, lr: 0.0000\n",
      "Epoch: 763, Training loss: 1.381981, Validation loss: 1.3700, lr: 0.0000\n",
      "Epoch: 764, Training loss: 1.377046, Validation loss: 1.3597, lr: 0.0000\n",
      "Epoch: 765, Training loss: 1.374972, Validation loss: 1.4239, lr: 0.0000\n",
      "Epoch: 766, Training loss: 1.384069, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 767, Training loss: 1.377877, Validation loss: 1.3897, lr: 0.0000\n",
      "Epoch: 768, Training loss: 1.372443, Validation loss: 1.3694, lr: 0.0000\n",
      "Epoch: 769, Training loss: 1.381587, Validation loss: 1.3780, lr: 0.0000\n",
      "Epoch: 770, Training loss: 1.374211, Validation loss: 1.3737, lr: 0.0000\n",
      "Epoch: 771, Training loss: 1.383360, Validation loss: 1.4602, lr: 0.0000\n",
      "Epoch: 772, Training loss: 1.394844, Validation loss: 1.3666, lr: 0.0000\n",
      "Epoch: 773, Training loss: 1.373043, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 774, Training loss: 1.364650, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 775, Training loss: 1.383038, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 776, Training loss: 1.366158, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 777, Training loss: 1.375644, Validation loss: 1.3778, lr: 0.0000\n",
      "Epoch: 778, Training loss: 1.393968, Validation loss: 1.3491, lr: 0.0000\n",
      "Epoch: 779, Training loss: 1.393937, Validation loss: 1.3648, lr: 0.0000\n",
      "Epoch: 780, Training loss: 1.387930, Validation loss: 1.3939, lr: 0.0000\n",
      "Epoch: 781, Training loss: 1.379210, Validation loss: 1.3546, lr: 0.0000\n",
      "Epoch: 782, Training loss: 1.370930, Validation loss: 1.3773, lr: 0.0000\n",
      "Epoch: 783, Training loss: 1.375526, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 784, Training loss: 1.375712, Validation loss: 1.3735, lr: 0.0000\n",
      "Epoch: 785, Training loss: 1.387348, Validation loss: 1.3783, lr: 0.0000\n",
      "Epoch: 786, Training loss: 1.376418, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 787, Training loss: 1.375037, Validation loss: 1.3787, lr: 0.0000\n",
      "Epoch: 788, Training loss: 1.420944, Validation loss: 1.3943, lr: 0.0000\n",
      "Epoch: 789, Training loss: 1.391577, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 790, Training loss: 1.382549, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 791, Training loss: 1.374358, Validation loss: 1.3759, lr: 0.0000\n",
      "Epoch: 792, Training loss: 1.384923, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 793, Training loss: 1.387679, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 794, Training loss: 1.383130, Validation loss: 1.3710, lr: 0.0000\n",
      "Epoch: 795, Training loss: 1.379687, Validation loss: 1.3725, lr: 0.0000\n",
      "Epoch: 796, Training loss: 1.375093, Validation loss: 1.3704, lr: 0.0000\n",
      "Epoch: 797, Training loss: 1.410977, Validation loss: 1.3735, lr: 0.0000\n",
      "Epoch: 798, Training loss: 1.378166, Validation loss: 1.4221, lr: 0.0000\n",
      "Epoch: 799, Training loss: 1.395548, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 800, Training loss: 1.388047, Validation loss: 1.3672, lr: 0.0000\n",
      "Epoch: 801, Training loss: 1.365334, Validation loss: 1.6818, lr: 0.0000\n",
      "Epoch: 802, Training loss: 1.373043, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 803, Training loss: 1.395133, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 804, Training loss: 1.363341, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 805, Training loss: 1.402586, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 806, Training loss: 1.369175, Validation loss: 1.3587, lr: 0.0000\n",
      "Epoch: 807, Training loss: 1.394244, Validation loss: 1.3782, lr: 0.0000\n",
      "Epoch: 808, Training loss: 1.377765, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 809, Training loss: 1.372447, Validation loss: 1.3564, lr: 0.0000\n",
      "Epoch: 810, Training loss: 1.379316, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 811, Training loss: 1.380177, Validation loss: 1.4683, lr: 0.0000\n",
      "Epoch: 812, Training loss: 1.373595, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 813, Training loss: 1.365733, Validation loss: 1.3720, lr: 0.0000\n",
      "Epoch: 814, Training loss: 1.385336, Validation loss: 1.3647, lr: 0.0000\n",
      "Epoch: 815, Training loss: 1.376755, Validation loss: 1.3786, lr: 0.0000\n",
      "Epoch: 816, Training loss: 1.386023, Validation loss: 1.3790, lr: 0.0000\n",
      "Epoch: 817, Training loss: 1.383092, Validation loss: 1.3800, lr: 0.0000\n",
      "Epoch: 818, Training loss: 1.388376, Validation loss: 1.3790, lr: 0.0000\n",
      "Epoch: 819, Training loss: 1.389670, Validation loss: 1.3786, lr: 0.0000\n",
      "Epoch: 820, Training loss: 1.378610, Validation loss: 1.3600, lr: 0.0000\n",
      "Epoch: 821, Training loss: 1.380065, Validation loss: 1.3786, lr: 0.0000\n",
      "Epoch: 822, Training loss: 1.398504, Validation loss: 1.4017, lr: 0.0000\n",
      "Epoch: 823, Training loss: 1.397101, Validation loss: 1.3782, lr: 0.0000\n",
      "Epoch: 824, Training loss: 1.428798, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 825, Training loss: 1.376485, Validation loss: 1.3922, lr: 0.0000\n",
      "Epoch: 826, Training loss: 1.383072, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 827, Training loss: 1.367976, Validation loss: 1.3724, lr: 0.0000\n",
      "Epoch: 828, Training loss: 1.377383, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 829, Training loss: 1.389235, Validation loss: 1.3991, lr: 0.0000\n",
      "Epoch: 830, Training loss: 1.370463, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 831, Training loss: 1.371364, Validation loss: 1.3758, lr: 0.0000\n",
      "Epoch: 832, Training loss: 1.370161, Validation loss: 1.3785, lr: 0.0000\n",
      "Epoch: 833, Training loss: 1.431361, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 834, Training loss: 1.403859, Validation loss: 1.4048, lr: 0.0000\n",
      "Epoch: 835, Training loss: 1.371930, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 836, Training loss: 1.375091, Validation loss: 1.3768, lr: 0.0000\n",
      "Epoch: 837, Training loss: 1.369887, Validation loss: 1.3636, lr: 0.0000\n",
      "Epoch: 838, Training loss: 1.384794, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 839, Training loss: 1.385965, Validation loss: 1.3882, lr: 0.0000\n",
      "Epoch: 840, Training loss: 1.369320, Validation loss: 1.3696, lr: 0.0000\n",
      "Epoch: 841, Training loss: 1.372903, Validation loss: 1.3736, lr: 0.0000\n",
      "Epoch: 842, Training loss: 1.375837, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 843, Training loss: 1.385717, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 844, Training loss: 1.382006, Validation loss: 1.3755, lr: 0.0000\n",
      "Epoch: 845, Training loss: 1.367036, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 846, Training loss: 1.368572, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 847, Training loss: 1.387199, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 848, Training loss: 1.405318, Validation loss: 1.3788, lr: 0.0000\n",
      "Epoch: 849, Training loss: 1.400479, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 850, Training loss: 1.379702, Validation loss: 1.3788, lr: 0.0000\n",
      "Epoch: 851, Training loss: 1.382683, Validation loss: 1.3735, lr: 0.0000\n",
      "Epoch: 852, Training loss: 1.369463, Validation loss: 1.3876, lr: 0.0000\n",
      "Epoch: 853, Training loss: 1.359243, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 854, Training loss: 1.391662, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 855, Training loss: 1.388334, Validation loss: 1.5122, lr: 0.0000\n",
      "Epoch: 856, Training loss: 1.391338, Validation loss: 1.3782, lr: 0.0000\n",
      "Epoch: 857, Training loss: 1.368875, Validation loss: 1.3759, lr: 0.0000\n",
      "Epoch: 858, Training loss: 1.359811, Validation loss: 1.6450, lr: 0.0000\n",
      "Epoch: 859, Training loss: 1.367359, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 860, Training loss: 1.380923, Validation loss: 1.3688, lr: 0.0000\n",
      "Epoch: 861, Training loss: 1.380801, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 862, Training loss: 1.378133, Validation loss: 1.3883, lr: 0.0000\n",
      "Epoch: 863, Training loss: 1.374441, Validation loss: 1.3760, lr: 0.0000\n",
      "Epoch: 864, Training loss: 1.364739, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 865, Training loss: 1.372939, Validation loss: 1.3898, lr: 0.0000\n",
      "Epoch: 866, Training loss: 1.387642, Validation loss: 1.4044, lr: 0.0000\n",
      "Epoch: 867, Training loss: 1.385262, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 868, Training loss: 1.376127, Validation loss: 1.3543, lr: 0.0000\n",
      "Epoch: 869, Training loss: 1.391249, Validation loss: 1.3779, lr: 0.0000\n",
      "Epoch: 870, Training loss: 1.365823, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 871, Training loss: 1.373951, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 872, Training loss: 1.376309, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 873, Training loss: 1.372540, Validation loss: 1.3755, lr: 0.0000\n",
      "Epoch: 874, Training loss: 1.376125, Validation loss: 1.4180, lr: 0.0000\n",
      "Epoch: 875, Training loss: 1.374889, Validation loss: 1.3587, lr: 0.0000\n",
      "Epoch: 876, Training loss: 1.386007, Validation loss: 1.3962, lr: 0.0000\n",
      "Epoch: 877, Training loss: 1.392781, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 878, Training loss: 1.375533, Validation loss: 1.3770, lr: 0.0000\n",
      "Epoch: 879, Training loss: 1.366118, Validation loss: 1.3872, lr: 0.0000\n",
      "Epoch: 880, Training loss: 1.381645, Validation loss: 1.3777, lr: 0.0000\n",
      "Epoch: 881, Training loss: 1.381351, Validation loss: 1.3891, lr: 0.0000\n",
      "Epoch: 882, Training loss: 1.368194, Validation loss: 1.3757, lr: 0.0000\n",
      "Epoch: 883, Training loss: 1.390131, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 884, Training loss: 1.356505, Validation loss: 1.4279, lr: 0.0000\n",
      "Epoch: 885, Training loss: 1.391846, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 886, Training loss: 1.368041, Validation loss: 1.3780, lr: 0.0000\n",
      "Epoch: 887, Training loss: 1.387009, Validation loss: 1.3886, lr: 0.0000\n",
      "Epoch: 888, Training loss: 1.380136, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 889, Training loss: 1.375093, Validation loss: 1.3749, lr: 0.0000\n",
      "Epoch: 890, Training loss: 1.382589, Validation loss: 1.4260, lr: 0.0000\n",
      "Epoch: 891, Training loss: 1.371758, Validation loss: 1.3874, lr: 0.0000\n",
      "Epoch: 892, Training loss: 1.384166, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 893, Training loss: 1.377981, Validation loss: 1.4251, lr: 0.0000\n",
      "Epoch: 894, Training loss: 1.382718, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 895, Training loss: 1.374574, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 896, Training loss: 1.371007, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 897, Training loss: 1.378111, Validation loss: 1.3788, lr: 0.0000\n",
      "Epoch: 898, Training loss: 1.383054, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 899, Training loss: 1.375446, Validation loss: 1.3909, lr: 0.0000\n",
      "Epoch: 900, Training loss: 1.375696, Validation loss: 1.3773, lr: 0.0000\n",
      "Epoch: 901, Training loss: 1.385436, Validation loss: 1.3484, lr: 0.0000\n",
      "Epoch: 902, Training loss: 1.374979, Validation loss: 1.3947, lr: 0.0000\n",
      "Epoch: 903, Training loss: 1.376699, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 904, Training loss: 1.377857, Validation loss: 1.3677, lr: 0.0000\n",
      "Epoch: 905, Training loss: 1.377030, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 906, Training loss: 1.401207, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 907, Training loss: 1.380594, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 908, Training loss: 1.453244, Validation loss: 1.3651, lr: 0.0000\n",
      "Epoch: 909, Training loss: 1.379362, Validation loss: 1.3802, lr: 0.0000\n",
      "Epoch: 910, Training loss: 1.372512, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 911, Training loss: 1.364883, Validation loss: 1.3755, lr: 0.0000\n",
      "Epoch: 912, Training loss: 1.377274, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 913, Training loss: 1.378308, Validation loss: 1.3872, lr: 0.0000\n",
      "Epoch: 914, Training loss: 1.375450, Validation loss: 1.3793, lr: 0.0000\n",
      "Epoch: 915, Training loss: 1.368315, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 916, Training loss: 1.370583, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 917, Training loss: 1.377953, Validation loss: 1.3715, lr: 0.0000\n",
      "Epoch: 918, Training loss: 1.382148, Validation loss: 1.3703, lr: 0.0000\n",
      "Epoch: 919, Training loss: 1.372508, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 920, Training loss: 1.387619, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 921, Training loss: 1.358387, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 922, Training loss: 1.379566, Validation loss: 1.3742, lr: 0.0000\n",
      "Epoch: 923, Training loss: 1.373728, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 924, Training loss: 1.364744, Validation loss: 1.3940, lr: 0.0000\n",
      "Epoch: 925, Training loss: 1.368131, Validation loss: 1.3737, lr: 0.0000\n",
      "Epoch: 926, Training loss: 1.382749, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 927, Training loss: 1.375471, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 928, Training loss: 1.377000, Validation loss: 1.3770, lr: 0.0000\n",
      "Epoch: 929, Training loss: 1.387704, Validation loss: 1.3433, lr: 0.0000\n",
      "Epoch: 930, Training loss: 1.391716, Validation loss: 1.3924, lr: 0.0000\n",
      "Epoch: 931, Training loss: 1.368962, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 932, Training loss: 1.381604, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 933, Training loss: 1.371262, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 934, Training loss: 1.369418, Validation loss: 1.3873, lr: 0.0000\n",
      "Epoch: 935, Training loss: 1.369939, Validation loss: 1.3770, lr: 0.0000\n",
      "Epoch: 936, Training loss: 1.383202, Validation loss: 1.3543, lr: 0.0000\n",
      "Epoch: 937, Training loss: 1.374276, Validation loss: 1.3891, lr: 0.0000\n",
      "Epoch: 938, Training loss: 1.370629, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 939, Training loss: 1.407202, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 940, Training loss: 1.373864, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 941, Training loss: 1.379548, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 942, Training loss: 1.377699, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 943, Training loss: 1.381222, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 944, Training loss: 1.388587, Validation loss: 1.3697, lr: 0.0000\n",
      "Epoch: 945, Training loss: 1.386152, Validation loss: 1.3734, lr: 0.0000\n",
      "Epoch: 946, Training loss: 1.363591, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 947, Training loss: 1.383569, Validation loss: 1.3754, lr: 0.0000\n",
      "Epoch: 948, Training loss: 1.373944, Validation loss: 1.3786, lr: 0.0000\n",
      "Epoch: 949, Training loss: 1.377775, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 950, Training loss: 1.370339, Validation loss: 1.4402, lr: 0.0000\n",
      "Epoch: 951, Training loss: 1.385194, Validation loss: 1.3739, lr: 0.0000\n",
      "Epoch: 952, Training loss: 1.380280, Validation loss: 1.3781, lr: 0.0000\n",
      "Epoch: 953, Training loss: 1.380744, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 954, Training loss: 1.395925, Validation loss: 1.3891, lr: 0.0000\n",
      "Epoch: 955, Training loss: 1.361286, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 956, Training loss: 1.378012, Validation loss: 1.3775, lr: 0.0000\n",
      "Epoch: 957, Training loss: 1.385958, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 958, Training loss: 1.389073, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 959, Training loss: 1.384669, Validation loss: 1.3512, lr: 0.0000\n",
      "Epoch: 960, Training loss: 1.376086, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 961, Training loss: 1.373639, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 962, Training loss: 1.374321, Validation loss: 1.3778, lr: 0.0000\n",
      "Epoch: 963, Training loss: 1.436442, Validation loss: 1.3799, lr: 0.0000\n",
      "Epoch: 964, Training loss: 1.389736, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 965, Training loss: 1.389480, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 966, Training loss: 1.371048, Validation loss: 1.3802, lr: 0.0000\n",
      "Epoch: 967, Training loss: 1.378114, Validation loss: 1.3770, lr: 0.0000\n",
      "Epoch: 968, Training loss: 1.401930, Validation loss: 1.3762, lr: 0.0000\n",
      "Epoch: 969, Training loss: 1.396277, Validation loss: 1.3899, lr: 0.0000\n",
      "Epoch: 970, Training loss: 1.411381, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 971, Training loss: 1.391697, Validation loss: 1.3728, lr: 0.0000\n",
      "Epoch: 972, Training loss: 1.396338, Validation loss: 1.3735, lr: 0.0000\n",
      "Epoch: 973, Training loss: 1.384075, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 974, Training loss: 1.372430, Validation loss: 1.3717, lr: 0.0000\n",
      "Epoch: 975, Training loss: 1.382109, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 976, Training loss: 1.395995, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 977, Training loss: 1.369487, Validation loss: 1.3779, lr: 0.0000\n",
      "Epoch: 978, Training loss: 1.375448, Validation loss: 1.3775, lr: 0.0000\n",
      "Epoch: 979, Training loss: 1.371719, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 980, Training loss: 1.378890, Validation loss: 1.3666, lr: 0.0000\n",
      "Epoch: 981, Training loss: 1.371959, Validation loss: 1.3959, lr: 0.0000\n",
      "Epoch: 982, Training loss: 1.362911, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 983, Training loss: 1.380557, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 984, Training loss: 1.390134, Validation loss: 1.3789, lr: 0.0000\n",
      "Epoch: 985, Training loss: 1.395590, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 986, Training loss: 1.376857, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 987, Training loss: 1.373931, Validation loss: 1.4016, lr: 0.0000\n",
      "Epoch: 988, Training loss: 1.380374, Validation loss: 1.3903, lr: 0.0000\n",
      "Epoch: 989, Training loss: 1.369788, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 990, Training loss: 1.368678, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 991, Training loss: 1.376009, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 992, Training loss: 1.361838, Validation loss: 1.3760, lr: 0.0000\n",
      "Epoch: 993, Training loss: 1.376060, Validation loss: 1.3733, lr: 0.0000\n",
      "Epoch: 994, Training loss: 1.365544, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 995, Training loss: 1.377448, Validation loss: 1.3751, lr: 0.0000\n",
      "Epoch: 996, Training loss: 1.385069, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 997, Training loss: 1.391382, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 998, Training loss: 1.371197, Validation loss: 1.3740, lr: 0.0000\n",
      "Epoch: 999, Training loss: 1.388453, Validation loss: 1.3880, lr: 0.0000\n",
      "Final test loss: 1.3793\n",
      "=== Run 07/10 ===\n",
      "\n",
      "---- Settings: \n",
      "\n",
      "epochs : 1000\n",
      "hidden_channels : [32]\n",
      "out_channels : 10\n",
      "inner_product_features : False\n",
      "batch_size : 64\n",
      "lr : 0.01\n",
      "momentum : 0.9\n",
      "dropout : 0.0\n",
      "batch_norm : batch_norm\n",
      "bias : True\n",
      "order : 2\n",
      "diffusion : True\n",
      "frac_sampled_nb : -1\n",
      "include_positions : False\n",
      "include_self : True\n",
      "vec_norm : False\n",
      "emb_norm : False\n",
      "seed : 0\n",
      "dim_signal : 100\n",
      "dim_emb : 100\n",
      "n_sampled_nb : -1\n",
      "\n",
      "---- Number of features to pass to the MLP:  1010100\n",
      "---- Total number of parameters:  32323627\n",
      "\n",
      "Using device cuda:0\n",
      "\n",
      "---- Training network ...\n",
      "\n",
      "---- Timestamp: 20250615-024737\n",
      "\n",
      " *och: 0, Training loss: 1.447557, Validation loss: 1.4779, lr: 0.0100\n",
      " *och: 1, Training loss: 1.397193, Validation loss: 1.3792, lr: 0.0100\n",
      " *och: 2, Training loss: 1.366315, Validation loss: 1.3622, lr: 0.0100\n",
      "Epoch: 3, Training loss: 1.396293, Validation loss: 1.3758, lr: 0.0100\n",
      "Epoch: 4, Training loss: 1.408321, Validation loss: 1.3760, lr: 0.0100\n",
      "Epoch: 5, Training loss: 1.422873, Validation loss: 1.3944, lr: 0.0100\n",
      "Epoch: 6, Training loss: 1.387862, Validation loss: 1.3919, lr: 0.0100\n",
      "Epoch: 7, Training loss: 1.375952, Validation loss: 1.4106, lr: 0.0100\n",
      "Epoch: 8, Training loss: 1.385947, Validation loss: 1.3736, lr: 0.0100\n",
      "Epoch: 9, Training loss: 1.397342, Validation loss: 1.3774, lr: 0.0100\n",
      "Epoch: 10, Training loss: 1.390205, Validation loss: 1.3898, lr: 0.0100\n",
      "Epoch: 11, Training loss: 1.405357, Validation loss: 1.3677, lr: 0.0100\n",
      "Epoch: 12, Training loss: 1.397166, Validation loss: 1.3771, lr: 0.0100\n",
      "Epoch: 13, Training loss: 1.390243, Validation loss: 1.4119, lr: 0.0010\n",
      "Epoch: 14, Training loss: 1.364637, Validation loss: 1.3912, lr: 0.0010\n",
      "Epoch: 15, Training loss: 1.388644, Validation loss: 1.3990, lr: 0.0010\n",
      "Epoch: 16, Training loss: 1.376662, Validation loss: 1.3950, lr: 0.0010\n",
      "Epoch: 17, Training loss: 1.443769, Validation loss: 1.3829, lr: 0.0010\n",
      "Epoch: 18, Training loss: 1.397385, Validation loss: 1.4606, lr: 0.0010\n",
      "Epoch: 19, Training loss: 1.412348, Validation loss: 1.3696, lr: 0.0010\n",
      "Epoch: 20, Training loss: 1.432547, Validation loss: 1.3694, lr: 0.0010\n",
      "Epoch: 21, Training loss: 1.405535, Validation loss: 1.3845, lr: 0.0010\n",
      "Epoch: 22, Training loss: 1.404304, Validation loss: 1.3899, lr: 0.0010\n",
      "Epoch: 23, Training loss: 1.382984, Validation loss: 1.3806, lr: 0.0010\n",
      "Epoch: 24, Training loss: 1.392961, Validation loss: 1.3835, lr: 0.0010\n",
      "Epoch: 25, Training loss: 1.413937, Validation loss: 1.3814, lr: 0.0001\n",
      "Epoch: 26, Training loss: 1.402957, Validation loss: 1.3751, lr: 0.0001\n",
      "Epoch: 27, Training loss: 1.385148, Validation loss: 1.3732, lr: 0.0001\n",
      "Epoch: 28, Training loss: 1.378419, Validation loss: 1.3783, lr: 0.0001\n",
      "Epoch: 29, Training loss: 1.359699, Validation loss: 1.3705, lr: 0.0001\n",
      "Epoch: 30, Training loss: 1.391282, Validation loss: 1.3814, lr: 0.0001\n",
      "Epoch: 31, Training loss: 1.382976, Validation loss: 1.4196, lr: 0.0001\n",
      "Epoch: 32, Training loss: 1.358306, Validation loss: 1.3751, lr: 0.0001\n",
      "Epoch: 33, Training loss: 1.359779, Validation loss: 1.3838, lr: 0.0001\n",
      "Epoch: 34, Training loss: 1.375232, Validation loss: 1.3654, lr: 0.0001\n",
      "Epoch: 35, Training loss: 1.374428, Validation loss: 1.3817, lr: 0.0001\n",
      "Epoch: 36, Training loss: 1.375528, Validation loss: 1.3813, lr: 0.0001\n",
      "Epoch: 37, Training loss: 1.390742, Validation loss: 1.3840, lr: 0.0001\n",
      "Epoch: 38, Training loss: 1.408783, Validation loss: 1.3733, lr: 0.0001\n",
      "Epoch: 39, Training loss: 1.398874, Validation loss: 1.3871, lr: 0.0001\n",
      "Epoch: 40, Training loss: 1.372784, Validation loss: 1.3800, lr: 0.0001\n",
      "Epoch: 41, Training loss: 1.384184, Validation loss: 1.3835, lr: 0.0001\n",
      "Epoch: 42, Training loss: 1.375545, Validation loss: 1.3759, lr: 0.0001\n",
      "Epoch: 43, Training loss: 1.395206, Validation loss: 1.3766, lr: 0.0000\n",
      "Epoch: 44, Training loss: 1.363891, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 45, Training loss: 1.361138, Validation loss: 1.3726, lr: 0.0000\n",
      "Epoch: 46, Training loss: 1.444313, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 47, Training loss: 1.404505, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 48, Training loss: 1.392950, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 49, Training loss: 1.389848, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 50, Training loss: 1.379772, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 51, Training loss: 1.387009, Validation loss: 1.3727, lr: 0.0000\n",
      "Epoch: 52, Training loss: 1.388021, Validation loss: 1.3882, lr: 0.0000\n",
      "Epoch: 53, Training loss: 1.388433, Validation loss: 1.3748, lr: 0.0000\n",
      "Epoch: 54, Training loss: 1.370586, Validation loss: 1.3877, lr: 0.0000\n",
      "Epoch: 55, Training loss: 1.372351, Validation loss: 1.3913, lr: 0.0000\n",
      "Epoch: 56, Training loss: 1.382134, Validation loss: 1.3997, lr: 0.0000\n",
      "Epoch: 57, Training loss: 1.396511, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 58, Training loss: 1.388532, Validation loss: 1.3759, lr: 0.0000\n",
      "Epoch: 59, Training loss: 1.357118, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 60, Training loss: 1.374489, Validation loss: 1.3685, lr: 0.0000\n",
      " *och: 61, Training loss: 1.513783, Validation loss: 1.3607, lr: 0.0000\n",
      "Epoch: 62, Training loss: 1.405660, Validation loss: 1.3973, lr: 0.0000\n",
      "Epoch: 63, Training loss: 1.355796, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 64, Training loss: 1.409665, Validation loss: 1.3797, lr: 0.0000\n",
      "Epoch: 65, Training loss: 1.384311, Validation loss: 1.3614, lr: 0.0000\n",
      "Epoch: 66, Training loss: 1.376767, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 67, Training loss: 1.359952, Validation loss: 1.3751, lr: 0.0000\n",
      "Epoch: 68, Training loss: 1.361527, Validation loss: 1.3738, lr: 0.0000\n",
      "Epoch: 69, Training loss: 1.372178, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 70, Training loss: 1.395344, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 71, Training loss: 1.393633, Validation loss: 1.4032, lr: 0.0000\n",
      "Epoch: 72, Training loss: 1.419834, Validation loss: 1.3733, lr: 0.0000\n",
      "Epoch: 73, Training loss: 1.383439, Validation loss: 1.4046, lr: 0.0000\n",
      "Epoch: 74, Training loss: 1.387026, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 75, Training loss: 1.373521, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 76, Training loss: 1.383152, Validation loss: 1.3929, lr: 0.0000\n",
      "Epoch: 77, Training loss: 1.424358, Validation loss: 1.3922, lr: 0.0000\n",
      "Epoch: 78, Training loss: 1.357664, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 79, Training loss: 1.363274, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 80, Training loss: 1.361749, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 81, Training loss: 1.374769, Validation loss: 1.3804, lr: 0.0000\n",
      " *och: 82, Training loss: 1.366100, Validation loss: 1.3425, lr: 0.0000\n",
      "Epoch: 83, Training loss: 1.373241, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 84, Training loss: 1.367923, Validation loss: 1.3755, lr: 0.0000\n",
      "Epoch: 85, Training loss: 1.394059, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 86, Training loss: 1.376017, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 87, Training loss: 1.378770, Validation loss: 1.3927, lr: 0.0000\n",
      "Epoch: 88, Training loss: 1.402184, Validation loss: 1.3979, lr: 0.0000\n",
      "Epoch: 89, Training loss: 1.368222, Validation loss: 1.3915, lr: 0.0000\n",
      "Epoch: 90, Training loss: 1.376751, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 91, Training loss: 1.380302, Validation loss: 1.3803, lr: 0.0000\n",
      "Epoch: 92, Training loss: 1.382175, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 93, Training loss: 1.375256, Validation loss: 1.3895, lr: 0.0000\n",
      "Epoch: 94, Training loss: 1.364530, Validation loss: 1.3736, lr: 0.0000\n",
      "Epoch: 95, Training loss: 1.372173, Validation loss: 1.3747, lr: 0.0000\n",
      "Epoch: 96, Training loss: 1.355711, Validation loss: 1.3943, lr: 0.0000\n",
      "Epoch: 97, Training loss: 1.392684, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 98, Training loss: 1.375062, Validation loss: 1.3886, lr: 0.0000\n",
      "Epoch: 99, Training loss: 1.383626, Validation loss: 1.3872, lr: 0.0000\n",
      "Epoch: 100, Training loss: 1.382853, Validation loss: 1.3959, lr: 0.0000\n",
      "Epoch: 101, Training loss: 1.364010, Validation loss: 1.3791, lr: 0.0000\n",
      "Epoch: 102, Training loss: 1.364839, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 103, Training loss: 1.385047, Validation loss: 1.3894, lr: 0.0000\n",
      "Epoch: 104, Training loss: 1.383611, Validation loss: 1.3695, lr: 0.0000\n",
      "Epoch: 105, Training loss: 1.372747, Validation loss: 1.5776, lr: 0.0000\n",
      "Epoch: 106, Training loss: 1.381556, Validation loss: 1.3688, lr: 0.0000\n",
      "Epoch: 107, Training loss: 1.385767, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 108, Training loss: 1.402668, Validation loss: 1.3762, lr: 0.0000\n",
      "Epoch: 109, Training loss: 1.381786, Validation loss: 1.3800, lr: 0.0000\n",
      "Epoch: 110, Training loss: 1.375120, Validation loss: 1.3689, lr: 0.0000\n",
      "Epoch: 111, Training loss: 1.371195, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 112, Training loss: 1.371788, Validation loss: 1.3687, lr: 0.0000\n",
      "Epoch: 113, Training loss: 1.373627, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 114, Training loss: 1.399301, Validation loss: 1.3744, lr: 0.0000\n",
      "Epoch: 115, Training loss: 1.395605, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 116, Training loss: 1.381616, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 117, Training loss: 1.384113, Validation loss: 1.3756, lr: 0.0000\n",
      "Epoch: 118, Training loss: 1.389080, Validation loss: 1.3942, lr: 0.0000\n",
      "Epoch: 119, Training loss: 1.377562, Validation loss: 1.3644, lr: 0.0000\n",
      "Epoch: 120, Training loss: 1.376645, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 121, Training loss: 1.359736, Validation loss: 1.3540, lr: 0.0000\n",
      "Epoch: 122, Training loss: 1.367147, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 123, Training loss: 1.376445, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 124, Training loss: 1.374166, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 125, Training loss: 1.427612, Validation loss: 1.3935, lr: 0.0000\n",
      "Epoch: 126, Training loss: 1.373103, Validation loss: 1.3800, lr: 0.0000\n",
      "Epoch: 127, Training loss: 1.391174, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 128, Training loss: 1.409652, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 129, Training loss: 1.397832, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 130, Training loss: 1.467724, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 131, Training loss: 1.375478, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 132, Training loss: 1.391421, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 133, Training loss: 1.362319, Validation loss: 1.3912, lr: 0.0000\n",
      "Epoch: 134, Training loss: 1.355884, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 135, Training loss: 1.406790, Validation loss: 1.3535, lr: 0.0000\n",
      "Epoch: 136, Training loss: 1.367378, Validation loss: 1.3791, lr: 0.0000\n",
      "Epoch: 137, Training loss: 1.400311, Validation loss: 1.3792, lr: 0.0000\n",
      "Epoch: 138, Training loss: 1.391936, Validation loss: 1.3791, lr: 0.0000\n",
      "Epoch: 139, Training loss: 1.389555, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 140, Training loss: 1.380676, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 141, Training loss: 1.386940, Validation loss: 1.3890, lr: 0.0000\n",
      "Epoch: 142, Training loss: 1.390859, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 143, Training loss: 1.355854, Validation loss: 1.5425, lr: 0.0000\n",
      "Epoch: 144, Training loss: 1.405295, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 145, Training loss: 1.394209, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 146, Training loss: 1.382664, Validation loss: 1.3776, lr: 0.0000\n",
      "Epoch: 147, Training loss: 1.378206, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 148, Training loss: 1.382461, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 149, Training loss: 1.387733, Validation loss: 1.3757, lr: 0.0000\n",
      "Epoch: 150, Training loss: 1.379109, Validation loss: 1.3814, lr: 0.0000\n",
      " *och: 151, Training loss: 1.388881, Validation loss: 1.3407, lr: 0.0000\n",
      "Epoch: 152, Training loss: 1.369095, Validation loss: 1.3665, lr: 0.0000\n",
      "Epoch: 153, Training loss: 1.382950, Validation loss: 1.3980, lr: 0.0000\n",
      "Epoch: 154, Training loss: 1.366793, Validation loss: 1.3802, lr: 0.0000\n",
      "Epoch: 155, Training loss: 1.377989, Validation loss: 1.3952, lr: 0.0000\n",
      "Epoch: 156, Training loss: 1.379399, Validation loss: 1.3883, lr: 0.0000\n",
      "Epoch: 157, Training loss: 1.380370, Validation loss: 1.3790, lr: 0.0000\n",
      "Epoch: 158, Training loss: 1.370801, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 159, Training loss: 1.396071, Validation loss: 1.3457, lr: 0.0000\n",
      "Epoch: 160, Training loss: 1.386412, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 161, Training loss: 1.376674, Validation loss: 1.4030, lr: 0.0000\n",
      "Epoch: 162, Training loss: 1.394003, Validation loss: 1.4177, lr: 0.0000\n",
      "Epoch: 163, Training loss: 1.432792, Validation loss: 1.3935, lr: 0.0000\n",
      "Epoch: 164, Training loss: 1.368520, Validation loss: 1.3791, lr: 0.0000\n",
      "Epoch: 165, Training loss: 1.376150, Validation loss: 1.3707, lr: 0.0000\n",
      "Epoch: 166, Training loss: 1.445494, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 167, Training loss: 1.378267, Validation loss: 1.3724, lr: 0.0000\n",
      "Epoch: 168, Training loss: 1.384855, Validation loss: 1.3765, lr: 0.0000\n",
      "Epoch: 169, Training loss: 1.402934, Validation loss: 1.3791, lr: 0.0000\n",
      "Epoch: 170, Training loss: 1.371545, Validation loss: 1.3973, lr: 0.0000\n",
      "Epoch: 171, Training loss: 1.369089, Validation loss: 1.4089, lr: 0.0000\n",
      "Epoch: 172, Training loss: 1.373027, Validation loss: 1.3895, lr: 0.0000\n",
      "Epoch: 173, Training loss: 1.409460, Validation loss: 1.3779, lr: 0.0000\n",
      "Epoch: 174, Training loss: 1.388684, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 175, Training loss: 1.391941, Validation loss: 1.3722, lr: 0.0000\n",
      "Epoch: 176, Training loss: 1.421917, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 177, Training loss: 1.369940, Validation loss: 1.3809, lr: 0.0000\n",
      "Epoch: 178, Training loss: 1.371562, Validation loss: 1.3881, lr: 0.0000\n",
      "Epoch: 179, Training loss: 1.368463, Validation loss: 1.3746, lr: 0.0000\n",
      "Epoch: 180, Training loss: 1.374589, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 181, Training loss: 1.407736, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 182, Training loss: 1.339248, Validation loss: 1.4134, lr: 0.0000\n",
      "Epoch: 183, Training loss: 1.427649, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 184, Training loss: 1.386156, Validation loss: 1.4629, lr: 0.0000\n",
      "Epoch: 185, Training loss: 1.427075, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 186, Training loss: 1.406703, Validation loss: 1.3734, lr: 0.0000\n",
      "Epoch: 187, Training loss: 1.391386, Validation loss: 1.3798, lr: 0.0000\n",
      "Epoch: 188, Training loss: 1.386045, Validation loss: 1.3882, lr: 0.0000\n",
      "Epoch: 189, Training loss: 1.374278, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 190, Training loss: 1.410894, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 191, Training loss: 1.397239, Validation loss: 1.3647, lr: 0.0000\n",
      "Epoch: 192, Training loss: 1.383930, Validation loss: 1.3888, lr: 0.0000\n",
      "Epoch: 193, Training loss: 1.381422, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 194, Training loss: 1.375299, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 195, Training loss: 1.379764, Validation loss: 1.3881, lr: 0.0000\n",
      "Epoch: 196, Training loss: 1.445578, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 197, Training loss: 1.401790, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 198, Training loss: 1.365006, Validation loss: 1.3646, lr: 0.0000\n",
      "Epoch: 199, Training loss: 1.386015, Validation loss: 1.3651, lr: 0.0000\n",
      "Epoch: 200, Training loss: 1.381773, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 201, Training loss: 1.359642, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 202, Training loss: 1.381409, Validation loss: 1.3743, lr: 0.0000\n",
      "Epoch: 203, Training loss: 1.391039, Validation loss: 1.3700, lr: 0.0000\n",
      "Epoch: 204, Training loss: 1.380218, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 205, Training loss: 1.384038, Validation loss: 1.3746, lr: 0.0000\n",
      "Epoch: 206, Training loss: 1.427790, Validation loss: 1.3877, lr: 0.0000\n",
      "Epoch: 207, Training loss: 1.362012, Validation loss: 1.3749, lr: 0.0000\n",
      "Epoch: 208, Training loss: 1.387725, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 209, Training loss: 1.499254, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 210, Training loss: 1.373995, Validation loss: 1.3880, lr: 0.0000\n",
      "Epoch: 211, Training loss: 1.388096, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 212, Training loss: 1.391713, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 213, Training loss: 1.387674, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 214, Training loss: 1.397753, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 215, Training loss: 1.398398, Validation loss: 1.3881, lr: 0.0000\n",
      "Epoch: 216, Training loss: 1.365261, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 217, Training loss: 1.384574, Validation loss: 1.3728, lr: 0.0000\n",
      "Epoch: 218, Training loss: 1.377899, Validation loss: 1.3683, lr: 0.0000\n",
      "Epoch: 219, Training loss: 1.400622, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 220, Training loss: 1.373293, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 221, Training loss: 1.380778, Validation loss: 1.3803, lr: 0.0000\n",
      "Epoch: 222, Training loss: 1.366373, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 223, Training loss: 1.371287, Validation loss: 1.3768, lr: 0.0000\n",
      "Epoch: 224, Training loss: 1.395934, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 225, Training loss: 1.373148, Validation loss: 1.3787, lr: 0.0000\n",
      "Epoch: 226, Training loss: 1.375598, Validation loss: 1.4160, lr: 0.0000\n",
      "Epoch: 227, Training loss: 1.391748, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 228, Training loss: 1.381948, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 229, Training loss: 1.367407, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 230, Training loss: 1.384445, Validation loss: 1.4026, lr: 0.0000\n",
      "Epoch: 231, Training loss: 1.395501, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 232, Training loss: 1.383720, Validation loss: 1.3896, lr: 0.0000\n",
      "Epoch: 233, Training loss: 1.400877, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 234, Training loss: 1.363345, Validation loss: 1.4062, lr: 0.0000\n",
      "Epoch: 235, Training loss: 1.394317, Validation loss: 1.3891, lr: 0.0000\n",
      "Epoch: 236, Training loss: 1.466900, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 237, Training loss: 1.425004, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 238, Training loss: 1.383725, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 239, Training loss: 1.378932, Validation loss: 1.3797, lr: 0.0000\n",
      "Epoch: 240, Training loss: 1.354399, Validation loss: 1.3919, lr: 0.0000\n",
      "Epoch: 241, Training loss: 1.417711, Validation loss: 1.4034, lr: 0.0000\n",
      "Epoch: 242, Training loss: 1.392095, Validation loss: 1.3594, lr: 0.0000\n",
      "Epoch: 243, Training loss: 1.377306, Validation loss: 1.3552, lr: 0.0000\n",
      "Epoch: 244, Training loss: 1.416708, Validation loss: 1.3930, lr: 0.0000\n",
      "Epoch: 245, Training loss: 1.408066, Validation loss: 1.4114, lr: 0.0000\n",
      "Epoch: 246, Training loss: 1.373072, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 247, Training loss: 1.380821, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 248, Training loss: 1.426301, Validation loss: 1.3757, lr: 0.0000\n",
      "Epoch: 249, Training loss: 1.382512, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 250, Training loss: 1.391522, Validation loss: 1.3882, lr: 0.0000\n",
      "Epoch: 251, Training loss: 1.427588, Validation loss: 1.4034, lr: 0.0000\n",
      "Epoch: 252, Training loss: 1.378105, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 253, Training loss: 1.395810, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 254, Training loss: 1.368058, Validation loss: 1.3673, lr: 0.0000\n",
      "Epoch: 255, Training loss: 1.366975, Validation loss: 1.3782, lr: 0.0000\n",
      "Epoch: 256, Training loss: 1.394166, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 257, Training loss: 1.401281, Validation loss: 1.3707, lr: 0.0000\n",
      "Epoch: 258, Training loss: 1.382829, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 259, Training loss: 1.376871, Validation loss: 1.3766, lr: 0.0000\n",
      "Epoch: 260, Training loss: 1.365546, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 261, Training loss: 1.383693, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 262, Training loss: 1.378509, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 263, Training loss: 1.366340, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 264, Training loss: 1.410440, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 265, Training loss: 1.389679, Validation loss: 1.3624, lr: 0.0000\n",
      "Epoch: 266, Training loss: 1.385744, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 267, Training loss: 1.386969, Validation loss: 1.3896, lr: 0.0000\n",
      "Epoch: 268, Training loss: 1.383978, Validation loss: 1.3692, lr: 0.0000\n",
      "Epoch: 269, Training loss: 1.372867, Validation loss: 1.3706, lr: 0.0000\n",
      "Epoch: 270, Training loss: 1.379234, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 271, Training loss: 1.375203, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 272, Training loss: 1.370333, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 273, Training loss: 1.369549, Validation loss: 1.3912, lr: 0.0000\n",
      "Epoch: 274, Training loss: 1.358777, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 275, Training loss: 1.402718, Validation loss: 1.3776, lr: 0.0000\n",
      "Epoch: 276, Training loss: 1.376948, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 277, Training loss: 1.392401, Validation loss: 1.3893, lr: 0.0000\n",
      "Epoch: 278, Training loss: 1.411873, Validation loss: 1.3590, lr: 0.0000\n",
      "Epoch: 279, Training loss: 1.433314, Validation loss: 1.3939, lr: 0.0000\n",
      "Epoch: 280, Training loss: 1.384363, Validation loss: 1.4162, lr: 0.0000\n",
      "Epoch: 281, Training loss: 1.391750, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 282, Training loss: 1.392038, Validation loss: 1.3608, lr: 0.0000\n",
      "Epoch: 283, Training loss: 1.364006, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 284, Training loss: 1.404200, Validation loss: 1.3797, lr: 0.0000\n",
      "Epoch: 285, Training loss: 1.441112, Validation loss: 1.3786, lr: 0.0000\n",
      "Epoch: 286, Training loss: 1.394233, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 287, Training loss: 1.390073, Validation loss: 1.3883, lr: 0.0000\n",
      "Epoch: 288, Training loss: 1.362465, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 289, Training loss: 1.374653, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 290, Training loss: 1.373986, Validation loss: 1.3802, lr: 0.0000\n",
      "Epoch: 291, Training loss: 1.424993, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 292, Training loss: 1.362397, Validation loss: 1.3920, lr: 0.0000\n",
      "Epoch: 293, Training loss: 1.374081, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 294, Training loss: 1.390687, Validation loss: 1.3800, lr: 0.0000\n",
      "Epoch: 295, Training loss: 1.413399, Validation loss: 1.4037, lr: 0.0000\n",
      "Epoch: 296, Training loss: 1.386832, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 297, Training loss: 1.380376, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 298, Training loss: 1.383511, Validation loss: 1.3796, lr: 0.0000\n",
      "Epoch: 299, Training loss: 1.382461, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 300, Training loss: 1.381110, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 301, Training loss: 1.367308, Validation loss: 1.3875, lr: 0.0000\n",
      "Epoch: 302, Training loss: 1.383768, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 303, Training loss: 1.396726, Validation loss: 1.3792, lr: 0.0000\n",
      "Epoch: 304, Training loss: 1.439545, Validation loss: 1.3761, lr: 0.0000\n",
      "Epoch: 305, Training loss: 1.406659, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 306, Training loss: 1.395428, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 307, Training loss: 1.384715, Validation loss: 1.3753, lr: 0.0000\n",
      "Epoch: 308, Training loss: 1.386484, Validation loss: 1.3809, lr: 0.0000\n",
      "Epoch: 309, Training loss: 1.390349, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 310, Training loss: 1.422242, Validation loss: 1.3692, lr: 0.0000\n",
      "Epoch: 311, Training loss: 1.375548, Validation loss: 1.3938, lr: 0.0000\n",
      "Epoch: 312, Training loss: 1.408328, Validation loss: 1.3580, lr: 0.0000\n",
      "Epoch: 313, Training loss: 1.400584, Validation loss: 1.3951, lr: 0.0000\n",
      "Epoch: 314, Training loss: 1.401936, Validation loss: 1.3756, lr: 0.0000\n",
      "Epoch: 315, Training loss: 1.394985, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 316, Training loss: 1.346121, Validation loss: 1.3875, lr: 0.0000\n",
      "Epoch: 317, Training loss: 1.396721, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 318, Training loss: 1.376911, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 319, Training loss: 1.366997, Validation loss: 1.3795, lr: 0.0000\n",
      "Epoch: 320, Training loss: 1.375800, Validation loss: 1.3761, lr: 0.0000\n",
      "Epoch: 321, Training loss: 1.380914, Validation loss: 1.3968, lr: 0.0000\n",
      "Epoch: 322, Training loss: 1.373808, Validation loss: 1.3951, lr: 0.0000\n",
      "Epoch: 323, Training loss: 1.373341, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 324, Training loss: 1.375676, Validation loss: 1.3772, lr: 0.0000\n",
      "Epoch: 325, Training loss: 1.373042, Validation loss: 1.3595, lr: 0.0000\n",
      "Epoch: 326, Training loss: 1.373860, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 327, Training loss: 1.371998, Validation loss: 1.3753, lr: 0.0000\n",
      "Epoch: 328, Training loss: 1.434738, Validation loss: 1.3636, lr: 0.0000\n",
      "Epoch: 329, Training loss: 1.372074, Validation loss: 1.3887, lr: 0.0000\n",
      "Epoch: 330, Training loss: 1.372483, Validation loss: 1.3765, lr: 0.0000\n",
      "Epoch: 331, Training loss: 1.367871, Validation loss: 1.3745, lr: 0.0000\n",
      "Epoch: 332, Training loss: 1.405718, Validation loss: 1.3632, lr: 0.0000\n",
      "Epoch: 333, Training loss: 1.362541, Validation loss: 1.3670, lr: 0.0000\n",
      "Epoch: 334, Training loss: 1.380800, Validation loss: 1.3774, lr: 0.0000\n",
      "Epoch: 335, Training loss: 1.402588, Validation loss: 1.3794, lr: 0.0000\n",
      "Epoch: 336, Training loss: 1.360286, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 337, Training loss: 1.383908, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 338, Training loss: 1.378000, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 339, Training loss: 1.390497, Validation loss: 1.3890, lr: 0.0000\n",
      "Epoch: 340, Training loss: 1.425339, Validation loss: 1.3800, lr: 0.0000\n",
      "Epoch: 341, Training loss: 1.381548, Validation loss: 1.3709, lr: 0.0000\n",
      "Epoch: 342, Training loss: 1.365744, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 343, Training loss: 1.371331, Validation loss: 1.3785, lr: 0.0000\n",
      "Epoch: 344, Training loss: 1.399373, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 345, Training loss: 1.558572, Validation loss: 1.3753, lr: 0.0000\n",
      "Epoch: 346, Training loss: 1.370428, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 347, Training loss: 1.359953, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 348, Training loss: 1.393382, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 349, Training loss: 1.401070, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 350, Training loss: 1.378735, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 351, Training loss: 1.375342, Validation loss: 1.3719, lr: 0.0000\n",
      "Epoch: 352, Training loss: 1.396437, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 353, Training loss: 1.392569, Validation loss: 1.3769, lr: 0.0000\n",
      "Epoch: 354, Training loss: 1.358809, Validation loss: 1.3891, lr: 0.0000\n",
      "Epoch: 355, Training loss: 1.427715, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 356, Training loss: 1.480493, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 357, Training loss: 1.377747, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 358, Training loss: 1.369255, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 359, Training loss: 1.353912, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 360, Training loss: 1.391291, Validation loss: 1.3800, lr: 0.0000\n",
      "Epoch: 361, Training loss: 1.429517, Validation loss: 1.3802, lr: 0.0000\n",
      "Epoch: 362, Training loss: 1.362753, Validation loss: 1.3879, lr: 0.0000\n",
      "Epoch: 363, Training loss: 1.368308, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 364, Training loss: 1.373234, Validation loss: 1.3777, lr: 0.0000\n",
      "Epoch: 365, Training loss: 1.392628, Validation loss: 1.4298, lr: 0.0000\n",
      "Epoch: 366, Training loss: 1.414575, Validation loss: 1.3960, lr: 0.0000\n",
      "Epoch: 367, Training loss: 1.380617, Validation loss: 1.3871, lr: 0.0000\n",
      " *och: 368, Training loss: 1.379838, Validation loss: 1.3381, lr: 0.0000\n",
      "Epoch: 369, Training loss: 1.384403, Validation loss: 1.3880, lr: 0.0000\n",
      "Epoch: 370, Training loss: 1.381873, Validation loss: 1.3796, lr: 0.0000\n",
      "Epoch: 371, Training loss: 1.388923, Validation loss: 1.3750, lr: 0.0000\n",
      "Epoch: 372, Training loss: 1.387806, Validation loss: 1.3899, lr: 0.0000\n",
      "Epoch: 373, Training loss: 1.391039, Validation loss: 1.3789, lr: 0.0000\n",
      "Epoch: 374, Training loss: 1.400327, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 375, Training loss: 1.384139, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 376, Training loss: 1.398889, Validation loss: 1.3803, lr: 0.0000\n",
      "Epoch: 377, Training loss: 1.384573, Validation loss: 1.3800, lr: 0.0000\n",
      "Epoch: 378, Training loss: 1.413223, Validation loss: 1.3951, lr: 0.0000\n",
      "Epoch: 379, Training loss: 1.395229, Validation loss: 1.3723, lr: 0.0000\n",
      "Epoch: 380, Training loss: 1.372615, Validation loss: 1.3882, lr: 0.0000\n",
      "Epoch: 381, Training loss: 1.408749, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 382, Training loss: 1.390460, Validation loss: 1.3749, lr: 0.0000\n",
      "Epoch: 383, Training loss: 1.395279, Validation loss: 1.3741, lr: 0.0000\n",
      "Epoch: 384, Training loss: 1.408545, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 385, Training loss: 1.396037, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 386, Training loss: 1.375199, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 387, Training loss: 1.376390, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 388, Training loss: 1.471132, Validation loss: 1.3893, lr: 0.0000\n",
      "Epoch: 389, Training loss: 1.370994, Validation loss: 1.3794, lr: 0.0000\n",
      "Epoch: 390, Training loss: 1.365331, Validation loss: 1.3576, lr: 0.0000\n",
      "Epoch: 391, Training loss: 1.358899, Validation loss: 1.3667, lr: 0.0000\n",
      "Epoch: 392, Training loss: 1.375306, Validation loss: 1.3709, lr: 0.0000\n",
      "Epoch: 393, Training loss: 1.373864, Validation loss: 1.3743, lr: 0.0000\n",
      "Epoch: 394, Training loss: 1.437947, Validation loss: 1.3909, lr: 0.0000\n",
      "Epoch: 395, Training loss: 1.385420, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 396, Training loss: 1.364453, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 397, Training loss: 1.399495, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 398, Training loss: 1.390873, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 399, Training loss: 1.387725, Validation loss: 1.3776, lr: 0.0000\n",
      "Epoch: 400, Training loss: 1.451926, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 401, Training loss: 1.374886, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 402, Training loss: 1.374733, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 403, Training loss: 1.386109, Validation loss: 1.3612, lr: 0.0000\n",
      "Epoch: 404, Training loss: 1.384857, Validation loss: 1.3707, lr: 0.0000\n",
      "Epoch: 405, Training loss: 1.376633, Validation loss: 1.3904, lr: 0.0000\n",
      "Epoch: 406, Training loss: 1.366981, Validation loss: 1.3930, lr: 0.0000\n",
      "Epoch: 407, Training loss: 1.361261, Validation loss: 1.3941, lr: 0.0000\n",
      "Epoch: 408, Training loss: 1.375344, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 409, Training loss: 1.377005, Validation loss: 1.3693, lr: 0.0000\n",
      "Epoch: 410, Training loss: 1.395503, Validation loss: 1.3930, lr: 0.0000\n",
      "Epoch: 411, Training loss: 1.403700, Validation loss: 1.3745, lr: 0.0000\n",
      "Epoch: 412, Training loss: 1.371858, Validation loss: 1.3927, lr: 0.0000\n",
      "Epoch: 413, Training loss: 1.366434, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 414, Training loss: 1.420491, Validation loss: 1.3925, lr: 0.0000\n",
      "Epoch: 415, Training loss: 1.364820, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 416, Training loss: 1.395778, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 417, Training loss: 1.404976, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 418, Training loss: 1.401643, Validation loss: 1.3697, lr: 0.0000\n",
      "Epoch: 419, Training loss: 1.481967, Validation loss: 1.3775, lr: 0.0000\n",
      "Epoch: 420, Training loss: 1.390109, Validation loss: 1.3904, lr: 0.0000\n",
      "Epoch: 421, Training loss: 1.387732, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 422, Training loss: 1.386186, Validation loss: 1.3926, lr: 0.0000\n",
      "Epoch: 423, Training loss: 1.375282, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 424, Training loss: 1.385800, Validation loss: 1.3891, lr: 0.0000\n",
      "Epoch: 425, Training loss: 1.387422, Validation loss: 1.3793, lr: 0.0000\n",
      "Epoch: 426, Training loss: 1.391235, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 427, Training loss: 1.385642, Validation loss: 1.3744, lr: 0.0000\n",
      "Epoch: 428, Training loss: 1.389731, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 429, Training loss: 1.394521, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 430, Training loss: 1.365300, Validation loss: 1.5413, lr: 0.0000\n",
      "Epoch: 431, Training loss: 1.384581, Validation loss: 1.3663, lr: 0.0000\n",
      "Epoch: 432, Training loss: 1.385291, Validation loss: 1.3733, lr: 0.0000\n",
      "Epoch: 433, Training loss: 1.363297, Validation loss: 1.3742, lr: 0.0000\n",
      "Epoch: 434, Training loss: 1.396157, Validation loss: 1.3900, lr: 0.0000\n",
      "Epoch: 435, Training loss: 1.367377, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 436, Training loss: 1.383041, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 437, Training loss: 1.382545, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 438, Training loss: 1.363627, Validation loss: 1.3654, lr: 0.0000\n",
      "Epoch: 439, Training loss: 1.395152, Validation loss: 1.3872, lr: 0.0000\n",
      "Epoch: 440, Training loss: 1.378638, Validation loss: 1.3709, lr: 0.0000\n",
      "Epoch: 441, Training loss: 1.369056, Validation loss: 1.3960, lr: 0.0000\n",
      "Epoch: 442, Training loss: 1.380995, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 443, Training loss: 1.416993, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 444, Training loss: 1.398509, Validation loss: 1.3730, lr: 0.0000\n",
      "Epoch: 445, Training loss: 1.368764, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 446, Training loss: 1.357059, Validation loss: 1.3545, lr: 0.0000\n",
      "Epoch: 447, Training loss: 1.369571, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 448, Training loss: 1.377856, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 449, Training loss: 1.366365, Validation loss: 1.3974, lr: 0.0000\n",
      "Epoch: 450, Training loss: 1.367710, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 451, Training loss: 1.381947, Validation loss: 1.3873, lr: 0.0000\n",
      "Epoch: 452, Training loss: 1.391019, Validation loss: 1.3609, lr: 0.0000\n",
      "Epoch: 453, Training loss: 1.363698, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 454, Training loss: 1.373918, Validation loss: 1.3795, lr: 0.0000\n",
      "Epoch: 455, Training loss: 1.370034, Validation loss: 1.3878, lr: 0.0000\n",
      "Epoch: 456, Training loss: 1.381163, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 457, Training loss: 1.399351, Validation loss: 1.3726, lr: 0.0000\n",
      "Epoch: 458, Training loss: 1.410287, Validation loss: 1.3687, lr: 0.0000\n",
      "Epoch: 459, Training loss: 1.404156, Validation loss: 1.3625, lr: 0.0000\n",
      "Epoch: 460, Training loss: 1.387887, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 461, Training loss: 1.380613, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 462, Training loss: 1.370529, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 463, Training loss: 1.395305, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 464, Training loss: 1.420643, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 465, Training loss: 1.379725, Validation loss: 1.3904, lr: 0.0000\n",
      "Epoch: 466, Training loss: 1.347517, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 467, Training loss: 1.346862, Validation loss: 1.3773, lr: 0.0000\n",
      "Epoch: 468, Training loss: 1.479219, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 469, Training loss: 1.414142, Validation loss: 1.3745, lr: 0.0000\n",
      "Epoch: 470, Training loss: 1.379476, Validation loss: 1.3654, lr: 0.0000\n",
      "Epoch: 471, Training loss: 1.375400, Validation loss: 1.4004, lr: 0.0000\n",
      "Epoch: 472, Training loss: 1.437410, Validation loss: 1.3799, lr: 0.0000\n",
      "Epoch: 473, Training loss: 1.417029, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 474, Training loss: 1.384699, Validation loss: 1.3901, lr: 0.0000\n",
      "Epoch: 475, Training loss: 1.406325, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 476, Training loss: 1.396027, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 477, Training loss: 1.351198, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 478, Training loss: 1.367418, Validation loss: 1.3770, lr: 0.0000\n",
      "Epoch: 479, Training loss: 1.377543, Validation loss: 1.3751, lr: 0.0000\n",
      "Epoch: 480, Training loss: 1.363465, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 481, Training loss: 1.379739, Validation loss: 1.3413, lr: 0.0000\n",
      "Epoch: 482, Training loss: 1.361688, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 483, Training loss: 1.383274, Validation loss: 1.3599, lr: 0.0000\n",
      "Epoch: 484, Training loss: 1.370594, Validation loss: 1.3852, lr: 0.0000\n",
      " *och: 485, Training loss: 1.390622, Validation loss: 1.3321, lr: 0.0000\n",
      "Epoch: 486, Training loss: 1.402020, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 487, Training loss: 1.399184, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 488, Training loss: 1.394554, Validation loss: 1.3755, lr: 0.0000\n",
      "Epoch: 489, Training loss: 1.407785, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 490, Training loss: 1.413563, Validation loss: 1.3787, lr: 0.0000\n",
      "Epoch: 491, Training loss: 1.368337, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 492, Training loss: 1.385370, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 493, Training loss: 1.366661, Validation loss: 1.3779, lr: 0.0000\n",
      "Epoch: 494, Training loss: 1.379071, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 495, Training loss: 1.381160, Validation loss: 1.3770, lr: 0.0000\n",
      "Epoch: 496, Training loss: 1.381144, Validation loss: 1.3796, lr: 0.0000\n",
      "Epoch: 497, Training loss: 1.421343, Validation loss: 1.3768, lr: 0.0000\n",
      "Epoch: 498, Training loss: 1.370822, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 499, Training loss: 1.401816, Validation loss: 1.3748, lr: 0.0000\n",
      "Epoch: 500, Training loss: 1.382890, Validation loss: 1.3872, lr: 0.0000\n",
      "Epoch: 501, Training loss: 1.417765, Validation loss: 1.3881, lr: 0.0000\n",
      "Epoch: 502, Training loss: 1.384835, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 503, Training loss: 1.373087, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 504, Training loss: 1.382173, Validation loss: 1.3871, lr: 0.0000\n",
      "Epoch: 505, Training loss: 1.370387, Validation loss: 1.3711, lr: 0.0000\n",
      "Epoch: 506, Training loss: 1.360812, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 507, Training loss: 1.395695, Validation loss: 1.3745, lr: 0.0000\n",
      "Epoch: 508, Training loss: 1.385529, Validation loss: 1.3550, lr: 0.0000\n",
      "Epoch: 509, Training loss: 1.378414, Validation loss: 1.3367, lr: 0.0000\n",
      "Epoch: 510, Training loss: 1.420786, Validation loss: 1.3778, lr: 0.0000\n",
      "Epoch: 511, Training loss: 1.391050, Validation loss: 1.3785, lr: 0.0000\n",
      "Epoch: 512, Training loss: 1.399768, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 513, Training loss: 1.365560, Validation loss: 1.3774, lr: 0.0000\n",
      "Epoch: 514, Training loss: 1.437637, Validation loss: 1.3883, lr: 0.0000\n",
      "Epoch: 515, Training loss: 1.373504, Validation loss: 1.3978, lr: 0.0000\n",
      "Epoch: 516, Training loss: 1.387075, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 517, Training loss: 1.366487, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 518, Training loss: 1.343502, Validation loss: 1.3342, lr: 0.0000\n",
      "Epoch: 519, Training loss: 1.371849, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 520, Training loss: 1.384051, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 521, Training loss: 1.382126, Validation loss: 1.3901, lr: 0.0000\n",
      "Epoch: 522, Training loss: 1.366323, Validation loss: 1.3797, lr: 0.0000\n",
      "Epoch: 523, Training loss: 1.403263, Validation loss: 1.3929, lr: 0.0000\n",
      "Epoch: 524, Training loss: 1.375363, Validation loss: 1.3575, lr: 0.0000\n",
      "Epoch: 525, Training loss: 1.449616, Validation loss: 1.3658, lr: 0.0000\n",
      "Epoch: 526, Training loss: 1.363153, Validation loss: 1.3752, lr: 0.0000\n",
      "Epoch: 527, Training loss: 1.392631, Validation loss: 1.3782, lr: 0.0000\n",
      "Epoch: 528, Training loss: 1.424368, Validation loss: 1.4330, lr: 0.0000\n",
      "Epoch: 529, Training loss: 1.378133, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 530, Training loss: 1.367198, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 531, Training loss: 1.430121, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 532, Training loss: 1.390040, Validation loss: 1.3673, lr: 0.0000\n",
      "Epoch: 533, Training loss: 1.366904, Validation loss: 1.3983, lr: 0.0000\n",
      "Epoch: 534, Training loss: 1.385389, Validation loss: 1.3763, lr: 0.0000\n",
      "Epoch: 535, Training loss: 1.391110, Validation loss: 1.3984, lr: 0.0000\n",
      "Epoch: 536, Training loss: 1.378891, Validation loss: 1.3775, lr: 0.0000\n",
      "Epoch: 537, Training loss: 1.386924, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 538, Training loss: 1.386041, Validation loss: 1.3355, lr: 0.0000\n",
      "Epoch: 539, Training loss: 1.389617, Validation loss: 1.4153, lr: 0.0000\n",
      "Epoch: 540, Training loss: 1.374321, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 541, Training loss: 1.393590, Validation loss: 1.3884, lr: 0.0000\n",
      "Epoch: 542, Training loss: 1.374149, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 543, Training loss: 1.423371, Validation loss: 1.3786, lr: 0.0000\n",
      "Epoch: 544, Training loss: 1.355577, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 545, Training loss: 1.370884, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 546, Training loss: 1.373603, Validation loss: 1.3760, lr: 0.0000\n",
      "Epoch: 547, Training loss: 1.383421, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 548, Training loss: 1.445192, Validation loss: 1.3696, lr: 0.0000\n",
      "Epoch: 549, Training loss: 1.399216, Validation loss: 1.3479, lr: 0.0000\n",
      "Epoch: 550, Training loss: 1.363070, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 551, Training loss: 1.376819, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 552, Training loss: 1.376762, Validation loss: 1.3691, lr: 0.0000\n",
      "Epoch: 553, Training loss: 1.360896, Validation loss: 1.3739, lr: 0.0000\n",
      "Epoch: 554, Training loss: 1.367824, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 555, Training loss: 1.389144, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 556, Training loss: 1.401117, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 557, Training loss: 1.389047, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 558, Training loss: 1.381500, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 559, Training loss: 1.363938, Validation loss: 1.3791, lr: 0.0000\n",
      "Epoch: 560, Training loss: 1.390379, Validation loss: 1.3643, lr: 0.0000\n",
      "Epoch: 561, Training loss: 1.392334, Validation loss: 1.3879, lr: 0.0000\n",
      "Epoch: 562, Training loss: 1.359703, Validation loss: 1.3747, lr: 0.0000\n",
      "Epoch: 563, Training loss: 1.406699, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 564, Training loss: 1.395862, Validation loss: 1.3661, lr: 0.0000\n",
      "Epoch: 565, Training loss: 1.386476, Validation loss: 1.3552, lr: 0.0000\n",
      "Epoch: 566, Training loss: 1.423715, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 567, Training loss: 1.375323, Validation loss: 1.4576, lr: 0.0000\n",
      "Epoch: 568, Training loss: 1.380228, Validation loss: 1.3903, lr: 0.0000\n",
      "Epoch: 569, Training loss: 1.378547, Validation loss: 1.3902, lr: 0.0000\n",
      "Epoch: 570, Training loss: 1.389865, Validation loss: 1.3910, lr: 0.0000\n",
      "Epoch: 571, Training loss: 1.380705, Validation loss: 1.3764, lr: 0.0000\n",
      "Epoch: 572, Training loss: 1.377258, Validation loss: 1.3624, lr: 0.0000\n",
      "Epoch: 573, Training loss: 1.389037, Validation loss: 1.3873, lr: 0.0000\n",
      "Epoch: 574, Training loss: 1.365734, Validation loss: 1.3930, lr: 0.0000\n",
      "Epoch: 575, Training loss: 1.359813, Validation loss: 1.3702, lr: 0.0000\n",
      "Epoch: 576, Training loss: 1.389737, Validation loss: 1.3731, lr: 0.0000\n",
      "Epoch: 577, Training loss: 1.402692, Validation loss: 1.3473, lr: 0.0000\n",
      "Epoch: 578, Training loss: 1.386471, Validation loss: 1.3660, lr: 0.0000\n",
      "Epoch: 579, Training loss: 1.454025, Validation loss: 1.3937, lr: 0.0000\n",
      "Epoch: 580, Training loss: 1.361711, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 581, Training loss: 1.380454, Validation loss: 1.3748, lr: 0.0000\n",
      "Epoch: 582, Training loss: 1.368343, Validation loss: 1.3770, lr: 0.0000\n",
      "Epoch: 583, Training loss: 1.377956, Validation loss: 2.4762, lr: 0.0000\n",
      "Epoch: 584, Training loss: 1.377815, Validation loss: 1.3916, lr: 0.0000\n",
      "Epoch: 585, Training loss: 1.443203, Validation loss: 1.3394, lr: 0.0000\n",
      "Epoch: 586, Training loss: 1.376487, Validation loss: 1.3741, lr: 0.0000\n",
      "Epoch: 587, Training loss: 1.413649, Validation loss: 1.3512, lr: 0.0000\n",
      "Epoch: 588, Training loss: 1.394667, Validation loss: 1.3780, lr: 0.0000\n",
      "Epoch: 589, Training loss: 1.389133, Validation loss: 1.3997, lr: 0.0000\n",
      "Epoch: 590, Training loss: 1.383375, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 591, Training loss: 1.375662, Validation loss: 1.3749, lr: 0.0000\n",
      "Epoch: 592, Training loss: 1.421753, Validation loss: 1.3942, lr: 0.0000\n",
      "Epoch: 593, Training loss: 1.387012, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 594, Training loss: 1.377788, Validation loss: 1.3766, lr: 0.0000\n",
      "Epoch: 595, Training loss: 1.367713, Validation loss: 1.3744, lr: 0.0000\n",
      "Epoch: 596, Training loss: 1.388627, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 597, Training loss: 1.377599, Validation loss: 1.3719, lr: 0.0000\n",
      "Epoch: 598, Training loss: 1.381985, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 599, Training loss: 1.377928, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 600, Training loss: 1.388955, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 601, Training loss: 1.378973, Validation loss: 1.3987, lr: 0.0000\n",
      "Epoch: 602, Training loss: 1.379293, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 603, Training loss: 1.390201, Validation loss: 1.3678, lr: 0.0000\n",
      "Epoch: 604, Training loss: 1.378091, Validation loss: 1.4079, lr: 0.0000\n",
      "Epoch: 605, Training loss: 1.370149, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 606, Training loss: 1.372788, Validation loss: 1.3803, lr: 0.0000\n",
      "Epoch: 607, Training loss: 1.414887, Validation loss: 1.3875, lr: 0.0000\n",
      "Epoch: 608, Training loss: 1.381041, Validation loss: 1.3894, lr: 0.0000\n",
      "Epoch: 609, Training loss: 1.402498, Validation loss: 1.3657, lr: 0.0000\n",
      "Epoch: 610, Training loss: 1.412262, Validation loss: 1.3745, lr: 0.0000\n",
      "Epoch: 611, Training loss: 1.363599, Validation loss: 1.4630, lr: 0.0000\n",
      "Epoch: 612, Training loss: 1.396033, Validation loss: 1.3774, lr: 0.0000\n",
      "Epoch: 613, Training loss: 1.381885, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 614, Training loss: 1.383315, Validation loss: 1.3725, lr: 0.0000\n",
      "Epoch: 615, Training loss: 1.383339, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 616, Training loss: 1.402907, Validation loss: 1.3750, lr: 0.0000\n",
      "Epoch: 617, Training loss: 1.376985, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 618, Training loss: 1.382845, Validation loss: 1.3726, lr: 0.0000\n",
      "Epoch: 619, Training loss: 1.393032, Validation loss: 1.3796, lr: 0.0000\n",
      "Epoch: 620, Training loss: 1.394095, Validation loss: 1.3714, lr: 0.0000\n",
      "Epoch: 621, Training loss: 1.380283, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 622, Training loss: 1.379977, Validation loss: 1.3873, lr: 0.0000\n",
      "Epoch: 623, Training loss: 1.428188, Validation loss: 1.3918, lr: 0.0000\n",
      "Epoch: 624, Training loss: 1.381283, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 625, Training loss: 1.373350, Validation loss: 1.3535, lr: 0.0000\n",
      "Epoch: 626, Training loss: 1.383146, Validation loss: 1.3682, lr: 0.0000\n",
      "Epoch: 627, Training loss: 1.400624, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 628, Training loss: 1.400302, Validation loss: 1.3889, lr: 0.0000\n",
      "Epoch: 629, Training loss: 1.379167, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 630, Training loss: 1.387825, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 631, Training loss: 1.363773, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 632, Training loss: 1.381696, Validation loss: 1.3620, lr: 0.0000\n",
      "Epoch: 633, Training loss: 1.373648, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 634, Training loss: 1.371288, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 635, Training loss: 1.399616, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 636, Training loss: 1.368440, Validation loss: 1.3967, lr: 0.0000\n",
      "Epoch: 637, Training loss: 1.387232, Validation loss: 1.3878, lr: 0.0000\n",
      "Epoch: 638, Training loss: 1.371065, Validation loss: 1.3564, lr: 0.0000\n",
      "Epoch: 639, Training loss: 1.404276, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 640, Training loss: 1.375779, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 641, Training loss: 1.368151, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 642, Training loss: 1.396467, Validation loss: 1.3800, lr: 0.0000\n",
      "Epoch: 643, Training loss: 1.361862, Validation loss: 1.3729, lr: 0.0000\n",
      "Epoch: 644, Training loss: 1.370079, Validation loss: 1.3791, lr: 0.0000\n",
      "Epoch: 645, Training loss: 1.379588, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 646, Training loss: 1.386455, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 647, Training loss: 1.367434, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 648, Training loss: 1.391219, Validation loss: 1.4925, lr: 0.0000\n",
      "Epoch: 649, Training loss: 1.546973, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 650, Training loss: 1.363123, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 651, Training loss: 1.379792, Validation loss: 1.3802, lr: 0.0000\n",
      "Epoch: 652, Training loss: 1.381916, Validation loss: 1.3789, lr: 0.0000\n",
      "Epoch: 653, Training loss: 1.394940, Validation loss: 1.3963, lr: 0.0000\n",
      "Epoch: 654, Training loss: 1.389779, Validation loss: 1.3746, lr: 0.0000\n",
      "Epoch: 655, Training loss: 1.350417, Validation loss: 1.3931, lr: 0.0000\n",
      "Epoch: 656, Training loss: 1.486828, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 657, Training loss: 1.402115, Validation loss: 1.3677, lr: 0.0000\n",
      "Epoch: 658, Training loss: 1.404833, Validation loss: 1.3529, lr: 0.0000\n",
      "Epoch: 659, Training loss: 1.448573, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 660, Training loss: 1.360311, Validation loss: 1.3881, lr: 0.0000\n",
      "Epoch: 661, Training loss: 1.388079, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 662, Training loss: 1.404309, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 663, Training loss: 1.433674, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 664, Training loss: 1.523203, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 665, Training loss: 1.371170, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 666, Training loss: 1.412082, Validation loss: 1.3748, lr: 0.0000\n",
      "Epoch: 667, Training loss: 1.361329, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 668, Training loss: 1.377882, Validation loss: 1.4282, lr: 0.0000\n",
      "Epoch: 669, Training loss: 1.369099, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 670, Training loss: 1.401499, Validation loss: 1.3714, lr: 0.0000\n",
      "Epoch: 671, Training loss: 1.391298, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 672, Training loss: 1.379024, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 673, Training loss: 1.384408, Validation loss: 1.3711, lr: 0.0000\n",
      "Epoch: 674, Training loss: 1.366948, Validation loss: 1.3726, lr: 0.0000\n",
      "Epoch: 675, Training loss: 1.385064, Validation loss: 1.3800, lr: 0.0000\n",
      "Epoch: 676, Training loss: 1.374604, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 677, Training loss: 1.387884, Validation loss: 1.3741, lr: 0.0000\n",
      "Epoch: 678, Training loss: 1.368217, Validation loss: 1.3703, lr: 0.0000\n",
      "Epoch: 679, Training loss: 1.378181, Validation loss: 1.3727, lr: 0.0000\n",
      "Epoch: 680, Training loss: 1.400684, Validation loss: 1.3790, lr: 0.0000\n",
      "Epoch: 681, Training loss: 1.365827, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 682, Training loss: 1.351562, Validation loss: 1.3872, lr: 0.0000\n",
      "Epoch: 683, Training loss: 1.407640, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 684, Training loss: 1.373432, Validation loss: 1.3659, lr: 0.0000\n",
      "Epoch: 685, Training loss: 1.363746, Validation loss: 1.3754, lr: 0.0000\n",
      "Epoch: 686, Training loss: 1.385020, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 687, Training loss: 1.378244, Validation loss: 1.3912, lr: 0.0000\n",
      "Epoch: 688, Training loss: 1.379421, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 689, Training loss: 1.387531, Validation loss: 1.3803, lr: 0.0000\n",
      "Epoch: 690, Training loss: 1.384352, Validation loss: 1.3872, lr: 0.0000\n",
      "Epoch: 691, Training loss: 1.353831, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 692, Training loss: 1.349946, Validation loss: 1.3795, lr: 0.0000\n",
      "Epoch: 693, Training loss: 1.386913, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 694, Training loss: 1.375878, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 695, Training loss: 1.375475, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 696, Training loss: 1.362708, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 697, Training loss: 1.374960, Validation loss: 1.3896, lr: 0.0000\n",
      "Epoch: 698, Training loss: 1.393489, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 699, Training loss: 1.376501, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 700, Training loss: 1.367397, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 701, Training loss: 1.466053, Validation loss: 1.3929, lr: 0.0000\n",
      "Epoch: 702, Training loss: 1.377985, Validation loss: 1.3799, lr: 0.0000\n",
      "Epoch: 703, Training loss: 1.379225, Validation loss: 1.3762, lr: 0.0000\n",
      "Epoch: 704, Training loss: 1.376349, Validation loss: 1.3747, lr: 0.0000\n",
      "Epoch: 705, Training loss: 1.370019, Validation loss: 1.3980, lr: 0.0000\n",
      "Epoch: 706, Training loss: 1.369215, Validation loss: 1.3904, lr: 0.0000\n",
      "Epoch: 707, Training loss: 1.435793, Validation loss: 1.3737, lr: 0.0000\n",
      "Epoch: 708, Training loss: 1.358498, Validation loss: 1.4451, lr: 0.0000\n",
      "Epoch: 709, Training loss: 1.373008, Validation loss: 1.3775, lr: 0.0000\n",
      "Epoch: 710, Training loss: 1.375809, Validation loss: 1.3718, lr: 0.0000\n",
      "Epoch: 711, Training loss: 1.378732, Validation loss: 1.3962, lr: 0.0000\n",
      "Epoch: 712, Training loss: 1.373081, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 713, Training loss: 1.380954, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 714, Training loss: 1.398968, Validation loss: 1.3898, lr: 0.0000\n",
      "Epoch: 715, Training loss: 1.363755, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 716, Training loss: 1.372502, Validation loss: 1.3476, lr: 0.0000\n",
      "Epoch: 717, Training loss: 1.394584, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 718, Training loss: 1.407970, Validation loss: 1.3701, lr: 0.0000\n",
      "Epoch: 719, Training loss: 1.395528, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 720, Training loss: 1.384364, Validation loss: 1.4012, lr: 0.0000\n",
      "Epoch: 721, Training loss: 1.364445, Validation loss: 1.3780, lr: 0.0000\n",
      "Epoch: 722, Training loss: 1.414108, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 723, Training loss: 1.380995, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 724, Training loss: 1.395181, Validation loss: 1.3786, lr: 0.0000\n",
      "Epoch: 725, Training loss: 1.458800, Validation loss: 1.3789, lr: 0.0000\n",
      "Epoch: 726, Training loss: 1.370519, Validation loss: 1.3717, lr: 0.0000\n",
      "Epoch: 727, Training loss: 1.383224, Validation loss: 1.3582, lr: 0.0000\n",
      "Epoch: 728, Training loss: 1.412654, Validation loss: 1.3919, lr: 0.0000\n",
      "Epoch: 729, Training loss: 1.379190, Validation loss: 1.3796, lr: 0.0000\n",
      "Epoch: 730, Training loss: 1.361838, Validation loss: 1.3552, lr: 0.0000\n",
      "Epoch: 731, Training loss: 1.405056, Validation loss: 1.3704, lr: 0.0000\n",
      "Epoch: 732, Training loss: 1.388180, Validation loss: 1.3952, lr: 0.0000\n",
      "Epoch: 733, Training loss: 1.372542, Validation loss: 1.3624, lr: 0.0000\n",
      "Epoch: 734, Training loss: 1.414177, Validation loss: 1.3753, lr: 0.0000\n",
      "Epoch: 735, Training loss: 1.457580, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 736, Training loss: 1.420874, Validation loss: 1.3763, lr: 0.0000\n",
      "Epoch: 737, Training loss: 1.398657, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 738, Training loss: 1.429447, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 739, Training loss: 1.367812, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 740, Training loss: 1.368635, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 741, Training loss: 1.378220, Validation loss: 1.4030, lr: 0.0000\n",
      "Epoch: 742, Training loss: 1.389941, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 743, Training loss: 1.389215, Validation loss: 1.3723, lr: 0.0000\n",
      "Epoch: 744, Training loss: 1.361118, Validation loss: 1.3559, lr: 0.0000\n",
      "Epoch: 745, Training loss: 1.364392, Validation loss: 1.3891, lr: 0.0000\n",
      "Epoch: 746, Training loss: 1.404045, Validation loss: 1.3742, lr: 0.0000\n",
      "Epoch: 747, Training loss: 1.398714, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 748, Training loss: 1.382987, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 749, Training loss: 1.380599, Validation loss: 1.3797, lr: 0.0000\n",
      "Epoch: 750, Training loss: 1.360288, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 751, Training loss: 1.389143, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 752, Training loss: 1.398893, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 753, Training loss: 1.393547, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 754, Training loss: 1.385117, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 755, Training loss: 1.394858, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 756, Training loss: 1.369775, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 757, Training loss: 1.391578, Validation loss: 1.4058, lr: 0.0000\n",
      "Epoch: 758, Training loss: 1.381542, Validation loss: 1.3885, lr: 0.0000\n",
      "Epoch: 759, Training loss: 1.374798, Validation loss: 1.3785, lr: 0.0000\n",
      "Epoch: 760, Training loss: 1.391226, Validation loss: 1.3956, lr: 0.0000\n",
      "Epoch: 761, Training loss: 1.394683, Validation loss: 1.3734, lr: 0.0000\n",
      "Epoch: 762, Training loss: 1.434990, Validation loss: 1.3729, lr: 0.0000\n",
      "Epoch: 763, Training loss: 1.366191, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 764, Training loss: 1.381416, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 765, Training loss: 1.360938, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 766, Training loss: 1.380599, Validation loss: 1.3723, lr: 0.0000\n",
      "Epoch: 767, Training loss: 1.360485, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 768, Training loss: 1.401440, Validation loss: 1.3751, lr: 0.0000\n",
      "Epoch: 769, Training loss: 1.379115, Validation loss: 1.3798, lr: 0.0000\n",
      "Epoch: 770, Training loss: 1.377837, Validation loss: 1.3874, lr: 0.0000\n",
      "Epoch: 771, Training loss: 1.369306, Validation loss: 1.3794, lr: 0.0000\n",
      "Epoch: 772, Training loss: 1.387093, Validation loss: 1.3740, lr: 0.0000\n",
      "Epoch: 773, Training loss: 1.379593, Validation loss: 1.3876, lr: 0.0000\n",
      "Epoch: 774, Training loss: 1.383634, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 775, Training loss: 1.380251, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 776, Training loss: 1.372353, Validation loss: 1.3794, lr: 0.0000\n",
      "Epoch: 777, Training loss: 1.384742, Validation loss: 1.3789, lr: 0.0000\n",
      "Epoch: 778, Training loss: 1.383077, Validation loss: 1.4028, lr: 0.0000\n",
      "Epoch: 779, Training loss: 1.377735, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 780, Training loss: 1.386581, Validation loss: 1.3774, lr: 0.0000\n",
      "Epoch: 781, Training loss: 1.395817, Validation loss: 1.3688, lr: 0.0000\n",
      "Epoch: 782, Training loss: 1.375184, Validation loss: 1.3743, lr: 0.0000\n",
      "Epoch: 783, Training loss: 1.378615, Validation loss: 1.3702, lr: 0.0000\n",
      "Epoch: 784, Training loss: 1.368243, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 785, Training loss: 1.374465, Validation loss: 1.3712, lr: 0.0000\n",
      "Epoch: 786, Training loss: 1.389163, Validation loss: 1.3735, lr: 0.0000\n",
      "Epoch: 787, Training loss: 1.395836, Validation loss: 1.3705, lr: 0.0000\n",
      "Epoch: 788, Training loss: 1.373300, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 789, Training loss: 1.408779, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 790, Training loss: 1.382173, Validation loss: 1.3778, lr: 0.0000\n",
      "Epoch: 791, Training loss: 1.388201, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 792, Training loss: 1.380400, Validation loss: 1.3781, lr: 0.0000\n",
      "Epoch: 793, Training loss: 1.394196, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 794, Training loss: 1.398648, Validation loss: 1.3884, lr: 0.0000\n",
      "Epoch: 795, Training loss: 1.452607, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 796, Training loss: 1.399958, Validation loss: 1.3956, lr: 0.0000\n",
      "Epoch: 797, Training loss: 1.372069, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 798, Training loss: 1.383192, Validation loss: 1.3665, lr: 0.0000\n",
      "Epoch: 799, Training loss: 1.397767, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 800, Training loss: 1.417487, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 801, Training loss: 1.376483, Validation loss: 1.3776, lr: 0.0000\n",
      "Epoch: 802, Training loss: 1.385429, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 803, Training loss: 1.438709, Validation loss: 1.3739, lr: 0.0000\n",
      "Epoch: 804, Training loss: 1.346638, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 805, Training loss: 1.418415, Validation loss: 1.3727, lr: 0.0000\n",
      "Epoch: 806, Training loss: 1.392671, Validation loss: 1.3746, lr: 0.0000\n",
      "Epoch: 807, Training loss: 1.430712, Validation loss: 1.3773, lr: 0.0000\n",
      "Epoch: 808, Training loss: 1.385661, Validation loss: 1.3797, lr: 0.0000\n",
      "Epoch: 809, Training loss: 1.387274, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 810, Training loss: 1.386697, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 811, Training loss: 1.368420, Validation loss: 1.3781, lr: 0.0000\n",
      "Epoch: 812, Training loss: 1.399715, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 813, Training loss: 1.379007, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 814, Training loss: 1.401681, Validation loss: 1.3778, lr: 0.0000\n",
      "Epoch: 815, Training loss: 1.377491, Validation loss: 1.3696, lr: 0.0000\n",
      "Epoch: 816, Training loss: 1.352569, Validation loss: 1.3985, lr: 0.0000\n",
      "Epoch: 817, Training loss: 1.371632, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 818, Training loss: 1.384154, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 819, Training loss: 1.383769, Validation loss: 1.3795, lr: 0.0000\n",
      "Epoch: 820, Training loss: 1.371914, Validation loss: 1.3694, lr: 0.0000\n",
      "Epoch: 821, Training loss: 1.376524, Validation loss: 1.3662, lr: 0.0000\n",
      "Epoch: 822, Training loss: 1.440339, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 823, Training loss: 1.432615, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 824, Training loss: 1.416366, Validation loss: 1.3631, lr: 0.0000\n",
      "Epoch: 825, Training loss: 1.371916, Validation loss: 1.3786, lr: 0.0000\n",
      "Epoch: 826, Training loss: 1.369175, Validation loss: 1.3781, lr: 0.0000\n",
      "Epoch: 827, Training loss: 1.364173, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 828, Training loss: 1.392256, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 829, Training loss: 1.409589, Validation loss: 1.3603, lr: 0.0000\n",
      "Epoch: 830, Training loss: 1.399680, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 831, Training loss: 1.398759, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 832, Training loss: 1.410775, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 833, Training loss: 1.359256, Validation loss: 1.3884, lr: 0.0000\n",
      "Epoch: 834, Training loss: 1.386755, Validation loss: 1.3750, lr: 0.0000\n",
      "Epoch: 835, Training loss: 1.386329, Validation loss: 1.4146, lr: 0.0000\n",
      "Epoch: 836, Training loss: 1.432044, Validation loss: 1.3769, lr: 0.0000\n",
      "Epoch: 837, Training loss: 1.409886, Validation loss: 1.3882, lr: 0.0000\n",
      "Epoch: 838, Training loss: 1.384817, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 839, Training loss: 1.394147, Validation loss: 1.3961, lr: 0.0000\n",
      "Epoch: 840, Training loss: 1.370085, Validation loss: 1.3711, lr: 0.0000\n",
      "Epoch: 841, Training loss: 1.446115, Validation loss: 1.3784, lr: 0.0000\n",
      "Epoch: 842, Training loss: 1.374354, Validation loss: 1.3633, lr: 0.0000\n",
      "Epoch: 843, Training loss: 1.369740, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 844, Training loss: 1.399891, Validation loss: 1.4045, lr: 0.0000\n",
      "Epoch: 845, Training loss: 1.380597, Validation loss: 1.3523, lr: 0.0000\n",
      "Epoch: 846, Training loss: 1.398234, Validation loss: 1.3684, lr: 0.0000\n",
      "Epoch: 847, Training loss: 1.371396, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 848, Training loss: 1.385936, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 849, Training loss: 1.397019, Validation loss: 1.3597, lr: 0.0000\n",
      "Epoch: 850, Training loss: 1.368246, Validation loss: 1.3791, lr: 0.0000\n",
      "Epoch: 851, Training loss: 1.386208, Validation loss: 1.3754, lr: 0.0000\n",
      "Epoch: 852, Training loss: 1.387161, Validation loss: 1.3791, lr: 0.0000\n",
      "Epoch: 853, Training loss: 1.390628, Validation loss: 1.3637, lr: 0.0000\n",
      "Epoch: 854, Training loss: 1.385936, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 855, Training loss: 1.380163, Validation loss: 1.3588, lr: 0.0000\n",
      "Epoch: 856, Training loss: 1.382900, Validation loss: 1.3789, lr: 0.0000\n",
      "Epoch: 857, Training loss: 1.416048, Validation loss: 1.3756, lr: 0.0000\n",
      "Epoch: 858, Training loss: 1.369452, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 859, Training loss: 1.387964, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 860, Training loss: 1.384632, Validation loss: 1.3944, lr: 0.0000\n",
      "Epoch: 861, Training loss: 1.405508, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 862, Training loss: 1.445709, Validation loss: 1.3743, lr: 0.0000\n",
      "Epoch: 863, Training loss: 1.403381, Validation loss: 1.3787, lr: 0.0000\n",
      "Epoch: 864, Training loss: 1.359356, Validation loss: 1.3972, lr: 0.0000\n",
      "Epoch: 865, Training loss: 1.393891, Validation loss: 1.3721, lr: 0.0000\n",
      "Epoch: 866, Training loss: 1.405418, Validation loss: 1.4930, lr: 0.0000\n",
      "Epoch: 867, Training loss: 1.385496, Validation loss: 1.3764, lr: 0.0000\n",
      "Epoch: 868, Training loss: 1.393406, Validation loss: 1.3798, lr: 0.0000\n",
      "Epoch: 869, Training loss: 1.419964, Validation loss: 1.3678, lr: 0.0000\n",
      "Epoch: 870, Training loss: 1.367059, Validation loss: 1.3752, lr: 0.0000\n",
      "Epoch: 871, Training loss: 1.381057, Validation loss: 1.3776, lr: 0.0000\n",
      "Epoch: 872, Training loss: 1.381906, Validation loss: 1.3772, lr: 0.0000\n",
      "Epoch: 873, Training loss: 1.377709, Validation loss: 1.3616, lr: 0.0000\n",
      "Epoch: 874, Training loss: 1.388861, Validation loss: 1.3467, lr: 0.0000\n",
      "Epoch: 875, Training loss: 1.377577, Validation loss: 1.3899, lr: 0.0000\n",
      "Epoch: 876, Training loss: 1.369056, Validation loss: 1.4393, lr: 0.0000\n",
      "Epoch: 877, Training loss: 1.374587, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 878, Training loss: 1.367286, Validation loss: 1.3877, lr: 0.0000\n",
      "Epoch: 879, Training loss: 1.381704, Validation loss: 1.3774, lr: 0.0000\n",
      "Epoch: 880, Training loss: 1.389504, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 881, Training loss: 1.395124, Validation loss: 1.3876, lr: 0.0000\n",
      "Epoch: 882, Training loss: 1.375384, Validation loss: 1.3759, lr: 0.0000\n",
      "Epoch: 883, Training loss: 1.393161, Validation loss: 1.3661, lr: 0.0000\n",
      "Epoch: 884, Training loss: 1.385572, Validation loss: 1.3724, lr: 0.0000\n",
      "Epoch: 885, Training loss: 1.361572, Validation loss: 1.3674, lr: 0.0000\n",
      "Epoch: 886, Training loss: 1.434175, Validation loss: 1.3803, lr: 0.0000\n",
      "Epoch: 887, Training loss: 1.379428, Validation loss: 1.3789, lr: 0.0000\n",
      "Epoch: 888, Training loss: 1.374214, Validation loss: 1.3681, lr: 0.0000\n",
      "Epoch: 889, Training loss: 1.386001, Validation loss: 1.3748, lr: 0.0000\n",
      "Epoch: 890, Training loss: 1.372624, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 891, Training loss: 1.390805, Validation loss: 1.3903, lr: 0.0000\n",
      "Epoch: 892, Training loss: 1.380444, Validation loss: 1.3733, lr: 0.0000\n",
      "Epoch: 893, Training loss: 1.360024, Validation loss: 1.3793, lr: 0.0000\n",
      "Epoch: 894, Training loss: 1.383967, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 895, Training loss: 1.389162, Validation loss: 1.3605, lr: 0.0000\n",
      "Epoch: 896, Training loss: 1.365003, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 897, Training loss: 1.365604, Validation loss: 1.3660, lr: 0.0000\n",
      "Epoch: 898, Training loss: 1.506820, Validation loss: 1.3903, lr: 0.0000\n",
      "Epoch: 899, Training loss: 1.421885, Validation loss: 1.3795, lr: 0.0000\n",
      "Epoch: 900, Training loss: 1.376196, Validation loss: 1.3919, lr: 0.0000\n",
      "Epoch: 901, Training loss: 1.374019, Validation loss: 1.3789, lr: 0.0000\n",
      "Epoch: 902, Training loss: 1.409504, Validation loss: 1.3927, lr: 0.0000\n",
      "Epoch: 903, Training loss: 1.400777, Validation loss: 1.3796, lr: 0.0000\n",
      "Epoch: 904, Training loss: 1.373231, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 905, Training loss: 1.384054, Validation loss: 1.3882, lr: 0.0000\n",
      "Epoch: 906, Training loss: 1.353119, Validation loss: 1.3764, lr: 0.0000\n",
      "Epoch: 907, Training loss: 1.389567, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 908, Training loss: 1.377131, Validation loss: 1.3757, lr: 0.0000\n",
      "Epoch: 909, Training loss: 1.373074, Validation loss: 1.4441, lr: 0.0000\n",
      "Epoch: 910, Training loss: 1.387478, Validation loss: 1.3913, lr: 0.0000\n",
      "Epoch: 911, Training loss: 1.374265, Validation loss: 1.3718, lr: 0.0000\n",
      "Epoch: 912, Training loss: 1.398056, Validation loss: 1.3713, lr: 0.0000\n",
      "Epoch: 913, Training loss: 1.391446, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 914, Training loss: 1.387656, Validation loss: 1.3675, lr: 0.0000\n",
      "Epoch: 915, Training loss: 1.371479, Validation loss: 1.3933, lr: 0.0000\n",
      "Epoch: 916, Training loss: 1.364855, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 917, Training loss: 1.381257, Validation loss: 1.3793, lr: 0.0000\n",
      "Epoch: 918, Training loss: 1.360564, Validation loss: 1.4047, lr: 0.0000\n",
      "Epoch: 919, Training loss: 1.380226, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 920, Training loss: 1.369815, Validation loss: 1.3803, lr: 0.0000\n",
      "Epoch: 921, Training loss: 1.380387, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 922, Training loss: 1.419234, Validation loss: 1.3615, lr: 0.0000\n",
      "Epoch: 923, Training loss: 1.361884, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 924, Training loss: 1.401571, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 925, Training loss: 1.410017, Validation loss: 1.3773, lr: 0.0000\n",
      "Epoch: 926, Training loss: 1.364233, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 927, Training loss: 1.382973, Validation loss: 1.3898, lr: 0.0000\n",
      "Epoch: 928, Training loss: 1.377539, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 929, Training loss: 1.413286, Validation loss: 1.3757, lr: 0.0000\n",
      "Epoch: 930, Training loss: 1.407048, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 931, Training loss: 1.376575, Validation loss: 1.3734, lr: 0.0000\n",
      "Epoch: 932, Training loss: 1.380852, Validation loss: 1.3702, lr: 0.0000\n",
      "Epoch: 933, Training loss: 1.371107, Validation loss: 1.3885, lr: 0.0000\n",
      "Epoch: 934, Training loss: 1.380215, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 935, Training loss: 1.379272, Validation loss: 1.3670, lr: 0.0000\n",
      "Epoch: 936, Training loss: 1.394603, Validation loss: 1.3752, lr: 0.0000\n",
      "Epoch: 937, Training loss: 1.385355, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 938, Training loss: 1.408309, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 939, Training loss: 1.377342, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 940, Training loss: 1.404870, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 941, Training loss: 1.371038, Validation loss: 1.3794, lr: 0.0000\n",
      "Epoch: 942, Training loss: 1.455902, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 943, Training loss: 1.377721, Validation loss: 1.3748, lr: 0.0000\n",
      "Epoch: 944, Training loss: 1.397170, Validation loss: 1.3729, lr: 0.0000\n",
      "Epoch: 945, Training loss: 1.368666, Validation loss: 1.3885, lr: 0.0000\n",
      "Epoch: 946, Training loss: 1.411704, Validation loss: 1.3732, lr: 0.0000\n",
      "Epoch: 947, Training loss: 1.364829, Validation loss: 1.6452, lr: 0.0000\n",
      "Epoch: 948, Training loss: 1.371518, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 949, Training loss: 1.378461, Validation loss: 1.4007, lr: 0.0000\n",
      "Epoch: 950, Training loss: 1.376849, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 951, Training loss: 1.414123, Validation loss: 1.3646, lr: 0.0000\n",
      "Epoch: 952, Training loss: 1.369550, Validation loss: 1.3934, lr: 0.0000\n",
      "Epoch: 953, Training loss: 1.371579, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 954, Training loss: 1.402032, Validation loss: 1.3712, lr: 0.0000\n",
      "Epoch: 955, Training loss: 1.374749, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 956, Training loss: 1.380860, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 957, Training loss: 1.366613, Validation loss: 1.3871, lr: 0.0000\n",
      "Epoch: 958, Training loss: 1.388203, Validation loss: 1.3809, lr: 0.0000\n",
      "Epoch: 959, Training loss: 1.395899, Validation loss: 1.3401, lr: 0.0000\n",
      "Epoch: 960, Training loss: 1.381954, Validation loss: 1.4153, lr: 0.0000\n",
      "Epoch: 961, Training loss: 1.426962, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 962, Training loss: 1.383775, Validation loss: 1.5133, lr: 0.0000\n",
      "Epoch: 963, Training loss: 1.392077, Validation loss: 1.3581, lr: 0.0000\n",
      "Epoch: 964, Training loss: 1.380730, Validation loss: 1.3769, lr: 0.0000\n",
      "Epoch: 965, Training loss: 1.403863, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 966, Training loss: 1.548717, Validation loss: 1.3788, lr: 0.0000\n",
      "Epoch: 967, Training loss: 1.352438, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 968, Training loss: 1.364777, Validation loss: 1.3916, lr: 0.0000\n",
      "Epoch: 969, Training loss: 1.377152, Validation loss: 1.3802, lr: 0.0000\n",
      "Epoch: 970, Training loss: 1.377173, Validation loss: 1.3749, lr: 0.0000\n",
      "Epoch: 971, Training loss: 1.377334, Validation loss: 1.3735, lr: 0.0000\n",
      "Epoch: 972, Training loss: 1.382448, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 973, Training loss: 1.377860, Validation loss: 1.3739, lr: 0.0000\n",
      "Epoch: 974, Training loss: 1.366855, Validation loss: 1.3788, lr: 0.0000\n",
      "Epoch: 975, Training loss: 1.397076, Validation loss: 1.4038, lr: 0.0000\n",
      "Epoch: 976, Training loss: 1.381311, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 977, Training loss: 1.410638, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 978, Training loss: 1.373964, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 979, Training loss: 1.421648, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 980, Training loss: 1.373861, Validation loss: 1.3659, lr: 0.0000\n",
      "Epoch: 981, Training loss: 1.383722, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 982, Training loss: 1.427319, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 983, Training loss: 1.364223, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 984, Training loss: 1.375979, Validation loss: 1.3794, lr: 0.0000\n",
      "Epoch: 985, Training loss: 1.375545, Validation loss: 1.3877, lr: 0.0000\n",
      "Epoch: 986, Training loss: 1.401777, Validation loss: 1.3924, lr: 0.0000\n",
      "Epoch: 987, Training loss: 1.410872, Validation loss: 1.3671, lr: 0.0000\n",
      "Epoch: 988, Training loss: 1.395354, Validation loss: 1.3741, lr: 0.0000\n",
      "Epoch: 989, Training loss: 1.381988, Validation loss: 1.3796, lr: 0.0000\n",
      "Epoch: 990, Training loss: 1.386964, Validation loss: 1.3920, lr: 0.0000\n",
      "Epoch: 991, Training loss: 1.360381, Validation loss: 1.3467, lr: 0.0000\n",
      "Epoch: 992, Training loss: 1.376998, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 993, Training loss: 1.371159, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 994, Training loss: 1.348904, Validation loss: 1.3738, lr: 0.0000\n",
      "Epoch: 995, Training loss: 1.358614, Validation loss: 1.3633, lr: 0.0000\n",
      "Epoch: 996, Training loss: 1.366627, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 997, Training loss: 1.389633, Validation loss: 1.3635, lr: 0.0000\n",
      "Epoch: 998, Training loss: 1.392216, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 999, Training loss: 1.372059, Validation loss: 1.3809, lr: 0.0000\n",
      "Final test loss: 1.3870\n",
      "=== Run 08/10 ===\n",
      "\n",
      "---- Settings: \n",
      "\n",
      "epochs : 1000\n",
      "hidden_channels : [32]\n",
      "out_channels : 10\n",
      "inner_product_features : False\n",
      "batch_size : 64\n",
      "lr : 0.01\n",
      "momentum : 0.9\n",
      "dropout : 0.0\n",
      "batch_norm : batch_norm\n",
      "bias : True\n",
      "order : 2\n",
      "diffusion : True\n",
      "frac_sampled_nb : -1\n",
      "include_positions : False\n",
      "include_self : True\n",
      "vec_norm : False\n",
      "emb_norm : False\n",
      "seed : 0\n",
      "dim_signal : 100\n",
      "dim_emb : 100\n",
      "n_sampled_nb : -1\n",
      "\n",
      "---- Number of features to pass to the MLP:  1010100\n",
      "---- Total number of parameters:  32323627\n",
      "\n",
      "Using device cuda:0\n",
      "\n",
      "---- Training network ...\n",
      "\n",
      "---- Timestamp: 20250615-035928\n",
      "\n",
      " *och: 0, Training loss: 1.473513, Validation loss: 1.5345, lr: 0.0100\n",
      " *och: 1, Training loss: 1.387978, Validation loss: 1.3669, lr: 0.0100\n",
      " *och: 2, Training loss: 1.389019, Validation loss: 1.3636, lr: 0.0100\n",
      "Epoch: 3, Training loss: 1.386112, Validation loss: 1.3953, lr: 0.0100\n",
      "Epoch: 4, Training loss: 1.396664, Validation loss: 1.4073, lr: 0.0100\n",
      "Epoch: 5, Training loss: 1.378601, Validation loss: 1.3657, lr: 0.0100\n",
      "Epoch: 6, Training loss: 1.382695, Validation loss: 1.3923, lr: 0.0100\n",
      "Epoch: 7, Training loss: 1.375426, Validation loss: 1.3851, lr: 0.0100\n",
      "Epoch: 8, Training loss: 1.383188, Validation loss: 1.3969, lr: 0.0100\n",
      "Epoch: 9, Training loss: 1.389151, Validation loss: 1.3749, lr: 0.0100\n",
      "Epoch: 10, Training loss: 1.394668, Validation loss: 1.3844, lr: 0.0100\n",
      "Epoch: 11, Training loss: 1.374939, Validation loss: 1.3932, lr: 0.0100\n",
      "Epoch: 12, Training loss: 1.412048, Validation loss: 1.4070, lr: 0.0100\n",
      "Epoch: 13, Training loss: 1.359531, Validation loss: 1.4090, lr: 0.0100\n",
      "Epoch: 14, Training loss: 1.392340, Validation loss: 1.3884, lr: 0.0100\n",
      "Epoch: 15, Training loss: 1.374691, Validation loss: 1.3849, lr: 0.0100\n",
      " *och: 16, Training loss: 1.383796, Validation loss: 1.3634, lr: 0.0100\n",
      "Epoch: 17, Training loss: 1.376393, Validation loss: 1.3856, lr: 0.0100\n",
      "Epoch: 18, Training loss: 1.387337, Validation loss: 1.4558, lr: 0.0100\n",
      "Epoch: 19, Training loss: 1.379612, Validation loss: 1.4791, lr: 0.0100\n",
      "Epoch: 20, Training loss: 1.367228, Validation loss: 1.3736, lr: 0.0100\n",
      "Epoch: 21, Training loss: 1.384059, Validation loss: 1.3874, lr: 0.0100\n",
      "Epoch: 22, Training loss: 1.382924, Validation loss: 1.3652, lr: 0.0100\n",
      "Epoch: 23, Training loss: 1.365784, Validation loss: 1.3725, lr: 0.0100\n",
      "Epoch: 24, Training loss: 1.372640, Validation loss: 1.3754, lr: 0.0010\n",
      "Epoch: 25, Training loss: 1.358520, Validation loss: 1.3859, lr: 0.0010\n",
      " *och: 26, Training loss: 1.399576, Validation loss: 1.3571, lr: 0.0010\n",
      "Epoch: 27, Training loss: 1.383360, Validation loss: 1.3882, lr: 0.0010\n",
      "Epoch: 28, Training loss: 1.387001, Validation loss: 1.3762, lr: 0.0010\n",
      "Epoch: 29, Training loss: 1.370688, Validation loss: 1.3754, lr: 0.0010\n",
      "Epoch: 30, Training loss: 1.359548, Validation loss: 1.3851, lr: 0.0010\n",
      "Epoch: 31, Training loss: 1.367000, Validation loss: 1.3714, lr: 0.0010\n",
      "Epoch: 32, Training loss: 1.379253, Validation loss: 1.3837, lr: 0.0010\n",
      "Epoch: 33, Training loss: 1.384708, Validation loss: 1.3867, lr: 0.0010\n",
      "Epoch: 34, Training loss: 1.354154, Validation loss: 1.3892, lr: 0.0010\n",
      "Epoch: 35, Training loss: 1.384799, Validation loss: 1.3834, lr: 0.0010\n",
      "Epoch: 36, Training loss: 1.354190, Validation loss: 1.3788, lr: 0.0010\n",
      "Epoch: 37, Training loss: 1.350359, Validation loss: 1.3938, lr: 0.0010\n",
      "Epoch: 38, Training loss: 1.360974, Validation loss: 1.3769, lr: 0.0010\n",
      "Epoch: 39, Training loss: 1.384931, Validation loss: 1.3736, lr: 0.0010\n",
      "Epoch: 40, Training loss: 1.372087, Validation loss: 1.3799, lr: 0.0010\n",
      "Epoch: 41, Training loss: 1.367461, Validation loss: 1.9284, lr: 0.0010\n",
      "Epoch: 42, Training loss: 1.369357, Validation loss: 1.3826, lr: 0.0010\n",
      "Epoch: 43, Training loss: 1.401753, Validation loss: 1.3843, lr: 0.0010\n",
      "Epoch: 44, Training loss: 1.360703, Validation loss: 1.3728, lr: 0.0010\n",
      "Epoch: 45, Training loss: 1.358428, Validation loss: 1.3829, lr: 0.0010\n",
      "Epoch: 46, Training loss: 1.403865, Validation loss: 1.3748, lr: 0.0010\n",
      "Epoch: 47, Training loss: 1.358004, Validation loss: 1.3862, lr: 0.0010\n",
      "Epoch: 48, Training loss: 1.373671, Validation loss: 1.3847, lr: 0.0001\n",
      "Epoch: 49, Training loss: 1.374739, Validation loss: 1.3839, lr: 0.0001\n",
      "Epoch: 50, Training loss: 1.379579, Validation loss: 1.3726, lr: 0.0001\n",
      "Epoch: 51, Training loss: 1.365147, Validation loss: 1.3868, lr: 0.0001\n",
      "Epoch: 52, Training loss: 1.384211, Validation loss: 1.3586, lr: 0.0001\n",
      "Epoch: 53, Training loss: 1.356025, Validation loss: 1.3762, lr: 0.0001\n",
      "Epoch: 54, Training loss: 1.357934, Validation loss: 1.3701, lr: 0.0001\n",
      "Epoch: 55, Training loss: 1.357627, Validation loss: 1.3684, lr: 0.0001\n",
      "Epoch: 56, Training loss: 1.366393, Validation loss: 1.3640, lr: 0.0001\n",
      "Epoch: 57, Training loss: 1.372840, Validation loss: 1.3649, lr: 0.0001\n",
      "Epoch: 58, Training loss: 1.355644, Validation loss: 1.3694, lr: 0.0001\n",
      " *och: 59, Training loss: 1.369069, Validation loss: 1.3566, lr: 0.0000\n",
      "Epoch: 60, Training loss: 1.408531, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 61, Training loss: 1.352761, Validation loss: 1.3771, lr: 0.0000\n",
      "Epoch: 62, Training loss: 1.399695, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 63, Training loss: 1.356298, Validation loss: 1.4134, lr: 0.0000\n",
      "Epoch: 64, Training loss: 1.366382, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 65, Training loss: 1.359053, Validation loss: 1.3684, lr: 0.0000\n",
      "Epoch: 66, Training loss: 1.386321, Validation loss: 1.3795, lr: 0.0000\n",
      "Epoch: 67, Training loss: 1.364823, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 68, Training loss: 1.404960, Validation loss: 1.3795, lr: 0.0000\n",
      "Epoch: 69, Training loss: 1.442397, Validation loss: 1.3681, lr: 0.0000\n",
      "Epoch: 70, Training loss: 1.379161, Validation loss: 1.3668, lr: 0.0000\n",
      "Epoch: 71, Training loss: 1.371236, Validation loss: 1.3646, lr: 0.0000\n",
      "Epoch: 72, Training loss: 1.364501, Validation loss: 1.4145, lr: 0.0000\n",
      "Epoch: 73, Training loss: 1.362751, Validation loss: 1.3778, lr: 0.0000\n",
      "Epoch: 74, Training loss: 1.408891, Validation loss: 1.3757, lr: 0.0000\n",
      "Epoch: 75, Training loss: 1.356586, Validation loss: 1.3887, lr: 0.0000\n",
      "Epoch: 76, Training loss: 1.367772, Validation loss: 1.3675, lr: 0.0000\n",
      "Epoch: 77, Training loss: 1.395183, Validation loss: 1.3776, lr: 0.0000\n",
      "Epoch: 78, Training loss: 1.360274, Validation loss: 1.3791, lr: 0.0000\n",
      "Epoch: 79, Training loss: 1.368783, Validation loss: 1.3922, lr: 0.0000\n",
      "Epoch: 80, Training loss: 1.372584, Validation loss: 1.3739, lr: 0.0000\n",
      "Epoch: 81, Training loss: 1.372439, Validation loss: 1.3809, lr: 0.0000\n",
      "Epoch: 82, Training loss: 1.381170, Validation loss: 1.4142, lr: 0.0000\n",
      "Epoch: 83, Training loss: 1.368123, Validation loss: 1.3765, lr: 0.0000\n",
      "Epoch: 84, Training loss: 1.434857, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 85, Training loss: 1.374695, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 86, Training loss: 1.380748, Validation loss: 1.3771, lr: 0.0000\n",
      "Epoch: 87, Training loss: 1.369740, Validation loss: 1.3763, lr: 0.0000\n",
      "Epoch: 88, Training loss: 1.360618, Validation loss: 1.3900, lr: 0.0000\n",
      "Epoch: 89, Training loss: 1.358934, Validation loss: 1.4635, lr: 0.0000\n",
      "Epoch: 90, Training loss: 1.391773, Validation loss: 1.3783, lr: 0.0000\n",
      "Epoch: 91, Training loss: 1.373178, Validation loss: 1.3761, lr: 0.0000\n",
      "Epoch: 92, Training loss: 1.361522, Validation loss: 1.4533, lr: 0.0000\n",
      "Epoch: 93, Training loss: 1.370994, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 94, Training loss: 1.358479, Validation loss: 1.3761, lr: 0.0000\n",
      "Epoch: 95, Training loss: 1.388583, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 96, Training loss: 1.363454, Validation loss: 1.4880, lr: 0.0000\n",
      "Epoch: 97, Training loss: 1.388139, Validation loss: 1.3766, lr: 0.0000\n",
      "Epoch: 98, Training loss: 1.373768, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 99, Training loss: 1.390845, Validation loss: 1.3797, lr: 0.0000\n",
      "Epoch: 100, Training loss: 1.366933, Validation loss: 1.3726, lr: 0.0000\n",
      "Epoch: 101, Training loss: 1.364188, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 102, Training loss: 1.398868, Validation loss: 1.3709, lr: 0.0000\n",
      "Epoch: 103, Training loss: 1.376225, Validation loss: 1.3774, lr: 0.0000\n",
      "Epoch: 104, Training loss: 1.366195, Validation loss: 1.3800, lr: 0.0000\n",
      "Epoch: 105, Training loss: 1.369665, Validation loss: 1.3972, lr: 0.0000\n",
      "Epoch: 106, Training loss: 1.365240, Validation loss: 1.3915, lr: 0.0000\n",
      "Epoch: 107, Training loss: 1.365734, Validation loss: 1.3788, lr: 0.0000\n",
      "Epoch: 108, Training loss: 1.362365, Validation loss: 1.4150, lr: 0.0000\n",
      "Epoch: 109, Training loss: 1.362607, Validation loss: 1.4231, lr: 0.0000\n",
      "Epoch: 110, Training loss: 1.347894, Validation loss: 1.3795, lr: 0.0000\n",
      "Epoch: 111, Training loss: 1.364750, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 112, Training loss: 1.356948, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 113, Training loss: 1.347772, Validation loss: 1.3935, lr: 0.0000\n",
      "Epoch: 114, Training loss: 1.394835, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 115, Training loss: 1.349259, Validation loss: 1.3785, lr: 0.0000\n",
      "Epoch: 116, Training loss: 1.382065, Validation loss: 1.3770, lr: 0.0000\n",
      "Epoch: 117, Training loss: 1.367986, Validation loss: 1.4235, lr: 0.0000\n",
      "Epoch: 118, Training loss: 1.341584, Validation loss: 1.3678, lr: 0.0000\n",
      "Epoch: 119, Training loss: 1.367902, Validation loss: 1.3687, lr: 0.0000\n",
      "Epoch: 120, Training loss: 1.360951, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 121, Training loss: 1.358332, Validation loss: 1.3913, lr: 0.0000\n",
      "Epoch: 122, Training loss: 1.369866, Validation loss: 1.3917, lr: 0.0000\n",
      "Epoch: 123, Training loss: 1.377788, Validation loss: 1.3928, lr: 0.0000\n",
      " *och: 124, Training loss: 1.385536, Validation loss: 1.3549, lr: 0.0000\n",
      "Epoch: 125, Training loss: 1.426393, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 126, Training loss: 1.356073, Validation loss: 1.3678, lr: 0.0000\n",
      "Epoch: 127, Training loss: 1.364583, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 128, Training loss: 1.407298, Validation loss: 1.4740, lr: 0.0000\n",
      "Epoch: 129, Training loss: 1.351704, Validation loss: 1.3795, lr: 0.0000\n",
      "Epoch: 130, Training loss: 1.430488, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 131, Training loss: 1.383177, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 132, Training loss: 1.363858, Validation loss: 1.3881, lr: 0.0000\n",
      "Epoch: 133, Training loss: 1.379483, Validation loss: 1.3767, lr: 0.0000\n",
      "Epoch: 134, Training loss: 1.353735, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 135, Training loss: 1.365664, Validation loss: 1.3751, lr: 0.0000\n",
      "Epoch: 136, Training loss: 1.399539, Validation loss: 1.3698, lr: 0.0000\n",
      "Epoch: 137, Training loss: 1.366923, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 138, Training loss: 1.376691, Validation loss: 1.3913, lr: 0.0000\n",
      "Epoch: 139, Training loss: 1.390101, Validation loss: 1.3760, lr: 0.0000\n",
      "Epoch: 140, Training loss: 1.355727, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 141, Training loss: 1.355000, Validation loss: 1.3739, lr: 0.0000\n",
      "Epoch: 142, Training loss: 1.422295, Validation loss: 1.3981, lr: 0.0000\n",
      "Epoch: 143, Training loss: 1.350167, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 144, Training loss: 1.371950, Validation loss: 1.3555, lr: 0.0000\n",
      "Epoch: 145, Training loss: 1.378209, Validation loss: 1.4102, lr: 0.0000\n",
      "Epoch: 146, Training loss: 1.355759, Validation loss: 1.3797, lr: 0.0000\n",
      "Epoch: 147, Training loss: 1.373908, Validation loss: 1.3744, lr: 0.0000\n",
      "Epoch: 148, Training loss: 1.381639, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 149, Training loss: 1.347069, Validation loss: 1.3692, lr: 0.0000\n",
      "Epoch: 150, Training loss: 1.376174, Validation loss: 1.4047, lr: 0.0000\n",
      " *och: 151, Training loss: 1.359628, Validation loss: 1.3426, lr: 0.0000\n",
      "Epoch: 152, Training loss: 1.331190, Validation loss: 1.3583, lr: 0.0000\n",
      "Epoch: 153, Training loss: 1.364075, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 154, Training loss: 1.375538, Validation loss: 1.3756, lr: 0.0000\n",
      "Epoch: 155, Training loss: 1.393939, Validation loss: 1.3723, lr: 0.0000\n",
      "Epoch: 156, Training loss: 1.386999, Validation loss: 1.3770, lr: 0.0000\n",
      "Epoch: 157, Training loss: 1.400976, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 158, Training loss: 1.374781, Validation loss: 1.3754, lr: 0.0000\n",
      "Epoch: 159, Training loss: 1.356296, Validation loss: 1.3776, lr: 0.0000\n",
      "Epoch: 160, Training loss: 1.368572, Validation loss: 1.3784, lr: 0.0000\n",
      "Epoch: 161, Training loss: 1.364519, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 162, Training loss: 1.373072, Validation loss: 1.4091, lr: 0.0000\n",
      "Epoch: 163, Training loss: 1.352170, Validation loss: 1.3657, lr: 0.0000\n",
      "Epoch: 164, Training loss: 1.383958, Validation loss: 1.3888, lr: 0.0000\n",
      "Epoch: 165, Training loss: 1.356341, Validation loss: 1.3743, lr: 0.0000\n",
      "Epoch: 166, Training loss: 1.352072, Validation loss: 1.4178, lr: 0.0000\n",
      "Epoch: 167, Training loss: 1.368627, Validation loss: 1.3771, lr: 0.0000\n",
      "Epoch: 168, Training loss: 1.375757, Validation loss: 1.3889, lr: 0.0000\n",
      "Epoch: 169, Training loss: 1.389415, Validation loss: 1.3893, lr: 0.0000\n",
      "Epoch: 170, Training loss: 1.374471, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 171, Training loss: 1.367103, Validation loss: 1.3783, lr: 0.0000\n",
      "Epoch: 172, Training loss: 1.354359, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 173, Training loss: 1.369437, Validation loss: 1.3732, lr: 0.0000\n",
      "Epoch: 174, Training loss: 1.386738, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 175, Training loss: 1.368513, Validation loss: 1.4856, lr: 0.0000\n",
      "Epoch: 176, Training loss: 1.371703, Validation loss: 1.3978, lr: 0.0000\n",
      "Epoch: 177, Training loss: 1.339371, Validation loss: 1.3704, lr: 0.0000\n",
      " *och: 178, Training loss: 1.368107, Validation loss: 1.3385, lr: 0.0000\n",
      "Epoch: 179, Training loss: 1.342486, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 180, Training loss: 1.364823, Validation loss: 1.3797, lr: 0.0000\n",
      "Epoch: 181, Training loss: 1.376676, Validation loss: 1.3789, lr: 0.0000\n",
      "Epoch: 182, Training loss: 1.356973, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 183, Training loss: 1.369983, Validation loss: 1.3628, lr: 0.0000\n",
      "Epoch: 184, Training loss: 1.340104, Validation loss: 1.3796, lr: 0.0000\n",
      "Epoch: 185, Training loss: 1.375416, Validation loss: 1.3618, lr: 0.0000\n",
      "Epoch: 186, Training loss: 1.364693, Validation loss: 1.3911, lr: 0.0000\n",
      "Epoch: 187, Training loss: 1.375065, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 188, Training loss: 1.373948, Validation loss: 1.3797, lr: 0.0000\n",
      "Epoch: 189, Training loss: 1.359892, Validation loss: 1.3773, lr: 0.0000\n",
      "Epoch: 190, Training loss: 1.411874, Validation loss: 1.3595, lr: 0.0000\n",
      "Epoch: 191, Training loss: 1.361584, Validation loss: 1.4198, lr: 0.0000\n",
      "Epoch: 192, Training loss: 1.374399, Validation loss: 1.3754, lr: 0.0000\n",
      "Epoch: 193, Training loss: 1.378554, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 194, Training loss: 1.349987, Validation loss: 1.3674, lr: 0.0000\n",
      "Epoch: 195, Training loss: 1.394284, Validation loss: 1.3725, lr: 0.0000\n",
      "Epoch: 196, Training loss: 1.379613, Validation loss: 1.3561, lr: 0.0000\n",
      "Epoch: 197, Training loss: 1.360694, Validation loss: 1.3696, lr: 0.0000\n",
      "Epoch: 198, Training loss: 1.381481, Validation loss: 1.3724, lr: 0.0000\n",
      "Epoch: 199, Training loss: 1.426817, Validation loss: 1.3948, lr: 0.0000\n",
      "Epoch: 200, Training loss: 1.376832, Validation loss: 1.3918, lr: 0.0000\n",
      "Epoch: 201, Training loss: 1.397043, Validation loss: 1.4535, lr: 0.0000\n",
      "Epoch: 202, Training loss: 1.351127, Validation loss: 1.4204, lr: 0.0000\n",
      "Epoch: 203, Training loss: 1.384056, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 204, Training loss: 1.362487, Validation loss: 1.3763, lr: 0.0000\n",
      "Epoch: 205, Training loss: 1.367563, Validation loss: 1.3782, lr: 0.0000\n",
      "Epoch: 206, Training loss: 1.376149, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 207, Training loss: 1.365658, Validation loss: 1.3743, lr: 0.0000\n",
      "Epoch: 208, Training loss: 1.366195, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 209, Training loss: 1.358730, Validation loss: 1.3513, lr: 0.0000\n",
      "Epoch: 210, Training loss: 1.371514, Validation loss: 1.3735, lr: 0.0000\n",
      "Epoch: 211, Training loss: 1.373057, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 212, Training loss: 1.393900, Validation loss: 1.3802, lr: 0.0000\n",
      "Epoch: 213, Training loss: 1.338192, Validation loss: 1.3906, lr: 0.0000\n",
      "Epoch: 214, Training loss: 1.365936, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 215, Training loss: 1.366702, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 216, Training loss: 1.365957, Validation loss: 1.3689, lr: 0.0000\n",
      "Epoch: 217, Training loss: 1.384277, Validation loss: 1.3715, lr: 0.0000\n",
      "Epoch: 218, Training loss: 1.368352, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 219, Training loss: 1.358647, Validation loss: 1.3744, lr: 0.0000\n",
      "Epoch: 220, Training loss: 1.350846, Validation loss: 1.3646, lr: 0.0000\n",
      "Epoch: 221, Training loss: 1.368341, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 222, Training loss: 1.368918, Validation loss: 1.3621, lr: 0.0000\n",
      "Epoch: 223, Training loss: 1.396007, Validation loss: 1.3734, lr: 0.0000\n",
      "Epoch: 224, Training loss: 1.348464, Validation loss: 1.3704, lr: 0.0000\n",
      "Epoch: 225, Training loss: 1.386086, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 226, Training loss: 1.356076, Validation loss: 1.3654, lr: 0.0000\n",
      "Epoch: 227, Training loss: 1.367418, Validation loss: 1.3700, lr: 0.0000\n",
      "Epoch: 228, Training loss: 1.377770, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 229, Training loss: 1.371129, Validation loss: 1.3690, lr: 0.0000\n",
      "Epoch: 230, Training loss: 1.352090, Validation loss: 1.3790, lr: 0.0000\n",
      "Epoch: 231, Training loss: 1.392534, Validation loss: 1.3780, lr: 0.0000\n",
      "Epoch: 232, Training loss: 1.372783, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 233, Training loss: 1.370349, Validation loss: 1.3469, lr: 0.0000\n",
      "Epoch: 234, Training loss: 1.375841, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 235, Training loss: 1.346350, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 236, Training loss: 1.355100, Validation loss: 1.3790, lr: 0.0000\n",
      "Epoch: 237, Training loss: 1.360371, Validation loss: 1.3671, lr: 0.0000\n",
      "Epoch: 238, Training loss: 1.367951, Validation loss: 1.3784, lr: 0.0000\n",
      "Epoch: 239, Training loss: 1.375445, Validation loss: 1.3556, lr: 0.0000\n",
      "Epoch: 240, Training loss: 1.349486, Validation loss: 1.3775, lr: 0.0000\n",
      "Epoch: 241, Training loss: 1.352873, Validation loss: 1.3651, lr: 0.0000\n",
      "Epoch: 242, Training loss: 1.367580, Validation loss: 1.3689, lr: 0.0000\n",
      "Epoch: 243, Training loss: 1.357748, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 244, Training loss: 1.363166, Validation loss: 1.3769, lr: 0.0000\n",
      "Epoch: 245, Training loss: 1.358777, Validation loss: 1.3916, lr: 0.0000\n",
      "Epoch: 246, Training loss: 1.361426, Validation loss: 1.3592, lr: 0.0000\n",
      "Epoch: 247, Training loss: 1.380815, Validation loss: 1.3693, lr: 0.0000\n",
      "Epoch: 248, Training loss: 1.382874, Validation loss: 1.3523, lr: 0.0000\n",
      "Epoch: 249, Training loss: 1.378616, Validation loss: 1.3789, lr: 0.0000\n",
      "Epoch: 250, Training loss: 1.372050, Validation loss: 1.3754, lr: 0.0000\n",
      "Epoch: 251, Training loss: 1.364143, Validation loss: 1.3725, lr: 0.0000\n",
      "Epoch: 252, Training loss: 1.371520, Validation loss: 1.3732, lr: 0.0000\n",
      "Epoch: 253, Training loss: 1.379357, Validation loss: 1.3889, lr: 0.0000\n",
      "Epoch: 254, Training loss: 1.364648, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 255, Training loss: 1.368522, Validation loss: 1.3896, lr: 0.0000\n",
      "Epoch: 256, Training loss: 1.354011, Validation loss: 1.3785, lr: 0.0000\n",
      "Epoch: 257, Training loss: 1.377163, Validation loss: 1.3790, lr: 0.0000\n",
      "Epoch: 258, Training loss: 1.345927, Validation loss: 1.3672, lr: 0.0000\n",
      "Epoch: 259, Training loss: 1.386840, Validation loss: 1.3903, lr: 0.0000\n",
      "Epoch: 260, Training loss: 1.384053, Validation loss: 1.4186, lr: 0.0000\n",
      "Epoch: 261, Training loss: 1.391376, Validation loss: 1.4095, lr: 0.0000\n",
      "Epoch: 262, Training loss: 1.376796, Validation loss: 1.3749, lr: 0.0000\n",
      "Epoch: 263, Training loss: 1.354703, Validation loss: 1.3907, lr: 0.0000\n",
      "Epoch: 264, Training loss: 1.363544, Validation loss: 1.3629, lr: 0.0000\n",
      "Epoch: 265, Training loss: 1.371414, Validation loss: 1.3738, lr: 0.0000\n",
      "Epoch: 266, Training loss: 1.367266, Validation loss: 1.3547, lr: 0.0000\n",
      "Epoch: 267, Training loss: 1.352994, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 268, Training loss: 1.365664, Validation loss: 1.3576, lr: 0.0000\n",
      "Epoch: 269, Training loss: 1.369583, Validation loss: 1.3650, lr: 0.0000\n",
      "Epoch: 270, Training loss: 1.346528, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 271, Training loss: 1.405689, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 272, Training loss: 1.388018, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 273, Training loss: 1.358922, Validation loss: 1.3925, lr: 0.0000\n",
      "Epoch: 274, Training loss: 1.362500, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 275, Training loss: 1.346459, Validation loss: 1.3697, lr: 0.0000\n",
      "Epoch: 276, Training loss: 1.386603, Validation loss: 1.3739, lr: 0.0000\n",
      "Epoch: 277, Training loss: 1.362454, Validation loss: 1.4025, lr: 0.0000\n",
      "Epoch: 278, Training loss: 1.368204, Validation loss: 1.3749, lr: 0.0000\n",
      "Epoch: 279, Training loss: 1.372295, Validation loss: 1.3509, lr: 0.0000\n",
      "Epoch: 280, Training loss: 1.398284, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 281, Training loss: 1.357706, Validation loss: 1.3883, lr: 0.0000\n",
      "Epoch: 282, Training loss: 1.360831, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 283, Training loss: 1.348139, Validation loss: 1.3724, lr: 0.0000\n",
      "Epoch: 284, Training loss: 1.393114, Validation loss: 1.3621, lr: 0.0000\n",
      "Epoch: 285, Training loss: 1.377692, Validation loss: 1.3775, lr: 0.0000\n",
      "Epoch: 286, Training loss: 1.392976, Validation loss: 1.3768, lr: 0.0000\n",
      "Epoch: 287, Training loss: 1.363612, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 288, Training loss: 1.374469, Validation loss: 1.3669, lr: 0.0000\n",
      "Epoch: 289, Training loss: 1.388620, Validation loss: 1.3648, lr: 0.0000\n",
      "Epoch: 290, Training loss: 1.378655, Validation loss: 1.4435, lr: 0.0000\n",
      "Epoch: 291, Training loss: 1.374740, Validation loss: 1.3577, lr: 0.0000\n",
      "Epoch: 292, Training loss: 1.356324, Validation loss: 1.3636, lr: 0.0000\n",
      "Epoch: 293, Training loss: 1.403085, Validation loss: 1.3728, lr: 0.0000\n",
      "Epoch: 294, Training loss: 1.360353, Validation loss: 1.4088, lr: 0.0000\n",
      "Epoch: 295, Training loss: 1.372480, Validation loss: 1.3452, lr: 0.0000\n",
      "Epoch: 296, Training loss: 1.372657, Validation loss: 1.3783, lr: 0.0000\n",
      "Epoch: 297, Training loss: 1.361198, Validation loss: 1.3780, lr: 0.0000\n",
      "Epoch: 298, Training loss: 1.357249, Validation loss: 1.3910, lr: 0.0000\n",
      "Epoch: 299, Training loss: 1.368290, Validation loss: 1.3414, lr: 0.0000\n",
      "Epoch: 300, Training loss: 1.379138, Validation loss: 1.3800, lr: 0.0000\n",
      "Epoch: 301, Training loss: 1.395455, Validation loss: 1.3797, lr: 0.0000\n",
      " *och: 302, Training loss: 1.375090, Validation loss: 1.3289, lr: 0.0000\n",
      "Epoch: 303, Training loss: 1.378891, Validation loss: 1.4139, lr: 0.0000\n",
      "Epoch: 304, Training loss: 1.367644, Validation loss: 1.4967, lr: 0.0000\n",
      "Epoch: 305, Training loss: 1.357626, Validation loss: 1.3791, lr: 0.0000\n",
      "Epoch: 306, Training loss: 1.380778, Validation loss: 1.3765, lr: 0.0000\n",
      "Epoch: 307, Training loss: 1.385126, Validation loss: 1.3707, lr: 0.0000\n",
      "Epoch: 308, Training loss: 1.374062, Validation loss: 1.3790, lr: 0.0000\n",
      "Epoch: 309, Training loss: 1.386939, Validation loss: 1.3745, lr: 0.0000\n",
      "Epoch: 310, Training loss: 1.359834, Validation loss: 1.3950, lr: 0.0000\n",
      "Epoch: 311, Training loss: 1.353514, Validation loss: 1.3957, lr: 0.0000\n",
      "Epoch: 312, Training loss: 1.384120, Validation loss: 1.3723, lr: 0.0000\n",
      "Epoch: 313, Training loss: 1.393169, Validation loss: 1.3790, lr: 0.0000\n",
      "Epoch: 314, Training loss: 1.372660, Validation loss: 1.3617, lr: 0.0000\n",
      "Epoch: 315, Training loss: 1.388423, Validation loss: 1.3619, lr: 0.0000\n",
      "Epoch: 316, Training loss: 1.400661, Validation loss: 1.3768, lr: 0.0000\n",
      "Epoch: 317, Training loss: 1.386737, Validation loss: 1.3880, lr: 0.0000\n",
      "Epoch: 318, Training loss: 1.359128, Validation loss: 1.3689, lr: 0.0000\n",
      "Epoch: 319, Training loss: 1.360702, Validation loss: 1.3740, lr: 0.0000\n",
      "Epoch: 320, Training loss: 1.357039, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 321, Training loss: 1.380695, Validation loss: 1.3716, lr: 0.0000\n",
      "Epoch: 322, Training loss: 1.361551, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 323, Training loss: 1.361665, Validation loss: 1.3758, lr: 0.0000\n",
      "Epoch: 324, Training loss: 1.441172, Validation loss: 1.3758, lr: 0.0000\n",
      "Epoch: 325, Training loss: 1.356920, Validation loss: 1.3762, lr: 0.0000\n",
      "Epoch: 326, Training loss: 1.402728, Validation loss: 1.3755, lr: 0.0000\n",
      "Epoch: 327, Training loss: 1.363269, Validation loss: 1.3795, lr: 0.0000\n",
      "Epoch: 328, Training loss: 1.363351, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 329, Training loss: 1.458882, Validation loss: 1.3756, lr: 0.0000\n",
      "Epoch: 330, Training loss: 1.352145, Validation loss: 1.3773, lr: 0.0000\n",
      "Epoch: 331, Training loss: 1.374667, Validation loss: 1.3878, lr: 0.0000\n",
      "Epoch: 332, Training loss: 1.371038, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 333, Training loss: 1.348275, Validation loss: 1.3700, lr: 0.0000\n",
      "Epoch: 334, Training loss: 1.346602, Validation loss: 1.3714, lr: 0.0000\n",
      "Epoch: 335, Training loss: 1.383102, Validation loss: 1.3650, lr: 0.0000\n",
      "Epoch: 336, Training loss: 1.341346, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 337, Training loss: 1.369552, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 338, Training loss: 1.356993, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 339, Training loss: 1.340170, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 340, Training loss: 1.376163, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 341, Training loss: 1.373979, Validation loss: 1.3958, lr: 0.0000\n",
      "Epoch: 342, Training loss: 1.356569, Validation loss: 1.3875, lr: 0.0000\n",
      "Epoch: 343, Training loss: 1.369127, Validation loss: 1.3770, lr: 0.0000\n",
      "Epoch: 344, Training loss: 1.383544, Validation loss: 1.3793, lr: 0.0000\n",
      "Epoch: 345, Training loss: 1.408255, Validation loss: 1.3773, lr: 0.0000\n",
      "Epoch: 346, Training loss: 1.397849, Validation loss: 1.3575, lr: 0.0000\n",
      "Epoch: 347, Training loss: 1.355334, Validation loss: 1.3596, lr: 0.0000\n",
      "Epoch: 348, Training loss: 1.362127, Validation loss: 1.3697, lr: 0.0000\n",
      "Epoch: 349, Training loss: 1.415153, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 350, Training loss: 1.379062, Validation loss: 1.3756, lr: 0.0000\n",
      "Epoch: 351, Training loss: 1.370500, Validation loss: 1.3734, lr: 0.0000\n",
      "Epoch: 352, Training loss: 1.409485, Validation loss: 1.4126, lr: 0.0000\n",
      "Epoch: 353, Training loss: 1.377189, Validation loss: 1.3929, lr: 0.0000\n",
      "Epoch: 354, Training loss: 1.364722, Validation loss: 1.3460, lr: 0.0000\n",
      "Epoch: 355, Training loss: 1.351909, Validation loss: 1.3561, lr: 0.0000\n",
      "Epoch: 356, Training loss: 1.369211, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 357, Training loss: 1.359730, Validation loss: 1.3341, lr: 0.0000\n",
      "Epoch: 358, Training loss: 1.385739, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 359, Training loss: 1.375248, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 360, Training loss: 1.358036, Validation loss: 1.3802, lr: 0.0000\n",
      "Epoch: 361, Training loss: 1.365629, Validation loss: 1.3752, lr: 0.0000\n",
      "Epoch: 362, Training loss: 1.372423, Validation loss: 1.3654, lr: 0.0000\n",
      "Epoch: 363, Training loss: 1.352404, Validation loss: 1.3691, lr: 0.0000\n",
      "Epoch: 364, Training loss: 1.382258, Validation loss: 1.3392, lr: 0.0000\n",
      "Epoch: 365, Training loss: 1.342955, Validation loss: 1.4189, lr: 0.0000\n",
      "Epoch: 366, Training loss: 1.368733, Validation loss: 1.3935, lr: 0.0000\n",
      "Epoch: 367, Training loss: 1.370959, Validation loss: 1.3494, lr: 0.0000\n",
      "Epoch: 368, Training loss: 1.387201, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 369, Training loss: 1.362118, Validation loss: 1.3659, lr: 0.0000\n",
      "Epoch: 370, Training loss: 1.367044, Validation loss: 1.3773, lr: 0.0000\n",
      "Epoch: 371, Training loss: 1.361353, Validation loss: 1.4005, lr: 0.0000\n",
      "Epoch: 372, Training loss: 1.377227, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 373, Training loss: 1.377388, Validation loss: 2.0113, lr: 0.0000\n",
      "Epoch: 374, Training loss: 1.350088, Validation loss: 1.3747, lr: 0.0000\n",
      "Epoch: 375, Training loss: 1.376748, Validation loss: 1.3708, lr: 0.0000\n",
      "Epoch: 376, Training loss: 1.344699, Validation loss: 1.3704, lr: 0.0000\n",
      "Epoch: 377, Training loss: 1.361776, Validation loss: 1.3713, lr: 0.0000\n",
      "Epoch: 378, Training loss: 1.353405, Validation loss: 1.3728, lr: 0.0000\n",
      "Epoch: 379, Training loss: 1.380395, Validation loss: 1.3995, lr: 0.0000\n",
      "Epoch: 380, Training loss: 1.354152, Validation loss: 1.3700, lr: 0.0000\n",
      "Epoch: 381, Training loss: 1.368378, Validation loss: 1.3748, lr: 0.0000\n",
      "Epoch: 382, Training loss: 1.359480, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 383, Training loss: 1.352578, Validation loss: 1.3603, lr: 0.0000\n",
      "Epoch: 384, Training loss: 1.375505, Validation loss: 1.5391, lr: 0.0000\n",
      "Epoch: 385, Training loss: 1.367877, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 386, Training loss: 1.418671, Validation loss: 1.4081, lr: 0.0000\n",
      "Epoch: 387, Training loss: 1.402170, Validation loss: 1.3790, lr: 0.0000\n",
      "Epoch: 388, Training loss: 1.386135, Validation loss: 1.3612, lr: 0.0000\n",
      "Epoch: 389, Training loss: 1.366081, Validation loss: 1.3786, lr: 0.0000\n",
      "Epoch: 390, Training loss: 1.385944, Validation loss: 1.3769, lr: 0.0000\n",
      "Epoch: 391, Training loss: 1.369282, Validation loss: 1.3809, lr: 0.0000\n",
      "Epoch: 392, Training loss: 1.359454, Validation loss: 1.3785, lr: 0.0000\n",
      "Epoch: 393, Training loss: 1.361273, Validation loss: 1.3779, lr: 0.0000\n",
      "Epoch: 394, Training loss: 1.360829, Validation loss: 1.3454, lr: 0.0000\n",
      "Epoch: 395, Training loss: 1.370524, Validation loss: 1.3736, lr: 0.0000\n",
      "Epoch: 396, Training loss: 1.384513, Validation loss: 1.3873, lr: 0.0000\n",
      "Epoch: 397, Training loss: 1.367163, Validation loss: 1.3369, lr: 0.0000\n",
      "Epoch: 398, Training loss: 1.368802, Validation loss: 1.3802, lr: 0.0000\n",
      "Epoch: 399, Training loss: 1.389551, Validation loss: 1.3764, lr: 0.0000\n",
      "Epoch: 400, Training loss: 1.365880, Validation loss: 1.4293, lr: 0.0000\n",
      "Epoch: 401, Training loss: 1.384029, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 402, Training loss: 1.352983, Validation loss: 1.3790, lr: 0.0000\n",
      "Epoch: 403, Training loss: 1.355345, Validation loss: 1.3761, lr: 0.0000\n",
      "Epoch: 404, Training loss: 1.418945, Validation loss: 1.3674, lr: 0.0000\n",
      "Epoch: 405, Training loss: 1.349339, Validation loss: 1.3798, lr: 0.0000\n",
      "Epoch: 406, Training loss: 1.370677, Validation loss: 1.3754, lr: 0.0000\n",
      "Epoch: 407, Training loss: 1.365035, Validation loss: 1.3706, lr: 0.0000\n",
      "Epoch: 408, Training loss: 1.340375, Validation loss: 1.3490, lr: 0.0000\n",
      "Epoch: 409, Training loss: 1.358076, Validation loss: 1.3651, lr: 0.0000\n",
      "Epoch: 410, Training loss: 1.378814, Validation loss: 1.3912, lr: 0.0000\n",
      "Epoch: 411, Training loss: 1.373197, Validation loss: 1.3718, lr: 0.0000\n",
      "Epoch: 412, Training loss: 1.356108, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 413, Training loss: 1.361346, Validation loss: 1.3673, lr: 0.0000\n",
      "Epoch: 414, Training loss: 1.376114, Validation loss: 1.3793, lr: 0.0000\n",
      "Epoch: 415, Training loss: 1.367386, Validation loss: 1.3425, lr: 0.0000\n",
      "Epoch: 416, Training loss: 1.350594, Validation loss: 1.3902, lr: 0.0000\n",
      "Epoch: 417, Training loss: 1.373200, Validation loss: 1.3630, lr: 0.0000\n",
      "Epoch: 418, Training loss: 1.375478, Validation loss: 1.3980, lr: 0.0000\n",
      "Epoch: 419, Training loss: 1.354755, Validation loss: 1.3592, lr: 0.0000\n",
      "Epoch: 420, Training loss: 1.368680, Validation loss: 1.3777, lr: 0.0000\n",
      "Epoch: 421, Training loss: 1.391237, Validation loss: 1.3770, lr: 0.0000\n",
      "Epoch: 422, Training loss: 1.379230, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 423, Training loss: 1.398981, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 424, Training loss: 1.355706, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 425, Training loss: 1.365628, Validation loss: 1.3775, lr: 0.0000\n",
      "Epoch: 426, Training loss: 1.376771, Validation loss: 1.3768, lr: 0.0000\n",
      "Epoch: 427, Training loss: 1.350794, Validation loss: 1.3749, lr: 0.0000\n",
      "Epoch: 428, Training loss: 1.375020, Validation loss: 1.3727, lr: 0.0000\n",
      "Epoch: 429, Training loss: 1.367055, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 430, Training loss: 1.372629, Validation loss: 1.3778, lr: 0.0000\n",
      "Epoch: 431, Training loss: 1.365660, Validation loss: 1.3878, lr: 0.0000\n",
      "Epoch: 432, Training loss: 1.353304, Validation loss: 1.4493, lr: 0.0000\n",
      "Epoch: 433, Training loss: 1.383719, Validation loss: 1.3731, lr: 0.0000\n",
      "Epoch: 434, Training loss: 1.375009, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 435, Training loss: 1.350264, Validation loss: 1.3595, lr: 0.0000\n",
      "Epoch: 436, Training loss: 1.387034, Validation loss: 1.3925, lr: 0.0000\n",
      "Epoch: 437, Training loss: 1.367318, Validation loss: 1.3365, lr: 0.0000\n",
      "Epoch: 438, Training loss: 1.358231, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 439, Training loss: 1.381137, Validation loss: 1.3898, lr: 0.0000\n",
      "Epoch: 440, Training loss: 1.362326, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 441, Training loss: 1.384067, Validation loss: 1.3651, lr: 0.0000\n",
      "Epoch: 442, Training loss: 1.383167, Validation loss: 1.3692, lr: 0.0000\n",
      "Epoch: 443, Training loss: 1.357366, Validation loss: 1.3741, lr: 0.0000\n",
      "Epoch: 444, Training loss: 1.355677, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 445, Training loss: 1.367196, Validation loss: 1.3722, lr: 0.0000\n",
      "Epoch: 446, Training loss: 1.365547, Validation loss: 1.3526, lr: 0.0000\n",
      "Epoch: 447, Training loss: 1.354933, Validation loss: 1.3474, lr: 0.0000\n",
      "Epoch: 448, Training loss: 1.371189, Validation loss: 1.4214, lr: 0.0000\n",
      "Epoch: 449, Training loss: 1.392176, Validation loss: 1.3907, lr: 0.0000\n",
      "Epoch: 450, Training loss: 1.350473, Validation loss: 1.3528, lr: 0.0000\n",
      "Epoch: 451, Training loss: 1.376708, Validation loss: 1.3882, lr: 0.0000\n",
      "Epoch: 452, Training loss: 1.348274, Validation loss: 1.3593, lr: 0.0000\n",
      "Epoch: 453, Training loss: 1.359820, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 454, Training loss: 1.367308, Validation loss: 1.3791, lr: 0.0000\n",
      "Epoch: 455, Training loss: 1.372301, Validation loss: 1.3796, lr: 0.0000\n",
      "Epoch: 456, Training loss: 1.369075, Validation loss: 1.3798, lr: 0.0000\n",
      "Epoch: 457, Training loss: 1.366178, Validation loss: 1.3971, lr: 0.0000\n",
      "Epoch: 458, Training loss: 1.386724, Validation loss: 1.3750, lr: 0.0000\n",
      "Epoch: 459, Training loss: 1.351219, Validation loss: 1.3782, lr: 0.0000\n",
      "Epoch: 460, Training loss: 1.392438, Validation loss: 1.3608, lr: 0.0000\n",
      "Epoch: 461, Training loss: 1.362916, Validation loss: 1.3758, lr: 0.0000\n",
      "Epoch: 462, Training loss: 1.355898, Validation loss: 1.3642, lr: 0.0000\n",
      "Epoch: 463, Training loss: 1.347267, Validation loss: 1.3721, lr: 0.0000\n",
      "Epoch: 464, Training loss: 1.379203, Validation loss: 1.3778, lr: 0.0000\n",
      "Epoch: 465, Training loss: 1.367727, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 466, Training loss: 1.366460, Validation loss: 1.3809, lr: 0.0000\n",
      "Epoch: 467, Training loss: 1.364787, Validation loss: 1.3618, lr: 0.0000\n",
      "Epoch: 468, Training loss: 1.358393, Validation loss: 1.3741, lr: 0.0000\n",
      "Epoch: 469, Training loss: 1.371706, Validation loss: 1.3672, lr: 0.0000\n",
      "Epoch: 470, Training loss: 1.355975, Validation loss: 1.3901, lr: 0.0000\n",
      "Epoch: 471, Training loss: 1.358313, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 472, Training loss: 1.372711, Validation loss: 1.4952, lr: 0.0000\n",
      "Epoch: 473, Training loss: 1.377325, Validation loss: 1.4133, lr: 0.0000\n",
      "Epoch: 474, Training loss: 1.362624, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 475, Training loss: 1.363260, Validation loss: 1.3791, lr: 0.0000\n",
      "Epoch: 476, Training loss: 1.426438, Validation loss: 1.3790, lr: 0.0000\n",
      "Epoch: 477, Training loss: 1.383366, Validation loss: 1.4031, lr: 0.0000\n",
      "Epoch: 478, Training loss: 1.367376, Validation loss: 1.5307, lr: 0.0000\n",
      "Epoch: 479, Training loss: 1.383933, Validation loss: 1.4003, lr: 0.0000\n",
      "Epoch: 480, Training loss: 1.338630, Validation loss: 1.3791, lr: 0.0000\n",
      "Epoch: 481, Training loss: 1.344763, Validation loss: 1.3618, lr: 0.0000\n",
      "Epoch: 482, Training loss: 1.351899, Validation loss: 1.3634, lr: 0.0000\n",
      "Epoch: 483, Training loss: 1.360195, Validation loss: 1.3628, lr: 0.0000\n",
      "Epoch: 484, Training loss: 1.357226, Validation loss: 1.3787, lr: 0.0000\n",
      "Epoch: 485, Training loss: 1.393825, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 486, Training loss: 1.369012, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 487, Training loss: 1.375393, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 488, Training loss: 1.351219, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 489, Training loss: 1.373115, Validation loss: 1.3756, lr: 0.0000\n",
      "Epoch: 490, Training loss: 1.379701, Validation loss: 1.3890, lr: 0.0000\n",
      "Epoch: 491, Training loss: 1.370292, Validation loss: 1.3879, lr: 0.0000\n",
      "Epoch: 492, Training loss: 1.339090, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 493, Training loss: 1.373519, Validation loss: 1.3742, lr: 0.0000\n",
      "Epoch: 494, Training loss: 1.398823, Validation loss: 1.4247, lr: 0.0000\n",
      "Epoch: 495, Training loss: 1.377878, Validation loss: 1.3777, lr: 0.0000\n",
      "Epoch: 496, Training loss: 1.473886, Validation loss: 1.3781, lr: 0.0000\n",
      "Epoch: 497, Training loss: 1.378358, Validation loss: 1.3797, lr: 0.0000\n",
      "Epoch: 498, Training loss: 1.386545, Validation loss: 1.3781, lr: 0.0000\n",
      "Epoch: 499, Training loss: 1.375778, Validation loss: 1.3608, lr: 0.0000\n",
      "Epoch: 500, Training loss: 1.374559, Validation loss: 1.3790, lr: 0.0000\n",
      "Epoch: 501, Training loss: 1.354621, Validation loss: 1.3799, lr: 0.0000\n",
      "Epoch: 502, Training loss: 1.364443, Validation loss: 1.3688, lr: 0.0000\n",
      "Epoch: 503, Training loss: 1.374884, Validation loss: 1.3750, lr: 0.0000\n",
      "Epoch: 504, Training loss: 1.372151, Validation loss: 1.3724, lr: 0.0000\n",
      "Epoch: 505, Training loss: 1.354141, Validation loss: 1.3482, lr: 0.0000\n",
      "Epoch: 506, Training loss: 1.388408, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 507, Training loss: 1.432851, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 508, Training loss: 1.362472, Validation loss: 1.3774, lr: 0.0000\n",
      "Epoch: 509, Training loss: 1.353161, Validation loss: 1.3743, lr: 0.0000\n",
      "Epoch: 510, Training loss: 1.407860, Validation loss: 1.3906, lr: 0.0000\n",
      "Epoch: 511, Training loss: 1.368336, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 512, Training loss: 1.347941, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 513, Training loss: 1.386181, Validation loss: 1.3534, lr: 0.0000\n",
      "Epoch: 514, Training loss: 1.370755, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 515, Training loss: 1.408094, Validation loss: 1.4029, lr: 0.0000\n",
      "Epoch: 516, Training loss: 1.365084, Validation loss: 1.4096, lr: 0.0000\n",
      "Epoch: 517, Training loss: 1.381860, Validation loss: 1.3696, lr: 0.0000\n",
      "Epoch: 518, Training loss: 1.383450, Validation loss: 1.3675, lr: 0.0000\n",
      "Epoch: 519, Training loss: 1.365783, Validation loss: 1.3761, lr: 0.0000\n",
      "Epoch: 520, Training loss: 1.364374, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 521, Training loss: 1.374565, Validation loss: 1.3446, lr: 0.0000\n",
      "Epoch: 522, Training loss: 1.360598, Validation loss: 1.3630, lr: 0.0000\n",
      "Epoch: 523, Training loss: 1.397833, Validation loss: 1.3534, lr: 0.0000\n",
      "Epoch: 524, Training loss: 1.441367, Validation loss: 1.3792, lr: 0.0000\n",
      "Epoch: 525, Training loss: 1.346716, Validation loss: 1.3762, lr: 0.0000\n",
      "Epoch: 526, Training loss: 1.344401, Validation loss: 1.3743, lr: 0.0000\n",
      "Epoch: 527, Training loss: 1.383527, Validation loss: 1.3605, lr: 0.0000\n",
      "Epoch: 528, Training loss: 1.361767, Validation loss: 1.3935, lr: 0.0000\n",
      "Epoch: 529, Training loss: 1.362149, Validation loss: 1.4016, lr: 0.0000\n",
      "Epoch: 530, Training loss: 1.391787, Validation loss: 1.3645, lr: 0.0000\n",
      "Epoch: 531, Training loss: 1.383092, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 532, Training loss: 1.421522, Validation loss: 1.3782, lr: 0.0000\n",
      "Epoch: 533, Training loss: 1.362529, Validation loss: 1.3791, lr: 0.0000\n",
      "Epoch: 534, Training loss: 1.368175, Validation loss: 1.3709, lr: 0.0000\n",
      "Epoch: 535, Training loss: 1.386686, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 536, Training loss: 1.367639, Validation loss: 1.3738, lr: 0.0000\n",
      "Epoch: 537, Training loss: 1.358923, Validation loss: 1.3696, lr: 0.0000\n",
      "Epoch: 538, Training loss: 1.347521, Validation loss: 1.3749, lr: 0.0000\n",
      "Epoch: 539, Training loss: 1.361086, Validation loss: 1.3802, lr: 0.0000\n",
      "Epoch: 540, Training loss: 1.379234, Validation loss: 1.3334, lr: 0.0000\n",
      "Epoch: 541, Training loss: 1.345388, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 542, Training loss: 1.346228, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 543, Training loss: 1.375849, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 544, Training loss: 1.368411, Validation loss: 1.4054, lr: 0.0000\n",
      "Epoch: 545, Training loss: 1.387118, Validation loss: 1.3751, lr: 0.0000\n",
      "Epoch: 546, Training loss: 1.386726, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 547, Training loss: 1.360687, Validation loss: 1.3692, lr: 0.0000\n",
      "Epoch: 548, Training loss: 1.358632, Validation loss: 1.3761, lr: 0.0000\n",
      "Epoch: 549, Training loss: 1.396189, Validation loss: 1.3990, lr: 0.0000\n",
      "Epoch: 550, Training loss: 1.369451, Validation loss: 1.3913, lr: 0.0000\n",
      "Epoch: 551, Training loss: 1.362658, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 552, Training loss: 1.347650, Validation loss: 1.3730, lr: 0.0000\n",
      "Epoch: 553, Training loss: 1.360812, Validation loss: 1.3732, lr: 0.0000\n",
      "Epoch: 554, Training loss: 1.392598, Validation loss: 1.3730, lr: 0.0000\n",
      "Epoch: 555, Training loss: 1.366742, Validation loss: 1.3607, lr: 0.0000\n",
      "Epoch: 556, Training loss: 1.373380, Validation loss: 1.3662, lr: 0.0000\n",
      "Epoch: 557, Training loss: 1.376593, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 558, Training loss: 1.389155, Validation loss: 1.4392, lr: 0.0000\n",
      "Epoch: 559, Training loss: 1.381207, Validation loss: 1.4105, lr: 0.0000\n",
      "Epoch: 560, Training loss: 1.372070, Validation loss: 1.3759, lr: 0.0000\n",
      "Epoch: 561, Training loss: 1.389020, Validation loss: 1.3500, lr: 0.0000\n",
      "Epoch: 562, Training loss: 1.361353, Validation loss: 1.3799, lr: 0.0000\n",
      "Epoch: 563, Training loss: 1.367303, Validation loss: 1.3972, lr: 0.0000\n",
      "Epoch: 564, Training loss: 1.384729, Validation loss: 1.3883, lr: 0.0000\n",
      "Epoch: 565, Training loss: 1.349302, Validation loss: 1.4337, lr: 0.0000\n",
      "Epoch: 566, Training loss: 1.362462, Validation loss: 1.3772, lr: 0.0000\n",
      "Epoch: 567, Training loss: 1.364344, Validation loss: 1.3645, lr: 0.0000\n",
      "Epoch: 568, Training loss: 1.354056, Validation loss: 1.3786, lr: 0.0000\n",
      "Epoch: 569, Training loss: 1.396028, Validation loss: 1.3666, lr: 0.0000\n",
      "Epoch: 570, Training loss: 1.366090, Validation loss: 1.3771, lr: 0.0000\n",
      "Epoch: 571, Training loss: 1.387184, Validation loss: 1.3689, lr: 0.0000\n",
      "Epoch: 572, Training loss: 1.370091, Validation loss: 1.3714, lr: 0.0000\n",
      "Epoch: 573, Training loss: 1.415826, Validation loss: 1.3875, lr: 0.0000\n",
      "Epoch: 574, Training loss: 1.383289, Validation loss: 1.5707, lr: 0.0000\n",
      "Epoch: 575, Training loss: 1.362410, Validation loss: 1.4041, lr: 0.0000\n",
      "Epoch: 576, Training loss: 1.350538, Validation loss: 1.3750, lr: 0.0000\n",
      "Epoch: 577, Training loss: 1.359964, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 578, Training loss: 1.375194, Validation loss: 1.3795, lr: 0.0000\n",
      "Epoch: 579, Training loss: 1.351499, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 580, Training loss: 1.434192, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 581, Training loss: 1.394793, Validation loss: 1.3707, lr: 0.0000\n",
      "Epoch: 582, Training loss: 1.387054, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 583, Training loss: 1.365314, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 584, Training loss: 1.358823, Validation loss: 1.3569, lr: 0.0000\n",
      "Epoch: 585, Training loss: 1.372890, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 586, Training loss: 1.371217, Validation loss: 1.3612, lr: 0.0000\n",
      "Epoch: 587, Training loss: 1.378758, Validation loss: 1.3694, lr: 0.0000\n",
      "Epoch: 588, Training loss: 1.360759, Validation loss: 1.3482, lr: 0.0000\n",
      "Epoch: 589, Training loss: 1.378420, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 590, Training loss: 1.389695, Validation loss: 1.3696, lr: 0.0000\n",
      "Epoch: 591, Training loss: 1.358689, Validation loss: 1.3664, lr: 0.0000\n",
      "Epoch: 592, Training loss: 1.397709, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 593, Training loss: 1.361822, Validation loss: 1.4710, lr: 0.0000\n",
      "Epoch: 594, Training loss: 1.360518, Validation loss: 1.3958, lr: 0.0000\n",
      "Epoch: 595, Training loss: 1.400085, Validation loss: 1.3887, lr: 0.0000\n",
      "Epoch: 596, Training loss: 1.370530, Validation loss: 1.3767, lr: 0.0000\n",
      "Epoch: 597, Training loss: 1.339409, Validation loss: 1.3738, lr: 0.0000\n",
      "Epoch: 598, Training loss: 1.342333, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 599, Training loss: 1.374510, Validation loss: 1.3740, lr: 0.0000\n",
      "Epoch: 600, Training loss: 1.366254, Validation loss: 1.3926, lr: 0.0000\n",
      "Epoch: 601, Training loss: 1.353927, Validation loss: 1.3572, lr: 0.0000\n",
      "Epoch: 602, Training loss: 1.365129, Validation loss: 1.3897, lr: 0.0000\n",
      "Epoch: 603, Training loss: 1.362037, Validation loss: 1.3653, lr: 0.0000\n",
      "Epoch: 604, Training loss: 1.355727, Validation loss: 1.3731, lr: 0.0000\n",
      "Epoch: 605, Training loss: 1.320795, Validation loss: 1.3749, lr: 0.0000\n",
      "Epoch: 606, Training loss: 1.362849, Validation loss: 1.3745, lr: 0.0000\n",
      "Epoch: 607, Training loss: 1.342457, Validation loss: 1.3744, lr: 0.0000\n",
      "Epoch: 608, Training loss: 1.376757, Validation loss: 1.3894, lr: 0.0000\n",
      "Epoch: 609, Training loss: 1.359060, Validation loss: 1.3932, lr: 0.0000\n",
      "Epoch: 610, Training loss: 1.359046, Validation loss: 1.3809, lr: 0.0000\n",
      "Epoch: 611, Training loss: 1.366516, Validation loss: 1.3782, lr: 0.0000\n",
      "Epoch: 612, Training loss: 1.378557, Validation loss: 1.3775, lr: 0.0000\n",
      "Epoch: 613, Training loss: 1.362824, Validation loss: 1.3754, lr: 0.0000\n",
      "Epoch: 614, Training loss: 1.355146, Validation loss: 1.3394, lr: 0.0000\n",
      "Epoch: 615, Training loss: 1.383408, Validation loss: 1.3809, lr: 0.0000\n",
      "Epoch: 616, Training loss: 1.381718, Validation loss: 1.3707, lr: 0.0000\n",
      "Epoch: 617, Training loss: 1.364482, Validation loss: 1.3778, lr: 0.0000\n",
      "Epoch: 618, Training loss: 1.346244, Validation loss: 1.3761, lr: 0.0000\n",
      "Epoch: 619, Training loss: 1.374492, Validation loss: 1.3792, lr: 0.0000\n",
      "Epoch: 620, Training loss: 1.369023, Validation loss: 1.3765, lr: 0.0000\n",
      "Epoch: 621, Training loss: 1.376465, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 622, Training loss: 1.373863, Validation loss: 1.3712, lr: 0.0000\n",
      "Epoch: 623, Training loss: 1.355563, Validation loss: 1.3554, lr: 0.0000\n",
      "Epoch: 624, Training loss: 1.407248, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 625, Training loss: 1.369449, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 626, Training loss: 1.349963, Validation loss: 1.3735, lr: 0.0000\n",
      "Epoch: 627, Training loss: 1.394679, Validation loss: 1.3745, lr: 0.0000\n",
      "Epoch: 628, Training loss: 1.347698, Validation loss: 1.3913, lr: 0.0000\n",
      "Epoch: 629, Training loss: 1.357556, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 630, Training loss: 1.351858, Validation loss: 1.3619, lr: 0.0000\n",
      "Epoch: 631, Training loss: 1.407195, Validation loss: 1.3574, lr: 0.0000\n",
      "Epoch: 632, Training loss: 1.378530, Validation loss: 1.3712, lr: 0.0000\n",
      "Epoch: 633, Training loss: 1.357037, Validation loss: 1.3665, lr: 0.0000\n",
      "Epoch: 634, Training loss: 1.431704, Validation loss: 1.3781, lr: 0.0000\n",
      "Epoch: 635, Training loss: 1.383427, Validation loss: 1.3687, lr: 0.0000\n",
      "Epoch: 636, Training loss: 1.370671, Validation loss: 1.3703, lr: 0.0000\n",
      "Epoch: 637, Training loss: 1.439497, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 638, Training loss: 1.378400, Validation loss: 1.3789, lr: 0.0000\n",
      "Epoch: 639, Training loss: 1.375481, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 640, Training loss: 1.352863, Validation loss: 1.3766, lr: 0.0000\n",
      "Epoch: 641, Training loss: 1.371495, Validation loss: 1.3728, lr: 0.0000\n",
      "Epoch: 642, Training loss: 1.373496, Validation loss: 1.3761, lr: 0.0000\n",
      "Epoch: 643, Training loss: 1.379598, Validation loss: 1.3934, lr: 0.0000\n",
      "Epoch: 644, Training loss: 1.371399, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 645, Training loss: 1.363648, Validation loss: 1.3786, lr: 0.0000\n",
      "Epoch: 646, Training loss: 1.361193, Validation loss: 1.3578, lr: 0.0000\n",
      "Epoch: 647, Training loss: 1.367131, Validation loss: 1.3789, lr: 0.0000\n",
      "Epoch: 648, Training loss: 1.399464, Validation loss: 1.3629, lr: 0.0000\n",
      "Epoch: 649, Training loss: 1.369238, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 650, Training loss: 1.388124, Validation loss: 1.3546, lr: 0.0000\n",
      "Epoch: 651, Training loss: 1.375877, Validation loss: 1.3668, lr: 0.0000\n",
      "Epoch: 652, Training loss: 1.373701, Validation loss: 1.3872, lr: 0.0000\n",
      "Epoch: 653, Training loss: 1.361295, Validation loss: 1.3695, lr: 0.0000\n",
      "Epoch: 654, Training loss: 1.373900, Validation loss: 1.3713, lr: 0.0000\n",
      "Epoch: 655, Training loss: 1.354517, Validation loss: 1.3784, lr: 0.0000\n",
      "Epoch: 656, Training loss: 1.343025, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 657, Training loss: 1.369393, Validation loss: 1.3899, lr: 0.0000\n",
      "Epoch: 658, Training loss: 1.371638, Validation loss: 1.3296, lr: 0.0000\n",
      "Epoch: 659, Training loss: 1.427914, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 660, Training loss: 1.394343, Validation loss: 1.3747, lr: 0.0000\n",
      "Epoch: 661, Training loss: 1.362098, Validation loss: 1.3874, lr: 0.0000\n",
      "Epoch: 662, Training loss: 1.343785, Validation loss: 1.3792, lr: 0.0000\n",
      "Epoch: 663, Training loss: 1.379485, Validation loss: 1.3903, lr: 0.0000\n",
      "Epoch: 664, Training loss: 1.360103, Validation loss: 1.3364, lr: 0.0000\n",
      "Epoch: 665, Training loss: 1.372659, Validation loss: 1.3395, lr: 0.0000\n",
      "Epoch: 666, Training loss: 1.363735, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 667, Training loss: 1.356999, Validation loss: 1.3729, lr: 0.0000\n",
      "Epoch: 668, Training loss: 1.363775, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 669, Training loss: 1.421534, Validation loss: 1.3764, lr: 0.0000\n",
      "Epoch: 670, Training loss: 1.342081, Validation loss: 1.3676, lr: 0.0000\n",
      "Epoch: 671, Training loss: 1.359893, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 672, Training loss: 1.373529, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 673, Training loss: 1.375107, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 674, Training loss: 1.371600, Validation loss: 1.3800, lr: 0.0000\n",
      "Epoch: 675, Training loss: 1.356491, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 676, Training loss: 1.402511, Validation loss: 1.3798, lr: 0.0000\n",
      "Epoch: 677, Training loss: 1.353524, Validation loss: 1.3712, lr: 0.0000\n",
      "Epoch: 678, Training loss: 1.391551, Validation loss: 1.3762, lr: 0.0000\n",
      "Epoch: 679, Training loss: 1.347050, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 680, Training loss: 1.363403, Validation loss: 1.3548, lr: 0.0000\n",
      "Epoch: 681, Training loss: 1.363590, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 682, Training loss: 1.341515, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 683, Training loss: 1.357182, Validation loss: 1.3755, lr: 0.0000\n",
      "Epoch: 684, Training loss: 1.392091, Validation loss: 1.3718, lr: 0.0000\n",
      "Epoch: 685, Training loss: 1.402796, Validation loss: 1.3614, lr: 0.0000\n",
      "Epoch: 686, Training loss: 1.470133, Validation loss: 1.3770, lr: 0.0000\n",
      "Epoch: 687, Training loss: 1.335833, Validation loss: 1.3548, lr: 0.0000\n",
      "Epoch: 688, Training loss: 1.367942, Validation loss: 1.3879, lr: 0.0000\n",
      "Epoch: 689, Training loss: 1.370667, Validation loss: 1.3774, lr: 0.0000\n",
      "Epoch: 690, Training loss: 1.353743, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 691, Training loss: 1.366148, Validation loss: 1.3484, lr: 0.0000\n",
      "Epoch: 692, Training loss: 1.346277, Validation loss: 1.3581, lr: 0.0000\n",
      "Epoch: 693, Training loss: 1.382944, Validation loss: 1.3706, lr: 0.0000\n",
      "Epoch: 694, Training loss: 1.383897, Validation loss: 1.3679, lr: 0.0000\n",
      "Epoch: 695, Training loss: 1.353364, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 696, Training loss: 1.366653, Validation loss: 1.3690, lr: 0.0000\n",
      "Epoch: 697, Training loss: 1.353177, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 698, Training loss: 1.378897, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 699, Training loss: 1.386331, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 700, Training loss: 1.362107, Validation loss: 1.3764, lr: 0.0000\n",
      "Epoch: 701, Training loss: 1.374360, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 702, Training loss: 1.368289, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 703, Training loss: 1.348690, Validation loss: 1.3935, lr: 0.0000\n",
      "Epoch: 704, Training loss: 1.376930, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 705, Training loss: 1.374205, Validation loss: 1.3799, lr: 0.0000\n",
      "Epoch: 706, Training loss: 1.389954, Validation loss: 1.4045, lr: 0.0000\n",
      "Epoch: 707, Training loss: 1.370702, Validation loss: 1.3784, lr: 0.0000\n",
      "Epoch: 708, Training loss: 1.368680, Validation loss: 1.3673, lr: 0.0000\n",
      "Epoch: 709, Training loss: 1.367650, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 710, Training loss: 1.352530, Validation loss: 1.3617, lr: 0.0000\n",
      "Epoch: 711, Training loss: 1.377820, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 712, Training loss: 1.359432, Validation loss: 1.3637, lr: 0.0000\n",
      "Epoch: 713, Training loss: 1.346709, Validation loss: 1.3445, lr: 0.0000\n",
      "Epoch: 714, Training loss: 1.358313, Validation loss: 1.3729, lr: 0.0000\n",
      "Epoch: 715, Training loss: 1.374744, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 716, Training loss: 1.378864, Validation loss: 1.3748, lr: 0.0000\n",
      "Epoch: 717, Training loss: 1.375417, Validation loss: 1.3616, lr: 0.0000\n",
      "Epoch: 718, Training loss: 1.382276, Validation loss: 1.6172, lr: 0.0000\n",
      "Epoch: 719, Training loss: 1.359554, Validation loss: 1.3652, lr: 0.0000\n",
      "Epoch: 720, Training loss: 1.366652, Validation loss: 1.3743, lr: 0.0000\n",
      "Epoch: 721, Training loss: 1.377018, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 722, Training loss: 1.348244, Validation loss: 1.3757, lr: 0.0000\n",
      "Epoch: 723, Training loss: 1.371154, Validation loss: 1.6533, lr: 0.0000\n",
      "Epoch: 724, Training loss: 1.383544, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 725, Training loss: 1.376975, Validation loss: 1.3624, lr: 0.0000\n",
      "Epoch: 726, Training loss: 1.355077, Validation loss: 1.3667, lr: 0.0000\n",
      "Epoch: 727, Training loss: 1.376270, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 728, Training loss: 1.382645, Validation loss: 1.3789, lr: 0.0000\n",
      "Epoch: 729, Training loss: 1.362487, Validation loss: 1.3745, lr: 0.0000\n",
      "Epoch: 730, Training loss: 1.387887, Validation loss: 1.5370, lr: 0.0000\n",
      "Epoch: 731, Training loss: 1.355063, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 732, Training loss: 1.361416, Validation loss: 1.3779, lr: 0.0000\n",
      "Epoch: 733, Training loss: 1.360011, Validation loss: 1.3679, lr: 0.0000\n",
      "Epoch: 734, Training loss: 1.368453, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 735, Training loss: 1.385541, Validation loss: 1.3788, lr: 0.0000\n",
      "Epoch: 736, Training loss: 1.355709, Validation loss: 1.3771, lr: 0.0000\n",
      "Epoch: 737, Training loss: 1.407257, Validation loss: 1.3583, lr: 0.0000\n",
      "Epoch: 738, Training loss: 1.360935, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 739, Training loss: 1.361017, Validation loss: 1.3793, lr: 0.0000\n",
      "Epoch: 740, Training loss: 1.364440, Validation loss: 1.3524, lr: 0.0000\n",
      "Epoch: 741, Training loss: 1.390429, Validation loss: 1.3664, lr: 0.0000\n",
      "Epoch: 742, Training loss: 1.363850, Validation loss: 1.3786, lr: 0.0000\n",
      "Epoch: 743, Training loss: 1.372624, Validation loss: 1.3909, lr: 0.0000\n",
      "Epoch: 744, Training loss: 1.356198, Validation loss: 1.3695, lr: 0.0000\n",
      "Epoch: 745, Training loss: 1.374943, Validation loss: 1.3654, lr: 0.0000\n",
      "Epoch: 746, Training loss: 1.349503, Validation loss: 1.5300, lr: 0.0000\n",
      "Epoch: 747, Training loss: 1.367785, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 748, Training loss: 1.393922, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 749, Training loss: 1.359276, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 750, Training loss: 1.351431, Validation loss: 1.3548, lr: 0.0000\n",
      "Epoch: 751, Training loss: 1.381704, Validation loss: 1.3783, lr: 0.0000\n",
      "Epoch: 752, Training loss: 1.372991, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 753, Training loss: 1.388186, Validation loss: 1.3788, lr: 0.0000\n",
      "Epoch: 754, Training loss: 1.395047, Validation loss: 1.3787, lr: 0.0000\n",
      "Epoch: 755, Training loss: 1.342577, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 756, Training loss: 1.348729, Validation loss: 1.3756, lr: 0.0000\n",
      "Epoch: 757, Training loss: 1.346731, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 758, Training loss: 1.343524, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 759, Training loss: 1.373934, Validation loss: 1.4815, lr: 0.0000\n",
      "Epoch: 760, Training loss: 1.374256, Validation loss: 1.3765, lr: 0.0000\n",
      "Epoch: 761, Training loss: 1.366113, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 762, Training loss: 1.358166, Validation loss: 1.3686, lr: 0.0000\n",
      "Epoch: 763, Training loss: 1.380300, Validation loss: 1.3766, lr: 0.0000\n",
      "Epoch: 764, Training loss: 1.333209, Validation loss: 1.3802, lr: 0.0000\n",
      "Epoch: 765, Training loss: 1.354475, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 766, Training loss: 1.358059, Validation loss: 1.3765, lr: 0.0000\n",
      "Epoch: 767, Training loss: 1.359498, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 768, Training loss: 1.348558, Validation loss: 1.3787, lr: 0.0000\n",
      "Epoch: 769, Training loss: 1.398614, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 770, Training loss: 1.358170, Validation loss: 1.3425, lr: 0.0000\n",
      "Epoch: 771, Training loss: 1.353920, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 772, Training loss: 1.355161, Validation loss: 1.3900, lr: 0.0000\n",
      "Epoch: 773, Training loss: 1.389375, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 774, Training loss: 1.389447, Validation loss: 1.3782, lr: 0.0000\n",
      "Epoch: 775, Training loss: 1.366656, Validation loss: 1.3775, lr: 0.0000\n",
      "Epoch: 776, Training loss: 1.372242, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 777, Training loss: 1.351336, Validation loss: 1.4275, lr: 0.0000\n",
      "Epoch: 778, Training loss: 1.351422, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 779, Training loss: 1.379670, Validation loss: 1.3775, lr: 0.0000\n",
      "Epoch: 780, Training loss: 1.386165, Validation loss: 1.3705, lr: 0.0000\n",
      "Epoch: 781, Training loss: 1.375429, Validation loss: 1.3642, lr: 0.0000\n",
      "Epoch: 782, Training loss: 1.378533, Validation loss: 1.3669, lr: 0.0000\n",
      "Epoch: 783, Training loss: 1.366479, Validation loss: 1.3695, lr: 0.0000\n",
      "Epoch: 784, Training loss: 1.331797, Validation loss: 1.3737, lr: 0.0000\n",
      "Epoch: 785, Training loss: 1.316067, Validation loss: 1.3414, lr: 0.0000\n",
      "Epoch: 786, Training loss: 1.358963, Validation loss: 1.3802, lr: 0.0000\n",
      "Epoch: 787, Training loss: 1.360405, Validation loss: 1.3760, lr: 0.0000\n",
      "Epoch: 788, Training loss: 1.397215, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 789, Training loss: 1.447958, Validation loss: 1.3761, lr: 0.0000\n",
      "Epoch: 790, Training loss: 1.349191, Validation loss: 1.3724, lr: 0.0000\n",
      "Epoch: 791, Training loss: 1.385581, Validation loss: 1.3753, lr: 0.0000\n",
      "Epoch: 792, Training loss: 1.420411, Validation loss: 1.3756, lr: 0.0000\n",
      "Epoch: 793, Training loss: 1.381632, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 794, Training loss: 1.371079, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 795, Training loss: 1.367203, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 796, Training loss: 1.432338, Validation loss: 1.3931, lr: 0.0000\n",
      "Epoch: 797, Training loss: 1.359131, Validation loss: 1.3691, lr: 0.0000\n",
      "Epoch: 798, Training loss: 1.388543, Validation loss: 1.3771, lr: 0.0000\n",
      "Epoch: 799, Training loss: 1.351237, Validation loss: 1.3766, lr: 0.0000\n",
      "Epoch: 800, Training loss: 1.367152, Validation loss: 1.3755, lr: 0.0000\n",
      "Epoch: 801, Training loss: 1.383919, Validation loss: 1.3781, lr: 0.0000\n",
      "Epoch: 802, Training loss: 1.403716, Validation loss: 1.3924, lr: 0.0000\n",
      "Epoch: 803, Training loss: 1.374055, Validation loss: 1.3706, lr: 0.0000\n",
      "Epoch: 804, Training loss: 1.360626, Validation loss: 1.3746, lr: 0.0000\n",
      "Epoch: 805, Training loss: 1.382533, Validation loss: 1.3790, lr: 0.0000\n",
      "Epoch: 806, Training loss: 1.363281, Validation loss: 1.3798, lr: 0.0000\n",
      "Epoch: 807, Training loss: 1.369313, Validation loss: 1.3775, lr: 0.0000\n",
      "Epoch: 808, Training loss: 1.369022, Validation loss: 1.3885, lr: 0.0000\n",
      "Epoch: 809, Training loss: 1.384334, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 810, Training loss: 1.374533, Validation loss: 1.3886, lr: 0.0000\n",
      "Epoch: 811, Training loss: 1.363400, Validation loss: 1.3641, lr: 0.0000\n",
      "Epoch: 812, Training loss: 1.359222, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 813, Training loss: 1.345125, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 814, Training loss: 1.374283, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 815, Training loss: 1.379924, Validation loss: 1.3895, lr: 0.0000\n",
      "Epoch: 816, Training loss: 1.373922, Validation loss: 1.3753, lr: 0.0000\n",
      "Epoch: 817, Training loss: 1.373185, Validation loss: 1.3727, lr: 0.0000\n",
      "Epoch: 818, Training loss: 1.363232, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 819, Training loss: 1.437319, Validation loss: 1.3746, lr: 0.0000\n",
      "Epoch: 820, Training loss: 1.372666, Validation loss: 1.3733, lr: 0.0000\n",
      "Epoch: 821, Training loss: 1.412315, Validation loss: 1.3766, lr: 0.0000\n",
      "Epoch: 822, Training loss: 1.364266, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 823, Training loss: 1.365788, Validation loss: 1.3715, lr: 0.0000\n",
      "Epoch: 824, Training loss: 1.351256, Validation loss: 1.3898, lr: 0.0000\n",
      "Epoch: 825, Training loss: 1.342939, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 826, Training loss: 1.388130, Validation loss: 1.3746, lr: 0.0000\n",
      "Epoch: 827, Training loss: 1.369564, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 828, Training loss: 1.374208, Validation loss: 1.3665, lr: 0.0000\n",
      "Epoch: 829, Training loss: 1.354325, Validation loss: 1.3803, lr: 0.0000\n",
      "Epoch: 830, Training loss: 1.379046, Validation loss: 1.3728, lr: 0.0000\n",
      "Epoch: 831, Training loss: 1.371558, Validation loss: 1.3725, lr: 0.0000\n",
      "Epoch: 832, Training loss: 1.361447, Validation loss: 1.3527, lr: 0.0000\n",
      "Epoch: 833, Training loss: 1.375493, Validation loss: 1.3613, lr: 0.0000\n",
      "Epoch: 834, Training loss: 1.334887, Validation loss: 1.3637, lr: 0.0000\n",
      "Epoch: 835, Training loss: 1.355687, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 836, Training loss: 1.405923, Validation loss: 1.3768, lr: 0.0000\n",
      "Epoch: 837, Training loss: 1.395469, Validation loss: 1.3601, lr: 0.0000\n",
      "Epoch: 838, Training loss: 1.376369, Validation loss: 1.4125, lr: 0.0000\n",
      "Epoch: 839, Training loss: 1.390306, Validation loss: 1.3539, lr: 0.0000\n",
      "Epoch: 840, Training loss: 1.367243, Validation loss: 1.3602, lr: 0.0000\n",
      "Epoch: 841, Training loss: 1.376236, Validation loss: 1.3765, lr: 0.0000\n",
      "Epoch: 842, Training loss: 1.372242, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 843, Training loss: 1.370217, Validation loss: 1.3876, lr: 0.0000\n",
      "Epoch: 844, Training loss: 1.367238, Validation loss: 1.3747, lr: 0.0000\n",
      "Epoch: 845, Training loss: 1.363858, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 846, Training loss: 1.351986, Validation loss: 1.3883, lr: 0.0000\n",
      "Epoch: 847, Training loss: 1.363845, Validation loss: 1.3883, lr: 0.0000\n",
      "Epoch: 848, Training loss: 1.369029, Validation loss: 1.3633, lr: 0.0000\n",
      "Epoch: 849, Training loss: 1.377746, Validation loss: 1.3770, lr: 0.0000\n",
      "Epoch: 850, Training loss: 1.391191, Validation loss: 1.3753, lr: 0.0000\n",
      "Epoch: 851, Training loss: 1.367818, Validation loss: 1.3546, lr: 0.0000\n",
      "Epoch: 852, Training loss: 1.355958, Validation loss: 1.3770, lr: 0.0000\n",
      "Epoch: 853, Training loss: 1.362930, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 854, Training loss: 1.372995, Validation loss: 1.3566, lr: 0.0000\n",
      "Epoch: 855, Training loss: 1.378250, Validation loss: 1.3350, lr: 0.0000\n",
      "Epoch: 856, Training loss: 1.372140, Validation loss: 1.3725, lr: 0.0000\n",
      "Epoch: 857, Training loss: 1.358352, Validation loss: 1.3784, lr: 0.0000\n",
      "Epoch: 858, Training loss: 1.391820, Validation loss: 1.3979, lr: 0.0000\n",
      "Epoch: 859, Training loss: 1.381135, Validation loss: 1.3797, lr: 0.0000\n",
      "Epoch: 860, Training loss: 1.400848, Validation loss: 1.3599, lr: 0.0000\n",
      "Epoch: 861, Training loss: 1.355755, Validation loss: 1.3579, lr: 0.0000\n",
      "Epoch: 862, Training loss: 1.369986, Validation loss: 1.3660, lr: 0.0000\n",
      "Epoch: 863, Training loss: 1.367303, Validation loss: 1.3678, lr: 0.0000\n",
      "Epoch: 864, Training loss: 1.366920, Validation loss: 1.3901, lr: 0.0000\n",
      "Epoch: 865, Training loss: 1.357788, Validation loss: 1.4358, lr: 0.0000\n",
      "Epoch: 866, Training loss: 1.357142, Validation loss: 1.3793, lr: 0.0000\n",
      "Epoch: 867, Training loss: 1.376161, Validation loss: 1.3478, lr: 0.0000\n",
      "Epoch: 868, Training loss: 1.372393, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 869, Training loss: 1.401549, Validation loss: 1.3749, lr: 0.0000\n",
      "Epoch: 870, Training loss: 1.365528, Validation loss: 1.4206, lr: 0.0000\n",
      "Epoch: 871, Training loss: 1.374593, Validation loss: 1.3690, lr: 0.0000\n",
      "Epoch: 872, Training loss: 1.374291, Validation loss: 1.4803, lr: 0.0000\n",
      "Epoch: 873, Training loss: 1.371198, Validation loss: 1.4001, lr: 0.0000\n",
      "Epoch: 874, Training loss: 1.359711, Validation loss: 1.4052, lr: 0.0000\n",
      "Epoch: 875, Training loss: 1.354587, Validation loss: 1.3939, lr: 0.0000\n",
      "Epoch: 876, Training loss: 1.384865, Validation loss: 1.3794, lr: 0.0000\n",
      "Epoch: 877, Training loss: 1.370380, Validation loss: 1.3913, lr: 0.0000\n",
      "Epoch: 878, Training loss: 1.382153, Validation loss: 1.3809, lr: 0.0000\n",
      "Epoch: 879, Training loss: 1.376236, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 880, Training loss: 1.398823, Validation loss: 1.3574, lr: 0.0000\n",
      "Epoch: 881, Training loss: 1.354666, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 882, Training loss: 1.382258, Validation loss: 1.3757, lr: 0.0000\n",
      "Epoch: 883, Training loss: 1.373233, Validation loss: 1.3760, lr: 0.0000\n",
      "Epoch: 884, Training loss: 1.369511, Validation loss: 1.3775, lr: 0.0000\n",
      "Epoch: 885, Training loss: 1.370424, Validation loss: 1.3717, lr: 0.0000\n",
      "Epoch: 886, Training loss: 1.351556, Validation loss: 1.3644, lr: 0.0000\n",
      "Epoch: 887, Training loss: 1.368144, Validation loss: 1.3907, lr: 0.0000\n",
      "Epoch: 888, Training loss: 1.380978, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 889, Training loss: 1.374353, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 890, Training loss: 1.367949, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 891, Training loss: 1.363636, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 892, Training loss: 1.367843, Validation loss: 1.3878, lr: 0.0000\n",
      "Epoch: 893, Training loss: 1.368970, Validation loss: 1.3602, lr: 0.0000\n",
      "Epoch: 894, Training loss: 1.369319, Validation loss: 1.3795, lr: 0.0000\n",
      "Epoch: 895, Training loss: 1.380730, Validation loss: 1.3796, lr: 0.0000\n",
      "Epoch: 896, Training loss: 1.370242, Validation loss: 1.3774, lr: 0.0000\n",
      "Epoch: 897, Training loss: 1.350652, Validation loss: 1.3782, lr: 0.0000\n",
      "Epoch: 898, Training loss: 1.379584, Validation loss: 1.3797, lr: 0.0000\n",
      "Epoch: 899, Training loss: 1.376463, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 900, Training loss: 1.390564, Validation loss: 1.3786, lr: 0.0000\n",
      "Epoch: 901, Training loss: 1.370674, Validation loss: 1.3763, lr: 0.0000\n",
      "Epoch: 902, Training loss: 1.367580, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 903, Training loss: 1.360666, Validation loss: 1.3636, lr: 0.0000\n",
      "Epoch: 904, Training loss: 1.363662, Validation loss: 1.3728, lr: 0.0000\n",
      "Epoch: 905, Training loss: 1.379554, Validation loss: 1.3776, lr: 0.0000\n",
      "Epoch: 906, Training loss: 1.372563, Validation loss: 1.3785, lr: 0.0000\n",
      "Epoch: 907, Training loss: 1.379600, Validation loss: 1.4338, lr: 0.0000\n",
      "Epoch: 908, Training loss: 1.359182, Validation loss: 1.3806, lr: 0.0000\n",
      " *och: 909, Training loss: 1.367085, Validation loss: 1.3236, lr: 0.0000\n",
      "Epoch: 910, Training loss: 1.362482, Validation loss: 1.3733, lr: 0.0000\n",
      "Epoch: 911, Training loss: 1.378732, Validation loss: 1.3780, lr: 0.0000\n",
      "Epoch: 912, Training loss: 1.394647, Validation loss: 1.3747, lr: 0.0000\n",
      "Epoch: 913, Training loss: 1.382487, Validation loss: 1.3768, lr: 0.0000\n",
      "Epoch: 914, Training loss: 1.360447, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 915, Training loss: 1.410308, Validation loss: 1.3770, lr: 0.0000\n",
      "Epoch: 916, Training loss: 1.371379, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 917, Training loss: 1.356691, Validation loss: 1.3760, lr: 0.0000\n",
      "Epoch: 918, Training loss: 1.385982, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 919, Training loss: 1.375123, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 920, Training loss: 1.368252, Validation loss: 1.3656, lr: 0.0000\n",
      "Epoch: 921, Training loss: 1.405758, Validation loss: 1.3705, lr: 0.0000\n",
      "Epoch: 922, Training loss: 1.381983, Validation loss: 1.4316, lr: 0.0000\n",
      "Epoch: 923, Training loss: 1.353461, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 924, Training loss: 1.388590, Validation loss: 1.3764, lr: 0.0000\n",
      "Epoch: 925, Training loss: 1.386736, Validation loss: 1.3764, lr: 0.0000\n",
      "Epoch: 926, Training loss: 1.345107, Validation loss: 1.3379, lr: 0.0000\n",
      "Epoch: 927, Training loss: 1.385367, Validation loss: 1.3945, lr: 0.0000\n",
      "Epoch: 928, Training loss: 1.393471, Validation loss: 1.4751, lr: 0.0000\n",
      "Epoch: 929, Training loss: 1.365109, Validation loss: 1.3987, lr: 0.0000\n",
      "Epoch: 930, Training loss: 1.385883, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 931, Training loss: 1.380431, Validation loss: 1.4050, lr: 0.0000\n",
      "Epoch: 932, Training loss: 1.365099, Validation loss: 1.3693, lr: 0.0000\n",
      "Epoch: 933, Training loss: 1.367025, Validation loss: 1.3703, lr: 0.0000\n",
      "Epoch: 934, Training loss: 1.346763, Validation loss: 1.3452, lr: 0.0000\n",
      "Epoch: 935, Training loss: 1.368694, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 936, Training loss: 1.366134, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 937, Training loss: 1.369111, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 938, Training loss: 1.395860, Validation loss: 1.3608, lr: 0.0000\n",
      "Epoch: 939, Training loss: 1.363193, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 940, Training loss: 1.382189, Validation loss: 1.4113, lr: 0.0000\n",
      "Epoch: 941, Training loss: 1.365371, Validation loss: 1.3621, lr: 0.0000\n",
      "Epoch: 942, Training loss: 1.375292, Validation loss: 1.3765, lr: 0.0000\n",
      "Epoch: 943, Training loss: 1.379134, Validation loss: 1.3777, lr: 0.0000\n",
      "Epoch: 944, Training loss: 1.373249, Validation loss: 1.3741, lr: 0.0000\n",
      "Epoch: 945, Training loss: 1.376653, Validation loss: 1.3636, lr: 0.0000\n",
      "Epoch: 946, Training loss: 1.392812, Validation loss: 1.3792, lr: 0.0000\n",
      "Epoch: 947, Training loss: 1.361806, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 948, Training loss: 1.354285, Validation loss: 1.3774, lr: 0.0000\n",
      "Epoch: 949, Training loss: 1.367099, Validation loss: 1.3392, lr: 0.0000\n",
      "Epoch: 950, Training loss: 1.407594, Validation loss: 1.3625, lr: 0.0000\n",
      "Epoch: 951, Training loss: 1.352206, Validation loss: 1.3755, lr: 0.0000\n",
      "Epoch: 952, Training loss: 1.357106, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 953, Training loss: 1.356496, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 954, Training loss: 1.348729, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 955, Training loss: 1.394501, Validation loss: 1.3995, lr: 0.0000\n",
      "Epoch: 956, Training loss: 1.355164, Validation loss: 1.3777, lr: 0.0000\n",
      "Epoch: 957, Training loss: 1.376287, Validation loss: 1.3571, lr: 0.0000\n",
      "Epoch: 958, Training loss: 1.400769, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 959, Training loss: 1.375894, Validation loss: 1.3769, lr: 0.0000\n",
      "Epoch: 960, Training loss: 1.345346, Validation loss: 1.3668, lr: 0.0000\n",
      "Epoch: 961, Training loss: 1.373994, Validation loss: 1.3783, lr: 0.0000\n",
      "Epoch: 962, Training loss: 1.357860, Validation loss: 1.3875, lr: 0.0000\n",
      "Epoch: 963, Training loss: 1.357675, Validation loss: 1.3790, lr: 0.0000\n",
      "Epoch: 964, Training loss: 1.401460, Validation loss: 1.3690, lr: 0.0000\n",
      "Epoch: 965, Training loss: 1.356664, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 966, Training loss: 1.353615, Validation loss: 1.3767, lr: 0.0000\n",
      "Epoch: 967, Training loss: 1.369100, Validation loss: 1.3780, lr: 0.0000\n",
      "Epoch: 968, Training loss: 1.372838, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 969, Training loss: 1.376174, Validation loss: 1.3654, lr: 0.0000\n",
      "Epoch: 970, Training loss: 1.386552, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 971, Training loss: 1.363508, Validation loss: 1.3702, lr: 0.0000\n",
      "Epoch: 972, Training loss: 1.382922, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 973, Training loss: 1.374434, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 974, Training loss: 1.382089, Validation loss: 1.3589, lr: 0.0000\n",
      "Epoch: 975, Training loss: 1.347564, Validation loss: 1.3732, lr: 0.0000\n",
      "Epoch: 976, Training loss: 1.405755, Validation loss: 1.3760, lr: 0.0000\n",
      "Epoch: 977, Training loss: 1.415294, Validation loss: 1.3655, lr: 0.0000\n",
      "Epoch: 978, Training loss: 1.381775, Validation loss: 1.3599, lr: 0.0000\n",
      "Epoch: 979, Training loss: 1.385601, Validation loss: 1.3772, lr: 0.0000\n",
      "Epoch: 980, Training loss: 1.389291, Validation loss: 1.3670, lr: 0.0000\n",
      "Epoch: 981, Training loss: 1.357958, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 982, Training loss: 1.373011, Validation loss: 1.3779, lr: 0.0000\n",
      "Epoch: 983, Training loss: 1.350940, Validation loss: 1.3690, lr: 0.0000\n",
      "Epoch: 984, Training loss: 1.385597, Validation loss: 1.3777, lr: 0.0000\n",
      "Epoch: 985, Training loss: 1.385204, Validation loss: 1.3803, lr: 0.0000\n",
      "Epoch: 986, Training loss: 1.373804, Validation loss: 1.3781, lr: 0.0000\n",
      "Epoch: 987, Training loss: 1.365154, Validation loss: 1.4184, lr: 0.0000\n",
      "Epoch: 988, Training loss: 1.357969, Validation loss: 1.3753, lr: 0.0000\n",
      "Epoch: 989, Training loss: 1.354361, Validation loss: 1.3747, lr: 0.0000\n",
      "Epoch: 990, Training loss: 1.351623, Validation loss: 1.3948, lr: 0.0000\n",
      "Epoch: 991, Training loss: 1.362769, Validation loss: 1.3500, lr: 0.0000\n",
      "Epoch: 992, Training loss: 1.359550, Validation loss: 1.3916, lr: 0.0000\n",
      "Epoch: 993, Training loss: 1.360376, Validation loss: 1.3532, lr: 0.0000\n",
      "Epoch: 994, Training loss: 1.364212, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 995, Training loss: 1.380062, Validation loss: 1.3508, lr: 0.0000\n",
      "Epoch: 996, Training loss: 1.379792, Validation loss: 1.3881, lr: 0.0000\n",
      "Epoch: 997, Training loss: 1.376113, Validation loss: 1.4190, lr: 0.0000\n",
      "Epoch: 998, Training loss: 1.372862, Validation loss: 1.3695, lr: 0.0000\n",
      "Epoch: 999, Training loss: 1.371368, Validation loss: 1.3788, lr: 0.0000\n",
      "Final test loss: 1.3916\n",
      "=== Run 09/10 ===\n",
      "\n",
      "---- Settings: \n",
      "\n",
      "epochs : 1000\n",
      "hidden_channels : [32]\n",
      "out_channels : 10\n",
      "inner_product_features : False\n",
      "batch_size : 64\n",
      "lr : 0.01\n",
      "momentum : 0.9\n",
      "dropout : 0.0\n",
      "batch_norm : batch_norm\n",
      "bias : True\n",
      "order : 2\n",
      "diffusion : True\n",
      "frac_sampled_nb : -1\n",
      "include_positions : False\n",
      "include_self : True\n",
      "vec_norm : False\n",
      "emb_norm : False\n",
      "seed : 0\n",
      "dim_signal : 100\n",
      "dim_emb : 100\n",
      "n_sampled_nb : -1\n",
      "\n",
      "---- Number of features to pass to the MLP:  1010100\n",
      "---- Total number of parameters:  32323627\n",
      "\n",
      "Using device cuda:0\n",
      "\n",
      "---- Training network ...\n",
      "\n",
      "---- Timestamp: 20250615-051138\n",
      "\n",
      " *och: 0, Training loss: 1.393640, Validation loss: 1.6878, lr: 0.0100\n",
      " *och: 1, Training loss: 1.386571, Validation loss: 1.4318, lr: 0.0100\n",
      " *och: 2, Training loss: 1.437190, Validation loss: 1.3390, lr: 0.0100\n",
      "Epoch: 3, Training loss: 1.395337, Validation loss: 1.3788, lr: 0.0100\n",
      "Epoch: 4, Training loss: 1.361833, Validation loss: 1.3814, lr: 0.0100\n",
      "Epoch: 5, Training loss: 1.379916, Validation loss: 1.3867, lr: 0.0100\n",
      "Epoch: 6, Training loss: 1.362030, Validation loss: 1.3435, lr: 0.0100\n",
      " *och: 7, Training loss: 1.378836, Validation loss: 1.3331, lr: 0.0100\n",
      "Epoch: 8, Training loss: 1.387128, Validation loss: 1.3610, lr: 0.0100\n",
      "Epoch: 9, Training loss: 1.488661, Validation loss: 1.3821, lr: 0.0100\n",
      "Epoch: 10, Training loss: 1.380931, Validation loss: 1.3807, lr: 0.0100\n",
      "Epoch: 11, Training loss: 1.376698, Validation loss: 1.3951, lr: 0.0100\n",
      "Epoch: 12, Training loss: 1.370949, Validation loss: 1.3775, lr: 0.0100\n",
      "Epoch: 13, Training loss: 1.353831, Validation loss: 1.3833, lr: 0.0100\n",
      "Epoch: 14, Training loss: 1.372189, Validation loss: 1.3786, lr: 0.0100\n",
      "Epoch: 15, Training loss: 1.383015, Validation loss: 1.3847, lr: 0.0100\n",
      "Epoch: 16, Training loss: 1.406266, Validation loss: 1.3818, lr: 0.0100\n",
      "Epoch: 17, Training loss: 1.381320, Validation loss: 1.3583, lr: 0.0100\n",
      "Epoch: 18, Training loss: 1.366779, Validation loss: 1.3839, lr: 0.0100\n",
      "Epoch: 19, Training loss: 1.404999, Validation loss: 1.3769, lr: 0.0100\n",
      "Epoch: 20, Training loss: 1.365774, Validation loss: 1.3686, lr: 0.0100\n",
      "Epoch: 21, Training loss: 1.385307, Validation loss: 1.3631, lr: 0.0100\n",
      "Epoch: 22, Training loss: 1.374320, Validation loss: 1.3757, lr: 0.0100\n",
      "Epoch: 23, Training loss: 1.394307, Validation loss: 1.4158, lr: 0.0100\n",
      "Epoch: 24, Training loss: 1.369766, Validation loss: 1.3782, lr: 0.0010\n",
      "Epoch: 25, Training loss: 1.373425, Validation loss: 1.3628, lr: 0.0010\n",
      "Epoch: 26, Training loss: 1.374130, Validation loss: 1.3785, lr: 0.0010\n",
      "Epoch: 27, Training loss: 1.372956, Validation loss: 1.3796, lr: 0.0010\n",
      "Epoch: 28, Training loss: 1.420017, Validation loss: 1.3861, lr: 0.0010\n",
      "Epoch: 29, Training loss: 1.383113, Validation loss: 1.3827, lr: 0.0010\n",
      "Epoch: 30, Training loss: 1.377912, Validation loss: 1.3844, lr: 0.0010\n",
      "Epoch: 31, Training loss: 1.370788, Validation loss: 1.3798, lr: 0.0010\n",
      "Epoch: 32, Training loss: 1.394196, Validation loss: 1.3691, lr: 0.0010\n",
      "Epoch: 33, Training loss: 1.420238, Validation loss: 1.3782, lr: 0.0010\n",
      "Epoch: 34, Training loss: 1.358692, Validation loss: 1.3752, lr: 0.0010\n",
      "Epoch: 35, Training loss: 1.393600, Validation loss: 1.3733, lr: 0.0001\n",
      "Epoch: 36, Training loss: 1.378315, Validation loss: 1.3815, lr: 0.0001\n",
      " *och: 37, Training loss: 1.347958, Validation loss: 1.3317, lr: 0.0001\n",
      "Epoch: 38, Training loss: 1.369034, Validation loss: 1.3713, lr: 0.0001\n",
      "Epoch: 39, Training loss: 1.348693, Validation loss: 1.3589, lr: 0.0001\n",
      "Epoch: 40, Training loss: 1.378711, Validation loss: 1.3809, lr: 0.0001\n",
      "Epoch: 41, Training loss: 1.400438, Validation loss: 1.4339, lr: 0.0001\n",
      "Epoch: 42, Training loss: 1.364286, Validation loss: 1.3690, lr: 0.0001\n",
      "Epoch: 43, Training loss: 1.363568, Validation loss: 1.3665, lr: 0.0001\n",
      "Epoch: 44, Training loss: 1.375516, Validation loss: 1.3910, lr: 0.0001\n",
      "Epoch: 45, Training loss: 1.395643, Validation loss: 1.3688, lr: 0.0001\n",
      "Epoch: 46, Training loss: 1.359949, Validation loss: 1.3850, lr: 0.0001\n",
      "Epoch: 47, Training loss: 1.375454, Validation loss: 1.3847, lr: 0.0001\n",
      "Epoch: 48, Training loss: 1.355103, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 49, Training loss: 1.410352, Validation loss: 1.3786, lr: 0.0000\n",
      "Epoch: 50, Training loss: 1.342206, Validation loss: 1.3921, lr: 0.0000\n",
      "Epoch: 51, Training loss: 1.385302, Validation loss: 1.4006, lr: 0.0000\n",
      "Epoch: 52, Training loss: 1.375445, Validation loss: 1.3789, lr: 0.0000\n",
      "Epoch: 53, Training loss: 1.379183, Validation loss: 1.3802, lr: 0.0000\n",
      "Epoch: 54, Training loss: 1.354699, Validation loss: 1.3710, lr: 0.0000\n",
      "Epoch: 55, Training loss: 1.352422, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 56, Training loss: 1.359842, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 57, Training loss: 1.371787, Validation loss: 1.3702, lr: 0.0000\n",
      "Epoch: 58, Training loss: 1.361564, Validation loss: 1.3770, lr: 0.0000\n",
      "Epoch: 59, Training loss: 1.366180, Validation loss: 1.3787, lr: 0.0000\n",
      "Epoch: 60, Training loss: 1.364644, Validation loss: 1.3583, lr: 0.0000\n",
      "Epoch: 61, Training loss: 1.377539, Validation loss: 1.3720, lr: 0.0000\n",
      "Epoch: 62, Training loss: 1.371157, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 63, Training loss: 1.375848, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 64, Training loss: 1.351183, Validation loss: 1.3916, lr: 0.0000\n",
      "Epoch: 65, Training loss: 1.361749, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 66, Training loss: 1.372676, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 67, Training loss: 1.370461, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 68, Training loss: 1.373114, Validation loss: 1.3796, lr: 0.0000\n",
      "Epoch: 69, Training loss: 1.366037, Validation loss: 1.4626, lr: 0.0000\n",
      "Epoch: 70, Training loss: 1.352756, Validation loss: 1.3798, lr: 0.0000\n",
      "Epoch: 71, Training loss: 1.361040, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 72, Training loss: 1.377824, Validation loss: 1.3668, lr: 0.0000\n",
      "Epoch: 73, Training loss: 1.365292, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 74, Training loss: 1.370354, Validation loss: 1.3755, lr: 0.0000\n",
      "Epoch: 75, Training loss: 1.369757, Validation loss: 1.3714, lr: 0.0000\n",
      "Epoch: 76, Training loss: 1.397791, Validation loss: 1.3735, lr: 0.0000\n",
      "Epoch: 77, Training loss: 1.394559, Validation loss: 1.3903, lr: 0.0000\n",
      "Epoch: 78, Training loss: 1.354180, Validation loss: 1.3888, lr: 0.0000\n",
      "Epoch: 79, Training loss: 1.363234, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 80, Training loss: 1.389833, Validation loss: 1.3673, lr: 0.0000\n",
      "Epoch: 81, Training loss: 1.363412, Validation loss: 1.3696, lr: 0.0000\n",
      "Epoch: 82, Training loss: 1.419582, Validation loss: 1.4136, lr: 0.0000\n",
      "Epoch: 83, Training loss: 1.376754, Validation loss: 1.3755, lr: 0.0000\n",
      "Epoch: 84, Training loss: 1.432657, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 85, Training loss: 1.393668, Validation loss: 1.4331, lr: 0.0000\n",
      "Epoch: 86, Training loss: 1.400753, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 87, Training loss: 1.445815, Validation loss: 1.3752, lr: 0.0000\n",
      "Epoch: 88, Training loss: 1.391859, Validation loss: 1.4005, lr: 0.0000\n",
      "Epoch: 89, Training loss: 1.413270, Validation loss: 1.3726, lr: 0.0000\n",
      "Epoch: 90, Training loss: 1.358886, Validation loss: 1.3803, lr: 0.0000\n",
      "Epoch: 91, Training loss: 1.371677, Validation loss: 1.3731, lr: 0.0000\n",
      "Epoch: 92, Training loss: 1.358669, Validation loss: 1.3879, lr: 0.0000\n",
      "Epoch: 93, Training loss: 1.376635, Validation loss: 1.3789, lr: 0.0000\n",
      "Epoch: 94, Training loss: 1.361152, Validation loss: 1.3776, lr: 0.0000\n",
      "Epoch: 95, Training loss: 1.372131, Validation loss: 1.3656, lr: 0.0000\n",
      "Epoch: 96, Training loss: 1.365624, Validation loss: 1.3800, lr: 0.0000\n",
      "Epoch: 97, Training loss: 1.373494, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 98, Training loss: 1.353003, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 99, Training loss: 1.421409, Validation loss: 1.3471, lr: 0.0000\n",
      "Epoch: 100, Training loss: 1.362178, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 101, Training loss: 1.389619, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 102, Training loss: 1.366459, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 103, Training loss: 1.374932, Validation loss: 1.3789, lr: 0.0000\n",
      "Epoch: 104, Training loss: 1.367358, Validation loss: 1.4262, lr: 0.0000\n",
      "Epoch: 105, Training loss: 1.378330, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 106, Training loss: 1.349445, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 107, Training loss: 1.360008, Validation loss: 1.3888, lr: 0.0000\n",
      "Epoch: 108, Training loss: 1.359556, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 109, Training loss: 1.406134, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 110, Training loss: 1.379557, Validation loss: 1.3613, lr: 0.0000\n",
      "Epoch: 111, Training loss: 1.364133, Validation loss: 1.3548, lr: 0.0000\n",
      "Epoch: 112, Training loss: 1.383132, Validation loss: 1.3786, lr: 0.0000\n",
      "Epoch: 113, Training loss: 1.362516, Validation loss: 1.3613, lr: 0.0000\n",
      "Epoch: 114, Training loss: 1.372609, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 115, Training loss: 1.364141, Validation loss: 1.3726, lr: 0.0000\n",
      "Epoch: 116, Training loss: 1.366164, Validation loss: 1.3713, lr: 0.0000\n",
      "Epoch: 117, Training loss: 1.366126, Validation loss: 1.3927, lr: 0.0000\n",
      "Epoch: 118, Training loss: 1.387041, Validation loss: 1.3668, lr: 0.0000\n",
      "Epoch: 119, Training loss: 1.361669, Validation loss: 1.3796, lr: 0.0000\n",
      "Epoch: 120, Training loss: 1.360002, Validation loss: 1.3633, lr: 0.0000\n",
      "Epoch: 121, Training loss: 1.357854, Validation loss: 1.4015, lr: 0.0000\n",
      "Epoch: 122, Training loss: 1.386365, Validation loss: 1.3559, lr: 0.0000\n",
      "Epoch: 123, Training loss: 1.386764, Validation loss: 1.3503, lr: 0.0000\n",
      "Epoch: 124, Training loss: 1.402631, Validation loss: 1.3909, lr: 0.0000\n",
      "Epoch: 125, Training loss: 1.423422, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 126, Training loss: 1.381195, Validation loss: 1.3803, lr: 0.0000\n",
      "Epoch: 127, Training loss: 1.375939, Validation loss: 1.3683, lr: 0.0000\n",
      "Epoch: 128, Training loss: 1.383729, Validation loss: 1.3570, lr: 0.0000\n",
      "Epoch: 129, Training loss: 1.365036, Validation loss: 1.3730, lr: 0.0000\n",
      "Epoch: 130, Training loss: 1.341027, Validation loss: 1.3784, lr: 0.0000\n",
      "Epoch: 131, Training loss: 1.340356, Validation loss: 1.3682, lr: 0.0000\n",
      "Epoch: 132, Training loss: 1.372109, Validation loss: 1.3717, lr: 0.0000\n",
      "Epoch: 133, Training loss: 1.339929, Validation loss: 1.3769, lr: 0.0000\n",
      "Epoch: 134, Training loss: 1.379889, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 135, Training loss: 1.381685, Validation loss: 1.3901, lr: 0.0000\n",
      "Epoch: 136, Training loss: 1.356504, Validation loss: 1.3765, lr: 0.0000\n",
      "Epoch: 137, Training loss: 1.363090, Validation loss: 1.3793, lr: 0.0000\n",
      "Epoch: 138, Training loss: 1.389908, Validation loss: 1.3790, lr: 0.0000\n",
      "Epoch: 139, Training loss: 1.375423, Validation loss: 1.3746, lr: 0.0000\n",
      "Epoch: 140, Training loss: 1.361220, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 141, Training loss: 1.368505, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 142, Training loss: 1.369450, Validation loss: 1.3800, lr: 0.0000\n",
      "Epoch: 143, Training loss: 1.425324, Validation loss: 1.3794, lr: 0.0000\n",
      "Epoch: 144, Training loss: 1.367863, Validation loss: 1.3881, lr: 0.0000\n",
      "Epoch: 145, Training loss: 1.369967, Validation loss: 1.3739, lr: 0.0000\n",
      "Epoch: 146, Training loss: 1.357433, Validation loss: 1.3737, lr: 0.0000\n",
      "Epoch: 147, Training loss: 1.360032, Validation loss: 1.3893, lr: 0.0000\n",
      "Epoch: 148, Training loss: 1.377321, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 149, Training loss: 1.390986, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 150, Training loss: 1.395243, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 151, Training loss: 1.364212, Validation loss: 1.3519, lr: 0.0000\n",
      "Epoch: 152, Training loss: 1.399137, Validation loss: 1.3796, lr: 0.0000\n",
      "Epoch: 153, Training loss: 1.380839, Validation loss: 1.3796, lr: 0.0000\n",
      "Epoch: 154, Training loss: 1.385867, Validation loss: 1.3765, lr: 0.0000\n",
      "Epoch: 155, Training loss: 1.418382, Validation loss: 1.3899, lr: 0.0000\n",
      "Epoch: 156, Training loss: 1.361523, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 157, Training loss: 1.364303, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 158, Training loss: 1.398525, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 159, Training loss: 1.355134, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 160, Training loss: 1.412610, Validation loss: 1.3599, lr: 0.0000\n",
      "Epoch: 161, Training loss: 1.357785, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 162, Training loss: 1.384574, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 163, Training loss: 1.368564, Validation loss: 1.3749, lr: 0.0000\n",
      "Epoch: 164, Training loss: 1.371818, Validation loss: 1.3787, lr: 0.0000\n",
      "Epoch: 165, Training loss: 1.384563, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 166, Training loss: 1.357746, Validation loss: 1.3718, lr: 0.0000\n",
      "Epoch: 167, Training loss: 1.359815, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 168, Training loss: 1.390422, Validation loss: 1.3449, lr: 0.0000\n",
      "Epoch: 169, Training loss: 1.353789, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 170, Training loss: 1.362101, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 171, Training loss: 1.375175, Validation loss: 1.3912, lr: 0.0000\n",
      "Epoch: 172, Training loss: 1.369706, Validation loss: 1.3695, lr: 0.0000\n",
      "Epoch: 173, Training loss: 1.344925, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 174, Training loss: 1.350464, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 175, Training loss: 1.376271, Validation loss: 1.3585, lr: 0.0000\n",
      "Epoch: 176, Training loss: 1.373778, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 177, Training loss: 1.405981, Validation loss: 1.3706, lr: 0.0000\n",
      "Epoch: 178, Training loss: 1.361792, Validation loss: 1.3765, lr: 0.0000\n",
      "Epoch: 179, Training loss: 1.381242, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 180, Training loss: 1.365378, Validation loss: 1.3509, lr: 0.0000\n",
      "Epoch: 181, Training loss: 1.370033, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 182, Training loss: 1.374191, Validation loss: 1.3750, lr: 0.0000\n",
      "Epoch: 183, Training loss: 1.360941, Validation loss: 1.3628, lr: 0.0000\n",
      "Epoch: 184, Training loss: 1.363385, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 185, Training loss: 1.369515, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 186, Training loss: 1.370218, Validation loss: 1.3795, lr: 0.0000\n",
      "Epoch: 187, Training loss: 1.356806, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 188, Training loss: 1.379751, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 189, Training loss: 1.369917, Validation loss: 1.3800, lr: 0.0000\n",
      "Epoch: 190, Training loss: 1.366325, Validation loss: 1.3781, lr: 0.0000\n",
      "Epoch: 191, Training loss: 1.423856, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 192, Training loss: 1.403069, Validation loss: 1.3633, lr: 0.0000\n",
      "Epoch: 193, Training loss: 1.351108, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 194, Training loss: 1.503411, Validation loss: 1.3559, lr: 0.0000\n",
      "Epoch: 195, Training loss: 1.367565, Validation loss: 1.3411, lr: 0.0000\n",
      "Epoch: 196, Training loss: 1.370216, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 197, Training loss: 1.364234, Validation loss: 1.4393, lr: 0.0000\n",
      "Epoch: 198, Training loss: 1.360728, Validation loss: 1.3650, lr: 0.0000\n",
      "Epoch: 199, Training loss: 1.376798, Validation loss: 1.3918, lr: 0.0000\n",
      "Epoch: 200, Training loss: 1.400417, Validation loss: 1.3718, lr: 0.0000\n",
      "Epoch: 201, Training loss: 1.392945, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 202, Training loss: 1.362785, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 203, Training loss: 1.364506, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 204, Training loss: 1.375969, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 205, Training loss: 1.358563, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 206, Training loss: 1.352356, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 207, Training loss: 1.351117, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 208, Training loss: 1.395931, Validation loss: 1.3669, lr: 0.0000\n",
      "Epoch: 209, Training loss: 1.376067, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 210, Training loss: 1.355121, Validation loss: 1.3628, lr: 0.0000\n",
      "Epoch: 211, Training loss: 1.376228, Validation loss: 1.4307, lr: 0.0000\n",
      "Epoch: 212, Training loss: 1.369820, Validation loss: 1.3782, lr: 0.0000\n",
      "Epoch: 213, Training loss: 1.357984, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 214, Training loss: 1.371734, Validation loss: 1.3859, lr: 0.0000\n",
      "Epoch: 215, Training loss: 1.367161, Validation loss: 1.3554, lr: 0.0000\n",
      "Epoch: 216, Training loss: 1.374378, Validation loss: 1.3672, lr: 0.0000\n",
      "Epoch: 217, Training loss: 1.353395, Validation loss: 1.3650, lr: 0.0000\n",
      "Epoch: 218, Training loss: 1.351264, Validation loss: 1.3912, lr: 0.0000\n",
      "Epoch: 219, Training loss: 1.365370, Validation loss: 1.3664, lr: 0.0000\n",
      "Epoch: 220, Training loss: 1.366232, Validation loss: 1.3795, lr: 0.0000\n",
      "Epoch: 221, Training loss: 1.386635, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 222, Training loss: 1.395020, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 223, Training loss: 1.370290, Validation loss: 1.3793, lr: 0.0000\n",
      "Epoch: 224, Training loss: 1.376642, Validation loss: 1.3790, lr: 0.0000\n",
      "Epoch: 225, Training loss: 1.382410, Validation loss: 1.3751, lr: 0.0000\n",
      "Epoch: 226, Training loss: 1.384238, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 227, Training loss: 1.365871, Validation loss: 1.3765, lr: 0.0000\n",
      "Epoch: 228, Training loss: 1.376824, Validation loss: 1.3907, lr: 0.0000\n",
      "Epoch: 229, Training loss: 1.353254, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 230, Training loss: 1.371234, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 231, Training loss: 1.396677, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 232, Training loss: 1.369325, Validation loss: 1.3766, lr: 0.0000\n",
      "Epoch: 233, Training loss: 1.364711, Validation loss: 1.3490, lr: 0.0000\n",
      "Epoch: 234, Training loss: 1.391367, Validation loss: 1.3482, lr: 0.0000\n",
      "Epoch: 235, Training loss: 1.357008, Validation loss: 1.3744, lr: 0.0000\n",
      "Epoch: 236, Training loss: 1.355016, Validation loss: 1.3779, lr: 0.0000\n",
      "Epoch: 237, Training loss: 1.357948, Validation loss: 1.3920, lr: 0.0000\n",
      "Epoch: 238, Training loss: 1.497942, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 239, Training loss: 1.366458, Validation loss: 1.3713, lr: 0.0000\n",
      "Epoch: 240, Training loss: 1.396810, Validation loss: 1.3608, lr: 0.0000\n",
      "Epoch: 241, Training loss: 1.372489, Validation loss: 1.3780, lr: 0.0000\n",
      "Epoch: 242, Training loss: 1.364463, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 243, Training loss: 1.378399, Validation loss: 1.3764, lr: 0.0000\n",
      "Epoch: 244, Training loss: 1.392041, Validation loss: 1.3716, lr: 0.0000\n",
      "Epoch: 245, Training loss: 1.344295, Validation loss: 1.3697, lr: 0.0000\n",
      "Epoch: 246, Training loss: 1.384017, Validation loss: 1.3792, lr: 0.0000\n",
      "Epoch: 247, Training loss: 1.405504, Validation loss: 1.3720, lr: 0.0000\n",
      "Epoch: 248, Training loss: 1.395210, Validation loss: 1.3890, lr: 0.0000\n",
      "Epoch: 249, Training loss: 1.380786, Validation loss: 1.3669, lr: 0.0000\n",
      "Epoch: 250, Training loss: 1.371926, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 251, Training loss: 1.354865, Validation loss: 1.3540, lr: 0.0000\n",
      "Epoch: 252, Training loss: 1.374526, Validation loss: 1.3777, lr: 0.0000\n",
      "Epoch: 253, Training loss: 1.350391, Validation loss: 1.3800, lr: 0.0000\n",
      "Epoch: 254, Training loss: 1.378518, Validation loss: 1.3898, lr: 0.0000\n",
      "Epoch: 255, Training loss: 1.371606, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 256, Training loss: 1.378533, Validation loss: 1.3873, lr: 0.0000\n",
      "Epoch: 257, Training loss: 1.405053, Validation loss: 1.3769, lr: 0.0000\n",
      "Epoch: 258, Training loss: 1.370086, Validation loss: 1.3601, lr: 0.0000\n",
      "Epoch: 259, Training loss: 1.406646, Validation loss: 1.3908, lr: 0.0000\n",
      "Epoch: 260, Training loss: 1.381694, Validation loss: 1.3879, lr: 0.0000\n",
      "Epoch: 261, Training loss: 1.359353, Validation loss: 1.3698, lr: 0.0000\n",
      "Epoch: 262, Training loss: 1.380345, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 263, Training loss: 1.394061, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 264, Training loss: 1.372594, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 265, Training loss: 1.372786, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 266, Training loss: 1.361721, Validation loss: 1.3502, lr: 0.0000\n",
      "Epoch: 267, Training loss: 1.384397, Validation loss: 1.3747, lr: 0.0000\n",
      "Epoch: 268, Training loss: 1.377430, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 269, Training loss: 1.377495, Validation loss: 1.3796, lr: 0.0000\n",
      "Epoch: 270, Training loss: 1.393839, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 271, Training loss: 1.388690, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 272, Training loss: 1.384984, Validation loss: 1.3738, lr: 0.0000\n",
      "Epoch: 273, Training loss: 1.377823, Validation loss: 1.3636, lr: 0.0000\n",
      "Epoch: 274, Training loss: 1.373246, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 275, Training loss: 1.364280, Validation loss: 1.3759, lr: 0.0000\n",
      "Epoch: 276, Training loss: 1.375666, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 277, Training loss: 1.339614, Validation loss: 1.3414, lr: 0.0000\n",
      "Epoch: 278, Training loss: 1.344390, Validation loss: 1.3673, lr: 0.0000\n",
      "Epoch: 279, Training loss: 1.358492, Validation loss: 1.3881, lr: 0.0000\n",
      "Epoch: 280, Training loss: 1.369398, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 281, Training loss: 1.362371, Validation loss: 1.3645, lr: 0.0000\n",
      "Epoch: 282, Training loss: 1.385190, Validation loss: 1.3763, lr: 0.0000\n",
      "Epoch: 283, Training loss: 1.381383, Validation loss: 1.3884, lr: 0.0000\n",
      "Epoch: 284, Training loss: 1.361560, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 285, Training loss: 1.385026, Validation loss: 1.3521, lr: 0.0000\n",
      "Epoch: 286, Training loss: 1.366013, Validation loss: 1.3913, lr: 0.0000\n",
      "Epoch: 287, Training loss: 1.367970, Validation loss: 1.3646, lr: 0.0000\n",
      "Epoch: 288, Training loss: 1.360003, Validation loss: 1.4019, lr: 0.0000\n",
      "Epoch: 289, Training loss: 1.387735, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 290, Training loss: 1.372544, Validation loss: 1.3709, lr: 0.0000\n",
      "Epoch: 291, Training loss: 1.396848, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 292, Training loss: 1.371874, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 293, Training loss: 1.379584, Validation loss: 1.3671, lr: 0.0000\n",
      "Epoch: 294, Training loss: 1.350214, Validation loss: 1.3962, lr: 0.0000\n",
      "Epoch: 295, Training loss: 1.373067, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 296, Training loss: 1.389664, Validation loss: 1.3645, lr: 0.0000\n",
      "Epoch: 297, Training loss: 1.367109, Validation loss: 1.3765, lr: 0.0000\n",
      "Epoch: 298, Training loss: 1.370751, Validation loss: 1.3368, lr: 0.0000\n",
      "Epoch: 299, Training loss: 1.378423, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 300, Training loss: 1.369411, Validation loss: 1.3799, lr: 0.0000\n",
      "Epoch: 301, Training loss: 1.379158, Validation loss: 1.3789, lr: 0.0000\n",
      "Epoch: 302, Training loss: 1.358642, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 303, Training loss: 1.359644, Validation loss: 1.3558, lr: 0.0000\n",
      "Epoch: 304, Training loss: 1.367959, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 305, Training loss: 1.372614, Validation loss: 1.3924, lr: 0.0000\n",
      "Epoch: 306, Training loss: 1.352062, Validation loss: 1.3753, lr: 0.0000\n",
      "Epoch: 307, Training loss: 1.358030, Validation loss: 1.3792, lr: 0.0000\n",
      "Epoch: 308, Training loss: 1.364520, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 309, Training loss: 1.369720, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 310, Training loss: 1.386924, Validation loss: 1.3793, lr: 0.0000\n",
      "Epoch: 311, Training loss: 1.366493, Validation loss: 1.3693, lr: 0.0000\n",
      "Epoch: 312, Training loss: 1.390945, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 313, Training loss: 1.355476, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 314, Training loss: 1.353664, Validation loss: 1.3746, lr: 0.0000\n",
      "Epoch: 315, Training loss: 1.345330, Validation loss: 1.3721, lr: 0.0000\n",
      "Epoch: 316, Training loss: 1.362509, Validation loss: 1.3734, lr: 0.0000\n",
      "Epoch: 317, Training loss: 1.343635, Validation loss: 1.3761, lr: 0.0000\n",
      "Epoch: 318, Training loss: 1.370709, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 319, Training loss: 1.350087, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 320, Training loss: 1.416614, Validation loss: 1.3746, lr: 0.0000\n",
      "Epoch: 321, Training loss: 1.374575, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 322, Training loss: 1.366498, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 323, Training loss: 1.398395, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 324, Training loss: 1.373014, Validation loss: 1.3727, lr: 0.0000\n",
      "Epoch: 325, Training loss: 1.403328, Validation loss: 1.3787, lr: 0.0000\n",
      "Epoch: 326, Training loss: 1.349542, Validation loss: 1.3865, lr: 0.0000\n",
      "Epoch: 327, Training loss: 1.381567, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 328, Training loss: 1.394620, Validation loss: 1.3779, lr: 0.0000\n",
      "Epoch: 329, Training loss: 1.385851, Validation loss: 1.4013, lr: 0.0000\n",
      "Epoch: 330, Training loss: 1.390490, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 331, Training loss: 1.364813, Validation loss: 1.3676, lr: 0.0000\n",
      "Epoch: 332, Training loss: 1.392391, Validation loss: 1.3637, lr: 0.0000\n",
      "Epoch: 333, Training loss: 1.375454, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 334, Training loss: 1.372585, Validation loss: 1.3789, lr: 0.0000\n",
      "Epoch: 335, Training loss: 1.391252, Validation loss: 1.3875, lr: 0.0000\n",
      "Epoch: 336, Training loss: 1.387489, Validation loss: 1.3719, lr: 0.0000\n",
      "Epoch: 337, Training loss: 1.371693, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 338, Training loss: 1.419735, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 339, Training loss: 1.378590, Validation loss: 1.4401, lr: 0.0000\n",
      "Epoch: 340, Training loss: 1.373405, Validation loss: 1.3809, lr: 0.0000\n",
      "Epoch: 341, Training loss: 1.376603, Validation loss: 1.3548, lr: 0.0000\n",
      "Epoch: 342, Training loss: 1.398489, Validation loss: 1.3777, lr: 0.0000\n",
      "Epoch: 343, Training loss: 1.347995, Validation loss: 1.3965, lr: 0.0000\n",
      "Epoch: 344, Training loss: 1.377386, Validation loss: 1.3907, lr: 0.0000\n",
      "Epoch: 345, Training loss: 1.376619, Validation loss: 1.3682, lr: 0.0000\n",
      "Epoch: 346, Training loss: 1.373973, Validation loss: 1.3720, lr: 0.0000\n",
      "Epoch: 347, Training loss: 1.362528, Validation loss: 1.3744, lr: 0.0000\n",
      "Epoch: 348, Training loss: 1.390385, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 349, Training loss: 1.346768, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 350, Training loss: 1.397416, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 351, Training loss: 1.357545, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 352, Training loss: 1.399242, Validation loss: 1.3794, lr: 0.0000\n",
      "Epoch: 353, Training loss: 1.364256, Validation loss: 1.3663, lr: 0.0000\n",
      "Epoch: 354, Training loss: 1.350810, Validation loss: 1.3694, lr: 0.0000\n",
      "Epoch: 355, Training loss: 1.486143, Validation loss: 1.3751, lr: 0.0000\n",
      "Epoch: 356, Training loss: 1.356535, Validation loss: 1.3671, lr: 0.0000\n",
      "Epoch: 357, Training loss: 1.353398, Validation loss: 1.3726, lr: 0.0000\n",
      "Epoch: 358, Training loss: 1.371885, Validation loss: 1.4830, lr: 0.0000\n",
      "Epoch: 359, Training loss: 1.375402, Validation loss: 1.3690, lr: 0.0000\n",
      "Epoch: 360, Training loss: 1.374555, Validation loss: 1.3733, lr: 0.0000\n",
      "Epoch: 361, Training loss: 1.359234, Validation loss: 1.3545, lr: 0.0000\n",
      "Epoch: 362, Training loss: 1.369717, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 363, Training loss: 1.375172, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 364, Training loss: 1.354516, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 365, Training loss: 1.391860, Validation loss: 1.3763, lr: 0.0000\n",
      "Epoch: 366, Training loss: 1.370420, Validation loss: 1.4060, lr: 0.0000\n",
      "Epoch: 367, Training loss: 1.353149, Validation loss: 1.3767, lr: 0.0000\n",
      "Epoch: 368, Training loss: 1.377802, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 369, Training loss: 1.392921, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 370, Training loss: 1.361097, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 371, Training loss: 1.378463, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 372, Training loss: 1.385564, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 373, Training loss: 1.373372, Validation loss: 1.3881, lr: 0.0000\n",
      "Epoch: 374, Training loss: 1.369536, Validation loss: 1.3946, lr: 0.0000\n",
      "Epoch: 375, Training loss: 1.395759, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 376, Training loss: 1.389508, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 377, Training loss: 1.407559, Validation loss: 1.3978, lr: 0.0000\n",
      "Epoch: 378, Training loss: 1.371374, Validation loss: 1.3737, lr: 0.0000\n",
      "Epoch: 379, Training loss: 1.340283, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 380, Training loss: 1.382202, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 381, Training loss: 1.356231, Validation loss: 1.3651, lr: 0.0000\n",
      "Epoch: 382, Training loss: 1.346097, Validation loss: 1.3673, lr: 0.0000\n",
      "Epoch: 383, Training loss: 1.373052, Validation loss: 1.3661, lr: 0.0000\n",
      "Epoch: 384, Training loss: 1.360986, Validation loss: 1.3700, lr: 0.0000\n",
      "Epoch: 385, Training loss: 1.375828, Validation loss: 1.3787, lr: 0.0000\n",
      "Epoch: 386, Training loss: 1.348601, Validation loss: 1.3671, lr: 0.0000\n",
      "Epoch: 387, Training loss: 1.373741, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 388, Training loss: 1.362865, Validation loss: 1.3665, lr: 0.0000\n",
      "Epoch: 389, Training loss: 1.390297, Validation loss: 1.3677, lr: 0.0000\n",
      "Epoch: 390, Training loss: 1.386444, Validation loss: 1.3787, lr: 0.0000\n",
      "Epoch: 391, Training loss: 1.361972, Validation loss: 1.3725, lr: 0.0000\n",
      "Epoch: 392, Training loss: 1.384187, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 393, Training loss: 1.420656, Validation loss: 1.3755, lr: 0.0000\n",
      "Epoch: 394, Training loss: 1.371507, Validation loss: 1.3791, lr: 0.0000\n",
      "Epoch: 395, Training loss: 1.365906, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 396, Training loss: 1.373434, Validation loss: 1.3793, lr: 0.0000\n",
      "Epoch: 397, Training loss: 1.381707, Validation loss: 1.3753, lr: 0.0000\n",
      "Epoch: 398, Training loss: 1.364467, Validation loss: 1.3902, lr: 0.0000\n",
      "Epoch: 399, Training loss: 1.361358, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 400, Training loss: 1.367419, Validation loss: 1.3744, lr: 0.0000\n",
      "Epoch: 401, Training loss: 1.344343, Validation loss: 1.3734, lr: 0.0000\n",
      "Epoch: 402, Training loss: 1.370539, Validation loss: 1.3611, lr: 0.0000\n",
      "Epoch: 403, Training loss: 1.381356, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 404, Training loss: 1.351076, Validation loss: 1.3659, lr: 0.0000\n",
      "Epoch: 405, Training loss: 1.373503, Validation loss: 1.3671, lr: 0.0000\n",
      "Epoch: 406, Training loss: 1.354863, Validation loss: 1.4071, lr: 0.0000\n",
      "Epoch: 407, Training loss: 1.378251, Validation loss: 1.3708, lr: 0.0000\n",
      "Epoch: 408, Training loss: 1.360505, Validation loss: 1.3799, lr: 0.0000\n",
      "Epoch: 409, Training loss: 1.376231, Validation loss: 1.3770, lr: 0.0000\n",
      "Epoch: 410, Training loss: 1.355819, Validation loss: 1.3632, lr: 0.0000\n",
      "Epoch: 411, Training loss: 1.386398, Validation loss: 1.3688, lr: 0.0000\n",
      "Epoch: 412, Training loss: 1.373696, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 413, Training loss: 1.364638, Validation loss: 1.3777, lr: 0.0000\n",
      "Epoch: 414, Training loss: 1.412708, Validation loss: 1.3766, lr: 0.0000\n",
      "Epoch: 415, Training loss: 1.374281, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 416, Training loss: 1.388334, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 417, Training loss: 1.387975, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 418, Training loss: 1.368028, Validation loss: 1.3518, lr: 0.0000\n",
      "Epoch: 419, Training loss: 1.367521, Validation loss: 1.3678, lr: 0.0000\n",
      "Epoch: 420, Training loss: 1.379994, Validation loss: 1.3670, lr: 0.0000\n",
      "Epoch: 421, Training loss: 1.382367, Validation loss: 1.3748, lr: 0.0000\n",
      "Epoch: 422, Training loss: 1.398143, Validation loss: 1.3687, lr: 0.0000\n",
      "Epoch: 423, Training loss: 1.460442, Validation loss: 1.3890, lr: 0.0000\n",
      "Epoch: 424, Training loss: 1.379756, Validation loss: 1.3724, lr: 0.0000\n",
      "Epoch: 425, Training loss: 1.391327, Validation loss: 1.3802, lr: 0.0000\n",
      "Epoch: 426, Training loss: 1.404853, Validation loss: 1.3881, lr: 0.0000\n",
      "Epoch: 427, Training loss: 1.358607, Validation loss: 1.3768, lr: 0.0000\n",
      "Epoch: 428, Training loss: 1.374169, Validation loss: 1.3777, lr: 0.0000\n",
      "Epoch: 429, Training loss: 1.378841, Validation loss: 1.3701, lr: 0.0000\n",
      "Epoch: 430, Training loss: 1.366199, Validation loss: 1.3480, lr: 0.0000\n",
      "Epoch: 431, Training loss: 1.370057, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 432, Training loss: 1.378984, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 433, Training loss: 1.395597, Validation loss: 1.4604, lr: 0.0000\n",
      "Epoch: 434, Training loss: 1.374572, Validation loss: 1.3680, lr: 0.0000\n",
      "Epoch: 435, Training loss: 1.365636, Validation loss: 1.4043, lr: 0.0000\n",
      "Epoch: 436, Training loss: 1.358679, Validation loss: 1.3464, lr: 0.0000\n",
      "Epoch: 437, Training loss: 1.401195, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 438, Training loss: 1.361800, Validation loss: 1.3724, lr: 0.0000\n",
      "Epoch: 439, Training loss: 1.415329, Validation loss: 1.4358, lr: 0.0000\n",
      "Epoch: 440, Training loss: 1.371655, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 441, Training loss: 1.384034, Validation loss: 1.3684, lr: 0.0000\n",
      "Epoch: 442, Training loss: 1.383470, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 443, Training loss: 1.372948, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 444, Training loss: 1.374531, Validation loss: 1.3761, lr: 0.0000\n",
      "Epoch: 445, Training loss: 1.358305, Validation loss: 1.3768, lr: 0.0000\n",
      "Epoch: 446, Training loss: 1.375100, Validation loss: 1.3883, lr: 0.0000\n",
      "Epoch: 447, Training loss: 1.395539, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 448, Training loss: 1.375358, Validation loss: 1.3777, lr: 0.0000\n",
      "Epoch: 449, Training loss: 1.371436, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 450, Training loss: 1.355525, Validation loss: 1.3784, lr: 0.0000\n",
      "Epoch: 451, Training loss: 1.410332, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 452, Training loss: 1.357353, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 453, Training loss: 1.374539, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 454, Training loss: 1.360655, Validation loss: 1.4024, lr: 0.0000\n",
      "Epoch: 455, Training loss: 1.349656, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 456, Training loss: 1.365309, Validation loss: 1.3635, lr: 0.0000\n",
      "Epoch: 457, Training loss: 1.379175, Validation loss: 1.3796, lr: 0.0000\n",
      "Epoch: 458, Training loss: 1.367172, Validation loss: 1.3595, lr: 0.0000\n",
      "Epoch: 459, Training loss: 1.378582, Validation loss: 1.3751, lr: 0.0000\n",
      "Epoch: 460, Training loss: 1.364178, Validation loss: 1.3781, lr: 0.0000\n",
      "Epoch: 461, Training loss: 1.360315, Validation loss: 1.3720, lr: 0.0000\n",
      "Epoch: 462, Training loss: 1.361093, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 463, Training loss: 1.396864, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 464, Training loss: 1.455408, Validation loss: 1.3544, lr: 0.0000\n",
      "Epoch: 465, Training loss: 1.356853, Validation loss: 1.3933, lr: 0.0000\n",
      "Epoch: 466, Training loss: 1.419263, Validation loss: 1.3632, lr: 0.0000\n",
      "Epoch: 467, Training loss: 1.383533, Validation loss: 1.3946, lr: 0.0000\n",
      "Epoch: 468, Training loss: 1.432762, Validation loss: 1.3526, lr: 0.0000\n",
      "Epoch: 469, Training loss: 1.356558, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 470, Training loss: 1.371479, Validation loss: 1.3709, lr: 0.0000\n",
      "Epoch: 471, Training loss: 1.360719, Validation loss: 1.3758, lr: 0.0000\n",
      "Epoch: 472, Training loss: 1.351140, Validation loss: 1.3741, lr: 0.0000\n",
      "Epoch: 473, Training loss: 1.383754, Validation loss: 1.3783, lr: 0.0000\n",
      "Epoch: 474, Training loss: 1.380312, Validation loss: 1.3899, lr: 0.0000\n",
      "Epoch: 475, Training loss: 1.398912, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 476, Training loss: 1.393838, Validation loss: 1.3452, lr: 0.0000\n",
      "Epoch: 477, Training loss: 1.373345, Validation loss: 1.3669, lr: 0.0000\n",
      "Epoch: 478, Training loss: 1.385201, Validation loss: 1.3681, lr: 0.0000\n",
      "Epoch: 479, Training loss: 1.388243, Validation loss: 1.3747, lr: 0.0000\n",
      "Epoch: 480, Training loss: 1.356695, Validation loss: 1.3742, lr: 0.0000\n",
      "Epoch: 481, Training loss: 1.396039, Validation loss: 1.3794, lr: 0.0000\n",
      "Epoch: 482, Training loss: 1.397220, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 483, Training loss: 1.358698, Validation loss: 1.3635, lr: 0.0000\n",
      "Epoch: 484, Training loss: 1.363138, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 485, Training loss: 1.388857, Validation loss: 1.3789, lr: 0.0000\n",
      "Epoch: 486, Training loss: 1.390409, Validation loss: 1.3531, lr: 0.0000\n",
      "Epoch: 487, Training loss: 1.364417, Validation loss: 1.3763, lr: 0.0000\n",
      "Epoch: 488, Training loss: 1.350681, Validation loss: 1.3344, lr: 0.0000\n",
      "Epoch: 489, Training loss: 1.366177, Validation loss: 1.3751, lr: 0.0000\n",
      "Epoch: 490, Training loss: 1.393916, Validation loss: 1.4561, lr: 0.0000\n",
      "Epoch: 491, Training loss: 1.353026, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 492, Training loss: 1.373608, Validation loss: 1.3752, lr: 0.0000\n",
      "Epoch: 493, Training loss: 1.373322, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 494, Training loss: 1.383292, Validation loss: 1.3803, lr: 0.0000\n",
      "Epoch: 495, Training loss: 1.367649, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 496, Training loss: 1.346577, Validation loss: 1.3874, lr: 0.0000\n",
      "Epoch: 497, Training loss: 1.367320, Validation loss: 1.3645, lr: 0.0000\n",
      "Epoch: 498, Training loss: 1.382917, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 499, Training loss: 1.353661, Validation loss: 1.3427, lr: 0.0000\n",
      "Epoch: 500, Training loss: 1.399686, Validation loss: 1.3673, lr: 0.0000\n",
      "Epoch: 501, Training loss: 1.362182, Validation loss: 1.4515, lr: 0.0000\n",
      "Epoch: 502, Training loss: 1.362738, Validation loss: 1.3747, lr: 0.0000\n",
      "Epoch: 503, Training loss: 1.380220, Validation loss: 1.3973, lr: 0.0000\n",
      "Epoch: 504, Training loss: 1.399243, Validation loss: 1.4853, lr: 0.0000\n",
      "Epoch: 505, Training loss: 1.360602, Validation loss: 1.3653, lr: 0.0000\n",
      "Epoch: 506, Training loss: 1.369905, Validation loss: 1.3782, lr: 0.0000\n",
      "Epoch: 507, Training loss: 1.367691, Validation loss: 1.3669, lr: 0.0000\n",
      "Epoch: 508, Training loss: 1.403596, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 509, Training loss: 1.373596, Validation loss: 1.3758, lr: 0.0000\n",
      "Epoch: 510, Training loss: 1.381227, Validation loss: 1.3800, lr: 0.0000\n",
      "Epoch: 511, Training loss: 1.382897, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 512, Training loss: 1.359974, Validation loss: 1.3781, lr: 0.0000\n",
      "Epoch: 513, Training loss: 1.386851, Validation loss: 1.3798, lr: 0.0000\n",
      "Epoch: 514, Training loss: 1.370802, Validation loss: 1.4141, lr: 0.0000\n",
      "Epoch: 515, Training loss: 1.352656, Validation loss: 1.3762, lr: 0.0000\n",
      "Epoch: 516, Training loss: 1.379842, Validation loss: 1.3792, lr: 0.0000\n",
      "Epoch: 517, Training loss: 1.350671, Validation loss: 1.3933, lr: 0.0000\n",
      "Epoch: 518, Training loss: 1.377107, Validation loss: 1.3641, lr: 0.0000\n",
      "Epoch: 519, Training loss: 1.380463, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 520, Training loss: 1.359686, Validation loss: 1.3949, lr: 0.0000\n",
      "Epoch: 521, Training loss: 1.381699, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 522, Training loss: 1.358435, Validation loss: 1.3800, lr: 0.0000\n",
      "Epoch: 523, Training loss: 1.365841, Validation loss: 1.3719, lr: 0.0000\n",
      "Epoch: 524, Training loss: 1.348960, Validation loss: 1.3769, lr: 0.0000\n",
      "Epoch: 525, Training loss: 1.363053, Validation loss: 1.3715, lr: 0.0000\n",
      "Epoch: 526, Training loss: 1.435943, Validation loss: 1.3783, lr: 0.0000\n",
      "Epoch: 527, Training loss: 1.379671, Validation loss: 1.3884, lr: 0.0000\n",
      "Epoch: 528, Training loss: 1.440778, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 529, Training loss: 1.384132, Validation loss: 1.3693, lr: 0.0000\n",
      "Epoch: 530, Training loss: 1.395484, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 531, Training loss: 1.380547, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 532, Training loss: 1.384001, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 533, Training loss: 1.369854, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 534, Training loss: 1.367934, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 535, Training loss: 1.386275, Validation loss: 1.3703, lr: 0.0000\n",
      "Epoch: 536, Training loss: 1.365500, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 537, Training loss: 1.388243, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 538, Training loss: 1.374619, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 539, Training loss: 1.400783, Validation loss: 1.3928, lr: 0.0000\n",
      "Epoch: 540, Training loss: 1.386202, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 541, Training loss: 1.336703, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 542, Training loss: 1.366113, Validation loss: 1.4235, lr: 0.0000\n",
      "Epoch: 543, Training loss: 1.375428, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 544, Training loss: 1.368845, Validation loss: 1.3799, lr: 0.0000\n",
      "Epoch: 545, Training loss: 1.372436, Validation loss: 1.3729, lr: 0.0000\n",
      "Epoch: 546, Training loss: 1.375959, Validation loss: 1.3802, lr: 0.0000\n",
      "Epoch: 547, Training loss: 1.368865, Validation loss: 1.3796, lr: 0.0000\n",
      "Epoch: 548, Training loss: 1.355337, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 549, Training loss: 1.365612, Validation loss: 1.3502, lr: 0.0000\n",
      "Epoch: 550, Training loss: 1.369198, Validation loss: 1.3631, lr: 0.0000\n",
      "Epoch: 551, Training loss: 1.385140, Validation loss: 1.3802, lr: 0.0000\n",
      "Epoch: 552, Training loss: 1.359919, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 553, Training loss: 1.367834, Validation loss: 1.3779, lr: 0.0000\n",
      "Epoch: 554, Training loss: 1.414573, Validation loss: 1.3689, lr: 0.0000\n",
      "Epoch: 555, Training loss: 1.405936, Validation loss: 1.3962, lr: 0.0000\n",
      "Epoch: 556, Training loss: 1.358719, Validation loss: 1.3723, lr: 0.0000\n",
      "Epoch: 557, Training loss: 1.383494, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 558, Training loss: 1.383766, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 559, Training loss: 1.362258, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 560, Training loss: 1.365946, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 561, Training loss: 1.385785, Validation loss: 1.3666, lr: 0.0000\n",
      "Epoch: 562, Training loss: 1.393950, Validation loss: 1.3493, lr: 0.0000\n",
      "Epoch: 563, Training loss: 1.383843, Validation loss: 1.3751, lr: 0.0000\n",
      "Epoch: 564, Training loss: 1.371985, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 565, Training loss: 1.337528, Validation loss: 1.3752, lr: 0.0000\n",
      "Epoch: 566, Training loss: 1.367425, Validation loss: 1.3718, lr: 0.0000\n",
      "Epoch: 567, Training loss: 1.375840, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 568, Training loss: 1.385759, Validation loss: 1.3690, lr: 0.0000\n",
      "Epoch: 569, Training loss: 1.438039, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 570, Training loss: 1.358730, Validation loss: 1.3756, lr: 0.0000\n",
      "Epoch: 571, Training loss: 1.360663, Validation loss: 1.3682, lr: 0.0000\n",
      "Epoch: 572, Training loss: 1.411663, Validation loss: 1.4056, lr: 0.0000\n",
      "Epoch: 573, Training loss: 1.382452, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 574, Training loss: 1.411832, Validation loss: 1.3753, lr: 0.0000\n",
      "Epoch: 575, Training loss: 1.355510, Validation loss: 1.7392, lr: 0.0000\n",
      "Epoch: 576, Training loss: 1.426346, Validation loss: 1.3783, lr: 0.0000\n",
      "Epoch: 577, Training loss: 1.361631, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 578, Training loss: 1.373251, Validation loss: 1.3727, lr: 0.0000\n",
      "Epoch: 579, Training loss: 1.371748, Validation loss: 1.3742, lr: 0.0000\n",
      "Epoch: 580, Training loss: 1.363186, Validation loss: 1.3590, lr: 0.0000\n",
      "Epoch: 581, Training loss: 1.378676, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 582, Training loss: 1.387150, Validation loss: 1.3678, lr: 0.0000\n",
      "Epoch: 583, Training loss: 1.352649, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 584, Training loss: 1.358235, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 585, Training loss: 1.396886, Validation loss: 1.3721, lr: 0.0000\n",
      "Epoch: 586, Training loss: 1.368678, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 587, Training loss: 1.404225, Validation loss: 1.3738, lr: 0.0000\n",
      "Epoch: 588, Training loss: 1.355640, Validation loss: 1.3763, lr: 0.0000\n",
      "Epoch: 589, Training loss: 1.396928, Validation loss: 1.3799, lr: 0.0000\n",
      "Epoch: 590, Training loss: 1.403979, Validation loss: 1.3654, lr: 0.0000\n",
      "Epoch: 591, Training loss: 1.378568, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 592, Training loss: 1.370391, Validation loss: 1.3743, lr: 0.0000\n",
      "Epoch: 593, Training loss: 1.387986, Validation loss: 1.3595, lr: 0.0000\n",
      "Epoch: 594, Training loss: 1.367668, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 595, Training loss: 1.372284, Validation loss: 1.3665, lr: 0.0000\n",
      "Epoch: 596, Training loss: 1.408820, Validation loss: 1.3875, lr: 0.0000\n",
      "Epoch: 597, Training loss: 1.394155, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 598, Training loss: 1.400261, Validation loss: 1.3660, lr: 0.0000\n",
      "Epoch: 599, Training loss: 1.372508, Validation loss: 1.4133, lr: 0.0000\n",
      "Epoch: 600, Training loss: 1.370230, Validation loss: 1.3742, lr: 0.0000\n",
      "Epoch: 601, Training loss: 1.385858, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 602, Training loss: 1.373119, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 603, Training loss: 1.361763, Validation loss: 1.3845, lr: 0.0000\n",
      "Epoch: 604, Training loss: 1.351630, Validation loss: 1.3762, lr: 0.0000\n",
      "Epoch: 605, Training loss: 1.383881, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 606, Training loss: 1.367190, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 607, Training loss: 1.349513, Validation loss: 1.3553, lr: 0.0000\n",
      "Epoch: 608, Training loss: 1.399398, Validation loss: 1.3632, lr: 0.0000\n",
      "Epoch: 609, Training loss: 1.360808, Validation loss: 1.3777, lr: 0.0000\n",
      "Epoch: 610, Training loss: 1.369679, Validation loss: 1.3793, lr: 0.0000\n",
      "Epoch: 611, Training loss: 1.383193, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 612, Training loss: 1.380694, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 613, Training loss: 1.376522, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 614, Training loss: 1.382365, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 615, Training loss: 1.373207, Validation loss: 1.4652, lr: 0.0000\n",
      "Epoch: 616, Training loss: 1.366309, Validation loss: 1.3768, lr: 0.0000\n",
      "Epoch: 617, Training loss: 1.378097, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 618, Training loss: 1.391858, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 619, Training loss: 1.390568, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 620, Training loss: 1.382909, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 621, Training loss: 1.355408, Validation loss: 1.3707, lr: 0.0000\n",
      "Epoch: 622, Training loss: 1.407482, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 623, Training loss: 1.402511, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 624, Training loss: 1.388111, Validation loss: 1.3785, lr: 0.0000\n",
      "Epoch: 625, Training loss: 1.383856, Validation loss: 1.3762, lr: 0.0000\n",
      "Epoch: 626, Training loss: 1.355653, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 627, Training loss: 1.354309, Validation loss: 1.3594, lr: 0.0000\n",
      "Epoch: 628, Training loss: 1.379031, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 629, Training loss: 1.365943, Validation loss: 1.3432, lr: 0.0000\n",
      "Epoch: 630, Training loss: 1.389201, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 631, Training loss: 1.371725, Validation loss: 1.3649, lr: 0.0000\n",
      "Epoch: 632, Training loss: 1.359743, Validation loss: 1.3707, lr: 0.0000\n",
      "Epoch: 633, Training loss: 1.359223, Validation loss: 1.3582, lr: 0.0000\n",
      "Epoch: 634, Training loss: 1.379294, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 635, Training loss: 1.421923, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 636, Training loss: 1.389643, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 637, Training loss: 1.379799, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 638, Training loss: 1.361779, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 639, Training loss: 1.387483, Validation loss: 1.3742, lr: 0.0000\n",
      "Epoch: 640, Training loss: 1.375072, Validation loss: 1.3755, lr: 0.0000\n",
      "Epoch: 641, Training loss: 1.364028, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 642, Training loss: 1.367017, Validation loss: 1.3939, lr: 0.0000\n",
      "Epoch: 643, Training loss: 1.357096, Validation loss: 1.3789, lr: 0.0000\n",
      "Epoch: 644, Training loss: 1.359511, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 645, Training loss: 1.468696, Validation loss: 1.3829, lr: 0.0000\n",
      "Epoch: 646, Training loss: 1.372362, Validation loss: 1.3501, lr: 0.0000\n",
      "Epoch: 647, Training loss: 1.354423, Validation loss: 1.3793, lr: 0.0000\n",
      "Epoch: 648, Training loss: 1.419701, Validation loss: 1.3445, lr: 0.0000\n",
      "Epoch: 649, Training loss: 1.392894, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 650, Training loss: 1.368959, Validation loss: 1.3871, lr: 0.0000\n",
      "Epoch: 651, Training loss: 1.387359, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 652, Training loss: 1.376749, Validation loss: 1.3916, lr: 0.0000\n",
      "Epoch: 653, Training loss: 1.344859, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 654, Training loss: 1.346618, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 655, Training loss: 1.356781, Validation loss: 1.3560, lr: 0.0000\n",
      "Epoch: 656, Training loss: 1.385289, Validation loss: 1.3736, lr: 0.0000\n",
      "Epoch: 657, Training loss: 1.363698, Validation loss: 1.3793, lr: 0.0000\n",
      "Epoch: 658, Training loss: 1.354454, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 659, Training loss: 1.394874, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 660, Training loss: 1.361943, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 661, Training loss: 1.467840, Validation loss: 1.3730, lr: 0.0000\n",
      "Epoch: 662, Training loss: 1.348753, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 663, Training loss: 1.383005, Validation loss: 1.3727, lr: 0.0000\n",
      "Epoch: 664, Training loss: 1.358768, Validation loss: 1.6809, lr: 0.0000\n",
      "Epoch: 665, Training loss: 1.438144, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 666, Training loss: 1.371479, Validation loss: 1.3857, lr: 0.0000\n",
      "Epoch: 667, Training loss: 1.409510, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 668, Training loss: 1.383800, Validation loss: 1.3727, lr: 0.0000\n",
      "Epoch: 669, Training loss: 1.383678, Validation loss: 1.3498, lr: 0.0000\n",
      "Epoch: 670, Training loss: 1.353058, Validation loss: 1.3928, lr: 0.0000\n",
      "Epoch: 671, Training loss: 1.397173, Validation loss: 1.3686, lr: 0.0000\n",
      "Epoch: 672, Training loss: 1.375427, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 673, Training loss: 1.348845, Validation loss: 1.3660, lr: 0.0000\n",
      "Epoch: 674, Training loss: 1.362601, Validation loss: 1.3684, lr: 0.0000\n",
      "Epoch: 675, Training loss: 1.381480, Validation loss: 1.3720, lr: 0.0000\n",
      "Epoch: 676, Training loss: 1.369822, Validation loss: 1.3898, lr: 0.0000\n",
      "Epoch: 677, Training loss: 1.346862, Validation loss: 1.3486, lr: 0.0000\n",
      "Epoch: 678, Training loss: 1.383536, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 679, Training loss: 1.365703, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 680, Training loss: 1.375735, Validation loss: 1.3927, lr: 0.0000\n",
      "Epoch: 681, Training loss: 1.377704, Validation loss: 1.3792, lr: 0.0000\n",
      "Epoch: 682, Training loss: 1.374317, Validation loss: 1.3677, lr: 0.0000\n",
      "Epoch: 683, Training loss: 1.382181, Validation loss: 1.3837, lr: 0.0000\n",
      "Epoch: 684, Training loss: 1.392801, Validation loss: 1.3874, lr: 0.0000\n",
      "Epoch: 685, Training loss: 1.367729, Validation loss: 1.3761, lr: 0.0000\n",
      "Epoch: 686, Training loss: 1.360778, Validation loss: 1.6370, lr: 0.0000\n",
      "Epoch: 687, Training loss: 1.376696, Validation loss: 1.3740, lr: 0.0000\n",
      "Epoch: 688, Training loss: 1.351925, Validation loss: 1.3407, lr: 0.0000\n",
      "Epoch: 689, Training loss: 1.366583, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 690, Training loss: 1.359789, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 691, Training loss: 1.336507, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 692, Training loss: 1.347079, Validation loss: 1.3715, lr: 0.0000\n",
      "Epoch: 693, Training loss: 1.381835, Validation loss: 1.3775, lr: 0.0000\n",
      "Epoch: 694, Training loss: 1.371283, Validation loss: 1.3734, lr: 0.0000\n",
      "Epoch: 695, Training loss: 1.402190, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 696, Training loss: 1.387539, Validation loss: 1.3744, lr: 0.0000\n",
      "Epoch: 697, Training loss: 1.376746, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 698, Training loss: 1.432868, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 699, Training loss: 1.370635, Validation loss: 1.3706, lr: 0.0000\n",
      "Epoch: 700, Training loss: 1.368200, Validation loss: 1.3727, lr: 0.0000\n",
      "Epoch: 701, Training loss: 1.403287, Validation loss: 1.3921, lr: 0.0000\n",
      "Epoch: 702, Training loss: 1.378895, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 703, Training loss: 1.380403, Validation loss: 1.3794, lr: 0.0000\n",
      "Epoch: 704, Training loss: 1.375903, Validation loss: 1.3691, lr: 0.0000\n",
      "Epoch: 705, Training loss: 1.360221, Validation loss: 1.3741, lr: 0.0000\n",
      "Epoch: 706, Training loss: 1.429183, Validation loss: 1.3508, lr: 0.0000\n",
      "Epoch: 707, Training loss: 1.401329, Validation loss: 1.3716, lr: 0.0000\n",
      "Epoch: 708, Training loss: 1.367345, Validation loss: 1.3797, lr: 0.0000\n",
      "Epoch: 709, Training loss: 1.357174, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 710, Training loss: 1.366086, Validation loss: 1.3797, lr: 0.0000\n",
      "Epoch: 711, Training loss: 1.377467, Validation loss: 1.3675, lr: 0.0000\n",
      "Epoch: 712, Training loss: 1.391616, Validation loss: 1.3786, lr: 0.0000\n",
      "Epoch: 713, Training loss: 1.397353, Validation loss: 1.3904, lr: 0.0000\n",
      "Epoch: 714, Training loss: 1.368801, Validation loss: 1.5455, lr: 0.0000\n",
      "Epoch: 715, Training loss: 1.372975, Validation loss: 1.3871, lr: 0.0000\n",
      "Epoch: 716, Training loss: 1.390405, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 717, Training loss: 1.362330, Validation loss: 1.3725, lr: 0.0000\n",
      "Epoch: 718, Training loss: 1.377924, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 719, Training loss: 1.366231, Validation loss: 1.3882, lr: 0.0000\n",
      "Epoch: 720, Training loss: 1.366092, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 721, Training loss: 1.343761, Validation loss: 1.3817, lr: 0.0000\n",
      "Epoch: 722, Training loss: 1.358658, Validation loss: 1.3760, lr: 0.0000\n",
      "Epoch: 723, Training loss: 1.362911, Validation loss: 1.3642, lr: 0.0000\n",
      "Epoch: 724, Training loss: 1.379547, Validation loss: 1.3870, lr: 0.0000\n",
      "Epoch: 725, Training loss: 1.377072, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 726, Training loss: 1.431954, Validation loss: 1.3638, lr: 0.0000\n",
      "Epoch: 727, Training loss: 1.365382, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 728, Training loss: 1.372956, Validation loss: 1.3809, lr: 0.0000\n",
      "Epoch: 729, Training loss: 1.376484, Validation loss: 1.3789, lr: 0.0000\n",
      "Epoch: 730, Training loss: 1.394118, Validation loss: 1.4039, lr: 0.0000\n",
      "Epoch: 731, Training loss: 1.380713, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 732, Training loss: 1.367456, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 733, Training loss: 1.384117, Validation loss: 1.3788, lr: 0.0000\n",
      "Epoch: 734, Training loss: 1.354265, Validation loss: 1.3666, lr: 0.0000\n",
      "Epoch: 735, Training loss: 1.385448, Validation loss: 1.3798, lr: 0.0000\n",
      "Epoch: 736, Training loss: 1.389415, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 737, Training loss: 1.373620, Validation loss: 1.3803, lr: 0.0000\n",
      "Epoch: 738, Training loss: 1.354858, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 739, Training loss: 1.373784, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 740, Training loss: 1.356530, Validation loss: 1.3715, lr: 0.0000\n",
      "Epoch: 741, Training loss: 1.360793, Validation loss: 1.3727, lr: 0.0000\n",
      "Epoch: 742, Training loss: 1.374941, Validation loss: 1.3937, lr: 0.0000\n",
      "Epoch: 743, Training loss: 1.367796, Validation loss: 1.3759, lr: 0.0000\n",
      "Epoch: 744, Training loss: 1.540096, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 745, Training loss: 1.375808, Validation loss: 1.3709, lr: 0.0000\n",
      "Epoch: 746, Training loss: 1.377770, Validation loss: 1.3583, lr: 0.0000\n",
      "Epoch: 747, Training loss: 1.384703, Validation loss: 1.3747, lr: 0.0000\n",
      "Epoch: 748, Training loss: 1.370091, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 749, Training loss: 1.370093, Validation loss: 1.3789, lr: 0.0000\n",
      "Epoch: 750, Training loss: 1.428673, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 751, Training loss: 1.386482, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 752, Training loss: 1.379222, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 753, Training loss: 1.372361, Validation loss: 1.3766, lr: 0.0000\n",
      "Epoch: 754, Training loss: 1.385059, Validation loss: 1.3773, lr: 0.0000\n",
      "Epoch: 755, Training loss: 1.370032, Validation loss: 1.3681, lr: 0.0000\n",
      "Epoch: 756, Training loss: 1.357255, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 757, Training loss: 1.377077, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 758, Training loss: 1.384342, Validation loss: 1.3688, lr: 0.0000\n",
      "Epoch: 759, Training loss: 1.375616, Validation loss: 1.3653, lr: 0.0000\n",
      "Epoch: 760, Training loss: 1.380629, Validation loss: 1.3568, lr: 0.0000\n",
      "Epoch: 761, Training loss: 1.392427, Validation loss: 1.3782, lr: 0.0000\n",
      "Epoch: 762, Training loss: 1.409314, Validation loss: 1.3770, lr: 0.0000\n",
      "Epoch: 763, Training loss: 1.354962, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 764, Training loss: 1.370107, Validation loss: 1.3735, lr: 0.0000\n",
      "Epoch: 765, Training loss: 1.367700, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 766, Training loss: 1.355974, Validation loss: 1.3761, lr: 0.0000\n",
      "Epoch: 767, Training loss: 1.360841, Validation loss: 1.3883, lr: 0.0000\n",
      "Epoch: 768, Training loss: 1.364226, Validation loss: 1.3724, lr: 0.0000\n",
      "Epoch: 769, Training loss: 1.369278, Validation loss: 1.3883, lr: 0.0000\n",
      "Epoch: 770, Training loss: 1.392470, Validation loss: 1.3772, lr: 0.0000\n",
      "Epoch: 771, Training loss: 1.352212, Validation loss: 1.3702, lr: 0.0000\n",
      "Epoch: 772, Training loss: 1.362431, Validation loss: 1.3972, lr: 0.0000\n",
      "Epoch: 773, Training loss: 1.369505, Validation loss: 1.3777, lr: 0.0000\n",
      "Epoch: 774, Training loss: 1.370660, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 775, Training loss: 1.431592, Validation loss: 1.3604, lr: 0.0000\n",
      "Epoch: 776, Training loss: 1.362530, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 777, Training loss: 1.395150, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 778, Training loss: 1.385522, Validation loss: 1.3605, lr: 0.0000\n",
      "Epoch: 779, Training loss: 1.369088, Validation loss: 1.3719, lr: 0.0000\n",
      "Epoch: 780, Training loss: 1.376175, Validation loss: 1.4049, lr: 0.0000\n",
      "Epoch: 781, Training loss: 1.390365, Validation loss: 1.3871, lr: 0.0000\n",
      "Epoch: 782, Training loss: 1.369591, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 783, Training loss: 1.377323, Validation loss: 1.3816, lr: 0.0000\n",
      "Epoch: 784, Training loss: 1.371001, Validation loss: 1.3787, lr: 0.0000\n",
      "Epoch: 785, Training loss: 1.374806, Validation loss: 1.3756, lr: 0.0000\n",
      "Epoch: 786, Training loss: 1.370293, Validation loss: 1.3752, lr: 0.0000\n",
      "Epoch: 787, Training loss: 1.374946, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 788, Training loss: 1.358708, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 789, Training loss: 1.383128, Validation loss: 1.3802, lr: 0.0000\n",
      "Epoch: 790, Training loss: 1.354111, Validation loss: 1.3783, lr: 0.0000\n",
      "Epoch: 791, Training loss: 1.376655, Validation loss: 1.3664, lr: 0.0000\n",
      "Epoch: 792, Training loss: 1.378695, Validation loss: 1.3752, lr: 0.0000\n",
      "Epoch: 793, Training loss: 1.403644, Validation loss: 1.3697, lr: 0.0000\n",
      "Epoch: 794, Training loss: 1.377811, Validation loss: 1.3426, lr: 0.0000\n",
      "Epoch: 795, Training loss: 1.379337, Validation loss: 1.3638, lr: 0.0000\n",
      "Epoch: 796, Training loss: 1.382111, Validation loss: 1.3778, lr: 0.0000\n",
      "Epoch: 797, Training loss: 1.373748, Validation loss: 1.3803, lr: 0.0000\n",
      "Epoch: 798, Training loss: 1.413383, Validation loss: 1.3610, lr: 0.0000\n",
      "Epoch: 799, Training loss: 1.369590, Validation loss: 1.3649, lr: 0.0000\n",
      "Epoch: 800, Training loss: 1.409023, Validation loss: 1.3779, lr: 0.0000\n",
      "Epoch: 801, Training loss: 1.358294, Validation loss: 1.3751, lr: 0.0000\n",
      "Epoch: 802, Training loss: 1.351664, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 803, Training loss: 1.380047, Validation loss: 1.3686, lr: 0.0000\n",
      "Epoch: 804, Training loss: 1.365355, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 805, Training loss: 1.383965, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 806, Training loss: 1.365530, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 807, Training loss: 1.376096, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 808, Training loss: 1.379199, Validation loss: 1.3843, lr: 0.0000\n",
      "Epoch: 809, Training loss: 1.368603, Validation loss: 1.3669, lr: 0.0000\n",
      "Epoch: 810, Training loss: 1.366994, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 811, Training loss: 1.369141, Validation loss: 1.4572, lr: 0.0000\n",
      "Epoch: 812, Training loss: 1.519907, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 813, Training loss: 1.369372, Validation loss: 1.3706, lr: 0.0000\n",
      "Epoch: 814, Training loss: 1.380667, Validation loss: 1.3841, lr: 0.0000\n",
      "Epoch: 815, Training loss: 1.405377, Validation loss: 1.3795, lr: 0.0000\n",
      "Epoch: 816, Training loss: 1.375055, Validation loss: 1.3941, lr: 0.0000\n",
      "Epoch: 817, Training loss: 1.487236, Validation loss: 1.3489, lr: 0.0000\n",
      "Epoch: 818, Training loss: 1.372183, Validation loss: 1.3738, lr: 0.0000\n",
      "Epoch: 819, Training loss: 1.372759, Validation loss: 1.3777, lr: 0.0000\n",
      "Epoch: 820, Training loss: 1.361752, Validation loss: 1.4131, lr: 0.0000\n",
      "Epoch: 821, Training loss: 1.385599, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 822, Training loss: 1.413897, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 823, Training loss: 1.353695, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 824, Training loss: 1.366173, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 825, Training loss: 1.368422, Validation loss: 1.3687, lr: 0.0000\n",
      "Epoch: 826, Training loss: 1.375615, Validation loss: 1.3785, lr: 0.0000\n",
      "Epoch: 827, Training loss: 1.391332, Validation loss: 1.3733, lr: 0.0000\n",
      "Epoch: 828, Training loss: 1.362853, Validation loss: 1.3726, lr: 0.0000\n",
      "Epoch: 829, Training loss: 1.411180, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 830, Training loss: 1.378392, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 831, Training loss: 1.386056, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 832, Training loss: 1.365523, Validation loss: 1.3866, lr: 0.0000\n",
      "Epoch: 833, Training loss: 1.409552, Validation loss: 1.3907, lr: 0.0000\n",
      "Epoch: 834, Training loss: 1.368024, Validation loss: 1.3931, lr: 0.0000\n",
      "Epoch: 835, Training loss: 1.417783, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 836, Training loss: 1.379152, Validation loss: 1.3736, lr: 0.0000\n",
      "Epoch: 837, Training loss: 1.424540, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 838, Training loss: 1.388977, Validation loss: 1.3790, lr: 0.0000\n",
      "Epoch: 839, Training loss: 1.493423, Validation loss: 1.3770, lr: 0.0000\n",
      "Epoch: 840, Training loss: 1.348645, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 841, Training loss: 1.374454, Validation loss: 1.3795, lr: 0.0000\n",
      "Epoch: 842, Training loss: 1.391414, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 843, Training loss: 1.350327, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 844, Training loss: 1.355009, Validation loss: 1.4606, lr: 0.0000\n",
      "Epoch: 845, Training loss: 1.383989, Validation loss: 1.3770, lr: 0.0000\n",
      "Epoch: 846, Training loss: 1.357580, Validation loss: 1.3818, lr: 0.0000\n",
      "Epoch: 847, Training loss: 1.357354, Validation loss: 1.3748, lr: 0.0000\n",
      "Epoch: 848, Training loss: 1.373258, Validation loss: 1.3835, lr: 0.0000\n",
      "Epoch: 849, Training loss: 1.358282, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 850, Training loss: 1.373972, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 851, Training loss: 1.362069, Validation loss: 1.3788, lr: 0.0000\n",
      "Epoch: 852, Training loss: 1.359232, Validation loss: 1.3709, lr: 0.0000\n",
      "Epoch: 853, Training loss: 1.379303, Validation loss: 1.3792, lr: 0.0000\n",
      "Epoch: 854, Training loss: 1.361870, Validation loss: 1.3757, lr: 0.0000\n",
      "Epoch: 855, Training loss: 1.392350, Validation loss: 1.3763, lr: 0.0000\n",
      "Epoch: 856, Training loss: 1.386719, Validation loss: 1.3675, lr: 0.0000\n",
      "Epoch: 857, Training loss: 1.362973, Validation loss: 1.3643, lr: 0.0000\n",
      "Epoch: 858, Training loss: 1.377555, Validation loss: 1.3798, lr: 0.0000\n",
      "Epoch: 859, Training loss: 1.368944, Validation loss: 1.3775, lr: 0.0000\n",
      "Epoch: 860, Training loss: 1.357895, Validation loss: 1.3767, lr: 0.0000\n",
      "Epoch: 861, Training loss: 1.365755, Validation loss: 1.3667, lr: 0.0000\n",
      "Epoch: 862, Training loss: 1.381882, Validation loss: 1.3792, lr: 0.0000\n",
      "Epoch: 863, Training loss: 1.380084, Validation loss: 1.3918, lr: 0.0000\n",
      "Epoch: 864, Training loss: 1.387716, Validation loss: 1.5136, lr: 0.0000\n",
      "Epoch: 865, Training loss: 1.422108, Validation loss: 1.3795, lr: 0.0000\n",
      "Epoch: 866, Training loss: 1.359048, Validation loss: 1.3800, lr: 0.0000\n",
      "Epoch: 867, Training loss: 1.344333, Validation loss: 1.3755, lr: 0.0000\n",
      "Epoch: 868, Training loss: 1.366875, Validation loss: 1.3607, lr: 0.0000\n",
      "Epoch: 869, Training loss: 1.369078, Validation loss: 1.3809, lr: 0.0000\n",
      "Epoch: 870, Training loss: 1.352574, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 871, Training loss: 1.370621, Validation loss: 1.3701, lr: 0.0000\n",
      "Epoch: 872, Training loss: 1.398131, Validation loss: 1.3662, lr: 0.0000\n",
      "Epoch: 873, Training loss: 1.371319, Validation loss: 1.4074, lr: 0.0000\n",
      "Epoch: 874, Training loss: 1.364824, Validation loss: 1.3796, lr: 0.0000\n",
      "Epoch: 875, Training loss: 1.364209, Validation loss: 1.3652, lr: 0.0000\n",
      "Epoch: 876, Training loss: 1.367822, Validation loss: 1.3591, lr: 0.0000\n",
      "Epoch: 877, Training loss: 1.370618, Validation loss: 1.3880, lr: 0.0000\n",
      "Epoch: 878, Training loss: 1.393575, Validation loss: 1.3869, lr: 0.0000\n",
      "Epoch: 879, Training loss: 1.363368, Validation loss: 1.3932, lr: 0.0000\n",
      "Epoch: 880, Training loss: 1.374454, Validation loss: 1.3779, lr: 0.0000\n",
      "Epoch: 881, Training loss: 1.376219, Validation loss: 1.3794, lr: 0.0000\n",
      "Epoch: 882, Training loss: 1.363271, Validation loss: 1.3730, lr: 0.0000\n",
      "Epoch: 883, Training loss: 1.377728, Validation loss: 1.3768, lr: 0.0000\n",
      "Epoch: 884, Training loss: 1.358532, Validation loss: 1.4036, lr: 0.0000\n",
      "Epoch: 885, Training loss: 1.396674, Validation loss: 1.3691, lr: 0.0000\n",
      "Epoch: 886, Training loss: 1.371882, Validation loss: 1.3740, lr: 0.0000\n",
      "Epoch: 887, Training loss: 1.350231, Validation loss: 1.3890, lr: 0.0000\n",
      "Epoch: 888, Training loss: 1.364274, Validation loss: 1.3809, lr: 0.0000\n",
      "Epoch: 889, Training loss: 1.363541, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 890, Training loss: 1.390249, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 891, Training loss: 1.379483, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 892, Training loss: 1.367417, Validation loss: 1.3744, lr: 0.0000\n",
      "Epoch: 893, Training loss: 1.401815, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 894, Training loss: 1.403526, Validation loss: 1.3739, lr: 0.0000\n",
      "Epoch: 895, Training loss: 1.382590, Validation loss: 1.3701, lr: 0.0000\n",
      "Epoch: 896, Training loss: 1.380005, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 897, Training loss: 1.383097, Validation loss: 1.3735, lr: 0.0000\n",
      "Epoch: 898, Training loss: 1.372250, Validation loss: 1.3855, lr: 0.0000\n",
      "Epoch: 899, Training loss: 1.352701, Validation loss: 1.3906, lr: 0.0000\n",
      "Epoch: 900, Training loss: 1.348566, Validation loss: 1.3696, lr: 0.0000\n",
      "Epoch: 901, Training loss: 1.362322, Validation loss: 1.3711, lr: 0.0000\n",
      "Epoch: 902, Training loss: 1.343247, Validation loss: 1.3809, lr: 0.0000\n",
      "Epoch: 903, Training loss: 1.357367, Validation loss: 1.3776, lr: 0.0000\n",
      "Epoch: 904, Training loss: 1.368375, Validation loss: 1.3781, lr: 0.0000\n",
      "Epoch: 905, Training loss: 1.333695, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 906, Training loss: 1.365272, Validation loss: 1.3846, lr: 0.0000\n",
      "Epoch: 907, Training loss: 1.366246, Validation loss: 1.3705, lr: 0.0000\n",
      "Epoch: 908, Training loss: 1.352088, Validation loss: 3.9087, lr: 0.0000\n",
      "Epoch: 909, Training loss: 1.389871, Validation loss: 1.3649, lr: 0.0000\n",
      "Epoch: 910, Training loss: 1.397916, Validation loss: 1.3992, lr: 0.0000\n",
      "Epoch: 911, Training loss: 1.363786, Validation loss: 1.3619, lr: 0.0000\n",
      "Epoch: 912, Training loss: 1.393802, Validation loss: 1.3679, lr: 0.0000\n",
      "Epoch: 913, Training loss: 1.387030, Validation loss: 1.3851, lr: 0.0000\n",
      "Epoch: 914, Training loss: 1.348494, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 915, Training loss: 1.366760, Validation loss: 1.3785, lr: 0.0000\n",
      "Epoch: 916, Training loss: 1.365057, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 917, Training loss: 1.374455, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 918, Training loss: 1.374460, Validation loss: 1.3921, lr: 0.0000\n",
      "Epoch: 919, Training loss: 1.382058, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 920, Training loss: 1.368400, Validation loss: 1.3852, lr: 0.0000\n",
      "Epoch: 921, Training loss: 1.377482, Validation loss: 1.3701, lr: 0.0000\n",
      "Epoch: 922, Training loss: 1.377591, Validation loss: 1.3781, lr: 0.0000\n",
      "Epoch: 923, Training loss: 1.360249, Validation loss: 1.3681, lr: 0.0000\n",
      "Epoch: 924, Training loss: 1.369428, Validation loss: 1.3660, lr: 0.0000\n",
      "Epoch: 925, Training loss: 1.367308, Validation loss: 1.3782, lr: 0.0000\n",
      "Epoch: 926, Training loss: 1.372929, Validation loss: 1.3682, lr: 0.0000\n",
      "Epoch: 927, Training loss: 1.374925, Validation loss: 1.3844, lr: 0.0000\n",
      "Epoch: 928, Training loss: 1.390083, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 929, Training loss: 1.418120, Validation loss: 1.3822, lr: 0.0000\n",
      "Epoch: 930, Training loss: 1.386811, Validation loss: 1.3780, lr: 0.0000\n",
      " *och: 931, Training loss: 1.366246, Validation loss: 1.3223, lr: 0.0000\n",
      "Epoch: 932, Training loss: 1.375104, Validation loss: 1.3689, lr: 0.0000\n",
      "Epoch: 933, Training loss: 1.355955, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 934, Training loss: 1.348419, Validation loss: 1.3677, lr: 0.0000\n",
      "Epoch: 935, Training loss: 1.341131, Validation loss: 1.3744, lr: 0.0000\n",
      "Epoch: 936, Training loss: 1.360413, Validation loss: 1.3863, lr: 0.0000\n",
      "Epoch: 937, Training loss: 1.377641, Validation loss: 1.3804, lr: 0.0000\n",
      "Epoch: 938, Training loss: 1.373013, Validation loss: 1.3721, lr: 0.0000\n",
      "Epoch: 939, Training loss: 1.362796, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 940, Training loss: 1.367445, Validation loss: 1.3799, lr: 0.0000\n",
      "Epoch: 941, Training loss: 1.348194, Validation loss: 1.3681, lr: 0.0000\n",
      "Epoch: 942, Training loss: 1.356889, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 943, Training loss: 1.352133, Validation loss: 1.3587, lr: 0.0000\n",
      "Epoch: 944, Training loss: 1.355548, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 945, Training loss: 1.364183, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 946, Training loss: 1.375529, Validation loss: 1.3729, lr: 0.0000\n",
      "Epoch: 947, Training loss: 1.369115, Validation loss: 1.3679, lr: 0.0000\n",
      "Epoch: 948, Training loss: 1.386866, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 949, Training loss: 1.357205, Validation loss: 1.3717, lr: 0.0000\n",
      "Epoch: 950, Training loss: 1.372970, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 951, Training loss: 1.380809, Validation loss: 1.3842, lr: 0.0000\n",
      "Epoch: 952, Training loss: 1.348802, Validation loss: 1.3680, lr: 0.0000\n",
      "Epoch: 953, Training loss: 1.358516, Validation loss: 1.3854, lr: 0.0000\n",
      "Epoch: 954, Training loss: 1.353762, Validation loss: 1.3790, lr: 0.0000\n",
      "Epoch: 955, Training loss: 1.361565, Validation loss: 1.3764, lr: 0.0000\n",
      "Epoch: 956, Training loss: 1.386797, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 957, Training loss: 1.364767, Validation loss: 1.3860, lr: 0.0000\n",
      "Epoch: 958, Training loss: 1.371156, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 959, Training loss: 1.349158, Validation loss: 1.3759, lr: 0.0000\n",
      "Epoch: 960, Training loss: 1.381227, Validation loss: 1.3689, lr: 0.0000\n",
      "Epoch: 961, Training loss: 1.366058, Validation loss: 1.3777, lr: 0.0000\n",
      "Epoch: 962, Training loss: 1.368265, Validation loss: 1.4017, lr: 0.0000\n",
      "Epoch: 963, Training loss: 1.365299, Validation loss: 1.3751, lr: 0.0000\n",
      "Epoch: 964, Training loss: 1.429837, Validation loss: 1.3881, lr: 0.0000\n",
      "Epoch: 965, Training loss: 1.395320, Validation loss: 1.3754, lr: 0.0000\n",
      "Epoch: 966, Training loss: 1.365440, Validation loss: 1.3484, lr: 0.0000\n",
      "Epoch: 967, Training loss: 1.427054, Validation loss: 1.3681, lr: 0.0000\n",
      "Epoch: 968, Training loss: 1.404371, Validation loss: 1.3912, lr: 0.0000\n",
      "Epoch: 969, Training loss: 1.370556, Validation loss: 1.3867, lr: 0.0000\n",
      "Epoch: 970, Training loss: 1.361337, Validation loss: 1.3582, lr: 0.0000\n",
      "Epoch: 971, Training loss: 1.357554, Validation loss: 1.3881, lr: 0.0000\n",
      "Epoch: 972, Training loss: 1.434208, Validation loss: 1.3797, lr: 0.0000\n",
      "Epoch: 973, Training loss: 1.376554, Validation loss: 1.3754, lr: 0.0000\n",
      "Epoch: 974, Training loss: 1.407242, Validation loss: 1.3723, lr: 0.0000\n",
      "Epoch: 975, Training loss: 1.366696, Validation loss: 1.3531, lr: 0.0000\n",
      "Epoch: 976, Training loss: 1.371197, Validation loss: 1.3701, lr: 0.0000\n",
      "Epoch: 977, Training loss: 1.360200, Validation loss: 1.3798, lr: 0.0000\n",
      "Epoch: 978, Training loss: 1.381569, Validation loss: 1.3702, lr: 0.0000\n",
      "Epoch: 979, Training loss: 1.349891, Validation loss: 1.3761, lr: 0.0000\n",
      "Epoch: 980, Training loss: 1.370837, Validation loss: 1.3885, lr: 0.0000\n",
      "Epoch: 981, Training loss: 1.426395, Validation loss: 1.3641, lr: 0.0000\n",
      "Epoch: 982, Training loss: 1.356350, Validation loss: 1.3656, lr: 0.0000\n",
      "Epoch: 983, Training loss: 1.364984, Validation loss: 1.3609, lr: 0.0000\n",
      "Epoch: 984, Training loss: 1.377344, Validation loss: 1.3533, lr: 0.0000\n",
      "Epoch: 985, Training loss: 1.366959, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 986, Training loss: 1.440127, Validation loss: 1.3890, lr: 0.0000\n",
      "Epoch: 987, Training loss: 1.367571, Validation loss: 1.3426, lr: 0.0000\n",
      "Epoch: 988, Training loss: 1.362105, Validation loss: 1.3742, lr: 0.0000\n",
      "Epoch: 989, Training loss: 1.363532, Validation loss: 1.3756, lr: 0.0000\n",
      "Epoch: 990, Training loss: 1.410378, Validation loss: 1.3723, lr: 0.0000\n",
      "Epoch: 991, Training loss: 1.367594, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 992, Training loss: 1.355016, Validation loss: 1.3593, lr: 0.0000\n",
      "Epoch: 993, Training loss: 1.364099, Validation loss: 1.4701, lr: 0.0000\n",
      "Epoch: 994, Training loss: 1.373049, Validation loss: 1.3779, lr: 0.0000\n",
      "Epoch: 995, Training loss: 1.356945, Validation loss: 1.3793, lr: 0.0000\n",
      "Epoch: 996, Training loss: 1.357533, Validation loss: 1.6468, lr: 0.0000\n",
      "Epoch: 997, Training loss: 1.352747, Validation loss: 1.3740, lr: 0.0000\n",
      "Epoch: 998, Training loss: 1.434865, Validation loss: 1.3516, lr: 0.0000\n",
      "Epoch: 999, Training loss: 1.357280, Validation loss: 1.3763, lr: 0.0000\n",
      "Final test loss: 1.3626\n",
      "=== Run 10/10 ===\n",
      "\n",
      "---- Settings: \n",
      "\n",
      "epochs : 1000\n",
      "hidden_channels : [32]\n",
      "out_channels : 10\n",
      "inner_product_features : False\n",
      "batch_size : 64\n",
      "lr : 0.01\n",
      "momentum : 0.9\n",
      "dropout : 0.0\n",
      "batch_norm : batch_norm\n",
      "bias : True\n",
      "order : 2\n",
      "diffusion : True\n",
      "frac_sampled_nb : -1\n",
      "include_positions : False\n",
      "include_self : True\n",
      "vec_norm : False\n",
      "emb_norm : False\n",
      "seed : 0\n",
      "dim_signal : 100\n",
      "dim_emb : 100\n",
      "n_sampled_nb : -1\n",
      "\n",
      "---- Number of features to pass to the MLP:  1010100\n",
      "---- Total number of parameters:  32323627\n",
      "\n",
      "Using device cuda:0\n",
      "\n",
      "---- Training network ...\n",
      "\n",
      "---- Timestamp: 20250615-062339\n",
      "\n",
      " *och: 0, Training loss: 1.406501, Validation loss: 1.9699, lr: 0.0100\n",
      " *och: 1, Training loss: 1.396120, Validation loss: 1.4615, lr: 0.0100\n",
      " *och: 2, Training loss: 1.468665, Validation loss: 1.4078, lr: 0.0100\n",
      "Epoch: 3, Training loss: 1.458493, Validation loss: 2.9476, lr: 0.0100\n",
      "Epoch: 4, Training loss: 1.440495, Validation loss: 1.7053, lr: 0.0100\n",
      " *och: 5, Training loss: 1.431168, Validation loss: 1.3660, lr: 0.0100\n",
      "Epoch: 6, Training loss: 1.413289, Validation loss: 1.3852, lr: 0.0100\n",
      " *och: 7, Training loss: 1.390170, Validation loss: 1.3563, lr: 0.0100\n",
      "Epoch: 8, Training loss: 1.437236, Validation loss: 1.3827, lr: 0.0100\n",
      "Epoch: 9, Training loss: 1.420370, Validation loss: 1.3823, lr: 0.0100\n",
      "Epoch: 10, Training loss: 1.403134, Validation loss: 1.3796, lr: 0.0100\n",
      "Epoch: 11, Training loss: 1.380313, Validation loss: 1.3758, lr: 0.0100\n",
      " *och: 12, Training loss: 1.394546, Validation loss: 1.3557, lr: 0.0100\n",
      "Epoch: 13, Training loss: 1.392878, Validation loss: 1.3684, lr: 0.0100\n",
      " *och: 14, Training loss: 1.390184, Validation loss: 1.3537, lr: 0.0100\n",
      "Epoch: 15, Training loss: 1.375975, Validation loss: 1.4093, lr: 0.0100\n",
      "Epoch: 16, Training loss: 1.381417, Validation loss: 1.3680, lr: 0.0100\n",
      "Epoch: 17, Training loss: 1.376185, Validation loss: 1.3935, lr: 0.0100\n",
      "Epoch: 18, Training loss: 1.404011, Validation loss: 1.3589, lr: 0.0100\n",
      "Epoch: 19, Training loss: 1.383278, Validation loss: 1.3808, lr: 0.0100\n",
      "Epoch: 20, Training loss: 1.414433, Validation loss: 1.3784, lr: 0.0100\n",
      "Epoch: 21, Training loss: 1.370519, Validation loss: 1.3823, lr: 0.0100\n",
      "Epoch: 22, Training loss: 1.384456, Validation loss: 1.3795, lr: 0.0100\n",
      "Epoch: 23, Training loss: 1.374692, Validation loss: 1.4452, lr: 0.0100\n",
      "Epoch: 24, Training loss: 1.366038, Validation loss: 1.3819, lr: 0.0100\n",
      "Epoch: 25, Training loss: 1.394067, Validation loss: 1.3742, lr: 0.0100\n",
      "Epoch: 26, Training loss: 1.373107, Validation loss: 1.3775, lr: 0.0100\n",
      "Epoch: 27, Training loss: 1.377407, Validation loss: 1.3777, lr: 0.0100\n",
      "Epoch: 28, Training loss: 1.383316, Validation loss: 1.3857, lr: 0.0100\n",
      "Epoch: 29, Training loss: 1.381415, Validation loss: 1.3756, lr: 0.0100\n",
      "Epoch: 30, Training loss: 1.374830, Validation loss: 1.3831, lr: 0.0100\n",
      " *och: 31, Training loss: 1.360617, Validation loss: 1.3492, lr: 0.0100\n",
      "Epoch: 32, Training loss: 1.376878, Validation loss: 1.3525, lr: 0.0100\n",
      "Epoch: 33, Training loss: 1.399648, Validation loss: 1.3751, lr: 0.0100\n",
      "Epoch: 34, Training loss: 1.359323, Validation loss: 1.3823, lr: 0.0100\n",
      "Epoch: 35, Training loss: 1.362637, Validation loss: 1.3592, lr: 0.0100\n",
      "Epoch: 36, Training loss: 1.344341, Validation loss: 1.3691, lr: 0.0100\n",
      "Epoch: 37, Training loss: 1.368987, Validation loss: 1.4764, lr: 0.0100\n",
      "Epoch: 38, Training loss: 1.413508, Validation loss: 1.3899, lr: 0.0100\n",
      "Epoch: 39, Training loss: 1.388639, Validation loss: 1.3715, lr: 0.0100\n",
      "Epoch: 40, Training loss: 1.359806, Validation loss: 1.3881, lr: 0.0100\n",
      "Epoch: 41, Training loss: 1.387342, Validation loss: 1.3591, lr: 0.0100\n",
      "Epoch: 42, Training loss: 1.343167, Validation loss: 1.3816, lr: 0.0100\n",
      "Epoch: 43, Training loss: 1.381321, Validation loss: 1.3989, lr: 0.0100\n",
      "Epoch: 44, Training loss: 1.362382, Validation loss: 1.3807, lr: 0.0100\n",
      "Epoch: 45, Training loss: 1.364044, Validation loss: 1.3846, lr: 0.0100\n",
      "Epoch: 46, Training loss: 1.360575, Validation loss: 1.3757, lr: 0.0100\n",
      "Epoch: 47, Training loss: 1.400356, Validation loss: 1.3662, lr: 0.0100\n",
      "Epoch: 48, Training loss: 1.359383, Validation loss: 1.3767, lr: 0.0100\n",
      "Epoch: 49, Training loss: 1.360961, Validation loss: 1.3756, lr: 0.0100\n",
      "Epoch: 50, Training loss: 1.350493, Validation loss: 1.3726, lr: 0.0100\n",
      "Epoch: 51, Training loss: 1.374520, Validation loss: 1.3822, lr: 0.0100\n",
      "Epoch: 52, Training loss: 1.360468, Validation loss: 1.3498, lr: 0.0100\n",
      "Epoch: 53, Training loss: 1.367657, Validation loss: 1.3842, lr: 0.0010\n",
      "Epoch: 54, Training loss: 1.368202, Validation loss: 1.4131, lr: 0.0010\n",
      "Epoch: 55, Training loss: 1.384976, Validation loss: 1.3816, lr: 0.0010\n",
      "Epoch: 56, Training loss: 1.429044, Validation loss: 1.3544, lr: 0.0010\n",
      "Epoch: 57, Training loss: 1.345669, Validation loss: 1.3626, lr: 0.0010\n",
      "Epoch: 58, Training loss: 1.311947, Validation loss: 1.3656, lr: 0.0010\n",
      " *och: 59, Training loss: 1.343974, Validation loss: 1.3125, lr: 0.0010\n",
      "Epoch: 60, Training loss: 1.358609, Validation loss: 1.3694, lr: 0.0010\n",
      "Epoch: 61, Training loss: 1.333845, Validation loss: 1.3675, lr: 0.0010\n",
      "Epoch: 62, Training loss: 1.347085, Validation loss: 1.4620, lr: 0.0010\n",
      "Epoch: 63, Training loss: 1.346479, Validation loss: 1.3590, lr: 0.0010\n",
      "Epoch: 64, Training loss: 1.336673, Validation loss: 1.3730, lr: 0.0010\n",
      "Epoch: 65, Training loss: 1.375815, Validation loss: 40.0556, lr: 0.0010\n",
      "Epoch: 66, Training loss: 1.361958, Validation loss: 1.3485, lr: 0.0010\n",
      "Epoch: 67, Training loss: 1.323581, Validation loss: 1.3643, lr: 0.0010\n",
      "Epoch: 68, Training loss: 1.369856, Validation loss: 1.3880, lr: 0.0010\n",
      "Epoch: 69, Training loss: 1.396254, Validation loss: 1.3701, lr: 0.0001\n",
      "Epoch: 70, Training loss: 1.348385, Validation loss: 1.3465, lr: 0.0001\n",
      "Epoch: 71, Training loss: 1.352170, Validation loss: 1.3726, lr: 0.0001\n",
      "Epoch: 72, Training loss: 1.402559, Validation loss: 1.3737, lr: 0.0001\n",
      "Epoch: 73, Training loss: 1.363558, Validation loss: 1.3697, lr: 0.0001\n",
      "Epoch: 74, Training loss: 1.361820, Validation loss: 1.3770, lr: 0.0001\n",
      "Epoch: 75, Training loss: 1.372404, Validation loss: 1.3785, lr: 0.0001\n",
      "Epoch: 76, Training loss: 1.375529, Validation loss: 1.4323, lr: 0.0001\n",
      "Epoch: 77, Training loss: 1.359746, Validation loss: 1.3650, lr: 0.0001\n",
      "Epoch: 78, Training loss: 1.373389, Validation loss: 1.3419, lr: 0.0001\n",
      "Epoch: 79, Training loss: 1.341946, Validation loss: 1.3732, lr: 0.0001\n",
      "Epoch: 80, Training loss: 1.341694, Validation loss: 1.3627, lr: 0.0000\n",
      "Epoch: 81, Training loss: 1.410633, Validation loss: 1.3684, lr: 0.0000\n",
      "Epoch: 82, Training loss: 1.345856, Validation loss: 1.3760, lr: 0.0000\n",
      "Epoch: 83, Training loss: 1.345133, Validation loss: 1.3743, lr: 0.0000\n",
      "Epoch: 84, Training loss: 1.389154, Validation loss: 1.3814, lr: 0.0000\n",
      "Epoch: 85, Training loss: 1.346348, Validation loss: 1.3748, lr: 0.0000\n",
      "Epoch: 86, Training loss: 1.346023, Validation loss: 1.3374, lr: 0.0000\n",
      "Epoch: 87, Training loss: 1.348469, Validation loss: 1.3710, lr: 0.0000\n",
      "Epoch: 88, Training loss: 1.344076, Validation loss: 1.3511, lr: 0.0000\n",
      "Epoch: 89, Training loss: 1.383367, Validation loss: 1.3700, lr: 0.0000\n",
      "Epoch: 90, Training loss: 1.371416, Validation loss: 1.3550, lr: 0.0000\n",
      "Epoch: 91, Training loss: 1.413852, Validation loss: 1.3746, lr: 0.0000\n",
      "Epoch: 92, Training loss: 1.356069, Validation loss: 2.0564, lr: 0.0000\n",
      "Epoch: 93, Training loss: 1.363901, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 94, Training loss: 1.363141, Validation loss: 1.3266, lr: 0.0000\n",
      "Epoch: 95, Training loss: 1.335298, Validation loss: 1.3617, lr: 0.0000\n",
      "Epoch: 96, Training loss: 1.367166, Validation loss: 1.3626, lr: 0.0000\n",
      "Epoch: 97, Training loss: 1.363426, Validation loss: 1.3756, lr: 0.0000\n",
      "Epoch: 98, Training loss: 1.358564, Validation loss: 1.3494, lr: 0.0000\n",
      "Epoch: 99, Training loss: 1.374758, Validation loss: 1.3353, lr: 0.0000\n",
      "Epoch: 100, Training loss: 1.359498, Validation loss: 1.3871, lr: 0.0000\n",
      "Epoch: 101, Training loss: 1.406371, Validation loss: 1.3746, lr: 0.0000\n",
      "Epoch: 102, Training loss: 1.325005, Validation loss: 1.3913, lr: 0.0000\n",
      "Epoch: 103, Training loss: 1.388222, Validation loss: 1.3209, lr: 0.0000\n",
      "Epoch: 104, Training loss: 1.361349, Validation loss: 1.3531, lr: 0.0000\n",
      "Epoch: 105, Training loss: 1.371577, Validation loss: 1.3438, lr: 0.0000\n",
      "Epoch: 106, Training loss: 1.353776, Validation loss: 1.3379, lr: 0.0000\n",
      "Epoch: 107, Training loss: 1.364213, Validation loss: 1.3763, lr: 0.0000\n",
      "Epoch: 108, Training loss: 1.357224, Validation loss: 1.3508, lr: 0.0000\n",
      "Epoch: 109, Training loss: 1.366438, Validation loss: 1.3513, lr: 0.0000\n",
      "Epoch: 110, Training loss: 1.339895, Validation loss: 1.3797, lr: 0.0000\n",
      "Epoch: 111, Training loss: 1.356931, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 112, Training loss: 1.357088, Validation loss: 1.4918, lr: 0.0000\n",
      "Epoch: 113, Training loss: 1.341868, Validation loss: 1.4025, lr: 0.0000\n",
      "Epoch: 114, Training loss: 1.354783, Validation loss: 1.3467, lr: 0.0000\n",
      "Epoch: 115, Training loss: 1.356353, Validation loss: 1.3512, lr: 0.0000\n",
      "Epoch: 116, Training loss: 1.343065, Validation loss: 1.3643, lr: 0.0000\n",
      "Epoch: 117, Training loss: 1.385872, Validation loss: 1.4202, lr: 0.0000\n",
      "Epoch: 118, Training loss: 1.371548, Validation loss: 1.3563, lr: 0.0000\n",
      "Epoch: 119, Training loss: 1.339662, Validation loss: 1.3764, lr: 0.0000\n",
      "Epoch: 120, Training loss: 1.370312, Validation loss: 1.3847, lr: 0.0000\n",
      "Epoch: 121, Training loss: 1.370653, Validation loss: 1.3716, lr: 0.0000\n",
      "Epoch: 122, Training loss: 1.353538, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 123, Training loss: 1.375235, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 124, Training loss: 1.372422, Validation loss: 1.3812, lr: 0.0000\n",
      "Epoch: 125, Training loss: 1.384124, Validation loss: 1.3820, lr: 0.0000\n",
      "Epoch: 126, Training loss: 1.352642, Validation loss: 1.3853, lr: 0.0000\n",
      "Epoch: 127, Training loss: 1.349544, Validation loss: 1.3715, lr: 0.0000\n",
      "Epoch: 128, Training loss: 1.353026, Validation loss: 1.3487, lr: 0.0000\n",
      "Epoch: 129, Training loss: 1.349317, Validation loss: 1.3599, lr: 0.0000\n",
      "Epoch: 130, Training loss: 1.378006, Validation loss: 1.3571, lr: 0.0000\n",
      "Epoch: 131, Training loss: 1.375411, Validation loss: 1.3422, lr: 0.0000\n",
      "Epoch: 132, Training loss: 1.374268, Validation loss: 1.4157, lr: 0.0000\n",
      "Epoch: 133, Training loss: 1.444849, Validation loss: 1.3787, lr: 0.0000\n",
      "Epoch: 134, Training loss: 1.348462, Validation loss: 1.3536, lr: 0.0000\n",
      "Epoch: 135, Training loss: 1.380751, Validation loss: 1.3739, lr: 0.0000\n",
      "Epoch: 136, Training loss: 1.360191, Validation loss: 1.3499, lr: 0.0000\n",
      "Epoch: 137, Training loss: 1.331499, Validation loss: 1.3605, lr: 0.0000\n",
      "Epoch: 138, Training loss: 1.346783, Validation loss: 1.3678, lr: 0.0000\n",
      "Epoch: 139, Training loss: 1.367442, Validation loss: 1.3276, lr: 0.0000\n",
      "Epoch: 140, Training loss: 1.381436, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 141, Training loss: 1.368221, Validation loss: 1.3753, lr: 0.0000\n",
      "Epoch: 142, Training loss: 1.341080, Validation loss: 1.4268, lr: 0.0000\n",
      "Epoch: 143, Training loss: 1.393920, Validation loss: 1.4866, lr: 0.0000\n",
      "Epoch: 144, Training loss: 1.363300, Validation loss: 1.3679, lr: 0.0000\n",
      "Epoch: 145, Training loss: 1.385189, Validation loss: 1.3610, lr: 0.0000\n",
      "Epoch: 146, Training loss: 1.369156, Validation loss: 1.3628, lr: 0.0000\n",
      "Epoch: 147, Training loss: 1.388389, Validation loss: 1.3649, lr: 0.0000\n",
      "Epoch: 148, Training loss: 1.443900, Validation loss: 1.3328, lr: 0.0000\n",
      "Epoch: 149, Training loss: 1.385026, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 150, Training loss: 1.384272, Validation loss: 1.3465, lr: 0.0000\n",
      "Epoch: 151, Training loss: 1.366007, Validation loss: 1.3655, lr: 0.0000\n",
      "Epoch: 152, Training loss: 1.376367, Validation loss: 1.3200, lr: 0.0000\n",
      "Epoch: 153, Training loss: 1.359663, Validation loss: 1.3509, lr: 0.0000\n",
      "Epoch: 154, Training loss: 1.343323, Validation loss: 1.3732, lr: 0.0000\n",
      "Epoch: 155, Training loss: 1.456121, Validation loss: 1.3558, lr: 0.0000\n",
      "Epoch: 156, Training loss: 1.344680, Validation loss: 1.3724, lr: 0.0000\n",
      "Epoch: 157, Training loss: 1.381132, Validation loss: 1.3444, lr: 0.0000\n",
      "Epoch: 158, Training loss: 1.327908, Validation loss: 1.3287, lr: 0.0000\n",
      "Epoch: 159, Training loss: 1.368934, Validation loss: 1.3539, lr: 0.0000\n",
      "Epoch: 160, Training loss: 1.356227, Validation loss: 1.3586, lr: 0.0000\n",
      "Epoch: 161, Training loss: 1.377873, Validation loss: 1.3565, lr: 0.0000\n",
      "Epoch: 162, Training loss: 1.366152, Validation loss: 1.4327, lr: 0.0000\n",
      "Epoch: 163, Training loss: 1.342482, Validation loss: 1.3738, lr: 0.0000\n",
      "Epoch: 164, Training loss: 1.344491, Validation loss: 1.3572, lr: 0.0000\n",
      "Epoch: 165, Training loss: 1.448140, Validation loss: 1.4140, lr: 0.0000\n",
      "Epoch: 166, Training loss: 1.342916, Validation loss: 1.3720, lr: 0.0000\n",
      "Epoch: 167, Training loss: 1.358979, Validation loss: 1.3695, lr: 0.0000\n",
      "Epoch: 168, Training loss: 1.400736, Validation loss: 1.3949, lr: 0.0000\n",
      "Epoch: 169, Training loss: 1.405097, Validation loss: 1.3697, lr: 0.0000\n",
      "Epoch: 170, Training loss: 1.349248, Validation loss: 1.3280, lr: 0.0000\n",
      "Epoch: 171, Training loss: 1.343493, Validation loss: 1.3831, lr: 0.0000\n",
      "Epoch: 172, Training loss: 1.335798, Validation loss: 1.3757, lr: 0.0000\n",
      "Epoch: 173, Training loss: 1.351058, Validation loss: 1.7688, lr: 0.0000\n",
      "Epoch: 174, Training loss: 1.335178, Validation loss: 1.4160, lr: 0.0000\n",
      "Epoch: 175, Training loss: 1.306634, Validation loss: 1.3378, lr: 0.0000\n",
      "Epoch: 176, Training loss: 1.358595, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 177, Training loss: 1.328772, Validation loss: 1.3702, lr: 0.0000\n",
      "Epoch: 178, Training loss: 1.352705, Validation loss: 1.3594, lr: 0.0000\n",
      "Epoch: 179, Training loss: 1.343539, Validation loss: 1.4649, lr: 0.0000\n",
      "Epoch: 180, Training loss: 1.350198, Validation loss: 1.3422, lr: 0.0000\n",
      "Epoch: 181, Training loss: 1.367219, Validation loss: 1.9486, lr: 0.0000\n",
      "Epoch: 182, Training loss: 1.365887, Validation loss: 1.3699, lr: 0.0000\n",
      "Epoch: 183, Training loss: 1.349627, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 184, Training loss: 1.349031, Validation loss: 1.4340, lr: 0.0000\n",
      "Epoch: 185, Training loss: 1.366925, Validation loss: 1.3415, lr: 0.0000\n",
      "Epoch: 186, Training loss: 1.381373, Validation loss: 1.3555, lr: 0.0000\n",
      "Epoch: 187, Training loss: 1.373452, Validation loss: 1.3745, lr: 0.0000\n",
      "Epoch: 188, Training loss: 1.342636, Validation loss: 1.3193, lr: 0.0000\n",
      "Epoch: 189, Training loss: 1.348352, Validation loss: 1.3880, lr: 0.0000\n",
      "Epoch: 190, Training loss: 1.364904, Validation loss: 1.3457, lr: 0.0000\n",
      "Epoch: 191, Training loss: 1.365428, Validation loss: 1.3719, lr: 0.0000\n",
      "Epoch: 192, Training loss: 1.367925, Validation loss: 1.3147, lr: 0.0000\n",
      "Epoch: 193, Training loss: 1.374290, Validation loss: 1.3553, lr: 0.0000\n",
      "Epoch: 194, Training loss: 1.343100, Validation loss: 1.3709, lr: 0.0000\n",
      "Epoch: 195, Training loss: 1.372315, Validation loss: 1.3762, lr: 0.0000\n",
      "Epoch: 196, Training loss: 1.331359, Validation loss: 1.3672, lr: 0.0000\n",
      "Epoch: 197, Training loss: 1.390196, Validation loss: 1.3994, lr: 0.0000\n",
      "Epoch: 198, Training loss: 1.350331, Validation loss: 1.5797, lr: 0.0000\n",
      "Epoch: 199, Training loss: 1.373103, Validation loss: 1.3559, lr: 0.0000\n",
      "Epoch: 200, Training loss: 1.351879, Validation loss: 1.3528, lr: 0.0000\n",
      "Epoch: 201, Training loss: 1.377685, Validation loss: 1.3719, lr: 0.0000\n",
      "Epoch: 202, Training loss: 1.355668, Validation loss: 1.3658, lr: 0.0000\n",
      "Epoch: 203, Training loss: 1.376575, Validation loss: 1.3887, lr: 0.0000\n",
      "Epoch: 204, Training loss: 1.390198, Validation loss: 1.3656, lr: 0.0000\n",
      "Epoch: 205, Training loss: 1.386610, Validation loss: 1.3731, lr: 0.0000\n",
      "Epoch: 206, Training loss: 1.357239, Validation loss: 1.3769, lr: 0.0000\n",
      "Epoch: 207, Training loss: 1.382429, Validation loss: 1.3372, lr: 0.0000\n",
      "Epoch: 208, Training loss: 1.330876, Validation loss: 1.3560, lr: 0.0000\n",
      "Epoch: 209, Training loss: 1.349980, Validation loss: 1.3636, lr: 0.0000\n",
      "Epoch: 210, Training loss: 1.350557, Validation loss: 1.3723, lr: 0.0000\n",
      "Epoch: 211, Training loss: 1.354493, Validation loss: 1.3691, lr: 0.0000\n",
      "Epoch: 212, Training loss: 1.372354, Validation loss: 1.3685, lr: 0.0000\n",
      "Epoch: 213, Training loss: 1.339103, Validation loss: 1.4406, lr: 0.0000\n",
      "Epoch: 214, Training loss: 1.376371, Validation loss: 1.3733, lr: 0.0000\n",
      "Epoch: 215, Training loss: 1.363035, Validation loss: 1.3522, lr: 0.0000\n",
      "Epoch: 216, Training loss: 1.365198, Validation loss: 1.3638, lr: 0.0000\n",
      "Epoch: 217, Training loss: 1.362088, Validation loss: 1.3786, lr: 0.0000\n",
      "Epoch: 218, Training loss: 1.360117, Validation loss: 1.6252, lr: 0.0000\n",
      "Epoch: 219, Training loss: 1.370636, Validation loss: 1.3649, lr: 0.0000\n",
      "Epoch: 220, Training loss: 1.325416, Validation loss: 1.4523, lr: 0.0000\n",
      "Epoch: 221, Training loss: 1.348983, Validation loss: 1.3266, lr: 0.0000\n",
      "Epoch: 222, Training loss: 1.370394, Validation loss: 1.3520, lr: 0.0000\n",
      "Epoch: 223, Training loss: 1.375409, Validation loss: 1.3660, lr: 0.0000\n",
      "Epoch: 224, Training loss: 1.347238, Validation loss: 1.3725, lr: 0.0000\n",
      "Epoch: 225, Training loss: 1.351288, Validation loss: 1.3858, lr: 0.0000\n",
      "Epoch: 226, Training loss: 1.374956, Validation loss: 1.3690, lr: 0.0000\n",
      "Epoch: 227, Training loss: 1.337867, Validation loss: 1.3791, lr: 0.0000\n",
      "Epoch: 228, Training loss: 1.351122, Validation loss: 1.3702, lr: 0.0000\n",
      "Epoch: 229, Training loss: 1.371184, Validation loss: 1.3597, lr: 0.0000\n",
      "Epoch: 230, Training loss: 1.374583, Validation loss: 1.3655, lr: 0.0000\n",
      "Epoch: 231, Training loss: 1.354476, Validation loss: 1.3782, lr: 0.0000\n",
      "Epoch: 232, Training loss: 1.367768, Validation loss: 1.3767, lr: 0.0000\n",
      "Epoch: 233, Training loss: 1.355535, Validation loss: 1.3595, lr: 0.0000\n",
      "Epoch: 234, Training loss: 1.369214, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 235, Training loss: 1.360220, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 236, Training loss: 1.359418, Validation loss: 1.3725, lr: 0.0000\n",
      "Epoch: 237, Training loss: 1.353642, Validation loss: 1.3521, lr: 0.0000\n",
      "Epoch: 238, Training loss: 1.351549, Validation loss: 1.3532, lr: 0.0000\n",
      "Epoch: 239, Training loss: 1.362051, Validation loss: 1.3721, lr: 0.0000\n",
      "Epoch: 240, Training loss: 1.386208, Validation loss: 1.3517, lr: 0.0000\n",
      "Epoch: 241, Training loss: 1.367869, Validation loss: 1.3737, lr: 0.0000\n",
      "Epoch: 242, Training loss: 1.358306, Validation loss: 1.3644, lr: 0.0000\n",
      "Epoch: 243, Training loss: 1.328359, Validation loss: 1.3503, lr: 0.0000\n",
      "Epoch: 244, Training loss: 1.372549, Validation loss: 1.4163, lr: 0.0000\n",
      "Epoch: 245, Training loss: 1.403663, Validation loss: 1.3517, lr: 0.0000\n",
      "Epoch: 246, Training loss: 1.358531, Validation loss: 1.3776, lr: 0.0000\n",
      "Epoch: 247, Training loss: 1.357172, Validation loss: 1.3446, lr: 0.0000\n",
      "Epoch: 248, Training loss: 1.358152, Validation loss: 1.3289, lr: 0.0000\n",
      "Epoch: 249, Training loss: 1.349917, Validation loss: 1.3712, lr: 0.0000\n",
      "Epoch: 250, Training loss: 1.373605, Validation loss: 1.3660, lr: 0.0000\n",
      "Epoch: 251, Training loss: 1.370451, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 252, Training loss: 1.354306, Validation loss: 1.3625, lr: 0.0000\n",
      "Epoch: 253, Training loss: 1.359879, Validation loss: 1.3692, lr: 0.0000\n",
      "Epoch: 254, Training loss: 1.351234, Validation loss: 1.3517, lr: 0.0000\n",
      "Epoch: 255, Training loss: 1.352763, Validation loss: 1.3516, lr: 0.0000\n",
      "Epoch: 256, Training loss: 1.371388, Validation loss: 1.3750, lr: 0.0000\n",
      "Epoch: 257, Training loss: 1.330611, Validation loss: 1.3502, lr: 0.0000\n",
      "Epoch: 258, Training loss: 1.373802, Validation loss: 1.3716, lr: 0.0000\n",
      "Epoch: 259, Training loss: 1.349722, Validation loss: 1.3331, lr: 0.0000\n",
      "Epoch: 260, Training loss: 1.344346, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 261, Training loss: 1.354233, Validation loss: 1.3767, lr: 0.0000\n",
      "Epoch: 262, Training loss: 1.366374, Validation loss: 1.3751, lr: 0.0000\n",
      "Epoch: 263, Training loss: 1.371728, Validation loss: 1.3871, lr: 0.0000\n",
      "Epoch: 264, Training loss: 1.364948, Validation loss: 1.3581, lr: 0.0000\n",
      "Epoch: 265, Training loss: 1.349732, Validation loss: 1.3841, lr: 0.0000\n",
      " *och: 266, Training loss: 1.363362, Validation loss: 1.2913, lr: 0.0000\n",
      "Epoch: 267, Training loss: 1.357019, Validation loss: 1.3634, lr: 0.0000\n",
      "Epoch: 268, Training loss: 1.349178, Validation loss: 1.3890, lr: 0.0000\n",
      "Epoch: 269, Training loss: 1.360140, Validation loss: 1.4003, lr: 0.0000\n",
      "Epoch: 270, Training loss: 1.332863, Validation loss: 1.3160, lr: 0.0000\n",
      "Epoch: 271, Training loss: 1.358996, Validation loss: 1.3646, lr: 0.0000\n",
      "Epoch: 272, Training loss: 1.394052, Validation loss: 1.3363, lr: 0.0000\n",
      "Epoch: 273, Training loss: 1.360929, Validation loss: 1.3633, lr: 0.0000\n",
      "Epoch: 274, Training loss: 1.358957, Validation loss: 1.3695, lr: 0.0000\n",
      "Epoch: 275, Training loss: 1.341080, Validation loss: 1.3614, lr: 0.0000\n",
      "Epoch: 276, Training loss: 1.358880, Validation loss: 1.3706, lr: 0.0000\n",
      "Epoch: 277, Training loss: 1.381311, Validation loss: 1.4067, lr: 0.0000\n",
      "Epoch: 278, Training loss: 1.342311, Validation loss: 1.3231, lr: 0.0000\n",
      "Epoch: 279, Training loss: 1.337476, Validation loss: 1.3474, lr: 0.0000\n",
      "Epoch: 280, Training loss: 1.341992, Validation loss: 1.3659, lr: 0.0000\n",
      "Epoch: 281, Training loss: 1.361585, Validation loss: 1.3681, lr: 0.0000\n",
      "Epoch: 282, Training loss: 1.398292, Validation loss: 1.4845, lr: 0.0000\n",
      "Epoch: 283, Training loss: 1.334379, Validation loss: 1.3653, lr: 0.0000\n",
      "Epoch: 284, Training loss: 1.378259, Validation loss: 1.3291, lr: 0.0000\n",
      "Epoch: 285, Training loss: 1.340485, Validation loss: 1.3705, lr: 0.0000\n",
      "Epoch: 286, Training loss: 1.353968, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 287, Training loss: 1.352002, Validation loss: 1.3772, lr: 0.0000\n",
      "Epoch: 288, Training loss: 1.342618, Validation loss: 1.3519, lr: 0.0000\n",
      "Epoch: 289, Training loss: 1.389284, Validation loss: 1.3659, lr: 0.0000\n",
      "Epoch: 290, Training loss: 1.363786, Validation loss: 1.5547, lr: 0.0000\n",
      "Epoch: 291, Training loss: 1.362708, Validation loss: 1.3741, lr: 0.0000\n",
      "Epoch: 292, Training loss: 1.323885, Validation loss: 1.3481, lr: 0.0000\n",
      "Epoch: 293, Training loss: 1.344233, Validation loss: 1.3728, lr: 0.0000\n",
      "Epoch: 294, Training loss: 1.354957, Validation loss: 1.3746, lr: 0.0000\n",
      "Epoch: 295, Training loss: 1.357441, Validation loss: 1.3582, lr: 0.0000\n",
      "Epoch: 296, Training loss: 1.355602, Validation loss: 1.3531, lr: 0.0000\n",
      "Epoch: 297, Training loss: 1.347780, Validation loss: 1.3229, lr: 0.0000\n",
      "Epoch: 298, Training loss: 1.346884, Validation loss: 1.3624, lr: 0.0000\n",
      "Epoch: 299, Training loss: 1.395300, Validation loss: 1.3793, lr: 0.0000\n",
      "Epoch: 300, Training loss: 1.384848, Validation loss: 1.4222, lr: 0.0000\n",
      "Epoch: 301, Training loss: 1.376528, Validation loss: 1.3435, lr: 0.0000\n",
      "Epoch: 302, Training loss: 1.351953, Validation loss: 1.3695, lr: 0.0000\n",
      "Epoch: 303, Training loss: 1.332290, Validation loss: 1.3530, lr: 0.0000\n",
      "Epoch: 304, Training loss: 1.350977, Validation loss: 1.3479, lr: 0.0000\n",
      "Epoch: 305, Training loss: 1.367352, Validation loss: 1.3625, lr: 0.0000\n",
      "Epoch: 306, Training loss: 1.366327, Validation loss: 1.3685, lr: 0.0000\n",
      "Epoch: 307, Training loss: 1.344026, Validation loss: 1.3704, lr: 0.0000\n",
      "Epoch: 308, Training loss: 1.348767, Validation loss: 1.3688, lr: 0.0000\n",
      "Epoch: 309, Training loss: 1.347010, Validation loss: 1.3783, lr: 0.0000\n",
      "Epoch: 310, Training loss: 1.344119, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 311, Training loss: 1.343005, Validation loss: 1.3599, lr: 0.0000\n",
      "Epoch: 312, Training loss: 1.362163, Validation loss: 1.3793, lr: 0.0000\n",
      "Epoch: 313, Training loss: 1.342864, Validation loss: 1.4164, lr: 0.0000\n",
      "Epoch: 314, Training loss: 1.346520, Validation loss: 1.3596, lr: 0.0000\n",
      "Epoch: 315, Training loss: 1.359218, Validation loss: 1.3054, lr: 0.0000\n",
      "Epoch: 316, Training loss: 1.370899, Validation loss: 1.5202, lr: 0.0000\n",
      "Epoch: 317, Training loss: 1.352673, Validation loss: 1.3633, lr: 0.0000\n",
      "Epoch: 318, Training loss: 1.369694, Validation loss: 1.3766, lr: 0.0000\n",
      "Epoch: 319, Training loss: 1.339343, Validation loss: 1.3420, lr: 0.0000\n",
      "Epoch: 320, Training loss: 1.370581, Validation loss: 1.4231, lr: 0.0000\n",
      "Epoch: 321, Training loss: 1.345383, Validation loss: 1.3598, lr: 0.0000\n",
      "Epoch: 322, Training loss: 1.360407, Validation loss: 1.3731, lr: 0.0000\n",
      "Epoch: 323, Training loss: 1.356380, Validation loss: 1.3107, lr: 0.0000\n",
      "Epoch: 324, Training loss: 1.353314, Validation loss: 1.3476, lr: 0.0000\n",
      "Epoch: 325, Training loss: 1.374561, Validation loss: 1.3597, lr: 0.0000\n",
      "Epoch: 326, Training loss: 1.350928, Validation loss: 1.3545, lr: 0.0000\n",
      "Epoch: 327, Training loss: 1.367968, Validation loss: 1.3890, lr: 0.0000\n",
      "Epoch: 328, Training loss: 1.374681, Validation loss: 1.3746, lr: 0.0000\n",
      "Epoch: 329, Training loss: 1.400097, Validation loss: 1.2990, lr: 0.0000\n",
      "Epoch: 330, Training loss: 1.356483, Validation loss: 1.3808, lr: 0.0000\n",
      "Epoch: 331, Training loss: 1.356788, Validation loss: 1.3607, lr: 0.0000\n",
      "Epoch: 332, Training loss: 1.327012, Validation loss: 1.3774, lr: 0.0000\n",
      "Epoch: 333, Training loss: 1.350459, Validation loss: 1.3618, lr: 0.0000\n",
      "Epoch: 334, Training loss: 1.354303, Validation loss: 1.4060, lr: 0.0000\n",
      "Epoch: 335, Training loss: 1.381470, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 336, Training loss: 1.360324, Validation loss: 1.3791, lr: 0.0000\n",
      "Epoch: 337, Training loss: 1.353871, Validation loss: 1.3567, lr: 0.0000\n",
      "Epoch: 338, Training loss: 1.349230, Validation loss: 1.3787, lr: 0.0000\n",
      "Epoch: 339, Training loss: 1.352382, Validation loss: 1.3639, lr: 0.0000\n",
      "Epoch: 340, Training loss: 1.422648, Validation loss: 1.3703, lr: 0.0000\n",
      "Epoch: 341, Training loss: 1.395717, Validation loss: 1.3849, lr: 0.0000\n",
      "Epoch: 342, Training loss: 1.350677, Validation loss: 1.3652, lr: 0.0000\n",
      "Epoch: 343, Training loss: 1.362471, Validation loss: 1.3514, lr: 0.0000\n",
      "Epoch: 344, Training loss: 1.365317, Validation loss: 1.3599, lr: 0.0000\n",
      "Epoch: 345, Training loss: 1.331474, Validation loss: 1.3531, lr: 0.0000\n",
      "Epoch: 346, Training loss: 1.358114, Validation loss: 1.3792, lr: 0.0000\n",
      "Epoch: 347, Training loss: 1.335366, Validation loss: 1.3521, lr: 0.0000\n",
      "Epoch: 348, Training loss: 1.366710, Validation loss: 1.3646, lr: 0.0000\n",
      "Epoch: 349, Training loss: 1.384364, Validation loss: 1.4003, lr: 0.0000\n",
      "Epoch: 350, Training loss: 1.348375, Validation loss: 1.3565, lr: 0.0000\n",
      "Epoch: 351, Training loss: 1.365769, Validation loss: 1.3570, lr: 0.0000\n",
      "Epoch: 352, Training loss: 1.326532, Validation loss: 1.3666, lr: 0.0000\n",
      "Epoch: 353, Training loss: 1.373047, Validation loss: 1.3577, lr: 0.0000\n",
      "Epoch: 354, Training loss: 1.354471, Validation loss: 1.3468, lr: 0.0000\n",
      "Epoch: 355, Training loss: 1.351781, Validation loss: 1.3487, lr: 0.0000\n",
      "Epoch: 356, Training loss: 1.402688, Validation loss: 1.3919, lr: 0.0000\n",
      "Epoch: 357, Training loss: 1.358655, Validation loss: 1.3708, lr: 0.0000\n",
      "Epoch: 358, Training loss: 1.305768, Validation loss: 1.3783, lr: 0.0000\n",
      "Epoch: 359, Training loss: 1.364398, Validation loss: 1.3524, lr: 0.0000\n",
      "Epoch: 360, Training loss: 1.354388, Validation loss: 1.3434, lr: 0.0000\n",
      "Epoch: 361, Training loss: 1.338353, Validation loss: 1.3538, lr: 0.0000\n",
      "Epoch: 362, Training loss: 1.333081, Validation loss: 1.3721, lr: 0.0000\n",
      "Epoch: 363, Training loss: 1.326939, Validation loss: 1.4084, lr: 0.0000\n",
      "Epoch: 364, Training loss: 1.383217, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 365, Training loss: 1.347886, Validation loss: 1.3534, lr: 0.0000\n",
      "Epoch: 366, Training loss: 1.379176, Validation loss: 1.4246, lr: 0.0000\n",
      "Epoch: 367, Training loss: 1.359052, Validation loss: 1.3766, lr: 0.0000\n",
      "Epoch: 368, Training loss: 1.361139, Validation loss: 1.3575, lr: 0.0000\n",
      "Epoch: 369, Training loss: 1.344569, Validation loss: 1.3910, lr: 0.0000\n",
      "Epoch: 370, Training loss: 1.358803, Validation loss: 1.4639, lr: 0.0000\n",
      "Epoch: 371, Training loss: 1.355172, Validation loss: 1.3548, lr: 0.0000\n",
      "Epoch: 372, Training loss: 1.364595, Validation loss: 1.3304, lr: 0.0000\n",
      "Epoch: 373, Training loss: 1.355290, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 374, Training loss: 1.326592, Validation loss: 1.3695, lr: 0.0000\n",
      "Epoch: 375, Training loss: 1.347779, Validation loss: 1.3454, lr: 0.0000\n",
      "Epoch: 376, Training loss: 1.350248, Validation loss: 1.3668, lr: 0.0000\n",
      "Epoch: 377, Training loss: 1.346124, Validation loss: 1.3613, lr: 0.0000\n",
      "Epoch: 378, Training loss: 1.348310, Validation loss: 1.3705, lr: 0.0000\n",
      "Epoch: 379, Training loss: 1.389684, Validation loss: 1.3708, lr: 0.0000\n",
      "Epoch: 380, Training loss: 1.341169, Validation loss: 1.3696, lr: 0.0000\n",
      "Epoch: 381, Training loss: 1.371866, Validation loss: 1.3706, lr: 0.0000\n",
      "Epoch: 382, Training loss: 1.372846, Validation loss: 1.5142, lr: 0.0000\n",
      "Epoch: 383, Training loss: 1.364154, Validation loss: 1.3778, lr: 0.0000\n",
      "Epoch: 384, Training loss: 1.369127, Validation loss: 1.3731, lr: 0.0000\n",
      "Epoch: 385, Training loss: 1.349867, Validation loss: 1.3668, lr: 0.0000\n",
      "Epoch: 386, Training loss: 1.360663, Validation loss: 1.3784, lr: 0.0000\n",
      "Epoch: 387, Training loss: 1.357926, Validation loss: 1.3760, lr: 0.0000\n",
      "Epoch: 388, Training loss: 1.364193, Validation loss: 1.3618, lr: 0.0000\n",
      "Epoch: 389, Training loss: 1.375589, Validation loss: 1.3767, lr: 0.0000\n",
      "Epoch: 390, Training loss: 1.359250, Validation loss: 1.3768, lr: 0.0000\n",
      "Epoch: 391, Training loss: 1.356885, Validation loss: 1.3714, lr: 0.0000\n",
      "Epoch: 392, Training loss: 1.362418, Validation loss: 1.3785, lr: 0.0000\n",
      "Epoch: 393, Training loss: 1.354643, Validation loss: 1.3539, lr: 0.0000\n",
      "Epoch: 394, Training loss: 1.350580, Validation loss: 1.3096, lr: 0.0000\n",
      "Epoch: 395, Training loss: 1.385154, Validation loss: 1.3697, lr: 0.0000\n",
      "Epoch: 396, Training loss: 1.349587, Validation loss: 1.3633, lr: 0.0000\n",
      "Epoch: 397, Training loss: 1.373015, Validation loss: 1.3629, lr: 0.0000\n",
      "Epoch: 398, Training loss: 1.353026, Validation loss: 1.3790, lr: 0.0000\n",
      "Epoch: 399, Training loss: 1.345732, Validation loss: 1.3731, lr: 0.0000\n",
      "Epoch: 400, Training loss: 1.377955, Validation loss: 1.3705, lr: 0.0000\n",
      "Epoch: 401, Training loss: 1.348563, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 402, Training loss: 1.354677, Validation loss: 1.3543, lr: 0.0000\n",
      "Epoch: 403, Training loss: 1.361090, Validation loss: 1.3566, lr: 0.0000\n",
      "Epoch: 404, Training loss: 1.353502, Validation loss: 1.3710, lr: 0.0000\n",
      "Epoch: 405, Training loss: 1.412382, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 406, Training loss: 1.373964, Validation loss: 1.3525, lr: 0.0000\n",
      "Epoch: 407, Training loss: 1.385930, Validation loss: 1.3635, lr: 0.0000\n",
      "Epoch: 408, Training loss: 1.357465, Validation loss: 1.4836, lr: 0.0000\n",
      "Epoch: 409, Training loss: 1.345077, Validation loss: 1.3740, lr: 0.0000\n",
      "Epoch: 410, Training loss: 1.348660, Validation loss: 1.4641, lr: 0.0000\n",
      "Epoch: 411, Training loss: 1.363635, Validation loss: 1.3664, lr: 0.0000\n",
      "Epoch: 412, Training loss: 1.343979, Validation loss: 1.3488, lr: 0.0000\n",
      "Epoch: 413, Training loss: 1.321552, Validation loss: 1.4437, lr: 0.0000\n",
      "Epoch: 414, Training loss: 1.359569, Validation loss: 1.3444, lr: 0.0000\n",
      "Epoch: 415, Training loss: 1.352951, Validation loss: 1.3400, lr: 0.0000\n",
      "Epoch: 416, Training loss: 1.346852, Validation loss: 1.3786, lr: 0.0000\n",
      "Epoch: 417, Training loss: 1.366673, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 418, Training loss: 1.363236, Validation loss: 1.3615, lr: 0.0000\n",
      "Epoch: 419, Training loss: 1.343678, Validation loss: 1.3746, lr: 0.0000\n",
      "Epoch: 420, Training loss: 1.325658, Validation loss: 1.3681, lr: 0.0000\n",
      "Epoch: 421, Training loss: 1.373307, Validation loss: 1.3062, lr: 0.0000\n",
      "Epoch: 422, Training loss: 1.361415, Validation loss: 1.3276, lr: 0.0000\n",
      "Epoch: 423, Training loss: 1.365103, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 424, Training loss: 1.336986, Validation loss: 1.3260, lr: 0.0000\n",
      "Epoch: 425, Training loss: 1.412495, Validation loss: 1.3701, lr: 0.0000\n",
      "Epoch: 426, Training loss: 1.336480, Validation loss: 1.3781, lr: 0.0000\n",
      "Epoch: 427, Training loss: 1.370669, Validation loss: 1.3650, lr: 0.0000\n",
      "Epoch: 428, Training loss: 1.373640, Validation loss: 1.3880, lr: 0.0000\n",
      "Epoch: 429, Training loss: 1.377772, Validation loss: 1.3646, lr: 0.0000\n",
      "Epoch: 430, Training loss: 1.361416, Validation loss: 1.3597, lr: 0.0000\n",
      "Epoch: 431, Training loss: 1.344037, Validation loss: 1.4758, lr: 0.0000\n",
      "Epoch: 432, Training loss: 1.369365, Validation loss: 1.3662, lr: 0.0000\n",
      "Epoch: 433, Training loss: 1.349386, Validation loss: 1.3921, lr: 0.0000\n",
      "Epoch: 434, Training loss: 1.365589, Validation loss: 1.3533, lr: 0.0000\n",
      "Epoch: 435, Training loss: 1.358215, Validation loss: 1.3707, lr: 0.0000\n",
      "Epoch: 436, Training loss: 1.355781, Validation loss: 1.3701, lr: 0.0000\n",
      "Epoch: 437, Training loss: 1.353284, Validation loss: 1.5660, lr: 0.0000\n",
      "Epoch: 438, Training loss: 1.422746, Validation loss: 1.3612, lr: 0.0000\n",
      "Epoch: 439, Training loss: 1.338000, Validation loss: 1.3632, lr: 0.0000\n",
      "Epoch: 440, Training loss: 1.407497, Validation loss: 1.3439, lr: 0.0000\n",
      "Epoch: 441, Training loss: 1.356185, Validation loss: 1.4067, lr: 0.0000\n",
      "Epoch: 442, Training loss: 1.354588, Validation loss: 1.3716, lr: 0.0000\n",
      "Epoch: 443, Training loss: 1.376601, Validation loss: 1.3727, lr: 0.0000\n",
      "Epoch: 444, Training loss: 1.381945, Validation loss: 1.3243, lr: 0.0000\n",
      "Epoch: 445, Training loss: 1.382472, Validation loss: 1.3710, lr: 0.0000\n",
      "Epoch: 446, Training loss: 1.358886, Validation loss: 1.4002, lr: 0.0000\n",
      "Epoch: 447, Training loss: 1.348959, Validation loss: 1.3696, lr: 0.0000\n",
      "Epoch: 448, Training loss: 1.356763, Validation loss: 1.3512, lr: 0.0000\n",
      "Epoch: 449, Training loss: 1.374213, Validation loss: 1.3735, lr: 0.0000\n",
      "Epoch: 450, Training loss: 1.305396, Validation loss: 1.6737, lr: 0.0000\n",
      "Epoch: 451, Training loss: 1.371025, Validation loss: 1.3721, lr: 0.0000\n",
      "Epoch: 452, Training loss: 1.369560, Validation loss: 1.3850, lr: 0.0000\n",
      "Epoch: 453, Training loss: 1.378525, Validation loss: 1.3509, lr: 0.0000\n",
      "Epoch: 454, Training loss: 1.355312, Validation loss: 1.3647, lr: 0.0000\n",
      "Epoch: 455, Training loss: 1.330468, Validation loss: 1.3646, lr: 0.0000\n",
      "Epoch: 456, Training loss: 1.364431, Validation loss: 2.2620, lr: 0.0000\n",
      "Epoch: 457, Training loss: 1.364446, Validation loss: 1.3719, lr: 0.0000\n",
      "Epoch: 458, Training loss: 1.371087, Validation loss: 1.3203, lr: 0.0000\n",
      "Epoch: 459, Training loss: 1.386978, Validation loss: 1.3527, lr: 0.0000\n",
      "Epoch: 460, Training loss: 1.388894, Validation loss: 1.3569, lr: 0.0000\n",
      "Epoch: 461, Training loss: 1.384525, Validation loss: 1.3752, lr: 0.0000\n",
      "Epoch: 462, Training loss: 1.353663, Validation loss: 1.3645, lr: 0.0000\n",
      "Epoch: 463, Training loss: 1.366623, Validation loss: 1.3647, lr: 0.0000\n",
      "Epoch: 464, Training loss: 1.379834, Validation loss: 1.3510, lr: 0.0000\n",
      "Epoch: 465, Training loss: 1.350555, Validation loss: 1.3778, lr: 0.0000\n",
      "Epoch: 466, Training loss: 1.353466, Validation loss: 1.3689, lr: 0.0000\n",
      "Epoch: 467, Training loss: 1.376526, Validation loss: 1.3781, lr: 0.0000\n",
      "Epoch: 468, Training loss: 1.414872, Validation loss: 1.3721, lr: 0.0000\n",
      "Epoch: 469, Training loss: 1.362472, Validation loss: 1.3985, lr: 0.0000\n",
      "Epoch: 470, Training loss: 1.349694, Validation loss: 1.3677, lr: 0.0000\n",
      "Epoch: 471, Training loss: 1.349458, Validation loss: 1.3746, lr: 0.0000\n",
      "Epoch: 472, Training loss: 1.353403, Validation loss: 1.8064, lr: 0.0000\n",
      "Epoch: 473, Training loss: 1.368889, Validation loss: 1.3657, lr: 0.0000\n",
      "Epoch: 474, Training loss: 1.356259, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 475, Training loss: 1.389980, Validation loss: 1.3752, lr: 0.0000\n",
      "Epoch: 476, Training loss: 1.361999, Validation loss: 1.3362, lr: 0.0000\n",
      "Epoch: 477, Training loss: 1.364841, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 478, Training loss: 1.378283, Validation loss: 1.3671, lr: 0.0000\n",
      "Epoch: 479, Training loss: 1.352757, Validation loss: 1.3490, lr: 0.0000\n",
      "Epoch: 480, Training loss: 1.381249, Validation loss: 1.3696, lr: 0.0000\n",
      "Epoch: 481, Training loss: 1.392924, Validation loss: 1.3683, lr: 0.0000\n",
      "Epoch: 482, Training loss: 1.349270, Validation loss: 1.3568, lr: 0.0000\n",
      "Epoch: 483, Training loss: 1.332482, Validation loss: 1.3439, lr: 0.0000\n",
      "Epoch: 484, Training loss: 1.375358, Validation loss: 1.3811, lr: 0.0000\n",
      "Epoch: 485, Training loss: 1.340712, Validation loss: 1.3819, lr: 0.0000\n",
      "Epoch: 486, Training loss: 1.348855, Validation loss: 1.5866, lr: 0.0000\n",
      "Epoch: 487, Training loss: 1.347989, Validation loss: 1.3552, lr: 0.0000\n",
      "Epoch: 488, Training loss: 1.410172, Validation loss: 1.3785, lr: 0.0000\n",
      "Epoch: 489, Training loss: 1.338020, Validation loss: 1.3651, lr: 0.0000\n",
      "Epoch: 490, Training loss: 1.353497, Validation loss: 1.4037, lr: 0.0000\n",
      "Epoch: 491, Training loss: 1.352121, Validation loss: 1.3612, lr: 0.0000\n",
      "Epoch: 492, Training loss: 1.354134, Validation loss: 1.3762, lr: 0.0000\n",
      "Epoch: 493, Training loss: 1.359596, Validation loss: 1.6635, lr: 0.0000\n",
      "Epoch: 494, Training loss: 1.362901, Validation loss: 1.4034, lr: 0.0000\n",
      "Epoch: 495, Training loss: 1.360942, Validation loss: 1.4463, lr: 0.0000\n",
      "Epoch: 496, Training loss: 1.373289, Validation loss: 1.3371, lr: 0.0000\n",
      "Epoch: 497, Training loss: 1.364044, Validation loss: 1.3397, lr: 0.0000\n",
      "Epoch: 498, Training loss: 1.337486, Validation loss: 1.3277, lr: 0.0000\n",
      "Epoch: 499, Training loss: 1.344707, Validation loss: 1.3436, lr: 0.0000\n",
      "Epoch: 500, Training loss: 1.351211, Validation loss: 1.3249, lr: 0.0000\n",
      "Epoch: 501, Training loss: 1.377223, Validation loss: 1.3755, lr: 0.0000\n",
      "Epoch: 502, Training loss: 1.364417, Validation loss: 1.3733, lr: 0.0000\n",
      "Epoch: 503, Training loss: 1.352836, Validation loss: 1.3791, lr: 0.0000\n",
      "Epoch: 504, Training loss: 1.322349, Validation loss: 1.3630, lr: 0.0000\n",
      "Epoch: 505, Training loss: 1.320231, Validation loss: 1.3671, lr: 0.0000\n",
      "Epoch: 506, Training loss: 1.374874, Validation loss: 1.3739, lr: 0.0000\n",
      "Epoch: 507, Training loss: 1.368016, Validation loss: 1.3695, lr: 0.0000\n",
      "Epoch: 508, Training loss: 1.377454, Validation loss: 1.3723, lr: 0.0000\n",
      "Epoch: 509, Training loss: 1.360018, Validation loss: 1.5025, lr: 0.0000\n",
      "Epoch: 510, Training loss: 1.361241, Validation loss: 1.3759, lr: 0.0000\n",
      "Epoch: 511, Training loss: 1.361842, Validation loss: 1.3733, lr: 0.0000\n",
      "Epoch: 512, Training loss: 1.359438, Validation loss: 1.3711, lr: 0.0000\n",
      "Epoch: 513, Training loss: 1.370025, Validation loss: 1.3954, lr: 0.0000\n",
      "Epoch: 514, Training loss: 1.348461, Validation loss: 1.3638, lr: 0.0000\n",
      "Epoch: 515, Training loss: 1.356217, Validation loss: 1.4314, lr: 0.0000\n",
      "Epoch: 516, Training loss: 1.357663, Validation loss: 1.3619, lr: 0.0000\n",
      "Epoch: 517, Training loss: 1.361529, Validation loss: 1.3732, lr: 0.0000\n",
      "Epoch: 518, Training loss: 1.332405, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 519, Training loss: 1.354103, Validation loss: 1.3702, lr: 0.0000\n",
      "Epoch: 520, Training loss: 1.336969, Validation loss: 1.3706, lr: 0.0000\n",
      " *och: 521, Training loss: 1.342596, Validation loss: 1.2819, lr: 0.0000\n",
      "Epoch: 522, Training loss: 1.367446, Validation loss: 1.3149, lr: 0.0000\n",
      "Epoch: 523, Training loss: 1.321972, Validation loss: 1.3353, lr: 0.0000\n",
      "Epoch: 524, Training loss: 1.361989, Validation loss: 1.3931, lr: 0.0000\n",
      "Epoch: 525, Training loss: 1.361054, Validation loss: 1.3659, lr: 0.0000\n",
      "Epoch: 526, Training loss: 1.357160, Validation loss: 1.3690, lr: 0.0000\n",
      "Epoch: 527, Training loss: 1.340749, Validation loss: 1.3546, lr: 0.0000\n",
      "Epoch: 528, Training loss: 1.365218, Validation loss: 1.3686, lr: 0.0000\n",
      "Epoch: 529, Training loss: 1.358385, Validation loss: 1.3848, lr: 0.0000\n",
      "Epoch: 530, Training loss: 1.338961, Validation loss: 1.3519, lr: 0.0000\n",
      "Epoch: 531, Training loss: 1.388363, Validation loss: 1.2952, lr: 0.0000\n",
      "Epoch: 532, Training loss: 1.352542, Validation loss: 1.3771, lr: 0.0000\n",
      "Epoch: 533, Training loss: 1.340827, Validation loss: 1.3253, lr: 0.0000\n",
      "Epoch: 534, Training loss: 1.336574, Validation loss: 1.3993, lr: 0.0000\n",
      "Epoch: 535, Training loss: 1.370184, Validation loss: 14.0287, lr: 0.0000\n",
      "Epoch: 536, Training loss: 1.347526, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 537, Training loss: 1.346412, Validation loss: 1.3780, lr: 0.0000\n",
      "Epoch: 538, Training loss: 1.385312, Validation loss: 1.3616, lr: 0.0000\n",
      "Epoch: 539, Training loss: 1.354813, Validation loss: 1.3689, lr: 0.0000\n",
      "Epoch: 540, Training loss: 1.355151, Validation loss: 1.3678, lr: 0.0000\n",
      "Epoch: 541, Training loss: 1.345594, Validation loss: 1.3466, lr: 0.0000\n",
      "Epoch: 542, Training loss: 1.337292, Validation loss: 1.3740, lr: 0.0000\n",
      "Epoch: 543, Training loss: 1.337440, Validation loss: 1.3620, lr: 0.0000\n",
      "Epoch: 544, Training loss: 1.347248, Validation loss: 1.3724, lr: 0.0000\n",
      "Epoch: 545, Training loss: 1.356467, Validation loss: 1.3712, lr: 0.0000\n",
      "Epoch: 546, Training loss: 1.362093, Validation loss: 1.3733, lr: 0.0000\n",
      "Epoch: 547, Training loss: 1.371188, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 548, Training loss: 1.334084, Validation loss: 1.3617, lr: 0.0000\n",
      "Epoch: 549, Training loss: 1.385944, Validation loss: 1.3830, lr: 0.0000\n",
      "Epoch: 550, Training loss: 1.367358, Validation loss: 1.3778, lr: 0.0000\n",
      "Epoch: 551, Training loss: 1.364658, Validation loss: 1.3531, lr: 0.0000\n",
      "Epoch: 552, Training loss: 1.341508, Validation loss: 1.3548, lr: 0.0000\n",
      "Epoch: 553, Training loss: 1.364833, Validation loss: 1.3352, lr: 0.0000\n",
      "Epoch: 554, Training loss: 1.355354, Validation loss: 1.3756, lr: 0.0000\n",
      "Epoch: 555, Training loss: 1.369271, Validation loss: 1.3701, lr: 0.0000\n",
      "Epoch: 556, Training loss: 1.349016, Validation loss: 1.3279, lr: 0.0000\n",
      "Epoch: 557, Training loss: 1.366576, Validation loss: 1.3525, lr: 0.0000\n",
      "Epoch: 558, Training loss: 1.350970, Validation loss: 1.3042, lr: 0.0000\n",
      "Epoch: 559, Training loss: 1.353627, Validation loss: 1.3727, lr: 0.0000\n",
      "Epoch: 560, Training loss: 1.370229, Validation loss: 1.3628, lr: 0.0000\n",
      "Epoch: 561, Training loss: 1.346129, Validation loss: 1.3729, lr: 0.0000\n",
      "Epoch: 562, Training loss: 1.354850, Validation loss: 1.2912, lr: 0.0000\n",
      "Epoch: 563, Training loss: 1.343259, Validation loss: 2.4496, lr: 0.0000\n",
      "Epoch: 564, Training loss: 1.389833, Validation loss: 1.3753, lr: 0.0000\n",
      "Epoch: 565, Training loss: 1.335184, Validation loss: 1.3762, lr: 0.0000\n",
      "Epoch: 566, Training loss: 1.368339, Validation loss: 1.3777, lr: 0.0000\n",
      "Epoch: 567, Training loss: 1.348753, Validation loss: 1.3607, lr: 0.0000\n",
      "Epoch: 568, Training loss: 1.342193, Validation loss: 1.3657, lr: 0.0000\n",
      "Epoch: 569, Training loss: 1.379431, Validation loss: 1.3449, lr: 0.0000\n",
      "Epoch: 570, Training loss: 1.371091, Validation loss: 1.3752, lr: 0.0000\n",
      "Epoch: 571, Training loss: 1.357046, Validation loss: 1.3749, lr: 0.0000\n",
      "Epoch: 572, Training loss: 1.348239, Validation loss: 1.3802, lr: 0.0000\n",
      "Epoch: 573, Training loss: 1.349921, Validation loss: 1.3601, lr: 0.0000\n",
      "Epoch: 574, Training loss: 1.366039, Validation loss: 1.3582, lr: 0.0000\n",
      "Epoch: 575, Training loss: 1.356871, Validation loss: 1.3558, lr: 0.0000\n",
      "Epoch: 576, Training loss: 1.338236, Validation loss: 1.3782, lr: 0.0000\n",
      "Epoch: 577, Training loss: 1.368820, Validation loss: 1.3462, lr: 0.0000\n",
      "Epoch: 578, Training loss: 1.378712, Validation loss: 1.3580, lr: 0.0000\n",
      "Epoch: 579, Training loss: 1.341544, Validation loss: 1.3653, lr: 0.0000\n",
      "Epoch: 580, Training loss: 1.369602, Validation loss: 1.3736, lr: 0.0000\n",
      "Epoch: 581, Training loss: 1.364285, Validation loss: 1.3642, lr: 0.0000\n",
      "Epoch: 582, Training loss: 1.340388, Validation loss: 1.3285, lr: 0.0000\n",
      "Epoch: 583, Training loss: 1.376251, Validation loss: 1.3484, lr: 0.0000\n",
      "Epoch: 584, Training loss: 1.357408, Validation loss: 1.3749, lr: 0.0000\n",
      "Epoch: 585, Training loss: 1.357369, Validation loss: 1.3722, lr: 0.0000\n",
      "Epoch: 586, Training loss: 1.392600, Validation loss: 1.3799, lr: 0.0000\n",
      "Epoch: 587, Training loss: 1.344599, Validation loss: 1.3745, lr: 0.0000\n",
      "Epoch: 588, Training loss: 1.351579, Validation loss: 1.3647, lr: 0.0000\n",
      "Epoch: 589, Training loss: 1.349146, Validation loss: 1.3782, lr: 0.0000\n",
      "Epoch: 590, Training loss: 1.353487, Validation loss: 1.3990, lr: 0.0000\n",
      "Epoch: 591, Training loss: 1.348490, Validation loss: 1.3769, lr: 0.0000\n",
      "Epoch: 592, Training loss: 1.357330, Validation loss: 1.3803, lr: 0.0000\n",
      "Epoch: 593, Training loss: 1.340215, Validation loss: 1.3702, lr: 0.0000\n",
      "Epoch: 594, Training loss: 1.358315, Validation loss: 1.4051, lr: 0.0000\n",
      "Epoch: 595, Training loss: 1.351139, Validation loss: 1.4066, lr: 0.0000\n",
      "Epoch: 596, Training loss: 1.363535, Validation loss: 1.3823, lr: 0.0000\n",
      "Epoch: 597, Training loss: 1.345125, Validation loss: 1.3729, lr: 0.0000\n",
      "Epoch: 598, Training loss: 1.385882, Validation loss: 1.3743, lr: 0.0000\n",
      "Epoch: 599, Training loss: 1.373553, Validation loss: 1.3776, lr: 0.0000\n",
      "Epoch: 600, Training loss: 1.347153, Validation loss: 1.3543, lr: 0.0000\n",
      "Epoch: 601, Training loss: 1.375944, Validation loss: 1.8089, lr: 0.0000\n",
      "Epoch: 602, Training loss: 1.361024, Validation loss: 1.3542, lr: 0.0000\n",
      "Epoch: 603, Training loss: 1.345704, Validation loss: 1.4061, lr: 0.0000\n",
      "Epoch: 604, Training loss: 1.417628, Validation loss: 1.3611, lr: 0.0000\n",
      "Epoch: 605, Training loss: 1.359868, Validation loss: 1.3838, lr: 0.0000\n",
      "Epoch: 606, Training loss: 1.353766, Validation loss: 1.3664, lr: 0.0000\n",
      "Epoch: 607, Training loss: 1.354925, Validation loss: 1.3183, lr: 0.0000\n",
      "Epoch: 608, Training loss: 1.344208, Validation loss: 1.3622, lr: 0.0000\n",
      "Epoch: 609, Training loss: 1.352960, Validation loss: 1.3335, lr: 0.0000\n",
      "Epoch: 610, Training loss: 1.388091, Validation loss: 1.3695, lr: 0.0000\n",
      "Epoch: 611, Training loss: 1.363620, Validation loss: 1.3688, lr: 0.0000\n",
      "Epoch: 612, Training loss: 1.351914, Validation loss: 1.3639, lr: 0.0000\n",
      "Epoch: 613, Training loss: 1.370321, Validation loss: 1.3724, lr: 0.0000\n",
      "Epoch: 614, Training loss: 1.358907, Validation loss: 1.3891, lr: 0.0000\n",
      "Epoch: 615, Training loss: 1.355999, Validation loss: 1.3861, lr: 0.0000\n",
      "Epoch: 616, Training loss: 1.332852, Validation loss: 1.3479, lr: 0.0000\n",
      "Epoch: 617, Training loss: 1.354421, Validation loss: 1.3715, lr: 0.0000\n",
      "Epoch: 618, Training loss: 1.439229, Validation loss: 1.3705, lr: 0.0000\n",
      "Epoch: 619, Training loss: 1.377977, Validation loss: 1.3805, lr: 0.0000\n",
      "Epoch: 620, Training loss: 1.344371, Validation loss: 1.3945, lr: 0.0000\n",
      "Epoch: 621, Training loss: 1.393534, Validation loss: 1.3664, lr: 0.0000\n",
      "Epoch: 622, Training loss: 1.356900, Validation loss: 1.3969, lr: 0.0000\n",
      "Epoch: 623, Training loss: 1.339803, Validation loss: 1.3874, lr: 0.0000\n",
      "Epoch: 624, Training loss: 1.346753, Validation loss: 1.4777, lr: 0.0000\n",
      "Epoch: 625, Training loss: 1.337206, Validation loss: 1.3856, lr: 0.0000\n",
      "Epoch: 626, Training loss: 1.333327, Validation loss: 1.7421, lr: 0.0000\n",
      "Epoch: 627, Training loss: 1.344669, Validation loss: 1.3299, lr: 0.0000\n",
      "Epoch: 628, Training loss: 1.331741, Validation loss: 1.3732, lr: 0.0000\n",
      "Epoch: 629, Training loss: 1.365074, Validation loss: 1.3735, lr: 0.0000\n",
      "Epoch: 630, Training loss: 1.372121, Validation loss: 1.3512, lr: 0.0000\n",
      "Epoch: 631, Training loss: 1.400214, Validation loss: 1.4630, lr: 0.0000\n",
      "Epoch: 632, Training loss: 1.358937, Validation loss: 1.3595, lr: 0.0000\n",
      "Epoch: 633, Training loss: 1.388402, Validation loss: 1.3243, lr: 0.0000\n",
      "Epoch: 634, Training loss: 1.361825, Validation loss: 1.3654, lr: 0.0000\n",
      "Epoch: 635, Training loss: 1.365998, Validation loss: 1.3487, lr: 0.0000\n",
      "Epoch: 636, Training loss: 1.364995, Validation loss: 1.3790, lr: 0.0000\n",
      "Epoch: 637, Training loss: 1.344716, Validation loss: 1.3565, lr: 0.0000\n",
      "Epoch: 638, Training loss: 1.346446, Validation loss: 1.3142, lr: 0.0000\n",
      "Epoch: 639, Training loss: 1.346105, Validation loss: 1.3377, lr: 0.0000\n",
      "Epoch: 640, Training loss: 1.366760, Validation loss: 1.3560, lr: 0.0000\n",
      "Epoch: 641, Training loss: 1.355834, Validation loss: 1.3880, lr: 0.0000\n",
      "Epoch: 642, Training loss: 1.363697, Validation loss: 1.3738, lr: 0.0000\n",
      "Epoch: 643, Training loss: 1.430864, Validation loss: 1.3767, lr: 0.0000\n",
      "Epoch: 644, Training loss: 1.371449, Validation loss: 1.3571, lr: 0.0000\n",
      "Epoch: 645, Training loss: 1.357256, Validation loss: 1.3699, lr: 0.0000\n",
      "Epoch: 646, Training loss: 1.351750, Validation loss: 1.3677, lr: 0.0000\n",
      "Epoch: 647, Training loss: 1.333257, Validation loss: 1.3620, lr: 0.0000\n",
      "Epoch: 648, Training loss: 1.335603, Validation loss: 1.3274, lr: 0.0000\n",
      "Epoch: 649, Training loss: 1.361897, Validation loss: 1.3623, lr: 0.0000\n",
      "Epoch: 650, Training loss: 1.404055, Validation loss: 1.3438, lr: 0.0000\n",
      "Epoch: 651, Training loss: 1.366365, Validation loss: 1.3650, lr: 0.0000\n",
      "Epoch: 652, Training loss: 1.351743, Validation loss: 1.3753, lr: 0.0000\n",
      "Epoch: 653, Training loss: 1.357210, Validation loss: 1.3898, lr: 0.0000\n",
      "Epoch: 654, Training loss: 1.364250, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 655, Training loss: 1.378009, Validation loss: 1.3827, lr: 0.0000\n",
      "Epoch: 656, Training loss: 1.393877, Validation loss: 1.3329, lr: 0.0000\n",
      "Epoch: 657, Training loss: 1.363055, Validation loss: 1.3635, lr: 0.0000\n",
      "Epoch: 658, Training loss: 1.344120, Validation loss: 1.3724, lr: 0.0000\n",
      "Epoch: 659, Training loss: 1.359350, Validation loss: 1.4366, lr: 0.0000\n",
      "Epoch: 660, Training loss: 1.362331, Validation loss: 1.3883, lr: 0.0000\n",
      "Epoch: 661, Training loss: 1.400119, Validation loss: 1.3615, lr: 0.0000\n",
      "Epoch: 662, Training loss: 1.332474, Validation loss: 1.3644, lr: 0.0000\n",
      "Epoch: 663, Training loss: 1.371557, Validation loss: 1.3373, lr: 0.0000\n",
      "Epoch: 664, Training loss: 1.353682, Validation loss: 1.3594, lr: 0.0000\n",
      "Epoch: 665, Training loss: 1.343138, Validation loss: 1.3477, lr: 0.0000\n",
      "Epoch: 666, Training loss: 1.360074, Validation loss: 1.3313, lr: 0.0000\n",
      "Epoch: 667, Training loss: 1.352788, Validation loss: 1.3222, lr: 0.0000\n",
      "Epoch: 668, Training loss: 1.349365, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 669, Training loss: 1.364167, Validation loss: 1.3907, lr: 0.0000\n",
      "Epoch: 670, Training loss: 1.349943, Validation loss: 1.3762, lr: 0.0000\n",
      "Epoch: 671, Training loss: 1.354517, Validation loss: 1.3767, lr: 0.0000\n",
      "Epoch: 672, Training loss: 1.348211, Validation loss: 1.3300, lr: 0.0000\n",
      "Epoch: 673, Training loss: 1.359363, Validation loss: 1.3862, lr: 0.0000\n",
      "Epoch: 674, Training loss: 1.379808, Validation loss: 1.3692, lr: 0.0000\n",
      "Epoch: 675, Training loss: 1.353138, Validation loss: 1.4039, lr: 0.0000\n",
      "Epoch: 676, Training loss: 1.351555, Validation loss: 1.3716, lr: 0.0000\n",
      "Epoch: 677, Training loss: 1.418888, Validation loss: 1.3526, lr: 0.0000\n",
      "Epoch: 678, Training loss: 1.375905, Validation loss: 1.3732, lr: 0.0000\n",
      "Epoch: 679, Training loss: 1.348668, Validation loss: 1.4084, lr: 0.0000\n",
      "Epoch: 680, Training loss: 1.362233, Validation loss: 1.3796, lr: 0.0000\n",
      "Epoch: 681, Training loss: 1.353975, Validation loss: 1.3428, lr: 0.0000\n",
      "Epoch: 682, Training loss: 1.356403, Validation loss: 1.3732, lr: 0.0000\n",
      "Epoch: 683, Training loss: 1.353700, Validation loss: 1.3914, lr: 0.0000\n",
      "Epoch: 684, Training loss: 1.382130, Validation loss: 1.3868, lr: 0.0000\n",
      "Epoch: 685, Training loss: 1.370698, Validation loss: 1.3703, lr: 0.0000\n",
      "Epoch: 686, Training loss: 1.349287, Validation loss: 1.4064, lr: 0.0000\n",
      "Epoch: 687, Training loss: 1.368666, Validation loss: 1.3679, lr: 0.0000\n",
      "Epoch: 688, Training loss: 1.361956, Validation loss: 1.3600, lr: 0.0000\n",
      "Epoch: 689, Training loss: 1.382445, Validation loss: 1.3638, lr: 0.0000\n",
      "Epoch: 690, Training loss: 1.363618, Validation loss: 1.3656, lr: 0.0000\n",
      "Epoch: 691, Training loss: 1.385043, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 692, Training loss: 1.333072, Validation loss: 1.3614, lr: 0.0000\n",
      "Epoch: 693, Training loss: 1.373651, Validation loss: 1.3313, lr: 0.0000\n",
      "Epoch: 694, Training loss: 1.361072, Validation loss: 1.3807, lr: 0.0000\n",
      "Epoch: 695, Training loss: 1.352588, Validation loss: 1.3500, lr: 0.0000\n",
      "Epoch: 696, Training loss: 1.385595, Validation loss: 1.3800, lr: 0.0000\n",
      "Epoch: 697, Training loss: 1.349811, Validation loss: 1.3681, lr: 0.0000\n",
      "Epoch: 698, Training loss: 1.356629, Validation loss: 1.3632, lr: 0.0000\n",
      "Epoch: 699, Training loss: 1.384508, Validation loss: 1.3595, lr: 0.0000\n",
      "Epoch: 700, Training loss: 1.374651, Validation loss: 1.3990, lr: 0.0000\n",
      "Epoch: 701, Training loss: 1.371794, Validation loss: 1.3736, lr: 0.0000\n",
      "Epoch: 702, Training loss: 1.390212, Validation loss: 1.3480, lr: 0.0000\n",
      "Epoch: 703, Training loss: 1.362636, Validation loss: 1.3662, lr: 0.0000\n",
      "Epoch: 704, Training loss: 1.352123, Validation loss: 1.4001, lr: 0.0000\n",
      "Epoch: 705, Training loss: 1.389724, Validation loss: 1.3414, lr: 0.0000\n",
      "Epoch: 706, Training loss: 1.350104, Validation loss: 1.5828, lr: 0.0000\n",
      "Epoch: 707, Training loss: 1.365623, Validation loss: 1.3725, lr: 0.0000\n",
      "Epoch: 708, Training loss: 1.416375, Validation loss: 1.3906, lr: 0.0000\n",
      "Epoch: 709, Training loss: 1.369245, Validation loss: 1.3120, lr: 0.0000\n",
      " *och: 710, Training loss: 1.355559, Validation loss: 1.2692, lr: 0.0000\n",
      "Epoch: 711, Training loss: 1.372531, Validation loss: 1.3506, lr: 0.0000\n",
      "Epoch: 712, Training loss: 1.334943, Validation loss: 1.3714, lr: 0.0000\n",
      "Epoch: 713, Training loss: 1.364163, Validation loss: 1.3607, lr: 0.0000\n",
      "Epoch: 714, Training loss: 1.336025, Validation loss: 1.3588, lr: 0.0000\n",
      "Epoch: 715, Training loss: 1.365082, Validation loss: 1.3832, lr: 0.0000\n",
      "Epoch: 716, Training loss: 1.347684, Validation loss: 1.3757, lr: 0.0000\n",
      "Epoch: 717, Training loss: 1.378205, Validation loss: 1.3840, lr: 0.0000\n",
      "Epoch: 718, Training loss: 1.344667, Validation loss: 1.3604, lr: 0.0000\n",
      "Epoch: 719, Training loss: 1.347825, Validation loss: 1.3412, lr: 0.0000\n",
      "Epoch: 720, Training loss: 1.348392, Validation loss: 1.3723, lr: 0.0000\n",
      "Epoch: 721, Training loss: 1.343693, Validation loss: 1.3718, lr: 0.0000\n",
      "Epoch: 722, Training loss: 1.356255, Validation loss: 1.3738, lr: 0.0000\n",
      "Epoch: 723, Training loss: 1.365478, Validation loss: 1.3506, lr: 0.0000\n",
      "Epoch: 724, Training loss: 1.351352, Validation loss: 1.3492, lr: 0.0000\n",
      "Epoch: 725, Training loss: 1.375275, Validation loss: 1.3683, lr: 0.0000\n",
      "Epoch: 726, Training loss: 1.337316, Validation loss: 1.3676, lr: 0.0000\n",
      "Epoch: 727, Training loss: 1.362971, Validation loss: 1.3602, lr: 0.0000\n",
      "Epoch: 728, Training loss: 1.344830, Validation loss: 1.3836, lr: 0.0000\n",
      "Epoch: 729, Training loss: 1.370531, Validation loss: 1.3560, lr: 0.0000\n",
      "Epoch: 730, Training loss: 1.361654, Validation loss: 4.9150, lr: 0.0000\n",
      "Epoch: 731, Training loss: 1.390378, Validation loss: 1.3736, lr: 0.0000\n",
      "Epoch: 732, Training loss: 1.351961, Validation loss: 1.3503, lr: 0.0000\n",
      "Epoch: 733, Training loss: 1.373487, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 734, Training loss: 1.359321, Validation loss: 1.3636, lr: 0.0000\n",
      "Epoch: 735, Training loss: 1.358515, Validation loss: 1.3625, lr: 0.0000\n",
      "Epoch: 736, Training loss: 1.360019, Validation loss: 1.3691, lr: 0.0000\n",
      "Epoch: 737, Training loss: 1.369104, Validation loss: 1.3704, lr: 0.0000\n",
      "Epoch: 738, Training loss: 1.346933, Validation loss: 1.3342, lr: 0.0000\n",
      "Epoch: 739, Training loss: 1.342260, Validation loss: 1.3750, lr: 0.0000\n",
      "Epoch: 740, Training loss: 1.369528, Validation loss: 1.3368, lr: 0.0000\n",
      "Epoch: 741, Training loss: 1.356102, Validation loss: 1.3791, lr: 0.0000\n",
      "Epoch: 742, Training loss: 1.337400, Validation loss: 1.3500, lr: 0.0000\n",
      "Epoch: 743, Training loss: 1.339757, Validation loss: 1.3510, lr: 0.0000\n",
      "Epoch: 744, Training loss: 1.344177, Validation loss: 1.3611, lr: 0.0000\n",
      "Epoch: 745, Training loss: 1.353389, Validation loss: 1.4103, lr: 0.0000\n",
      "Epoch: 746, Training loss: 1.340781, Validation loss: 1.3733, lr: 0.0000\n",
      "Epoch: 747, Training loss: 1.337355, Validation loss: 1.3707, lr: 0.0000\n",
      "Epoch: 748, Training loss: 1.336298, Validation loss: 1.3567, lr: 0.0000\n",
      "Epoch: 749, Training loss: 1.375518, Validation loss: 1.3344, lr: 0.0000\n",
      "Epoch: 750, Training loss: 1.359234, Validation loss: 1.3506, lr: 0.0000\n",
      "Epoch: 751, Training loss: 1.339627, Validation loss: 1.3962, lr: 0.0000\n",
      "Epoch: 752, Training loss: 1.361407, Validation loss: 1.2904, lr: 0.0000\n",
      "Epoch: 753, Training loss: 1.357994, Validation loss: 1.3488, lr: 0.0000\n",
      "Epoch: 754, Training loss: 1.389162, Validation loss: 1.3198, lr: 0.0000\n",
      "Epoch: 755, Training loss: 1.357459, Validation loss: 1.3657, lr: 0.0000\n",
      "Epoch: 756, Training loss: 1.361022, Validation loss: 1.3724, lr: 0.0000\n",
      "Epoch: 757, Training loss: 1.377712, Validation loss: 1.3752, lr: 0.0000\n",
      "Epoch: 758, Training loss: 1.363844, Validation loss: 1.3656, lr: 0.0000\n",
      "Epoch: 759, Training loss: 1.362864, Validation loss: 1.3758, lr: 0.0000\n",
      "Epoch: 760, Training loss: 1.364798, Validation loss: 1.3760, lr: 0.0000\n",
      "Epoch: 761, Training loss: 1.355968, Validation loss: 1.3959, lr: 0.0000\n",
      "Epoch: 762, Training loss: 1.380971, Validation loss: 1.3677, lr: 0.0000\n",
      "Epoch: 763, Training loss: 1.361533, Validation loss: 1.4115, lr: 0.0000\n",
      "Epoch: 764, Training loss: 1.339184, Validation loss: 1.3782, lr: 0.0000\n",
      "Epoch: 765, Training loss: 1.378608, Validation loss: 1.3839, lr: 0.0000\n",
      "Epoch: 766, Training loss: 1.383825, Validation loss: 1.3750, lr: 0.0000\n",
      "Epoch: 767, Training loss: 1.367236, Validation loss: 1.3642, lr: 0.0000\n",
      "Epoch: 768, Training loss: 1.349431, Validation loss: 1.3813, lr: 0.0000\n",
      "Epoch: 769, Training loss: 1.374234, Validation loss: 1.3739, lr: 0.0000\n",
      "Epoch: 770, Training loss: 1.371023, Validation loss: 1.3710, lr: 0.0000\n",
      "Epoch: 771, Training loss: 1.346903, Validation loss: 1.3389, lr: 0.0000\n",
      "Epoch: 772, Training loss: 1.388300, Validation loss: 1.3763, lr: 0.0000\n",
      "Epoch: 773, Training loss: 1.390547, Validation loss: 1.3790, lr: 0.0000\n",
      "Epoch: 774, Training loss: 1.361578, Validation loss: 1.3729, lr: 0.0000\n",
      "Epoch: 775, Training loss: 1.358675, Validation loss: 1.3479, lr: 0.0000\n",
      "Epoch: 776, Training loss: 1.331832, Validation loss: 1.3771, lr: 0.0000\n",
      "Epoch: 777, Training loss: 1.351694, Validation loss: 1.3634, lr: 0.0000\n",
      "Epoch: 778, Training loss: 1.353814, Validation loss: 1.4110, lr: 0.0000\n",
      "Epoch: 779, Training loss: 1.330991, Validation loss: 1.3187, lr: 0.0000\n",
      "Epoch: 780, Training loss: 1.312905, Validation loss: 1.4167, lr: 0.0000\n",
      "Epoch: 781, Training loss: 1.334557, Validation loss: 1.3746, lr: 0.0000\n",
      "Epoch: 782, Training loss: 1.340149, Validation loss: 1.3810, lr: 0.0000\n",
      "Epoch: 783, Training loss: 1.384562, Validation loss: 1.3880, lr: 0.0000\n",
      "Epoch: 784, Training loss: 1.353666, Validation loss: 1.3753, lr: 0.0000\n",
      "Epoch: 785, Training loss: 1.362143, Validation loss: 1.3465, lr: 0.0000\n",
      "Epoch: 786, Training loss: 1.365416, Validation loss: 1.3933, lr: 0.0000\n",
      "Epoch: 787, Training loss: 1.374085, Validation loss: 1.3806, lr: 0.0000\n",
      "Epoch: 788, Training loss: 1.351464, Validation loss: 1.3633, lr: 0.0000\n",
      "Epoch: 789, Training loss: 1.359005, Validation loss: 1.3509, lr: 0.0000\n",
      "Epoch: 790, Training loss: 1.372757, Validation loss: 1.3306, lr: 0.0000\n",
      "Epoch: 791, Training loss: 1.358685, Validation loss: 1.3635, lr: 0.0000\n",
      "Epoch: 792, Training loss: 1.390141, Validation loss: 4.9299, lr: 0.0000\n",
      "Epoch: 793, Training loss: 1.350169, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 794, Training loss: 1.355862, Validation loss: 1.3596, lr: 0.0000\n",
      "Epoch: 795, Training loss: 1.389196, Validation loss: 1.4374, lr: 0.0000\n",
      "Epoch: 796, Training loss: 1.366602, Validation loss: 1.3749, lr: 0.0000\n",
      "Epoch: 797, Training loss: 1.408230, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 798, Training loss: 1.345075, Validation loss: 1.3689, lr: 0.0000\n",
      "Epoch: 799, Training loss: 1.332859, Validation loss: 1.7889, lr: 0.0000\n",
      "Epoch: 800, Training loss: 1.357728, Validation loss: 1.3667, lr: 0.0000\n",
      "Epoch: 801, Training loss: 1.366147, Validation loss: 1.3541, lr: 0.0000\n",
      "Epoch: 802, Training loss: 1.366786, Validation loss: 1.3526, lr: 0.0000\n",
      "Epoch: 803, Training loss: 1.358704, Validation loss: 1.3691, lr: 0.0000\n",
      "Epoch: 804, Training loss: 1.386615, Validation loss: 1.3698, lr: 0.0000\n",
      "Epoch: 805, Training loss: 1.350863, Validation loss: 1.4380, lr: 0.0000\n",
      "Epoch: 806, Training loss: 1.379507, Validation loss: 1.3768, lr: 0.0000\n",
      "Epoch: 807, Training loss: 1.360471, Validation loss: 1.3146, lr: 0.0000\n",
      "Epoch: 808, Training loss: 1.338443, Validation loss: 1.4058, lr: 0.0000\n",
      "Epoch: 809, Training loss: 1.378736, Validation loss: 1.3712, lr: 0.0000\n",
      "Epoch: 810, Training loss: 1.365753, Validation loss: 1.3605, lr: 0.0000\n",
      "Epoch: 811, Training loss: 1.364629, Validation loss: 1.4731, lr: 0.0000\n",
      "Epoch: 812, Training loss: 1.370021, Validation loss: 1.5169, lr: 0.0000\n",
      "Epoch: 813, Training loss: 1.357583, Validation loss: 1.3325, lr: 0.0000\n",
      "Epoch: 814, Training loss: 1.351911, Validation loss: 1.3970, lr: 0.0000\n",
      "Epoch: 815, Training loss: 1.376414, Validation loss: 1.3305, lr: 0.0000\n",
      "Epoch: 816, Training loss: 1.386229, Validation loss: 1.3627, lr: 0.0000\n",
      "Epoch: 817, Training loss: 1.333544, Validation loss: 1.3633, lr: 0.0000\n",
      "Epoch: 818, Training loss: 1.379567, Validation loss: 1.3692, lr: 0.0000\n",
      "Epoch: 819, Training loss: 1.340977, Validation loss: 1.3099, lr: 0.0000\n",
      "Epoch: 820, Training loss: 1.403684, Validation loss: 1.3592, lr: 0.0000\n",
      "Epoch: 821, Training loss: 1.380246, Validation loss: 1.3715, lr: 0.0000\n",
      "Epoch: 822, Training loss: 1.356150, Validation loss: 1.3538, lr: 0.0000\n",
      "Epoch: 823, Training loss: 1.362508, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 824, Training loss: 1.372291, Validation loss: 1.3500, lr: 0.0000\n",
      "Epoch: 825, Training loss: 1.352035, Validation loss: 1.3590, lr: 0.0000\n",
      "Epoch: 826, Training loss: 1.339910, Validation loss: 1.3607, lr: 0.0000\n",
      "Epoch: 827, Training loss: 1.358889, Validation loss: 1.2918, lr: 0.0000\n",
      "Epoch: 828, Training loss: 1.360987, Validation loss: 1.3380, lr: 0.0000\n",
      "Epoch: 829, Training loss: 1.344062, Validation loss: 1.3613, lr: 0.0000\n",
      "Epoch: 830, Training loss: 1.360931, Validation loss: 1.3763, lr: 0.0000\n",
      "Epoch: 831, Training loss: 1.316837, Validation loss: 1.3828, lr: 0.0000\n",
      "Epoch: 832, Training loss: 1.349009, Validation loss: 1.3729, lr: 0.0000\n",
      "Epoch: 833, Training loss: 1.360964, Validation loss: 1.3668, lr: 0.0000\n",
      "Epoch: 834, Training loss: 1.332298, Validation loss: 1.3744, lr: 0.0000\n",
      "Epoch: 835, Training loss: 1.339429, Validation loss: 1.3760, lr: 0.0000\n",
      "Epoch: 836, Training loss: 1.371407, Validation loss: 1.3751, lr: 0.0000\n",
      "Epoch: 837, Training loss: 1.404982, Validation loss: 1.3653, lr: 0.0000\n",
      "Epoch: 838, Training loss: 1.358065, Validation loss: 1.3272, lr: 0.0000\n",
      "Epoch: 839, Training loss: 1.350268, Validation loss: 1.3590, lr: 0.0000\n",
      "Epoch: 840, Training loss: 1.367283, Validation loss: 1.3540, lr: 0.0000\n",
      "Epoch: 841, Training loss: 1.383615, Validation loss: 1.3946, lr: 0.0000\n",
      "Epoch: 842, Training loss: 1.375772, Validation loss: 1.3322, lr: 0.0000\n",
      "Epoch: 843, Training loss: 1.314471, Validation loss: 1.3771, lr: 0.0000\n",
      "Epoch: 844, Training loss: 1.345206, Validation loss: 1.3742, lr: 0.0000\n",
      "Epoch: 845, Training loss: 1.347090, Validation loss: 1.3362, lr: 0.0000\n",
      "Epoch: 846, Training loss: 1.358220, Validation loss: 1.3690, lr: 0.0000\n",
      "Epoch: 847, Training loss: 1.394118, Validation loss: 1.3826, lr: 0.0000\n",
      "Epoch: 848, Training loss: 1.319844, Validation loss: 1.3450, lr: 0.0000\n",
      "Epoch: 849, Training loss: 1.355571, Validation loss: 1.3801, lr: 0.0000\n",
      "Epoch: 850, Training loss: 1.348391, Validation loss: 1.3277, lr: 0.0000\n",
      "Epoch: 851, Training loss: 1.353810, Validation loss: 1.3903, lr: 0.0000\n",
      "Epoch: 852, Training loss: 1.355041, Validation loss: 1.4189, lr: 0.0000\n",
      "Epoch: 853, Training loss: 1.368896, Validation loss: 1.3701, lr: 0.0000\n",
      "Epoch: 854, Training loss: 1.369861, Validation loss: 1.3743, lr: 0.0000\n",
      "Epoch: 855, Training loss: 1.345807, Validation loss: 1.3802, lr: 0.0000\n",
      "Epoch: 856, Training loss: 1.326706, Validation loss: 1.3526, lr: 0.0000\n",
      "Epoch: 857, Training loss: 1.344606, Validation loss: 1.3662, lr: 0.0000\n",
      "Epoch: 858, Training loss: 1.360828, Validation loss: 1.3393, lr: 0.0000\n",
      "Epoch: 859, Training loss: 1.364583, Validation loss: 1.3729, lr: 0.0000\n",
      "Epoch: 860, Training loss: 1.341186, Validation loss: 1.3793, lr: 0.0000\n",
      "Epoch: 861, Training loss: 1.382641, Validation loss: 1.3756, lr: 0.0000\n",
      "Epoch: 862, Training loss: 1.328357, Validation loss: 1.3672, lr: 0.0000\n",
      "Epoch: 863, Training loss: 1.359043, Validation loss: 1.3579, lr: 0.0000\n",
      "Epoch: 864, Training loss: 1.363267, Validation loss: 1.3618, lr: 0.0000\n",
      "Epoch: 865, Training loss: 1.366863, Validation loss: 1.3765, lr: 0.0000\n",
      "Epoch: 866, Training loss: 1.361684, Validation loss: 1.3731, lr: 0.0000\n",
      "Epoch: 867, Training loss: 1.370700, Validation loss: 1.3824, lr: 0.0000\n",
      "Epoch: 868, Training loss: 1.352905, Validation loss: 1.3707, lr: 0.0000\n",
      "Epoch: 869, Training loss: 1.366501, Validation loss: 1.3778, lr: 0.0000\n",
      "Epoch: 870, Training loss: 1.338457, Validation loss: 1.3295, lr: 0.0000\n",
      "Epoch: 871, Training loss: 1.363277, Validation loss: 1.3659, lr: 0.0000\n",
      "Epoch: 872, Training loss: 1.337263, Validation loss: 1.3733, lr: 0.0000\n",
      "Epoch: 873, Training loss: 1.346301, Validation loss: 1.4605, lr: 0.0000\n",
      "Epoch: 874, Training loss: 1.362241, Validation loss: 1.3649, lr: 0.0000\n",
      "Epoch: 875, Training loss: 1.371925, Validation loss: 1.3737, lr: 0.0000\n",
      "Epoch: 876, Training loss: 1.376743, Validation loss: 1.3526, lr: 0.0000\n",
      "Epoch: 877, Training loss: 1.400936, Validation loss: 1.3703, lr: 0.0000\n",
      "Epoch: 878, Training loss: 1.340690, Validation loss: 1.3354, lr: 0.0000\n",
      "Epoch: 879, Training loss: 1.336822, Validation loss: 1.3775, lr: 0.0000\n",
      "Epoch: 880, Training loss: 1.357901, Validation loss: 1.3179, lr: 0.0000\n",
      "Epoch: 881, Training loss: 1.371328, Validation loss: 1.3724, lr: 0.0000\n",
      "Epoch: 882, Training loss: 1.350331, Validation loss: 1.3734, lr: 0.0000\n",
      "Epoch: 883, Training loss: 1.353220, Validation loss: 1.3923, lr: 0.0000\n",
      "Epoch: 884, Training loss: 1.375203, Validation loss: 1.3779, lr: 0.0000\n",
      "Epoch: 885, Training loss: 1.329077, Validation loss: 1.3580, lr: 0.0000\n",
      "Epoch: 886, Training loss: 1.370350, Validation loss: 1.3864, lr: 0.0000\n",
      "Epoch: 887, Training loss: 1.360434, Validation loss: 1.3309, lr: 0.0000\n",
      "Epoch: 888, Training loss: 1.366351, Validation loss: 1.3680, lr: 0.0000\n",
      "Epoch: 889, Training loss: 1.426972, Validation loss: 1.3700, lr: 0.0000\n",
      "Epoch: 890, Training loss: 1.348129, Validation loss: 1.3834, lr: 0.0000\n",
      "Epoch: 891, Training loss: 1.340529, Validation loss: 1.3578, lr: 0.0000\n",
      "Epoch: 892, Training loss: 1.385726, Validation loss: 1.3640, lr: 0.0000\n",
      "Epoch: 893, Training loss: 1.362832, Validation loss: 1.3702, lr: 0.0000\n",
      "Epoch: 894, Training loss: 1.368651, Validation loss: 1.3699, lr: 0.0000\n",
      "Epoch: 895, Training loss: 1.352060, Validation loss: 1.3749, lr: 0.0000\n",
      "Epoch: 896, Training loss: 1.353737, Validation loss: 1.3833, lr: 0.0000\n",
      "Epoch: 897, Training loss: 1.382205, Validation loss: 1.3665, lr: 0.0000\n",
      "Epoch: 898, Training loss: 1.372509, Validation loss: 1.3751, lr: 0.0000\n",
      "Epoch: 899, Training loss: 1.340101, Validation loss: 1.3821, lr: 0.0000\n",
      "Epoch: 900, Training loss: 1.354318, Validation loss: 1.3878, lr: 0.0000\n",
      "Epoch: 901, Training loss: 1.346349, Validation loss: 1.3876, lr: 0.0000\n",
      "Epoch: 902, Training loss: 1.348810, Validation loss: 1.3679, lr: 0.0000\n",
      "Epoch: 903, Training loss: 1.353769, Validation loss: 1.3621, lr: 0.0000\n",
      "Epoch: 904, Training loss: 1.362594, Validation loss: 1.3690, lr: 0.0000\n",
      "Epoch: 905, Training loss: 1.374770, Validation loss: 1.5069, lr: 0.0000\n",
      "Epoch: 906, Training loss: 1.370892, Validation loss: 1.3643, lr: 0.0000\n",
      "Epoch: 907, Training loss: 1.378233, Validation loss: 1.3507, lr: 0.0000\n",
      "Epoch: 908, Training loss: 1.356259, Validation loss: 1.3753, lr: 0.0000\n",
      "Epoch: 909, Training loss: 1.364978, Validation loss: 1.3496, lr: 0.0000\n",
      "Epoch: 910, Training loss: 1.339378, Validation loss: 1.3602, lr: 0.0000\n",
      "Epoch: 911, Training loss: 1.379029, Validation loss: 1.3825, lr: 0.0000\n",
      "Epoch: 912, Training loss: 1.361914, Validation loss: 1.3760, lr: 0.0000\n",
      "Epoch: 913, Training loss: 1.365257, Validation loss: 1.3787, lr: 0.0000\n",
      "Epoch: 914, Training loss: 1.348924, Validation loss: 1.3435, lr: 0.0000\n",
      "Epoch: 915, Training loss: 1.366597, Validation loss: 1.3744, lr: 0.0000\n",
      "Epoch: 916, Training loss: 1.362960, Validation loss: 1.3689, lr: 0.0000\n",
      "Epoch: 917, Training loss: 1.351282, Validation loss: 1.3601, lr: 0.0000\n",
      "Epoch: 918, Training loss: 1.353364, Validation loss: 1.3575, lr: 0.0000\n",
      "Epoch: 919, Training loss: 1.368081, Validation loss: 1.3675, lr: 0.0000\n",
      "Epoch: 920, Training loss: 1.364700, Validation loss: 1.3674, lr: 0.0000\n",
      "Epoch: 921, Training loss: 1.356164, Validation loss: 1.3499, lr: 0.0000\n",
      "Epoch: 922, Training loss: 1.363643, Validation loss: 1.3459, lr: 0.0000\n",
      "Epoch: 923, Training loss: 1.381310, Validation loss: 1.3353, lr: 0.0000\n",
      "Epoch: 924, Training loss: 1.358447, Validation loss: 1.3683, lr: 0.0000\n",
      "Epoch: 925, Training loss: 1.399680, Validation loss: 1.4288, lr: 0.0000\n",
      "Epoch: 926, Training loss: 1.382520, Validation loss: 1.3989, lr: 0.0000\n",
      "Epoch: 927, Training loss: 1.344712, Validation loss: 1.4379, lr: 0.0000\n",
      "Epoch: 928, Training loss: 1.360662, Validation loss: 1.3713, lr: 0.0000\n",
      "Epoch: 929, Training loss: 1.408422, Validation loss: 1.3647, lr: 0.0000\n",
      "Epoch: 930, Training loss: 1.362242, Validation loss: 1.3633, lr: 0.0000\n",
      "Epoch: 931, Training loss: 1.365519, Validation loss: 1.5192, lr: 0.0000\n",
      "Epoch: 932, Training loss: 1.358327, Validation loss: 1.3815, lr: 0.0000\n",
      "Epoch: 933, Training loss: 1.355976, Validation loss: 1.3727, lr: 0.0000\n",
      "Epoch: 934, Training loss: 1.349517, Validation loss: 1.4476, lr: 0.0000\n",
      "Epoch: 935, Training loss: 1.357691, Validation loss: 1.3717, lr: 0.0000\n",
      "Epoch: 936, Training loss: 1.340225, Validation loss: 1.3668, lr: 0.0000\n",
      "Epoch: 937, Training loss: 1.343194, Validation loss: 1.3768, lr: 0.0000\n",
      "Epoch: 938, Training loss: 1.330722, Validation loss: 1.3726, lr: 0.0000\n",
      "Epoch: 939, Training loss: 1.375810, Validation loss: 1.3756, lr: 0.0000\n",
      "Epoch: 940, Training loss: 1.403369, Validation loss: 1.7925, lr: 0.0000\n",
      "Epoch: 941, Training loss: 1.357164, Validation loss: 1.3585, lr: 0.0000\n",
      "Epoch: 942, Training loss: 1.396169, Validation loss: 1.3562, lr: 0.0000\n",
      "Epoch: 943, Training loss: 1.348061, Validation loss: 1.3791, lr: 0.0000\n",
      "Epoch: 944, Training loss: 1.372453, Validation loss: 1.4729, lr: 0.0000\n",
      "Epoch: 945, Training loss: 1.361108, Validation loss: 1.3525, lr: 0.0000\n",
      "Epoch: 946, Training loss: 1.364025, Validation loss: 1.3600, lr: 0.0000\n",
      "Epoch: 947, Training loss: 1.362616, Validation loss: 1.3553, lr: 0.0000\n",
      "Epoch: 948, Training loss: 1.354959, Validation loss: 1.3676, lr: 0.0000\n",
      "Epoch: 949, Training loss: 1.353272, Validation loss: 1.3797, lr: 0.0000\n",
      "Epoch: 950, Training loss: 1.357806, Validation loss: 1.7482, lr: 0.0000\n",
      "Epoch: 951, Training loss: 1.329951, Validation loss: 1.3549, lr: 0.0000\n",
      "Epoch: 952, Training loss: 1.323430, Validation loss: 1.3580, lr: 0.0000\n",
      "Epoch: 953, Training loss: 1.352837, Validation loss: 5.9778, lr: 0.0000\n",
      "Epoch: 954, Training loss: 1.351193, Validation loss: 1.3783, lr: 0.0000\n",
      "Epoch: 955, Training loss: 1.356135, Validation loss: 1.3678, lr: 0.0000\n",
      "Epoch: 956, Training loss: 1.368780, Validation loss: 1.3616, lr: 0.0000\n",
      "Epoch: 957, Training loss: 1.346701, Validation loss: 1.3514, lr: 0.0000\n",
      "Epoch: 958, Training loss: 1.348186, Validation loss: 1.3756, lr: 0.0000\n",
      "Epoch: 959, Training loss: 1.379078, Validation loss: 1.3499, lr: 0.0000\n",
      "Epoch: 960, Training loss: 1.350245, Validation loss: 1.3568, lr: 0.0000\n",
      "Epoch: 961, Training loss: 1.350713, Validation loss: 1.3739, lr: 0.0000\n",
      "Epoch: 962, Training loss: 1.334974, Validation loss: 1.3766, lr: 0.0000\n",
      "Epoch: 963, Training loss: 1.348979, Validation loss: 1.3660, lr: 0.0000\n",
      "Epoch: 964, Training loss: 1.349581, Validation loss: 1.3359, lr: 0.0000\n",
      "Epoch: 965, Training loss: 1.348613, Validation loss: 1.8216, lr: 0.0000\n",
      "Epoch: 966, Training loss: 1.365753, Validation loss: 1.4481, lr: 0.0000\n",
      "Epoch: 967, Training loss: 1.366452, Validation loss: 1.3705, lr: 0.0000\n",
      "Epoch: 968, Training loss: 1.339405, Validation loss: 1.3675, lr: 0.0000\n",
      "Epoch: 969, Training loss: 1.328752, Validation loss: 1.3477, lr: 0.0000\n",
      "Epoch: 970, Training loss: 1.351597, Validation loss: 1.3508, lr: 0.0000\n",
      "Epoch: 971, Training loss: 1.381705, Validation loss: 1.3508, lr: 0.0000\n",
      "Epoch: 972, Training loss: 1.365772, Validation loss: 1.3506, lr: 0.0000\n",
      "Epoch: 973, Training loss: 1.348795, Validation loss: 1.3738, lr: 0.0000\n",
      "Epoch: 974, Training loss: 1.341279, Validation loss: 1.3648, lr: 0.0000\n",
      "Epoch: 975, Training loss: 1.361718, Validation loss: 1.3326, lr: 0.0000\n",
      "Epoch: 976, Training loss: 1.342962, Validation loss: 1.3757, lr: 0.0000\n",
      "Epoch: 977, Training loss: 1.348404, Validation loss: 1.3676, lr: 0.0000\n",
      "Epoch: 978, Training loss: 1.368461, Validation loss: 1.3571, lr: 0.0000\n",
      "Epoch: 979, Training loss: 1.371989, Validation loss: 1.3784, lr: 0.0000\n",
      "Epoch: 980, Training loss: 1.381030, Validation loss: 1.3549, lr: 0.0000\n",
      "Epoch: 981, Training loss: 1.321806, Validation loss: 1.3666, lr: 0.0000\n",
      "Epoch: 982, Training loss: 1.371109, Validation loss: 1.3886, lr: 0.0000\n",
      "Epoch: 983, Training loss: 1.364562, Validation loss: 1.3292, lr: 0.0000\n",
      "Epoch: 984, Training loss: 1.397220, Validation loss: 1.3671, lr: 0.0000\n",
      "Epoch: 985, Training loss: 1.408508, Validation loss: 1.3412, lr: 0.0000\n",
      "Epoch: 986, Training loss: 1.334253, Validation loss: 1.4350, lr: 0.0000\n",
      "Epoch: 987, Training loss: 1.371168, Validation loss: 1.3283, lr: 0.0000\n",
      "Epoch: 988, Training loss: 1.344644, Validation loss: 1.3167, lr: 0.0000\n",
      "Epoch: 989, Training loss: 1.349114, Validation loss: 1.3195, lr: 0.0000\n",
      "Epoch: 990, Training loss: 1.356425, Validation loss: 1.3461, lr: 0.0000\n",
      "Epoch: 991, Training loss: 1.332425, Validation loss: 1.3648, lr: 0.0000\n",
      "Epoch: 992, Training loss: 1.364680, Validation loss: 1.5604, lr: 0.0000\n",
      "Epoch: 993, Training loss: 1.412866, Validation loss: 1.3437, lr: 0.0000\n",
      "Epoch: 994, Training loss: 1.359762, Validation loss: 1.3602, lr: 0.0000\n",
      "Epoch: 995, Training loss: 1.387318, Validation loss: 1.3503, lr: 0.0000\n",
      "Epoch: 996, Training loss: 1.341901, Validation loss: 1.3696, lr: 0.0000\n",
      "Epoch: 997, Training loss: 1.353894, Validation loss: 1.3672, lr: 0.0000\n",
      "Epoch: 998, Training loss: 1.352597, Validation loss: 1.3643, lr: 0.0000\n",
      "Epoch: 999, Training loss: 1.353127, Validation loss: 1.3527, lr: 0.0000\n",
      "Final test loss: 1.3957\n",
      "Finished!\n"
     ]
    }
   ],
   "source": [
    "run run_sim.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238165a4-4c11-4076-ae6d-b1833074480a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9a24e0-faa5-49aa-be02-c9b2f5f12a14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873da835-eeac-420b-9690-0501e1a598b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
